{
  "best_global_step": 170000,
  "best_metric": 0.15275871753692627,
  "best_model_checkpoint": "D:/models2\\checkpoint-170000",
  "epoch": 5.144454104441141,
  "eval_steps": 10000,
  "global_step": 250000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 8.577570724751116e-05,
      "grad_norm": 3.954888105392456,
      "learning_rate": 3e-05,
      "loss": 0.2735,
      "step": 4
    },
    {
      "epoch": 0.00017155141449502233,
      "grad_norm": 2.5904877185821533,
      "learning_rate": 2.999914223832908e-05,
      "loss": 0.3872,
      "step": 8
    },
    {
      "epoch": 0.0002573271217425335,
      "grad_norm": 3.031928777694702,
      "learning_rate": 2.9998284476658162e-05,
      "loss": 0.2882,
      "step": 12
    },
    {
      "epoch": 0.00034310282899004466,
      "grad_norm": 2.6636123657226562,
      "learning_rate": 2.9997426714987243e-05,
      "loss": 0.217,
      "step": 16
    },
    {
      "epoch": 0.0004288785362375558,
      "grad_norm": 2.4248664379119873,
      "learning_rate": 2.999656895331632e-05,
      "loss": 0.2519,
      "step": 20
    },
    {
      "epoch": 0.000514654243485067,
      "grad_norm": 3.136092185974121,
      "learning_rate": 2.9995711191645404e-05,
      "loss": 0.1971,
      "step": 24
    },
    {
      "epoch": 0.0006004299507325781,
      "grad_norm": 2.8000826835632324,
      "learning_rate": 2.999485342997448e-05,
      "loss": 0.2361,
      "step": 28
    },
    {
      "epoch": 0.0006862056579800893,
      "grad_norm": 2.1062467098236084,
      "learning_rate": 2.999399566830356e-05,
      "loss": 0.2318,
      "step": 32
    },
    {
      "epoch": 0.0007719813652276005,
      "grad_norm": 3.01133394241333,
      "learning_rate": 2.9993137906632642e-05,
      "loss": 0.2502,
      "step": 36
    },
    {
      "epoch": 0.0008577570724751116,
      "grad_norm": 2.2916059494018555,
      "learning_rate": 2.9992280144961723e-05,
      "loss": 0.2237,
      "step": 40
    },
    {
      "epoch": 0.0009435327797226228,
      "grad_norm": 2.921205997467041,
      "learning_rate": 2.9991422383290803e-05,
      "loss": 0.3063,
      "step": 44
    },
    {
      "epoch": 0.001029308486970134,
      "grad_norm": 3.074824094772339,
      "learning_rate": 2.9990564621619884e-05,
      "loss": 0.2621,
      "step": 48
    },
    {
      "epoch": 0.0011150841942176451,
      "grad_norm": 3.240389823913574,
      "learning_rate": 2.9989706859948965e-05,
      "loss": 0.2686,
      "step": 52
    },
    {
      "epoch": 0.0012008599014651563,
      "grad_norm": 4.598827362060547,
      "learning_rate": 2.9988849098278045e-05,
      "loss": 0.19,
      "step": 56
    },
    {
      "epoch": 0.0012866356087126675,
      "grad_norm": 3.2059485912323,
      "learning_rate": 2.9987991336607126e-05,
      "loss": 0.2564,
      "step": 60
    },
    {
      "epoch": 0.0013724113159601786,
      "grad_norm": 2.1125919818878174,
      "learning_rate": 2.9987133574936203e-05,
      "loss": 0.221,
      "step": 64
    },
    {
      "epoch": 0.0014581870232076898,
      "grad_norm": 4.070745944976807,
      "learning_rate": 2.9986275813265287e-05,
      "loss": 0.302,
      "step": 68
    },
    {
      "epoch": 0.001543962730455201,
      "grad_norm": NaN,
      "learning_rate": 2.9985418051594364e-05,
      "loss": 0.2783,
      "step": 72
    },
    {
      "epoch": 0.0016297384377027121,
      "grad_norm": 2.282001256942749,
      "learning_rate": 2.9984774730341176e-05,
      "loss": 0.2179,
      "step": 76
    },
    {
      "epoch": 0.0017155141449502233,
      "grad_norm": 1.652780532836914,
      "learning_rate": 2.9983916968670253e-05,
      "loss": 0.1797,
      "step": 80
    },
    {
      "epoch": 0.0018012898521977344,
      "grad_norm": 4.296121120452881,
      "learning_rate": 2.9983059206999337e-05,
      "loss": 0.2544,
      "step": 84
    },
    {
      "epoch": 0.0018870655594452456,
      "grad_norm": 5.41752815246582,
      "learning_rate": 2.9982201445328417e-05,
      "loss": 0.2631,
      "step": 88
    },
    {
      "epoch": 0.0019728412666927568,
      "grad_norm": 2.455951690673828,
      "learning_rate": 2.9981343683657495e-05,
      "loss": 0.2006,
      "step": 92
    },
    {
      "epoch": 0.002058616973940268,
      "grad_norm": 2.3459506034851074,
      "learning_rate": 2.998048592198658e-05,
      "loss": 0.2458,
      "step": 96
    },
    {
      "epoch": 0.002144392681187779,
      "grad_norm": 3.1983802318573,
      "learning_rate": 2.9979628160315656e-05,
      "loss": 0.1251,
      "step": 100
    },
    {
      "epoch": 0.0022301683884352903,
      "grad_norm": 2.8879518508911133,
      "learning_rate": 2.9978770398644736e-05,
      "loss": 0.2656,
      "step": 104
    },
    {
      "epoch": 0.0023159440956828014,
      "grad_norm": 3.3351290225982666,
      "learning_rate": 2.9977912636973817e-05,
      "loss": 0.2121,
      "step": 108
    },
    {
      "epoch": 0.0024017198029303126,
      "grad_norm": 5.486785888671875,
      "learning_rate": 2.9977054875302898e-05,
      "loss": 0.2702,
      "step": 112
    },
    {
      "epoch": 0.0024874955101778238,
      "grad_norm": 2.7526919841766357,
      "learning_rate": 2.997619711363198e-05,
      "loss": 0.2234,
      "step": 116
    },
    {
      "epoch": 0.002573271217425335,
      "grad_norm": 4.690083026885986,
      "learning_rate": 2.997533935196106e-05,
      "loss": 0.211,
      "step": 120
    },
    {
      "epoch": 0.002659046924672846,
      "grad_norm": 7.473578453063965,
      "learning_rate": 2.9974481590290136e-05,
      "loss": 0.3153,
      "step": 124
    },
    {
      "epoch": 0.0027448226319203572,
      "grad_norm": 3.0330417156219482,
      "learning_rate": 2.997362382861922e-05,
      "loss": 0.2503,
      "step": 128
    },
    {
      "epoch": 0.0028305983391678684,
      "grad_norm": 6.502880096435547,
      "learning_rate": 2.99727660669483e-05,
      "loss": 0.2329,
      "step": 132
    },
    {
      "epoch": 0.0029163740464153796,
      "grad_norm": 5.359391212463379,
      "learning_rate": 2.9971908305277378e-05,
      "loss": 0.4148,
      "step": 136
    },
    {
      "epoch": 0.0030021497536628907,
      "grad_norm": 5.662907123565674,
      "learning_rate": 2.9971050543606462e-05,
      "loss": 0.2089,
      "step": 140
    },
    {
      "epoch": 0.003087925460910402,
      "grad_norm": 4.245725631713867,
      "learning_rate": 2.997019278193554e-05,
      "loss": 0.3097,
      "step": 144
    },
    {
      "epoch": 0.003173701168157913,
      "grad_norm": 1.9056662321090698,
      "learning_rate": 2.996933502026462e-05,
      "loss": 0.1603,
      "step": 148
    },
    {
      "epoch": 0.0032594768754054242,
      "grad_norm": 2.2214925289154053,
      "learning_rate": 2.99684772585937e-05,
      "loss": 0.1758,
      "step": 152
    },
    {
      "epoch": 0.0033452525826529354,
      "grad_norm": 3.1542201042175293,
      "learning_rate": 2.996761949692278e-05,
      "loss": 0.1868,
      "step": 156
    },
    {
      "epoch": 0.0034310282899004466,
      "grad_norm": 2.649697780609131,
      "learning_rate": 2.9966761735251858e-05,
      "loss": 0.2037,
      "step": 160
    },
    {
      "epoch": 0.0035168039971479577,
      "grad_norm": 2.6838631629943848,
      "learning_rate": 2.9965903973580942e-05,
      "loss": 0.2157,
      "step": 164
    },
    {
      "epoch": 0.003602579704395469,
      "grad_norm": 2.7715330123901367,
      "learning_rate": 2.996504621191002e-05,
      "loss": 0.2132,
      "step": 168
    },
    {
      "epoch": 0.00368835541164298,
      "grad_norm": 3.6204781532287598,
      "learning_rate": 2.99641884502391e-05,
      "loss": 0.2596,
      "step": 172
    },
    {
      "epoch": 0.003774131118890491,
      "grad_norm": 3.5612871646881104,
      "learning_rate": 2.9963330688568184e-05,
      "loss": 0.239,
      "step": 176
    },
    {
      "epoch": 0.0038599068261380024,
      "grad_norm": 4.6061601638793945,
      "learning_rate": 2.996247292689726e-05,
      "loss": 0.1861,
      "step": 180
    },
    {
      "epoch": 0.0039456825333855135,
      "grad_norm": 2.6989245414733887,
      "learning_rate": 2.9961615165226345e-05,
      "loss": 0.1942,
      "step": 184
    },
    {
      "epoch": 0.004031458240633025,
      "grad_norm": 2.593848705291748,
      "learning_rate": 2.9960757403555422e-05,
      "loss": 0.1787,
      "step": 188
    },
    {
      "epoch": 0.004117233947880536,
      "grad_norm": 3.445256233215332,
      "learning_rate": 2.9959899641884503e-05,
      "loss": 0.1731,
      "step": 192
    },
    {
      "epoch": 0.004203009655128047,
      "grad_norm": 5.566220283508301,
      "learning_rate": 2.9959041880213584e-05,
      "loss": 0.2174,
      "step": 196
    },
    {
      "epoch": 0.004288785362375558,
      "grad_norm": 4.840257167816162,
      "learning_rate": 2.9958184118542664e-05,
      "loss": 0.2525,
      "step": 200
    },
    {
      "epoch": 0.004374561069623069,
      "grad_norm": 2.525571346282959,
      "learning_rate": 2.995732635687174e-05,
      "loss": 0.3196,
      "step": 204
    },
    {
      "epoch": 0.0044603367768705805,
      "grad_norm": 3.926262855529785,
      "learning_rate": 2.9956468595200826e-05,
      "loss": 0.196,
      "step": 208
    },
    {
      "epoch": 0.004546112484118092,
      "grad_norm": 7.121889114379883,
      "learning_rate": 2.9955610833529903e-05,
      "loss": 0.3933,
      "step": 212
    },
    {
      "epoch": 0.004631888191365603,
      "grad_norm": 5.02571964263916,
      "learning_rate": 2.9954753071858983e-05,
      "loss": 0.1862,
      "step": 216
    },
    {
      "epoch": 0.004717663898613114,
      "grad_norm": 3.146577835083008,
      "learning_rate": 2.9953895310188067e-05,
      "loss": 0.2338,
      "step": 220
    },
    {
      "epoch": 0.004803439605860625,
      "grad_norm": 2.47592830657959,
      "learning_rate": 2.9953037548517145e-05,
      "loss": 0.2892,
      "step": 224
    },
    {
      "epoch": 0.004889215313108136,
      "grad_norm": 6.067681312561035,
      "learning_rate": 2.9952179786846225e-05,
      "loss": 0.2295,
      "step": 228
    },
    {
      "epoch": 0.0049749910203556475,
      "grad_norm": 3.0263538360595703,
      "learning_rate": 2.9951322025175306e-05,
      "loss": 0.2659,
      "step": 232
    },
    {
      "epoch": 0.005060766727603159,
      "grad_norm": 3.3760480880737305,
      "learning_rate": 2.9950464263504386e-05,
      "loss": 0.2393,
      "step": 236
    },
    {
      "epoch": 0.00514654243485067,
      "grad_norm": 1.739310383796692,
      "learning_rate": 2.9949606501833464e-05,
      "loss": 0.1653,
      "step": 240
    },
    {
      "epoch": 0.005232318142098181,
      "grad_norm": 3.501967191696167,
      "learning_rate": 2.9948748740162548e-05,
      "loss": 0.2951,
      "step": 244
    },
    {
      "epoch": 0.005318093849345692,
      "grad_norm": 6.086637496948242,
      "learning_rate": 2.9947890978491625e-05,
      "loss": 0.2315,
      "step": 248
    },
    {
      "epoch": 0.005403869556593203,
      "grad_norm": 3.7362101078033447,
      "learning_rate": 2.994703321682071e-05,
      "loss": 0.2586,
      "step": 252
    },
    {
      "epoch": 0.0054896452638407145,
      "grad_norm": 5.255030155181885,
      "learning_rate": 2.994617545514979e-05,
      "loss": 0.1971,
      "step": 256
    },
    {
      "epoch": 0.005575420971088226,
      "grad_norm": 3.7960891723632812,
      "learning_rate": 2.9945317693478867e-05,
      "loss": 0.2101,
      "step": 260
    },
    {
      "epoch": 0.005661196678335737,
      "grad_norm": 3.8809869289398193,
      "learning_rate": 2.994445993180795e-05,
      "loss": 0.1272,
      "step": 264
    },
    {
      "epoch": 0.005746972385583248,
      "grad_norm": 5.982343673706055,
      "learning_rate": 2.9943602170137028e-05,
      "loss": 0.3513,
      "step": 268
    },
    {
      "epoch": 0.005832748092830759,
      "grad_norm": 2.3097739219665527,
      "learning_rate": 2.994274440846611e-05,
      "loss": 0.2192,
      "step": 272
    },
    {
      "epoch": 0.00591852380007827,
      "grad_norm": 3.7955944538116455,
      "learning_rate": 2.994188664679519e-05,
      "loss": 0.2007,
      "step": 276
    },
    {
      "epoch": 0.0060042995073257815,
      "grad_norm": 4.323775291442871,
      "learning_rate": 2.994102888512427e-05,
      "loss": 0.3038,
      "step": 280
    },
    {
      "epoch": 0.006090075214573293,
      "grad_norm": 3.2726829051971436,
      "learning_rate": 2.9940171123453347e-05,
      "loss": 0.2874,
      "step": 284
    },
    {
      "epoch": 0.006175850921820804,
      "grad_norm": 4.080115795135498,
      "learning_rate": 2.993931336178243e-05,
      "loss": 0.1927,
      "step": 288
    },
    {
      "epoch": 0.006261626629068315,
      "grad_norm": 4.0823259353637695,
      "learning_rate": 2.9938455600111508e-05,
      "loss": 0.2217,
      "step": 292
    },
    {
      "epoch": 0.006347402336315826,
      "grad_norm": 2.5520198345184326,
      "learning_rate": 2.993759783844059e-05,
      "loss": 0.2253,
      "step": 296
    },
    {
      "epoch": 0.006433178043563337,
      "grad_norm": 2.4256062507629395,
      "learning_rate": 2.9936740076769673e-05,
      "loss": 0.1638,
      "step": 300
    },
    {
      "epoch": 0.0065189537508108485,
      "grad_norm": 4.478695392608643,
      "learning_rate": 2.993588231509875e-05,
      "loss": 0.26,
      "step": 304
    },
    {
      "epoch": 0.00660472945805836,
      "grad_norm": 7.348137855529785,
      "learning_rate": 2.993502455342783e-05,
      "loss": 0.2579,
      "step": 308
    },
    {
      "epoch": 0.006690505165305871,
      "grad_norm": 4.325891494750977,
      "learning_rate": 2.993416679175691e-05,
      "loss": 0.2317,
      "step": 312
    },
    {
      "epoch": 0.006776280872553382,
      "grad_norm": 4.517718315124512,
      "learning_rate": 2.9933309030085992e-05,
      "loss": 0.2483,
      "step": 316
    },
    {
      "epoch": 0.006862056579800893,
      "grad_norm": 3.4235427379608154,
      "learning_rate": 2.9932451268415072e-05,
      "loss": 0.2424,
      "step": 320
    },
    {
      "epoch": 0.006947832287048404,
      "grad_norm": 3.7136154174804688,
      "learning_rate": 2.9931593506744153e-05,
      "loss": 0.2679,
      "step": 324
    },
    {
      "epoch": 0.0070336079942959154,
      "grad_norm": 2.18277907371521,
      "learning_rate": 2.993073574507323e-05,
      "loss": 0.2437,
      "step": 328
    },
    {
      "epoch": 0.007119383701543427,
      "grad_norm": 3.429201602935791,
      "learning_rate": 2.9929877983402314e-05,
      "loss": 0.2662,
      "step": 332
    },
    {
      "epoch": 0.007205159408790938,
      "grad_norm": 2.641016721725464,
      "learning_rate": 2.992902022173139e-05,
      "loss": 0.2136,
      "step": 336
    },
    {
      "epoch": 0.007290935116038449,
      "grad_norm": 3.1571695804595947,
      "learning_rate": 2.9928162460060472e-05,
      "loss": 0.2522,
      "step": 340
    },
    {
      "epoch": 0.00737671082328596,
      "grad_norm": 2.6826157569885254,
      "learning_rate": 2.9927304698389556e-05,
      "loss": 0.3786,
      "step": 344
    },
    {
      "epoch": 0.007462486530533471,
      "grad_norm": 3.0712666511535645,
      "learning_rate": 2.9926446936718633e-05,
      "loss": 0.2478,
      "step": 348
    },
    {
      "epoch": 0.007548262237780982,
      "grad_norm": 3.6248557567596436,
      "learning_rate": 2.9925589175047714e-05,
      "loss": 0.3175,
      "step": 352
    },
    {
      "epoch": 0.007634037945028494,
      "grad_norm": 5.892080783843994,
      "learning_rate": 2.9924731413376794e-05,
      "loss": 0.3005,
      "step": 356
    },
    {
      "epoch": 0.007719813652276005,
      "grad_norm": 2.559755802154541,
      "learning_rate": 2.9923873651705875e-05,
      "loss": 0.238,
      "step": 360
    },
    {
      "epoch": 0.007805589359523516,
      "grad_norm": 2.6294398307800293,
      "learning_rate": 2.9923015890034952e-05,
      "loss": 0.2366,
      "step": 364
    },
    {
      "epoch": 0.007891365066771027,
      "grad_norm": 3.1823740005493164,
      "learning_rate": 2.9922158128364036e-05,
      "loss": 0.3016,
      "step": 368
    },
    {
      "epoch": 0.007977140774018539,
      "grad_norm": 2.9215328693389893,
      "learning_rate": 2.9921300366693113e-05,
      "loss": 0.201,
      "step": 372
    },
    {
      "epoch": 0.00806291648126605,
      "grad_norm": 1.6718342304229736,
      "learning_rate": 2.9920442605022194e-05,
      "loss": 0.212,
      "step": 376
    },
    {
      "epoch": 0.008148692188513561,
      "grad_norm": 2.238074541091919,
      "learning_rate": 2.9919584843351275e-05,
      "loss": 0.2432,
      "step": 380
    },
    {
      "epoch": 0.008234467895761072,
      "grad_norm": 3.009631872177124,
      "learning_rate": 2.9918727081680355e-05,
      "loss": 0.2857,
      "step": 384
    },
    {
      "epoch": 0.008320243603008584,
      "grad_norm": 3.573655605316162,
      "learning_rate": 2.991786932000944e-05,
      "loss": 0.1709,
      "step": 388
    },
    {
      "epoch": 0.008406019310256094,
      "grad_norm": 3.0232441425323486,
      "learning_rate": 2.9917011558338517e-05,
      "loss": 0.2007,
      "step": 392
    },
    {
      "epoch": 0.008491795017503606,
      "grad_norm": 4.46522331237793,
      "learning_rate": 2.9916153796667597e-05,
      "loss": 0.1614,
      "step": 396
    },
    {
      "epoch": 0.008577570724751116,
      "grad_norm": 2.2558741569519043,
      "learning_rate": 2.9915296034996678e-05,
      "loss": 0.1788,
      "step": 400
    },
    {
      "epoch": 0.008663346431998628,
      "grad_norm": 2.8108696937561035,
      "learning_rate": 2.991443827332576e-05,
      "loss": 0.1551,
      "step": 404
    },
    {
      "epoch": 0.008749122139246139,
      "grad_norm": 4.4491143226623535,
      "learning_rate": 2.9913580511654836e-05,
      "loss": 0.2288,
      "step": 408
    },
    {
      "epoch": 0.00883489784649365,
      "grad_norm": 3.0428271293640137,
      "learning_rate": 2.991272274998392e-05,
      "loss": 0.1625,
      "step": 412
    },
    {
      "epoch": 0.008920673553741161,
      "grad_norm": 4.914645671844482,
      "learning_rate": 2.9911864988312997e-05,
      "loss": 0.1957,
      "step": 416
    },
    {
      "epoch": 0.009006449260988673,
      "grad_norm": 3.9033310413360596,
      "learning_rate": 2.9911007226642077e-05,
      "loss": 0.3571,
      "step": 420
    },
    {
      "epoch": 0.009092224968236183,
      "grad_norm": 2.085965871810913,
      "learning_rate": 2.9910149464971158e-05,
      "loss": 0.2179,
      "step": 424
    },
    {
      "epoch": 0.009178000675483695,
      "grad_norm": 3.298288583755493,
      "learning_rate": 2.990929170330024e-05,
      "loss": 0.2588,
      "step": 428
    },
    {
      "epoch": 0.009263776382731206,
      "grad_norm": 4.952208042144775,
      "learning_rate": 2.990843394162932e-05,
      "loss": 0.2198,
      "step": 432
    },
    {
      "epoch": 0.009349552089978718,
      "grad_norm": 3.4558160305023193,
      "learning_rate": 2.99075761799584e-05,
      "loss": 0.1778,
      "step": 436
    },
    {
      "epoch": 0.009435327797226228,
      "grad_norm": 2.635413408279419,
      "learning_rate": 2.990671841828748e-05,
      "loss": 0.1261,
      "step": 440
    },
    {
      "epoch": 0.00952110350447374,
      "grad_norm": 2.903665542602539,
      "learning_rate": 2.9905860656616558e-05,
      "loss": 0.2874,
      "step": 444
    },
    {
      "epoch": 0.00960687921172125,
      "grad_norm": 2.2422094345092773,
      "learning_rate": 2.990500289494564e-05,
      "loss": 0.2255,
      "step": 448
    },
    {
      "epoch": 0.009692654918968762,
      "grad_norm": 3.4233086109161377,
      "learning_rate": 2.990414513327472e-05,
      "loss": 0.175,
      "step": 452
    },
    {
      "epoch": 0.009778430626216273,
      "grad_norm": 4.932296276092529,
      "learning_rate": 2.9903287371603803e-05,
      "loss": 0.2681,
      "step": 456
    },
    {
      "epoch": 0.009864206333463785,
      "grad_norm": 3.5348832607269287,
      "learning_rate": 2.990242960993288e-05,
      "loss": 0.2103,
      "step": 460
    },
    {
      "epoch": 0.009949982040711295,
      "grad_norm": 5.470242977142334,
      "learning_rate": 2.990157184826196e-05,
      "loss": 0.3332,
      "step": 464
    },
    {
      "epoch": 0.010035757747958807,
      "grad_norm": 4.30289363861084,
      "learning_rate": 2.990071408659104e-05,
      "loss": 0.2522,
      "step": 468
    },
    {
      "epoch": 0.010121533455206317,
      "grad_norm": 4.606200218200684,
      "learning_rate": 2.9899856324920122e-05,
      "loss": 0.2396,
      "step": 472
    },
    {
      "epoch": 0.01020730916245383,
      "grad_norm": 2.6041746139526367,
      "learning_rate": 2.9898998563249203e-05,
      "loss": 0.1293,
      "step": 476
    },
    {
      "epoch": 0.01029308486970134,
      "grad_norm": 4.887721538543701,
      "learning_rate": 2.9898140801578283e-05,
      "loss": 0.2916,
      "step": 480
    },
    {
      "epoch": 0.010378860576948852,
      "grad_norm": 2.8633768558502197,
      "learning_rate": 2.9897283039907364e-05,
      "loss": 0.2044,
      "step": 484
    },
    {
      "epoch": 0.010464636284196362,
      "grad_norm": 2.416017770767212,
      "learning_rate": 2.989642527823644e-05,
      "loss": 0.191,
      "step": 488
    },
    {
      "epoch": 0.010550411991443874,
      "grad_norm": 2.2817065715789795,
      "learning_rate": 2.9895567516565525e-05,
      "loss": 0.1573,
      "step": 492
    },
    {
      "epoch": 0.010636187698691384,
      "grad_norm": 2.485379457473755,
      "learning_rate": 2.9894709754894602e-05,
      "loss": 0.2625,
      "step": 496
    },
    {
      "epoch": 0.010721963405938896,
      "grad_norm": 3.4338550567626953,
      "learning_rate": 2.9893851993223683e-05,
      "loss": 0.1973,
      "step": 500
    },
    {
      "epoch": 0.010807739113186407,
      "grad_norm": 4.5499491691589355,
      "learning_rate": 2.9892994231552763e-05,
      "loss": 0.3645,
      "step": 504
    },
    {
      "epoch": 0.010893514820433919,
      "grad_norm": 4.34797477722168,
      "learning_rate": 2.9892136469881844e-05,
      "loss": 0.2224,
      "step": 508
    },
    {
      "epoch": 0.010979290527681429,
      "grad_norm": 4.9310994148254395,
      "learning_rate": 2.989127870821092e-05,
      "loss": 0.2715,
      "step": 512
    },
    {
      "epoch": 0.011065066234928941,
      "grad_norm": 1.7527177333831787,
      "learning_rate": 2.9890420946540005e-05,
      "loss": 0.1514,
      "step": 516
    },
    {
      "epoch": 0.011150841942176451,
      "grad_norm": 1.941923975944519,
      "learning_rate": 2.9889563184869086e-05,
      "loss": 0.2276,
      "step": 520
    },
    {
      "epoch": 0.011236617649423963,
      "grad_norm": 3.0981390476226807,
      "learning_rate": 2.9888705423198166e-05,
      "loss": 0.1949,
      "step": 524
    },
    {
      "epoch": 0.011322393356671474,
      "grad_norm": 5.524079322814941,
      "learning_rate": 2.9887847661527247e-05,
      "loss": 0.1725,
      "step": 528
    },
    {
      "epoch": 0.011408169063918986,
      "grad_norm": 3.71945858001709,
      "learning_rate": 2.9886989899856324e-05,
      "loss": 0.1623,
      "step": 532
    },
    {
      "epoch": 0.011493944771166496,
      "grad_norm": 1.0317440032958984,
      "learning_rate": 2.9886132138185408e-05,
      "loss": 0.1663,
      "step": 536
    },
    {
      "epoch": 0.011579720478414008,
      "grad_norm": 5.100423812866211,
      "learning_rate": 2.9885274376514485e-05,
      "loss": 0.2069,
      "step": 540
    },
    {
      "epoch": 0.011665496185661518,
      "grad_norm": 2.6086676120758057,
      "learning_rate": 2.9884416614843566e-05,
      "loss": 0.1843,
      "step": 544
    },
    {
      "epoch": 0.01175127189290903,
      "grad_norm": 3.7169363498687744,
      "learning_rate": 2.9883558853172647e-05,
      "loss": 0.2773,
      "step": 548
    },
    {
      "epoch": 0.01183704760015654,
      "grad_norm": 5.290051460266113,
      "learning_rate": 2.9882701091501727e-05,
      "loss": 0.227,
      "step": 552
    },
    {
      "epoch": 0.011922823307404053,
      "grad_norm": 3.253232717514038,
      "learning_rate": 2.9881843329830805e-05,
      "loss": 0.2218,
      "step": 556
    },
    {
      "epoch": 0.012008599014651563,
      "grad_norm": 3.235611915588379,
      "learning_rate": 2.988098556815989e-05,
      "loss": 0.1454,
      "step": 560
    },
    {
      "epoch": 0.012094374721899075,
      "grad_norm": 4.393868446350098,
      "learning_rate": 2.988012780648897e-05,
      "loss": 0.3242,
      "step": 564
    },
    {
      "epoch": 0.012180150429146585,
      "grad_norm": 5.037245750427246,
      "learning_rate": 2.9879270044818046e-05,
      "loss": 0.2166,
      "step": 568
    },
    {
      "epoch": 0.012265926136394097,
      "grad_norm": 5.987205982208252,
      "learning_rate": 2.987841228314713e-05,
      "loss": 0.2059,
      "step": 572
    },
    {
      "epoch": 0.012351701843641608,
      "grad_norm": 6.396546363830566,
      "learning_rate": 2.9877554521476208e-05,
      "loss": 0.1883,
      "step": 576
    },
    {
      "epoch": 0.01243747755088912,
      "grad_norm": 4.439767360687256,
      "learning_rate": 2.9876696759805288e-05,
      "loss": 0.2623,
      "step": 580
    },
    {
      "epoch": 0.01252325325813663,
      "grad_norm": 2.5318944454193115,
      "learning_rate": 2.987583899813437e-05,
      "loss": 0.1947,
      "step": 584
    },
    {
      "epoch": 0.012609028965384142,
      "grad_norm": 4.30803918838501,
      "learning_rate": 2.987498123646345e-05,
      "loss": 0.2101,
      "step": 588
    },
    {
      "epoch": 0.012694804672631652,
      "grad_norm": 3.271977663040161,
      "learning_rate": 2.987412347479253e-05,
      "loss": 0.144,
      "step": 592
    },
    {
      "epoch": 0.012780580379879164,
      "grad_norm": 3.5587825775146484,
      "learning_rate": 2.987326571312161e-05,
      "loss": 0.1961,
      "step": 596
    },
    {
      "epoch": 0.012866356087126675,
      "grad_norm": 4.278343200683594,
      "learning_rate": 2.9872407951450688e-05,
      "loss": 0.1728,
      "step": 600
    },
    {
      "epoch": 0.012952131794374187,
      "grad_norm": 4.354852199554443,
      "learning_rate": 2.9871550189779772e-05,
      "loss": 0.281,
      "step": 604
    },
    {
      "epoch": 0.013037907501621697,
      "grad_norm": 4.2750935554504395,
      "learning_rate": 2.9870692428108852e-05,
      "loss": 0.1961,
      "step": 608
    },
    {
      "epoch": 0.013123683208869209,
      "grad_norm": 3.4751789569854736,
      "learning_rate": 2.986983466643793e-05,
      "loss": 0.2262,
      "step": 612
    },
    {
      "epoch": 0.01320945891611672,
      "grad_norm": 2.914769411087036,
      "learning_rate": 2.9868976904767014e-05,
      "loss": 0.1424,
      "step": 616
    },
    {
      "epoch": 0.013295234623364231,
      "grad_norm": 2.632322311401367,
      "learning_rate": 2.986811914309609e-05,
      "loss": 0.2039,
      "step": 620
    },
    {
      "epoch": 0.013381010330611742,
      "grad_norm": 4.926440715789795,
      "learning_rate": 2.986726138142517e-05,
      "loss": 0.2406,
      "step": 624
    },
    {
      "epoch": 0.013466786037859254,
      "grad_norm": 5.097370147705078,
      "learning_rate": 2.9866403619754252e-05,
      "loss": 0.383,
      "step": 628
    },
    {
      "epoch": 0.013552561745106764,
      "grad_norm": 4.2560930252075195,
      "learning_rate": 2.9865545858083333e-05,
      "loss": 0.2728,
      "step": 632
    },
    {
      "epoch": 0.013638337452354276,
      "grad_norm": 3.0535731315612793,
      "learning_rate": 2.986468809641241e-05,
      "loss": 0.2669,
      "step": 636
    },
    {
      "epoch": 0.013724113159601786,
      "grad_norm": 3.457944631576538,
      "learning_rate": 2.9863830334741494e-05,
      "loss": 0.1208,
      "step": 640
    },
    {
      "epoch": 0.013809888866849298,
      "grad_norm": 3.8883087635040283,
      "learning_rate": 2.986297257307057e-05,
      "loss": 0.2568,
      "step": 644
    },
    {
      "epoch": 0.013895664574096809,
      "grad_norm": 6.2357401847839355,
      "learning_rate": 2.9862114811399652e-05,
      "loss": 0.276,
      "step": 648
    },
    {
      "epoch": 0.01398144028134432,
      "grad_norm": 4.530465126037598,
      "learning_rate": 2.9861257049728736e-05,
      "loss": 0.2128,
      "step": 652
    },
    {
      "epoch": 0.014067215988591831,
      "grad_norm": 2.488726854324341,
      "learning_rate": 2.9860399288057813e-05,
      "loss": 0.2169,
      "step": 656
    },
    {
      "epoch": 0.014152991695839343,
      "grad_norm": 2.972689390182495,
      "learning_rate": 2.9859541526386897e-05,
      "loss": 0.2418,
      "step": 660
    },
    {
      "epoch": 0.014238767403086853,
      "grad_norm": 2.6388003826141357,
      "learning_rate": 2.9858683764715974e-05,
      "loss": 0.332,
      "step": 664
    },
    {
      "epoch": 0.014324543110334365,
      "grad_norm": 1.801596999168396,
      "learning_rate": 2.9857826003045055e-05,
      "loss": 0.1839,
      "step": 668
    },
    {
      "epoch": 0.014410318817581876,
      "grad_norm": 6.066858768463135,
      "learning_rate": 2.9856968241374135e-05,
      "loss": 0.1848,
      "step": 672
    },
    {
      "epoch": 0.014496094524829388,
      "grad_norm": 2.0204687118530273,
      "learning_rate": 2.9856110479703216e-05,
      "loss": 0.1794,
      "step": 676
    },
    {
      "epoch": 0.014581870232076898,
      "grad_norm": 3.566758632659912,
      "learning_rate": 2.9855252718032293e-05,
      "loss": 0.3301,
      "step": 680
    },
    {
      "epoch": 0.01466764593932441,
      "grad_norm": 3.3739969730377197,
      "learning_rate": 2.9854394956361377e-05,
      "loss": 0.263,
      "step": 684
    },
    {
      "epoch": 0.01475342164657192,
      "grad_norm": 3.791771650314331,
      "learning_rate": 2.9853537194690454e-05,
      "loss": 0.2716,
      "step": 688
    },
    {
      "epoch": 0.014839197353819432,
      "grad_norm": 2.2750625610351562,
      "learning_rate": 2.9852679433019535e-05,
      "loss": 0.1333,
      "step": 692
    },
    {
      "epoch": 0.014924973061066943,
      "grad_norm": 4.531888484954834,
      "learning_rate": 2.985182167134862e-05,
      "loss": 0.2768,
      "step": 696
    },
    {
      "epoch": 0.015010748768314455,
      "grad_norm": 5.272165775299072,
      "learning_rate": 2.9850963909677696e-05,
      "loss": 0.1863,
      "step": 700
    },
    {
      "epoch": 0.015096524475561965,
      "grad_norm": 5.670816421508789,
      "learning_rate": 2.9850106148006777e-05,
      "loss": 0.2781,
      "step": 704
    },
    {
      "epoch": 0.015182300182809477,
      "grad_norm": 1.6994805335998535,
      "learning_rate": 2.9849248386335857e-05,
      "loss": 0.3238,
      "step": 708
    },
    {
      "epoch": 0.015268075890056987,
      "grad_norm": 5.800942420959473,
      "learning_rate": 2.9848390624664938e-05,
      "loss": 0.2224,
      "step": 712
    },
    {
      "epoch": 0.0153538515973045,
      "grad_norm": 2.5470454692840576,
      "learning_rate": 2.9847532862994015e-05,
      "loss": 0.1549,
      "step": 716
    },
    {
      "epoch": 0.01543962730455201,
      "grad_norm": 0.9596301913261414,
      "learning_rate": 2.98466751013231e-05,
      "loss": 0.1572,
      "step": 720
    },
    {
      "epoch": 0.015525403011799522,
      "grad_norm": 3.6164724826812744,
      "learning_rate": 2.9845817339652176e-05,
      "loss": 0.2431,
      "step": 724
    },
    {
      "epoch": 0.015611178719047032,
      "grad_norm": 4.2954511642456055,
      "learning_rate": 2.984495957798126e-05,
      "loss": 0.2238,
      "step": 728
    },
    {
      "epoch": 0.015696954426294544,
      "grad_norm": 6.256984233856201,
      "learning_rate": 2.9844101816310338e-05,
      "loss": 0.37,
      "step": 732
    },
    {
      "epoch": 0.015782730133542054,
      "grad_norm": 4.198709964752197,
      "learning_rate": 2.984324405463942e-05,
      "loss": 0.2214,
      "step": 736
    },
    {
      "epoch": 0.015868505840789564,
      "grad_norm": 1.2254689931869507,
      "learning_rate": 2.9842386292968502e-05,
      "loss": 0.1958,
      "step": 740
    },
    {
      "epoch": 0.015954281548037078,
      "grad_norm": 3.5668702125549316,
      "learning_rate": 2.984152853129758e-05,
      "loss": 0.2397,
      "step": 744
    },
    {
      "epoch": 0.01604005725528459,
      "grad_norm": 2.4094157218933105,
      "learning_rate": 2.984067076962666e-05,
      "loss": 0.1972,
      "step": 748
    },
    {
      "epoch": 0.0161258329625321,
      "grad_norm": 2.4099836349487305,
      "learning_rate": 2.983981300795574e-05,
      "loss": 0.1415,
      "step": 752
    },
    {
      "epoch": 0.01621160866977961,
      "grad_norm": 3.5004611015319824,
      "learning_rate": 2.983895524628482e-05,
      "loss": 0.2699,
      "step": 756
    },
    {
      "epoch": 0.016297384377027123,
      "grad_norm": 3.7016332149505615,
      "learning_rate": 2.98380974846139e-05,
      "loss": 0.2632,
      "step": 760
    },
    {
      "epoch": 0.016383160084274633,
      "grad_norm": 2.2915287017822266,
      "learning_rate": 2.9837239722942983e-05,
      "loss": 0.207,
      "step": 764
    },
    {
      "epoch": 0.016468935791522143,
      "grad_norm": 4.537829399108887,
      "learning_rate": 2.983638196127206e-05,
      "loss": 0.2634,
      "step": 768
    },
    {
      "epoch": 0.016554711498769654,
      "grad_norm": 4.8700947761535645,
      "learning_rate": 2.983552419960114e-05,
      "loss": 0.133,
      "step": 772
    },
    {
      "epoch": 0.016640487206017168,
      "grad_norm": 1.4886544942855835,
      "learning_rate": 2.983466643793022e-05,
      "loss": 0.2339,
      "step": 776
    },
    {
      "epoch": 0.016726262913264678,
      "grad_norm": 4.514779090881348,
      "learning_rate": 2.98338086762593e-05,
      "loss": 0.1865,
      "step": 780
    },
    {
      "epoch": 0.016812038620512188,
      "grad_norm": 4.1442766189575195,
      "learning_rate": 2.9832950914588382e-05,
      "loss": 0.2846,
      "step": 784
    },
    {
      "epoch": 0.0168978143277597,
      "grad_norm": 5.327695846557617,
      "learning_rate": 2.9832093152917463e-05,
      "loss": 0.2531,
      "step": 788
    },
    {
      "epoch": 0.016983590035007212,
      "grad_norm": 4.467089653015137,
      "learning_rate": 2.9831235391246543e-05,
      "loss": 0.248,
      "step": 792
    },
    {
      "epoch": 0.017069365742254723,
      "grad_norm": 2.495051622390747,
      "learning_rate": 2.9830377629575624e-05,
      "loss": 0.3047,
      "step": 796
    },
    {
      "epoch": 0.017155141449502233,
      "grad_norm": 2.8958632946014404,
      "learning_rate": 2.9829519867904705e-05,
      "loss": 0.2953,
      "step": 800
    },
    {
      "epoch": 0.017240917156749743,
      "grad_norm": 3.692551851272583,
      "learning_rate": 2.9828662106233782e-05,
      "loss": 0.2282,
      "step": 804
    },
    {
      "epoch": 0.017326692863997257,
      "grad_norm": 3.5758702754974365,
      "learning_rate": 2.9827804344562866e-05,
      "loss": 0.2689,
      "step": 808
    },
    {
      "epoch": 0.017412468571244767,
      "grad_norm": 5.497629642486572,
      "learning_rate": 2.9826946582891943e-05,
      "loss": 0.2297,
      "step": 812
    },
    {
      "epoch": 0.017498244278492277,
      "grad_norm": 2.4715967178344727,
      "learning_rate": 2.9826088821221024e-05,
      "loss": 0.2196,
      "step": 816
    },
    {
      "epoch": 0.017584019985739788,
      "grad_norm": 2.810371160507202,
      "learning_rate": 2.9825231059550104e-05,
      "loss": 0.2582,
      "step": 820
    },
    {
      "epoch": 0.0176697956929873,
      "grad_norm": 1.4230016469955444,
      "learning_rate": 2.9824373297879185e-05,
      "loss": 0.1061,
      "step": 824
    },
    {
      "epoch": 0.017755571400234812,
      "grad_norm": 2.880039691925049,
      "learning_rate": 2.9823515536208266e-05,
      "loss": 0.1813,
      "step": 828
    },
    {
      "epoch": 0.017841347107482322,
      "grad_norm": 4.474268436431885,
      "learning_rate": 2.9822657774537346e-05,
      "loss": 0.3526,
      "step": 832
    },
    {
      "epoch": 0.017927122814729832,
      "grad_norm": 3.4455597400665283,
      "learning_rate": 2.9821800012866427e-05,
      "loss": 0.1884,
      "step": 836
    },
    {
      "epoch": 0.018012898521977346,
      "grad_norm": 2.41204571723938,
      "learning_rate": 2.9820942251195504e-05,
      "loss": 0.2273,
      "step": 840
    },
    {
      "epoch": 0.018098674229224856,
      "grad_norm": 1.7157492637634277,
      "learning_rate": 2.9820084489524588e-05,
      "loss": 0.1573,
      "step": 844
    },
    {
      "epoch": 0.018184449936472367,
      "grad_norm": 3.6037614345550537,
      "learning_rate": 2.9819226727853665e-05,
      "loss": 0.2159,
      "step": 848
    },
    {
      "epoch": 0.018270225643719877,
      "grad_norm": 3.8445606231689453,
      "learning_rate": 2.9818368966182746e-05,
      "loss": 0.1933,
      "step": 852
    },
    {
      "epoch": 0.01835600135096739,
      "grad_norm": 1.2452348470687866,
      "learning_rate": 2.9817511204511826e-05,
      "loss": 0.1675,
      "step": 856
    },
    {
      "epoch": 0.0184417770582149,
      "grad_norm": 3.9403600692749023,
      "learning_rate": 2.9816653442840907e-05,
      "loss": 0.1673,
      "step": 860
    },
    {
      "epoch": 0.01852755276546241,
      "grad_norm": 5.7322998046875,
      "learning_rate": 2.9815795681169988e-05,
      "loss": 0.2316,
      "step": 864
    },
    {
      "epoch": 0.01861332847270992,
      "grad_norm": 2.190659999847412,
      "learning_rate": 2.9814937919499068e-05,
      "loss": 0.229,
      "step": 868
    },
    {
      "epoch": 0.018699104179957435,
      "grad_norm": 4.772931098937988,
      "learning_rate": 2.981408015782815e-05,
      "loss": 0.2197,
      "step": 872
    },
    {
      "epoch": 0.018784879887204946,
      "grad_norm": 5.1635003089904785,
      "learning_rate": 2.981322239615723e-05,
      "loss": 0.3334,
      "step": 876
    },
    {
      "epoch": 0.018870655594452456,
      "grad_norm": 1.1460880041122437,
      "learning_rate": 2.981236463448631e-05,
      "loss": 0.1261,
      "step": 880
    },
    {
      "epoch": 0.018956431301699966,
      "grad_norm": 6.321724891662598,
      "learning_rate": 2.9811506872815387e-05,
      "loss": 0.3461,
      "step": 884
    },
    {
      "epoch": 0.01904220700894748,
      "grad_norm": 3.322381019592285,
      "learning_rate": 2.981064911114447e-05,
      "loss": 0.1946,
      "step": 888
    },
    {
      "epoch": 0.01912798271619499,
      "grad_norm": 2.049656867980957,
      "learning_rate": 2.980979134947355e-05,
      "loss": 0.1928,
      "step": 892
    },
    {
      "epoch": 0.0192137584234425,
      "grad_norm": 4.278249740600586,
      "learning_rate": 2.980893358780263e-05,
      "loss": 0.3129,
      "step": 896
    },
    {
      "epoch": 0.01929953413069001,
      "grad_norm": 2.0081369876861572,
      "learning_rate": 2.980807582613171e-05,
      "loss": 0.3249,
      "step": 900
    },
    {
      "epoch": 0.019385309837937525,
      "grad_norm": 5.036409378051758,
      "learning_rate": 2.980721806446079e-05,
      "loss": 0.2321,
      "step": 904
    },
    {
      "epoch": 0.019471085545185035,
      "grad_norm": 5.14351749420166,
      "learning_rate": 2.9806360302789868e-05,
      "loss": 0.3272,
      "step": 908
    },
    {
      "epoch": 0.019556861252432545,
      "grad_norm": 3.754403829574585,
      "learning_rate": 2.980550254111895e-05,
      "loss": 0.247,
      "step": 912
    },
    {
      "epoch": 0.019642636959680056,
      "grad_norm": 8.260440826416016,
      "learning_rate": 2.9804644779448032e-05,
      "loss": 0.2455,
      "step": 916
    },
    {
      "epoch": 0.01972841266692757,
      "grad_norm": 3.1944642066955566,
      "learning_rate": 2.980378701777711e-05,
      "loss": 0.2139,
      "step": 920
    },
    {
      "epoch": 0.01981418837417508,
      "grad_norm": 1.5162358283996582,
      "learning_rate": 2.9802929256106193e-05,
      "loss": 0.1985,
      "step": 924
    },
    {
      "epoch": 0.01989996408142259,
      "grad_norm": 2.2218782901763916,
      "learning_rate": 2.980207149443527e-05,
      "loss": 0.1188,
      "step": 928
    },
    {
      "epoch": 0.0199857397886701,
      "grad_norm": 3.0463998317718506,
      "learning_rate": 2.9801213732764355e-05,
      "loss": 0.2173,
      "step": 932
    },
    {
      "epoch": 0.020071515495917614,
      "grad_norm": 4.634850025177002,
      "learning_rate": 2.9800355971093432e-05,
      "loss": 0.2041,
      "step": 936
    },
    {
      "epoch": 0.020157291203165124,
      "grad_norm": 3.206193685531616,
      "learning_rate": 2.9799498209422512e-05,
      "loss": 0.1678,
      "step": 940
    },
    {
      "epoch": 0.020243066910412635,
      "grad_norm": 3.792607069015503,
      "learning_rate": 2.9798640447751593e-05,
      "loss": 0.3031,
      "step": 944
    },
    {
      "epoch": 0.020328842617660145,
      "grad_norm": 4.509095191955566,
      "learning_rate": 2.9797782686080674e-05,
      "loss": 0.2514,
      "step": 948
    },
    {
      "epoch": 0.02041461832490766,
      "grad_norm": 3.7372584342956543,
      "learning_rate": 2.979692492440975e-05,
      "loss": 0.2075,
      "step": 952
    },
    {
      "epoch": 0.02050039403215517,
      "grad_norm": 2.1336557865142822,
      "learning_rate": 2.9796067162738835e-05,
      "loss": 0.0875,
      "step": 956
    },
    {
      "epoch": 0.02058616973940268,
      "grad_norm": 2.7639429569244385,
      "learning_rate": 2.9795209401067915e-05,
      "loss": 0.2597,
      "step": 960
    },
    {
      "epoch": 0.02067194544665019,
      "grad_norm": 4.624711990356445,
      "learning_rate": 2.9794351639396993e-05,
      "loss": 0.3022,
      "step": 964
    },
    {
      "epoch": 0.020757721153897703,
      "grad_norm": 1.6427842378616333,
      "learning_rate": 2.9793493877726077e-05,
      "loss": 0.1086,
      "step": 968
    },
    {
      "epoch": 0.020843496861145214,
      "grad_norm": 3.6972482204437256,
      "learning_rate": 2.9792636116055154e-05,
      "loss": 0.4175,
      "step": 972
    },
    {
      "epoch": 0.020929272568392724,
      "grad_norm": 2.840660572052002,
      "learning_rate": 2.9791778354384234e-05,
      "loss": 0.2776,
      "step": 976
    },
    {
      "epoch": 0.021015048275640234,
      "grad_norm": 1.5276343822479248,
      "learning_rate": 2.9790920592713315e-05,
      "loss": 0.1147,
      "step": 980
    },
    {
      "epoch": 0.021100823982887748,
      "grad_norm": 4.116544723510742,
      "learning_rate": 2.9790062831042396e-05,
      "loss": 0.2319,
      "step": 984
    },
    {
      "epoch": 0.02118659969013526,
      "grad_norm": 3.0093021392822266,
      "learning_rate": 2.9789205069371476e-05,
      "loss": 0.1939,
      "step": 988
    },
    {
      "epoch": 0.02127237539738277,
      "grad_norm": 2.609806537628174,
      "learning_rate": 2.9788347307700557e-05,
      "loss": 0.257,
      "step": 992
    },
    {
      "epoch": 0.02135815110463028,
      "grad_norm": 2.6250851154327393,
      "learning_rate": 2.9787489546029634e-05,
      "loss": 0.1431,
      "step": 996
    },
    {
      "epoch": 0.021443926811877793,
      "grad_norm": 4.079848766326904,
      "learning_rate": 2.9786631784358718e-05,
      "loss": 0.256,
      "step": 1000
    },
    {
      "epoch": 0.021529702519125303,
      "grad_norm": 2.3971190452575684,
      "learning_rate": 2.97857740226878e-05,
      "loss": 0.2029,
      "step": 1004
    },
    {
      "epoch": 0.021615478226372813,
      "grad_norm": 3.521202564239502,
      "learning_rate": 2.9784916261016876e-05,
      "loss": 0.1582,
      "step": 1008
    },
    {
      "epoch": 0.021701253933620324,
      "grad_norm": 3.654325485229492,
      "learning_rate": 2.978405849934596e-05,
      "loss": 0.2056,
      "step": 1012
    },
    {
      "epoch": 0.021787029640867837,
      "grad_norm": 1.2427115440368652,
      "learning_rate": 2.9783200737675037e-05,
      "loss": 0.147,
      "step": 1016
    },
    {
      "epoch": 0.021872805348115348,
      "grad_norm": 4.0971879959106445,
      "learning_rate": 2.9782342976004118e-05,
      "loss": 0.1415,
      "step": 1020
    },
    {
      "epoch": 0.021958581055362858,
      "grad_norm": 3.9761476516723633,
      "learning_rate": 2.97814852143332e-05,
      "loss": 0.2397,
      "step": 1024
    },
    {
      "epoch": 0.02204435676261037,
      "grad_norm": 2.672197103500366,
      "learning_rate": 2.978062745266228e-05,
      "loss": 0.1433,
      "step": 1028
    },
    {
      "epoch": 0.022130132469857882,
      "grad_norm": 1.6920026540756226,
      "learning_rate": 2.9779769690991356e-05,
      "loss": 0.1257,
      "step": 1032
    },
    {
      "epoch": 0.022215908177105392,
      "grad_norm": 3.9805285930633545,
      "learning_rate": 2.977891192932044e-05,
      "loss": 0.1695,
      "step": 1036
    },
    {
      "epoch": 0.022301683884352903,
      "grad_norm": 6.351752758026123,
      "learning_rate": 2.9778054167649517e-05,
      "loss": 0.2127,
      "step": 1040
    },
    {
      "epoch": 0.022387459591600413,
      "grad_norm": 4.259994983673096,
      "learning_rate": 2.9777196405978598e-05,
      "loss": 0.15,
      "step": 1044
    },
    {
      "epoch": 0.022473235298847927,
      "grad_norm": 4.057441711425781,
      "learning_rate": 2.9776338644307682e-05,
      "loss": 0.179,
      "step": 1048
    },
    {
      "epoch": 0.022559011006095437,
      "grad_norm": 3.394214153289795,
      "learning_rate": 2.977548088263676e-05,
      "loss": 0.0978,
      "step": 1052
    },
    {
      "epoch": 0.022644786713342947,
      "grad_norm": 3.7127907276153564,
      "learning_rate": 2.977462312096584e-05,
      "loss": 0.3222,
      "step": 1056
    },
    {
      "epoch": 0.022730562420590458,
      "grad_norm": 2.282374143600464,
      "learning_rate": 2.977376535929492e-05,
      "loss": 0.1272,
      "step": 1060
    },
    {
      "epoch": 0.02281633812783797,
      "grad_norm": 3.3447353839874268,
      "learning_rate": 2.9772907597624e-05,
      "loss": 0.1801,
      "step": 1064
    },
    {
      "epoch": 0.02290211383508548,
      "grad_norm": 3.462939500808716,
      "learning_rate": 2.977204983595308e-05,
      "loss": 0.2865,
      "step": 1068
    },
    {
      "epoch": 0.022987889542332992,
      "grad_norm": 4.535017967224121,
      "learning_rate": 2.9771192074282162e-05,
      "loss": 0.1641,
      "step": 1072
    },
    {
      "epoch": 0.023073665249580502,
      "grad_norm": 3.783102512359619,
      "learning_rate": 2.977033431261124e-05,
      "loss": 0.1883,
      "step": 1076
    },
    {
      "epoch": 0.023159440956828016,
      "grad_norm": 7.3901848793029785,
      "learning_rate": 2.9769476550940323e-05,
      "loss": 0.3026,
      "step": 1080
    },
    {
      "epoch": 0.023245216664075526,
      "grad_norm": 3.1551620960235596,
      "learning_rate": 2.97686187892694e-05,
      "loss": 0.1621,
      "step": 1084
    },
    {
      "epoch": 0.023330992371323037,
      "grad_norm": 3.3111822605133057,
      "learning_rate": 2.976776102759848e-05,
      "loss": 0.2071,
      "step": 1088
    },
    {
      "epoch": 0.023416768078570547,
      "grad_norm": 3.3723297119140625,
      "learning_rate": 2.9766903265927565e-05,
      "loss": 0.182,
      "step": 1092
    },
    {
      "epoch": 0.02350254378581806,
      "grad_norm": 5.557095527648926,
      "learning_rate": 2.9766045504256643e-05,
      "loss": 0.2426,
      "step": 1096
    },
    {
      "epoch": 0.02358831949306557,
      "grad_norm": 3.8025920391082764,
      "learning_rate": 2.9765187742585723e-05,
      "loss": 0.2548,
      "step": 1100
    },
    {
      "epoch": 0.02367409520031308,
      "grad_norm": 6.75748348236084,
      "learning_rate": 2.9764329980914804e-05,
      "loss": 0.3437,
      "step": 1104
    },
    {
      "epoch": 0.02375987090756059,
      "grad_norm": 3.147125482559204,
      "learning_rate": 2.9763472219243884e-05,
      "loss": 0.1485,
      "step": 1108
    },
    {
      "epoch": 0.023845646614808105,
      "grad_norm": 2.2834627628326416,
      "learning_rate": 2.976261445757296e-05,
      "loss": 0.1765,
      "step": 1112
    },
    {
      "epoch": 0.023931422322055616,
      "grad_norm": 2.806110143661499,
      "learning_rate": 2.9761756695902046e-05,
      "loss": 0.2165,
      "step": 1116
    },
    {
      "epoch": 0.024017198029303126,
      "grad_norm": 4.514120101928711,
      "learning_rate": 2.9760898934231123e-05,
      "loss": 0.2403,
      "step": 1120
    },
    {
      "epoch": 0.024102973736550636,
      "grad_norm": 3.6441445350646973,
      "learning_rate": 2.9760041172560203e-05,
      "loss": 0.2247,
      "step": 1124
    },
    {
      "epoch": 0.02418874944379815,
      "grad_norm": 4.306652545928955,
      "learning_rate": 2.9759183410889284e-05,
      "loss": 0.2077,
      "step": 1128
    },
    {
      "epoch": 0.02427452515104566,
      "grad_norm": 3.06215763092041,
      "learning_rate": 2.9758325649218365e-05,
      "loss": 0.2102,
      "step": 1132
    },
    {
      "epoch": 0.02436030085829317,
      "grad_norm": 3.347715139389038,
      "learning_rate": 2.975746788754745e-05,
      "loss": 0.2869,
      "step": 1136
    },
    {
      "epoch": 0.02444607656554068,
      "grad_norm": 3.343970537185669,
      "learning_rate": 2.9756610125876526e-05,
      "loss": 0.1999,
      "step": 1140
    },
    {
      "epoch": 0.024531852272788195,
      "grad_norm": 6.641284942626953,
      "learning_rate": 2.9755752364205606e-05,
      "loss": 0.3112,
      "step": 1144
    },
    {
      "epoch": 0.024617627980035705,
      "grad_norm": 1.5786411762237549,
      "learning_rate": 2.9754894602534687e-05,
      "loss": 0.3278,
      "step": 1148
    },
    {
      "epoch": 0.024703403687283215,
      "grad_norm": 2.66561222076416,
      "learning_rate": 2.9754036840863768e-05,
      "loss": 0.2366,
      "step": 1152
    },
    {
      "epoch": 0.024789179394530726,
      "grad_norm": 2.969357490539551,
      "learning_rate": 2.9753179079192845e-05,
      "loss": 0.2687,
      "step": 1156
    },
    {
      "epoch": 0.02487495510177824,
      "grad_norm": 5.09050178527832,
      "learning_rate": 2.975232131752193e-05,
      "loss": 0.1822,
      "step": 1160
    },
    {
      "epoch": 0.02496073080902575,
      "grad_norm": 2.091057300567627,
      "learning_rate": 2.9751463555851006e-05,
      "loss": 0.1317,
      "step": 1164
    },
    {
      "epoch": 0.02504650651627326,
      "grad_norm": 6.514374732971191,
      "learning_rate": 2.9750605794180087e-05,
      "loss": 0.2426,
      "step": 1168
    },
    {
      "epoch": 0.02513228222352077,
      "grad_norm": 3.337759256362915,
      "learning_rate": 2.9749748032509167e-05,
      "loss": 0.2127,
      "step": 1172
    },
    {
      "epoch": 0.025218057930768284,
      "grad_norm": 6.696815013885498,
      "learning_rate": 2.9748890270838248e-05,
      "loss": 0.1993,
      "step": 1176
    },
    {
      "epoch": 0.025303833638015794,
      "grad_norm": 1.6972342729568481,
      "learning_rate": 2.974803250916733e-05,
      "loss": 0.1804,
      "step": 1180
    },
    {
      "epoch": 0.025389609345263305,
      "grad_norm": 4.219553470611572,
      "learning_rate": 2.974717474749641e-05,
      "loss": 0.316,
      "step": 1184
    },
    {
      "epoch": 0.025475385052510815,
      "grad_norm": 2.8038840293884277,
      "learning_rate": 2.974631698582549e-05,
      "loss": 0.1736,
      "step": 1188
    },
    {
      "epoch": 0.02556116075975833,
      "grad_norm": 2.04353666305542,
      "learning_rate": 2.9745459224154567e-05,
      "loss": 0.1249,
      "step": 1192
    },
    {
      "epoch": 0.02564693646700584,
      "grad_norm": 4.418804168701172,
      "learning_rate": 2.974460146248365e-05,
      "loss": 0.3762,
      "step": 1196
    },
    {
      "epoch": 0.02573271217425335,
      "grad_norm": 4.068347454071045,
      "learning_rate": 2.9743743700812728e-05,
      "loss": 0.2061,
      "step": 1200
    },
    {
      "epoch": 0.02581848788150086,
      "grad_norm": 3.315417528152466,
      "learning_rate": 2.9742885939141812e-05,
      "loss": 0.2602,
      "step": 1204
    },
    {
      "epoch": 0.025904263588748373,
      "grad_norm": 3.1662609577178955,
      "learning_rate": 2.974202817747089e-05,
      "loss": 0.252,
      "step": 1208
    },
    {
      "epoch": 0.025990039295995884,
      "grad_norm": 1.4806407690048218,
      "learning_rate": 2.974117041579997e-05,
      "loss": 0.1917,
      "step": 1212
    },
    {
      "epoch": 0.026075815003243394,
      "grad_norm": 2.8318910598754883,
      "learning_rate": 2.9740312654129054e-05,
      "loss": 0.1855,
      "step": 1216
    },
    {
      "epoch": 0.026161590710490904,
      "grad_norm": 1.8348194360733032,
      "learning_rate": 2.973945489245813e-05,
      "loss": 0.207,
      "step": 1220
    },
    {
      "epoch": 0.026247366417738418,
      "grad_norm": 2.310452699661255,
      "learning_rate": 2.9738597130787212e-05,
      "loss": 0.2177,
      "step": 1224
    },
    {
      "epoch": 0.026333142124985928,
      "grad_norm": 7.07301664352417,
      "learning_rate": 2.9737739369116292e-05,
      "loss": 0.2628,
      "step": 1228
    },
    {
      "epoch": 0.02641891783223344,
      "grad_norm": 3.204806089401245,
      "learning_rate": 2.9736881607445373e-05,
      "loss": 0.1832,
      "step": 1232
    },
    {
      "epoch": 0.02650469353948095,
      "grad_norm": 4.6142778396606445,
      "learning_rate": 2.973602384577445e-05,
      "loss": 0.2989,
      "step": 1236
    },
    {
      "epoch": 0.026590469246728463,
      "grad_norm": 5.032226085662842,
      "learning_rate": 2.9735166084103534e-05,
      "loss": 0.2215,
      "step": 1240
    },
    {
      "epoch": 0.026676244953975973,
      "grad_norm": 3.026613712310791,
      "learning_rate": 2.973430832243261e-05,
      "loss": 0.2399,
      "step": 1244
    },
    {
      "epoch": 0.026762020661223483,
      "grad_norm": 1.8433551788330078,
      "learning_rate": 2.9733450560761692e-05,
      "loss": 0.1001,
      "step": 1248
    },
    {
      "epoch": 0.026847796368470993,
      "grad_norm": 6.575067520141602,
      "learning_rate": 2.9732592799090773e-05,
      "loss": 0.3194,
      "step": 1252
    },
    {
      "epoch": 0.026933572075718507,
      "grad_norm": 4.738956928253174,
      "learning_rate": 2.9731735037419853e-05,
      "loss": 0.2175,
      "step": 1256
    },
    {
      "epoch": 0.027019347782966018,
      "grad_norm": 4.324577331542969,
      "learning_rate": 2.9730877275748934e-05,
      "loss": 0.2555,
      "step": 1260
    },
    {
      "epoch": 0.027105123490213528,
      "grad_norm": 4.510285377502441,
      "learning_rate": 2.9730019514078015e-05,
      "loss": 0.3136,
      "step": 1264
    },
    {
      "epoch": 0.027190899197461038,
      "grad_norm": 4.019984245300293,
      "learning_rate": 2.9729161752407095e-05,
      "loss": 0.1668,
      "step": 1268
    },
    {
      "epoch": 0.027276674904708552,
      "grad_norm": 3.798903226852417,
      "learning_rate": 2.9728303990736176e-05,
      "loss": 0.262,
      "step": 1272
    },
    {
      "epoch": 0.027362450611956062,
      "grad_norm": 1.7788103818893433,
      "learning_rate": 2.9727446229065256e-05,
      "loss": 0.2234,
      "step": 1276
    },
    {
      "epoch": 0.027448226319203572,
      "grad_norm": 1.5661814212799072,
      "learning_rate": 2.9726588467394334e-05,
      "loss": 0.1591,
      "step": 1280
    },
    {
      "epoch": 0.027534002026451083,
      "grad_norm": 2.7413675785064697,
      "learning_rate": 2.9725730705723418e-05,
      "loss": 0.2323,
      "step": 1284
    },
    {
      "epoch": 0.027619777733698597,
      "grad_norm": 2.5919909477233887,
      "learning_rate": 2.9724872944052495e-05,
      "loss": 0.2085,
      "step": 1288
    },
    {
      "epoch": 0.027705553440946107,
      "grad_norm": 2.9527578353881836,
      "learning_rate": 2.9724015182381575e-05,
      "loss": 0.2527,
      "step": 1292
    },
    {
      "epoch": 0.027791329148193617,
      "grad_norm": 2.755288600921631,
      "learning_rate": 2.9723157420710656e-05,
      "loss": 0.1449,
      "step": 1296
    },
    {
      "epoch": 0.027877104855441127,
      "grad_norm": 2.124422311782837,
      "learning_rate": 2.9722299659039737e-05,
      "loss": 0.0818,
      "step": 1300
    },
    {
      "epoch": 0.026833070112713298,
      "grad_norm": 7.954781532287598,
      "learning_rate": 2.9732694048892915e-05,
      "loss": 0.3327,
      "step": 1304
    },
    {
      "epoch": 0.026915380143733892,
      "grad_norm": 4.330946445465088,
      "learning_rate": 2.9731870935879497e-05,
      "loss": 0.2051,
      "step": 1308
    },
    {
      "epoch": 0.026997690174754483,
      "grad_norm": 2.8090591430664062,
      "learning_rate": 2.973104782286608e-05,
      "loss": 0.1737,
      "step": 1312
    },
    {
      "epoch": 0.027080000205775077,
      "grad_norm": 3.5570127964019775,
      "learning_rate": 2.9730224709852662e-05,
      "loss": 0.194,
      "step": 1316
    },
    {
      "epoch": 0.027162310236795672,
      "grad_norm": 5.898624897003174,
      "learning_rate": 2.972940159683925e-05,
      "loss": 0.2555,
      "step": 1320
    },
    {
      "epoch": 0.027244620267816263,
      "grad_norm": 3.072272300720215,
      "learning_rate": 2.9728578483825828e-05,
      "loss": 0.2805,
      "step": 1324
    },
    {
      "epoch": 0.027326930298836857,
      "grad_norm": 4.055605411529541,
      "learning_rate": 2.9727755370812414e-05,
      "loss": 0.1855,
      "step": 1328
    },
    {
      "epoch": 0.02740924032985745,
      "grad_norm": 2.810551643371582,
      "learning_rate": 2.9726932257798996e-05,
      "loss": 0.1247,
      "step": 1332
    },
    {
      "epoch": 0.027491550360878043,
      "grad_norm": 3.5907912254333496,
      "learning_rate": 2.972610914478558e-05,
      "loss": 0.1351,
      "step": 1336
    },
    {
      "epoch": 0.027573860391898634,
      "grad_norm": 4.0676116943359375,
      "learning_rate": 2.972528603177216e-05,
      "loss": 0.2889,
      "step": 1340
    },
    {
      "epoch": 0.027656170422919228,
      "grad_norm": 3.315401554107666,
      "learning_rate": 2.9724462918758748e-05,
      "loss": 0.0943,
      "step": 1344
    },
    {
      "epoch": 0.027738480453939823,
      "grad_norm": 2.925596237182617,
      "learning_rate": 2.9723639805745327e-05,
      "loss": 0.1487,
      "step": 1348
    },
    {
      "epoch": 0.027820790484960414,
      "grad_norm": 1.9663612842559814,
      "learning_rate": 2.9722816692731913e-05,
      "loss": 0.283,
      "step": 1352
    },
    {
      "epoch": 0.027903100515981008,
      "grad_norm": 1.4784938097000122,
      "learning_rate": 2.9721993579718496e-05,
      "loss": 0.2151,
      "step": 1356
    },
    {
      "epoch": 0.0279854105470016,
      "grad_norm": 2.4692413806915283,
      "learning_rate": 2.9721170466705078e-05,
      "loss": 0.14,
      "step": 1360
    },
    {
      "epoch": 0.028067720578022193,
      "grad_norm": 2.263593912124634,
      "learning_rate": 2.972034735369166e-05,
      "loss": 0.2892,
      "step": 1364
    },
    {
      "epoch": 0.028150030609042784,
      "grad_norm": 2.051100492477417,
      "learning_rate": 2.9719524240678247e-05,
      "loss": 0.1671,
      "step": 1368
    },
    {
      "epoch": 0.02823234064006338,
      "grad_norm": 1.4457391500473022,
      "learning_rate": 2.971870112766483e-05,
      "loss": 0.2875,
      "step": 1372
    },
    {
      "epoch": 0.028314650671083973,
      "grad_norm": 2.6050586700439453,
      "learning_rate": 2.9717878014651412e-05,
      "loss": 0.2858,
      "step": 1376
    },
    {
      "epoch": 0.028396960702104564,
      "grad_norm": 4.112668037414551,
      "learning_rate": 2.9717054901637995e-05,
      "loss": 0.3497,
      "step": 1380
    },
    {
      "epoch": 0.02847927073312516,
      "grad_norm": 6.06806755065918,
      "learning_rate": 2.971623178862458e-05,
      "loss": 0.2266,
      "step": 1384
    },
    {
      "epoch": 0.02856158076414575,
      "grad_norm": 3.5955939292907715,
      "learning_rate": 2.971540867561116e-05,
      "loss": 0.3078,
      "step": 1388
    },
    {
      "epoch": 0.028643890795166344,
      "grad_norm": 3.740386962890625,
      "learning_rate": 2.9714585562597746e-05,
      "loss": 0.2152,
      "step": 1392
    },
    {
      "epoch": 0.028726200826186935,
      "grad_norm": 5.245201110839844,
      "learning_rate": 2.971376244958433e-05,
      "loss": 0.4059,
      "step": 1396
    },
    {
      "epoch": 0.02880851085720753,
      "grad_norm": 1.5764714479446411,
      "learning_rate": 2.971293933657091e-05,
      "loss": 0.2013,
      "step": 1400
    },
    {
      "epoch": 0.02880851085720753,
      "eval_accuracy": 0.7958248472505092,
      "eval_f1_contradiction": 0.8103703703703704,
      "eval_loss": 0.18421712517738342,
      "eval_runtime": 68.4767,
      "eval_samples_per_second": 57.363,
      "eval_steps_per_second": 7.17,
      "step": 1400
    },
    {
      "epoch": 0.02889082088822812,
      "grad_norm": 5.373536109924316,
      "learning_rate": 2.9712116223557494e-05,
      "loss": 0.2659,
      "step": 1404
    },
    {
      "epoch": 0.028973130919248715,
      "grad_norm": 4.843967437744141,
      "learning_rate": 2.971129311054408e-05,
      "loss": 0.2917,
      "step": 1408
    },
    {
      "epoch": 0.02905544095026931,
      "grad_norm": 3.695902109146118,
      "learning_rate": 2.971046999753066e-05,
      "loss": 0.2629,
      "step": 1412
    },
    {
      "epoch": 0.0291377509812899,
      "grad_norm": 1.962809443473816,
      "learning_rate": 2.9709646884517245e-05,
      "loss": 0.198,
      "step": 1416
    },
    {
      "epoch": 0.029220061012310495,
      "grad_norm": 3.9590983390808105,
      "learning_rate": 2.9708823771503828e-05,
      "loss": 0.2053,
      "step": 1420
    },
    {
      "epoch": 0.029302371043331086,
      "grad_norm": 3.4303295612335205,
      "learning_rate": 2.970800065849041e-05,
      "loss": 0.253,
      "step": 1424
    },
    {
      "epoch": 0.02938468107435168,
      "grad_norm": 2.92679762840271,
      "learning_rate": 2.9707177545476993e-05,
      "loss": 0.1753,
      "step": 1428
    },
    {
      "epoch": 0.02946699110537227,
      "grad_norm": 3.3405439853668213,
      "learning_rate": 2.970635443246358e-05,
      "loss": 0.1335,
      "step": 1432
    },
    {
      "epoch": 0.029549301136392866,
      "grad_norm": 4.160151958465576,
      "learning_rate": 2.970553131945016e-05,
      "loss": 0.1535,
      "step": 1436
    },
    {
      "epoch": 0.02963161116741346,
      "grad_norm": 2.9748637676239014,
      "learning_rate": 2.9704708206436744e-05,
      "loss": 0.1068,
      "step": 1440
    },
    {
      "epoch": 0.02971392119843405,
      "grad_norm": 2.160940647125244,
      "learning_rate": 2.9703885093423327e-05,
      "loss": 0.1699,
      "step": 1444
    },
    {
      "epoch": 0.029796231229454646,
      "grad_norm": 4.073643684387207,
      "learning_rate": 2.970306198040991e-05,
      "loss": 0.196,
      "step": 1448
    },
    {
      "epoch": 0.029878541260475237,
      "grad_norm": 3.709094762802124,
      "learning_rate": 2.9702238867396492e-05,
      "loss": 0.3065,
      "step": 1452
    },
    {
      "epoch": 0.02996085129149583,
      "grad_norm": 3.6640207767486572,
      "learning_rate": 2.970141575438308e-05,
      "loss": 0.266,
      "step": 1456
    },
    {
      "epoch": 0.030043161322516422,
      "grad_norm": 3.040907621383667,
      "learning_rate": 2.970059264136966e-05,
      "loss": 0.229,
      "step": 1460
    },
    {
      "epoch": 0.030125471353537017,
      "grad_norm": 8.233857154846191,
      "learning_rate": 2.9699769528356244e-05,
      "loss": 0.1927,
      "step": 1464
    },
    {
      "epoch": 0.03020778138455761,
      "grad_norm": 2.3406982421875,
      "learning_rate": 2.9698946415342826e-05,
      "loss": 0.1391,
      "step": 1468
    },
    {
      "epoch": 0.030290091415578202,
      "grad_norm": 4.245852947235107,
      "learning_rate": 2.9698123302329412e-05,
      "loss": 0.2213,
      "step": 1472
    },
    {
      "epoch": 0.030372401446598796,
      "grad_norm": 5.562298774719238,
      "learning_rate": 2.969730018931599e-05,
      "loss": 0.2268,
      "step": 1476
    },
    {
      "epoch": 0.030454711477619387,
      "grad_norm": 2.369706153869629,
      "learning_rate": 2.9696477076302578e-05,
      "loss": 0.1285,
      "step": 1480
    },
    {
      "epoch": 0.030537021508639982,
      "grad_norm": 2.4901533126831055,
      "learning_rate": 2.969565396328916e-05,
      "loss": 0.185,
      "step": 1484
    },
    {
      "epoch": 0.030619331539660573,
      "grad_norm": 0.5325233936309814,
      "learning_rate": 2.9694830850275743e-05,
      "loss": 0.2161,
      "step": 1488
    },
    {
      "epoch": 0.030701641570681167,
      "grad_norm": 4.431619644165039,
      "learning_rate": 2.9694007737262325e-05,
      "loss": 0.2508,
      "step": 1492
    },
    {
      "epoch": 0.030783951601701758,
      "grad_norm": 3.1837947368621826,
      "learning_rate": 2.969318462424891e-05,
      "loss": 0.2431,
      "step": 1496
    },
    {
      "epoch": 0.030866261632722353,
      "grad_norm": 2.112736940383911,
      "learning_rate": 2.969236151123549e-05,
      "loss": 0.1341,
      "step": 1500
    },
    {
      "epoch": 0.030866261632722353,
      "eval_accuracy": 0.814918533604888,
      "eval_f1_contradiction": 0.8245408362641657,
      "eval_loss": 0.16552197933197021,
      "eval_runtime": 69.784,
      "eval_samples_per_second": 56.288,
      "eval_steps_per_second": 7.036,
      "step": 1500
    },
    {
      "epoch": 0.030948571663742947,
      "grad_norm": 2.702127695083618,
      "learning_rate": 2.9691538398222077e-05,
      "loss": 0.2103,
      "step": 1504
    },
    {
      "epoch": 0.031030881694763538,
      "grad_norm": 2.6968910694122314,
      "learning_rate": 2.969071528520866e-05,
      "loss": 0.1414,
      "step": 1508
    },
    {
      "epoch": 0.031113191725784133,
      "grad_norm": 2.700615644454956,
      "learning_rate": 2.9689892172195242e-05,
      "loss": 0.1234,
      "step": 1512
    },
    {
      "epoch": 0.031195501756804724,
      "grad_norm": 2.638382911682129,
      "learning_rate": 2.9689069059181825e-05,
      "loss": 0.2073,
      "step": 1516
    },
    {
      "epoch": 0.031277811787825315,
      "grad_norm": 2.161388635635376,
      "learning_rate": 2.968824594616841e-05,
      "loss": 0.2486,
      "step": 1520
    },
    {
      "epoch": 0.03136012181884591,
      "grad_norm": 1.8904340267181396,
      "learning_rate": 2.968742283315499e-05,
      "loss": 0.1616,
      "step": 1524
    },
    {
      "epoch": 0.0314424318498665,
      "grad_norm": 7.9549760818481445,
      "learning_rate": 2.9686599720141576e-05,
      "loss": 0.2772,
      "step": 1528
    },
    {
      "epoch": 0.031524741880887094,
      "grad_norm": 2.8629086017608643,
      "learning_rate": 2.9685776607128162e-05,
      "loss": 0.1743,
      "step": 1532
    },
    {
      "epoch": 0.03160705191190769,
      "grad_norm": 1.2855126857757568,
      "learning_rate": 2.968495349411474e-05,
      "loss": 0.18,
      "step": 1536
    },
    {
      "epoch": 0.03168936194292828,
      "grad_norm": 1.7844009399414062,
      "learning_rate": 2.9684130381101327e-05,
      "loss": 0.2254,
      "step": 1540
    },
    {
      "epoch": 0.031771671973948874,
      "grad_norm": 3.0843007564544678,
      "learning_rate": 2.968330726808791e-05,
      "loss": 0.1872,
      "step": 1544
    },
    {
      "epoch": 0.031853982004969465,
      "grad_norm": 1.942681074142456,
      "learning_rate": 2.9682484155074493e-05,
      "loss": 0.1193,
      "step": 1548
    },
    {
      "epoch": 0.03193629203599006,
      "grad_norm": 5.619139194488525,
      "learning_rate": 2.9681661042061075e-05,
      "loss": 0.2054,
      "step": 1552
    },
    {
      "epoch": 0.032018602067010654,
      "grad_norm": 3.39432692527771,
      "learning_rate": 2.968083792904766e-05,
      "loss": 0.2183,
      "step": 1556
    },
    {
      "epoch": 0.032100912098031245,
      "grad_norm": 4.210982322692871,
      "learning_rate": 2.9680014816034244e-05,
      "loss": 0.2248,
      "step": 1560
    },
    {
      "epoch": 0.03218322212905184,
      "grad_norm": 2.2298178672790527,
      "learning_rate": 2.9679191703020826e-05,
      "loss": 0.1328,
      "step": 1564
    },
    {
      "epoch": 0.032265532160072434,
      "grad_norm": 2.7913193702697754,
      "learning_rate": 2.967836859000741e-05,
      "loss": 0.2162,
      "step": 1568
    },
    {
      "epoch": 0.032347842191093025,
      "grad_norm": 0.6761873960494995,
      "learning_rate": 2.9677545476993995e-05,
      "loss": 0.1454,
      "step": 1572
    },
    {
      "epoch": 0.032430152222113616,
      "grad_norm": 4.955743312835693,
      "learning_rate": 2.9676722363980574e-05,
      "loss": 0.3403,
      "step": 1576
    },
    {
      "epoch": 0.032512462253134214,
      "grad_norm": 3.6171977519989014,
      "learning_rate": 2.967589925096716e-05,
      "loss": 0.1155,
      "step": 1580
    },
    {
      "epoch": 0.032594772284154805,
      "grad_norm": 3.1890909671783447,
      "learning_rate": 2.9675076137953743e-05,
      "loss": 0.2834,
      "step": 1584
    },
    {
      "epoch": 0.032677082315175396,
      "grad_norm": 8.016182899475098,
      "learning_rate": 2.9674253024940326e-05,
      "loss": 0.3208,
      "step": 1588
    },
    {
      "epoch": 0.032759392346195994,
      "grad_norm": 4.057382106781006,
      "learning_rate": 2.9673429911926908e-05,
      "loss": 0.1787,
      "step": 1592
    },
    {
      "epoch": 0.032841702377216585,
      "grad_norm": 4.5932230949401855,
      "learning_rate": 2.9672606798913494e-05,
      "loss": 0.2594,
      "step": 1596
    },
    {
      "epoch": 0.032924012408237176,
      "grad_norm": 4.125920295715332,
      "learning_rate": 2.9671783685900074e-05,
      "loss": 0.1756,
      "step": 1600
    },
    {
      "epoch": 0.032924012408237176,
      "eval_accuracy": 0.8090631364562119,
      "eval_f1_contradiction": 0.8230390299355816,
      "eval_loss": 0.17030119895935059,
      "eval_runtime": 70.7063,
      "eval_samples_per_second": 55.554,
      "eval_steps_per_second": 6.944,
      "step": 1600
    },
    {
      "epoch": 0.03300632243925777,
      "grad_norm": 2.2450919151306152,
      "learning_rate": 2.967096057288666e-05,
      "loss": 0.1713,
      "step": 1604
    },
    {
      "epoch": 0.033088632470278365,
      "grad_norm": 5.328564643859863,
      "learning_rate": 2.9670137459873242e-05,
      "loss": 0.1648,
      "step": 1608
    },
    {
      "epoch": 0.033170942501298956,
      "grad_norm": 3.8551812171936035,
      "learning_rate": 2.9669314346859825e-05,
      "loss": 0.241,
      "step": 1612
    },
    {
      "epoch": 0.03325325253231955,
      "grad_norm": 4.119189262390137,
      "learning_rate": 2.9668491233846407e-05,
      "loss": 0.3252,
      "step": 1616
    },
    {
      "epoch": 0.033335562563340145,
      "grad_norm": 4.350866794586182,
      "learning_rate": 2.9667668120832993e-05,
      "loss": 0.1533,
      "step": 1620
    },
    {
      "epoch": 0.033417872594360735,
      "grad_norm": 1.4100462198257446,
      "learning_rate": 2.9666845007819573e-05,
      "loss": 0.1821,
      "step": 1624
    },
    {
      "epoch": 0.033500182625381326,
      "grad_norm": 5.554017066955566,
      "learning_rate": 2.966602189480616e-05,
      "loss": 0.2903,
      "step": 1628
    },
    {
      "epoch": 0.03358249265640192,
      "grad_norm": 4.574827194213867,
      "learning_rate": 2.966519878179274e-05,
      "loss": 0.1857,
      "step": 1632
    },
    {
      "epoch": 0.033664802687422515,
      "grad_norm": 2.213824987411499,
      "learning_rate": 2.9664375668779324e-05,
      "loss": 0.218,
      "step": 1636
    },
    {
      "epoch": 0.033747112718443106,
      "grad_norm": 3.683410882949829,
      "learning_rate": 2.9663552555765907e-05,
      "loss": 0.1879,
      "step": 1640
    },
    {
      "epoch": 0.0338294227494637,
      "grad_norm": 1.7499905824661255,
      "learning_rate": 2.9662729442752493e-05,
      "loss": 0.2116,
      "step": 1644
    },
    {
      "epoch": 0.03391173278048429,
      "grad_norm": 4.83503532409668,
      "learning_rate": 2.9661906329739072e-05,
      "loss": 0.1652,
      "step": 1648
    },
    {
      "epoch": 0.033994042811504886,
      "grad_norm": 2.2157905101776123,
      "learning_rate": 2.9661083216725658e-05,
      "loss": 0.2185,
      "step": 1652
    },
    {
      "epoch": 0.03407635284252548,
      "grad_norm": 1.8785405158996582,
      "learning_rate": 2.966026010371224e-05,
      "loss": 0.2468,
      "step": 1656
    },
    {
      "epoch": 0.03415866287354607,
      "grad_norm": 2.8472657203674316,
      "learning_rate": 2.9659436990698827e-05,
      "loss": 0.1382,
      "step": 1660
    },
    {
      "epoch": 0.034240972904566666,
      "grad_norm": 2.968749761581421,
      "learning_rate": 2.9658613877685406e-05,
      "loss": 0.1241,
      "step": 1664
    },
    {
      "epoch": 0.03432328293558726,
      "grad_norm": 4.44000768661499,
      "learning_rate": 2.9657790764671992e-05,
      "loss": 0.2699,
      "step": 1668
    },
    {
      "epoch": 0.03440559296660785,
      "grad_norm": 5.284221172332764,
      "learning_rate": 2.9656967651658575e-05,
      "loss": 0.2056,
      "step": 1672
    },
    {
      "epoch": 0.03448790299762844,
      "grad_norm": 4.154944896697998,
      "learning_rate": 2.9656144538645157e-05,
      "loss": 0.2278,
      "step": 1676
    },
    {
      "epoch": 0.03457021302864904,
      "grad_norm": 2.131753921508789,
      "learning_rate": 2.965532142563174e-05,
      "loss": 0.1358,
      "step": 1680
    },
    {
      "epoch": 0.03465252305966963,
      "grad_norm": 3.493619918823242,
      "learning_rate": 2.9654498312618326e-05,
      "loss": 0.1894,
      "step": 1684
    },
    {
      "epoch": 0.03473483309069022,
      "grad_norm": 3.7460291385650635,
      "learning_rate": 2.9653675199604905e-05,
      "loss": 0.14,
      "step": 1688
    },
    {
      "epoch": 0.03481714312171082,
      "grad_norm": 2.7889180183410645,
      "learning_rate": 2.965285208659149e-05,
      "loss": 0.1203,
      "step": 1692
    },
    {
      "epoch": 0.03489945315273141,
      "grad_norm": 4.820795059204102,
      "learning_rate": 2.9652028973578074e-05,
      "loss": 0.3623,
      "step": 1696
    },
    {
      "epoch": 0.034981763183752,
      "grad_norm": 3.2102699279785156,
      "learning_rate": 2.9651205860564656e-05,
      "loss": 0.2037,
      "step": 1700
    },
    {
      "epoch": 0.03506407321477259,
      "grad_norm": 2.7978756427764893,
      "learning_rate": 2.965038274755124e-05,
      "loss": 0.1442,
      "step": 1704
    },
    {
      "epoch": 0.03514638324579319,
      "grad_norm": 5.948385715484619,
      "learning_rate": 2.9649559634537825e-05,
      "loss": 0.2138,
      "step": 1708
    },
    {
      "epoch": 0.03522869327681378,
      "grad_norm": 3.0878653526306152,
      "learning_rate": 2.9648736521524404e-05,
      "loss": 0.1993,
      "step": 1712
    },
    {
      "epoch": 0.03531100330783437,
      "grad_norm": 2.036405563354492,
      "learning_rate": 2.964791340851099e-05,
      "loss": 0.2167,
      "step": 1716
    },
    {
      "epoch": 0.03539331333885497,
      "grad_norm": 3.8771743774414062,
      "learning_rate": 2.9647090295497573e-05,
      "loss": 0.1651,
      "step": 1720
    },
    {
      "epoch": 0.03547562336987556,
      "grad_norm": 2.7138755321502686,
      "learning_rate": 2.9646267182484156e-05,
      "loss": 0.1467,
      "step": 1724
    },
    {
      "epoch": 0.03555793340089615,
      "grad_norm": 3.396644353866577,
      "learning_rate": 2.9645444069470738e-05,
      "loss": 0.1892,
      "step": 1728
    },
    {
      "epoch": 0.03564024343191674,
      "grad_norm": 4.525886058807373,
      "learning_rate": 2.9644620956457324e-05,
      "loss": 0.2229,
      "step": 1732
    },
    {
      "epoch": 0.03572255346293734,
      "grad_norm": 9.21278190612793,
      "learning_rate": 2.9643797843443903e-05,
      "loss": 0.1922,
      "step": 1736
    },
    {
      "epoch": 0.03580486349395793,
      "grad_norm": 5.307187557220459,
      "learning_rate": 2.964297473043049e-05,
      "loss": 0.1334,
      "step": 1740
    },
    {
      "epoch": 0.03588717352497852,
      "grad_norm": 6.764775276184082,
      "learning_rate": 2.9642151617417072e-05,
      "loss": 0.2191,
      "step": 1744
    },
    {
      "epoch": 0.03596948355599912,
      "grad_norm": 0.694159746170044,
      "learning_rate": 2.9641328504403655e-05,
      "loss": 0.1077,
      "step": 1748
    },
    {
      "epoch": 0.03605179358701971,
      "grad_norm": 4.3340325355529785,
      "learning_rate": 2.9640505391390237e-05,
      "loss": 0.2806,
      "step": 1752
    },
    {
      "epoch": 0.0361341036180403,
      "grad_norm": 4.6569108963012695,
      "learning_rate": 2.9639682278376823e-05,
      "loss": 0.4359,
      "step": 1756
    },
    {
      "epoch": 0.03621641364906089,
      "grad_norm": 3.68233585357666,
      "learning_rate": 2.9638859165363406e-05,
      "loss": 0.1821,
      "step": 1760
    },
    {
      "epoch": 0.03629872368008149,
      "grad_norm": 3.069819927215576,
      "learning_rate": 2.963803605234999e-05,
      "loss": 0.2852,
      "step": 1764
    },
    {
      "epoch": 0.03638103371110208,
      "grad_norm": 2.562816858291626,
      "learning_rate": 2.963721293933657e-05,
      "loss": 0.1445,
      "step": 1768
    },
    {
      "epoch": 0.03646334374212267,
      "grad_norm": 4.317671775817871,
      "learning_rate": 2.9636389826323157e-05,
      "loss": 0.2911,
      "step": 1772
    },
    {
      "epoch": 0.03654565377314327,
      "grad_norm": 5.712774276733398,
      "learning_rate": 2.9635566713309737e-05,
      "loss": 0.2434,
      "step": 1776
    },
    {
      "epoch": 0.03662796380416386,
      "grad_norm": 3.588379383087158,
      "learning_rate": 2.9634743600296323e-05,
      "loss": 0.2345,
      "step": 1780
    },
    {
      "epoch": 0.03671027383518445,
      "grad_norm": 2.8192949295043945,
      "learning_rate": 2.9633920487282905e-05,
      "loss": 0.1749,
      "step": 1784
    },
    {
      "epoch": 0.03679258386620504,
      "grad_norm": 4.664095878601074,
      "learning_rate": 2.9633097374269488e-05,
      "loss": 0.2423,
      "step": 1788
    },
    {
      "epoch": 0.03687489389722564,
      "grad_norm": 3.383213758468628,
      "learning_rate": 2.963227426125607e-05,
      "loss": 0.3141,
      "step": 1792
    },
    {
      "epoch": 0.03695720392824623,
      "grad_norm": 6.062683582305908,
      "learning_rate": 2.9631451148242657e-05,
      "loss": 0.2017,
      "step": 1796
    },
    {
      "epoch": 0.03703951395926682,
      "grad_norm": 3.6630842685699463,
      "learning_rate": 2.9630628035229236e-05,
      "loss": 0.1846,
      "step": 1800
    },
    {
      "epoch": 0.03712182399028742,
      "grad_norm": 2.578606367111206,
      "learning_rate": 2.9629804922215822e-05,
      "loss": 0.1301,
      "step": 1804
    },
    {
      "epoch": 0.03720413402130801,
      "grad_norm": 3.3953888416290283,
      "learning_rate": 2.9628981809202404e-05,
      "loss": 0.2022,
      "step": 1808
    },
    {
      "epoch": 0.0372864440523286,
      "grad_norm": 3.389354944229126,
      "learning_rate": 2.9628158696188987e-05,
      "loss": 0.2152,
      "step": 1812
    },
    {
      "epoch": 0.03736875408334919,
      "grad_norm": 3.7030746936798096,
      "learning_rate": 2.962733558317557e-05,
      "loss": 0.1989,
      "step": 1816
    },
    {
      "epoch": 0.03745106411436979,
      "grad_norm": 2.3673243522644043,
      "learning_rate": 2.9626512470162156e-05,
      "loss": 0.1723,
      "step": 1820
    },
    {
      "epoch": 0.03753337414539038,
      "grad_norm": 3.7232580184936523,
      "learning_rate": 2.9625689357148735e-05,
      "loss": 0.2467,
      "step": 1824
    },
    {
      "epoch": 0.03761568417641097,
      "grad_norm": 3.69453501701355,
      "learning_rate": 2.962486624413532e-05,
      "loss": 0.2044,
      "step": 1828
    },
    {
      "epoch": 0.037697994207431564,
      "grad_norm": 4.229696273803711,
      "learning_rate": 2.9624043131121904e-05,
      "loss": 0.2162,
      "step": 1832
    },
    {
      "epoch": 0.03778030423845216,
      "grad_norm": 4.584323883056641,
      "learning_rate": 2.9623220018108486e-05,
      "loss": 0.1556,
      "step": 1836
    },
    {
      "epoch": 0.03786261426947275,
      "grad_norm": 7.316556453704834,
      "learning_rate": 2.962239690509507e-05,
      "loss": 0.2993,
      "step": 1840
    },
    {
      "epoch": 0.03794492430049334,
      "grad_norm": 3.4245493412017822,
      "learning_rate": 2.9621573792081655e-05,
      "loss": 0.2794,
      "step": 1844
    },
    {
      "epoch": 0.03802723433151394,
      "grad_norm": 2.666494131088257,
      "learning_rate": 2.9620750679068238e-05,
      "loss": 0.2622,
      "step": 1848
    },
    {
      "epoch": 0.03810954436253453,
      "grad_norm": 3.38006329536438,
      "learning_rate": 2.961992756605482e-05,
      "loss": 0.1353,
      "step": 1852
    },
    {
      "epoch": 0.03819185439355512,
      "grad_norm": 3.7088842391967773,
      "learning_rate": 2.9619104453041403e-05,
      "loss": 0.2871,
      "step": 1856
    },
    {
      "epoch": 0.038274164424575714,
      "grad_norm": 3.6001298427581787,
      "learning_rate": 2.961828134002799e-05,
      "loss": 0.1866,
      "step": 1860
    },
    {
      "epoch": 0.03835647445559631,
      "grad_norm": 1.7993096113204956,
      "learning_rate": 2.9617458227014568e-05,
      "loss": 0.2333,
      "step": 1864
    },
    {
      "epoch": 0.0384387844866169,
      "grad_norm": 1.956980586051941,
      "learning_rate": 2.9616635114001154e-05,
      "loss": 0.1506,
      "step": 1868
    },
    {
      "epoch": 0.038521094517637494,
      "grad_norm": 6.3405256271362305,
      "learning_rate": 2.9615812000987737e-05,
      "loss": 0.2389,
      "step": 1872
    },
    {
      "epoch": 0.03860340454865809,
      "grad_norm": 2.0353219509124756,
      "learning_rate": 2.961498888797432e-05,
      "loss": 0.1697,
      "step": 1876
    },
    {
      "epoch": 0.03868571457967868,
      "grad_norm": 4.612168788909912,
      "learning_rate": 2.9614165774960902e-05,
      "loss": 0.2382,
      "step": 1880
    },
    {
      "epoch": 0.038768024610699274,
      "grad_norm": 5.684258460998535,
      "learning_rate": 2.9613342661947488e-05,
      "loss": 0.2194,
      "step": 1884
    },
    {
      "epoch": 0.038850334641719865,
      "grad_norm": 3.526184558868408,
      "learning_rate": 2.9612519548934067e-05,
      "loss": 0.2247,
      "step": 1888
    },
    {
      "epoch": 0.03893264467274046,
      "grad_norm": 4.4768595695495605,
      "learning_rate": 2.9611696435920653e-05,
      "loss": 0.2074,
      "step": 1892
    },
    {
      "epoch": 0.039014954703761054,
      "grad_norm": 3.894367218017578,
      "learning_rate": 2.9610873322907236e-05,
      "loss": 0.3698,
      "step": 1896
    },
    {
      "epoch": 0.039097264734781645,
      "grad_norm": 3.034517526626587,
      "learning_rate": 2.961005020989382e-05,
      "loss": 0.2247,
      "step": 1900
    },
    {
      "epoch": 0.03917957476580224,
      "grad_norm": 2.778252363204956,
      "learning_rate": 2.96092270968804e-05,
      "loss": 0.1896,
      "step": 1904
    },
    {
      "epoch": 0.039261884796822834,
      "grad_norm": 4.914286136627197,
      "learning_rate": 2.9608403983866987e-05,
      "loss": 0.2414,
      "step": 1908
    },
    {
      "epoch": 0.039344194827843425,
      "grad_norm": 2.4700610637664795,
      "learning_rate": 2.9607580870853566e-05,
      "loss": 0.1339,
      "step": 1912
    },
    {
      "epoch": 0.039426504858864016,
      "grad_norm": 2.6936862468719482,
      "learning_rate": 2.9606757757840152e-05,
      "loss": 0.2352,
      "step": 1916
    },
    {
      "epoch": 0.039508814889884614,
      "grad_norm": 6.635237693786621,
      "learning_rate": 2.9605934644826735e-05,
      "loss": 0.2971,
      "step": 1920
    },
    {
      "epoch": 0.039591124920905205,
      "grad_norm": 1.4555338621139526,
      "learning_rate": 2.9605111531813318e-05,
      "loss": 0.1106,
      "step": 1924
    },
    {
      "epoch": 0.039673434951925796,
      "grad_norm": 7.178288459777832,
      "learning_rate": 2.96042884187999e-05,
      "loss": 0.1396,
      "step": 1928
    },
    {
      "epoch": 0.039755744982946394,
      "grad_norm": 2.374203681945801,
      "learning_rate": 2.9603465305786486e-05,
      "loss": 0.2219,
      "step": 1932
    },
    {
      "epoch": 0.039838055013966985,
      "grad_norm": 4.499241828918457,
      "learning_rate": 2.9602642192773066e-05,
      "loss": 0.3179,
      "step": 1936
    },
    {
      "epoch": 0.039920365044987575,
      "grad_norm": 1.891311526298523,
      "learning_rate": 2.960181907975965e-05,
      "loss": 0.2273,
      "step": 1940
    },
    {
      "epoch": 0.040002675076008166,
      "grad_norm": 5.001837253570557,
      "learning_rate": 2.9600995966746234e-05,
      "loss": 0.2573,
      "step": 1944
    },
    {
      "epoch": 0.040084985107028764,
      "grad_norm": 2.8851916790008545,
      "learning_rate": 2.960017285373282e-05,
      "loss": 0.1925,
      "step": 1948
    },
    {
      "epoch": 0.040167295138049355,
      "grad_norm": 4.436345100402832,
      "learning_rate": 2.95993497407194e-05,
      "loss": 0.3199,
      "step": 1952
    },
    {
      "epoch": 0.040249605169069946,
      "grad_norm": 4.050621509552002,
      "learning_rate": 2.9598526627705986e-05,
      "loss": 0.2555,
      "step": 1956
    },
    {
      "epoch": 0.040331915200090544,
      "grad_norm": 2.647738456726074,
      "learning_rate": 2.9597703514692568e-05,
      "loss": 0.2364,
      "step": 1960
    },
    {
      "epoch": 0.040414225231111135,
      "grad_norm": 4.695437908172607,
      "learning_rate": 2.959688040167915e-05,
      "loss": 0.1847,
      "step": 1964
    },
    {
      "epoch": 0.040496535262131726,
      "grad_norm": 3.5710642337799072,
      "learning_rate": 2.9596057288665734e-05,
      "loss": 0.2567,
      "step": 1968
    },
    {
      "epoch": 0.04057884529315232,
      "grad_norm": 2.901071786880493,
      "learning_rate": 2.959523417565232e-05,
      "loss": 0.1508,
      "step": 1972
    },
    {
      "epoch": 0.040661155324172915,
      "grad_norm": 2.8098011016845703,
      "learning_rate": 2.95944110626389e-05,
      "loss": 0.1724,
      "step": 1976
    },
    {
      "epoch": 0.040743465355193506,
      "grad_norm": 1.8661954402923584,
      "learning_rate": 2.9593587949625485e-05,
      "loss": 0.1312,
      "step": 1980
    },
    {
      "epoch": 0.0408257753862141,
      "grad_norm": 2.5779495239257812,
      "learning_rate": 2.9592764836612067e-05,
      "loss": 0.3293,
      "step": 1984
    },
    {
      "epoch": 0.040908085417234695,
      "grad_norm": 1.2227784395217896,
      "learning_rate": 2.959194172359865e-05,
      "loss": 0.1832,
      "step": 1988
    },
    {
      "epoch": 0.040990395448255286,
      "grad_norm": 2.8769819736480713,
      "learning_rate": 2.9591118610585233e-05,
      "loss": 0.1879,
      "step": 1992
    },
    {
      "epoch": 0.04107270547927588,
      "grad_norm": 1.026419758796692,
      "learning_rate": 2.959029549757182e-05,
      "loss": 0.2443,
      "step": 1996
    },
    {
      "epoch": 0.04115501551029647,
      "grad_norm": 3.5727789402008057,
      "learning_rate": 2.9589472384558398e-05,
      "loss": 0.2531,
      "step": 2000
    },
    {
      "epoch": 0.041237325541317066,
      "grad_norm": 2.406247138977051,
      "learning_rate": 2.9588649271544984e-05,
      "loss": 0.1524,
      "step": 2004
    },
    {
      "epoch": 0.04131963557233766,
      "grad_norm": 2.209493637084961,
      "learning_rate": 2.9587826158531567e-05,
      "loss": 0.248,
      "step": 2008
    },
    {
      "epoch": 0.04140194560335825,
      "grad_norm": 4.561828136444092,
      "learning_rate": 2.958700304551815e-05,
      "loss": 0.2843,
      "step": 2012
    },
    {
      "epoch": 0.04148425563437884,
      "grad_norm": 2.232680320739746,
      "learning_rate": 2.9586179932504732e-05,
      "loss": 0.2347,
      "step": 2016
    },
    {
      "epoch": 0.04156656566539944,
      "grad_norm": 4.080589294433594,
      "learning_rate": 2.9585356819491318e-05,
      "loss": 0.3261,
      "step": 2020
    },
    {
      "epoch": 0.04164887569642003,
      "grad_norm": 1.7297204732894897,
      "learning_rate": 2.9584533706477897e-05,
      "loss": 0.1489,
      "step": 2024
    },
    {
      "epoch": 0.04173118572744062,
      "grad_norm": 1.8819113969802856,
      "learning_rate": 2.9583710593464483e-05,
      "loss": 0.2376,
      "step": 2028
    },
    {
      "epoch": 0.04181349575846122,
      "grad_norm": 1.9221522808074951,
      "learning_rate": 2.9582887480451066e-05,
      "loss": 0.0924,
      "step": 2032
    },
    {
      "epoch": 0.04189580578948181,
      "grad_norm": 4.0743913650512695,
      "learning_rate": 2.958206436743765e-05,
      "loss": 0.2407,
      "step": 2036
    },
    {
      "epoch": 0.0419781158205024,
      "grad_norm": 1.8319593667984009,
      "learning_rate": 2.958124125442423e-05,
      "loss": 0.2067,
      "step": 2040
    },
    {
      "epoch": 0.04206042585152299,
      "grad_norm": 3.4937291145324707,
      "learning_rate": 2.9580418141410817e-05,
      "loss": 0.3069,
      "step": 2044
    },
    {
      "epoch": 0.04214273588254359,
      "grad_norm": 4.278603553771973,
      "learning_rate": 2.95795950283974e-05,
      "loss": 0.1678,
      "step": 2048
    },
    {
      "epoch": 0.04222504591356418,
      "grad_norm": 3.6175644397735596,
      "learning_rate": 2.9578771915383982e-05,
      "loss": 0.2041,
      "step": 2052
    },
    {
      "epoch": 0.04230735594458477,
      "grad_norm": 3.700361490249634,
      "learning_rate": 2.9577948802370565e-05,
      "loss": 0.2167,
      "step": 2056
    },
    {
      "epoch": 0.04238966597560537,
      "grad_norm": 6.636667251586914,
      "learning_rate": 2.957712568935715e-05,
      "loss": 0.2266,
      "step": 2060
    },
    {
      "epoch": 0.04247197600662596,
      "grad_norm": 4.2437543869018555,
      "learning_rate": 2.957630257634373e-05,
      "loss": 0.3158,
      "step": 2064
    },
    {
      "epoch": 0.04255428603764655,
      "grad_norm": 2.1398682594299316,
      "learning_rate": 2.9575479463330316e-05,
      "loss": 0.1289,
      "step": 2068
    },
    {
      "epoch": 0.04263659606866714,
      "grad_norm": 3.6152515411376953,
      "learning_rate": 2.95746563503169e-05,
      "loss": 0.1649,
      "step": 2072
    },
    {
      "epoch": 0.04271890609968774,
      "grad_norm": 3.5785834789276123,
      "learning_rate": 2.957383323730348e-05,
      "loss": 0.3294,
      "step": 2076
    },
    {
      "epoch": 0.04280121613070833,
      "grad_norm": 1.882423758506775,
      "learning_rate": 2.9573010124290064e-05,
      "loss": 0.1262,
      "step": 2080
    },
    {
      "epoch": 0.04288352616172892,
      "grad_norm": 3.925651788711548,
      "learning_rate": 2.957218701127665e-05,
      "loss": 0.3069,
      "step": 2084
    },
    {
      "epoch": 0.04296583619274952,
      "grad_norm": 3.494216203689575,
      "learning_rate": 2.9571363898263233e-05,
      "loss": 0.1098,
      "step": 2088
    },
    {
      "epoch": 0.04304814622377011,
      "grad_norm": 3.5707805156707764,
      "learning_rate": 2.9570540785249816e-05,
      "loss": 0.1713,
      "step": 2092
    },
    {
      "epoch": 0.0431304562547907,
      "grad_norm": 3.1692652702331543,
      "learning_rate": 2.95697176722364e-05,
      "loss": 0.2947,
      "step": 2096
    },
    {
      "epoch": 0.04321276628581129,
      "grad_norm": 2.352224111557007,
      "learning_rate": 2.956889455922298e-05,
      "loss": 0.2124,
      "step": 2100
    },
    {
      "epoch": 0.04329507631683189,
      "grad_norm": 3.3553924560546875,
      "learning_rate": 2.9568071446209567e-05,
      "loss": 0.3002,
      "step": 2104
    },
    {
      "epoch": 0.04337738634785248,
      "grad_norm": 5.369490146636963,
      "learning_rate": 2.956724833319615e-05,
      "loss": 0.316,
      "step": 2108
    },
    {
      "epoch": 0.04345969637887307,
      "grad_norm": NaN,
      "learning_rate": 2.9566425220182732e-05,
      "loss": 0.2987,
      "step": 2112
    },
    {
      "epoch": 0.04354200640989367,
      "grad_norm": 5.493595600128174,
      "learning_rate": 2.956580788542267e-05,
      "loss": 0.1647,
      "step": 2116
    },
    {
      "epoch": 0.04362431644091426,
      "grad_norm": 3.102144241333008,
      "learning_rate": 2.9564984772409255e-05,
      "loss": 0.1601,
      "step": 2120
    },
    {
      "epoch": 0.04370662647193485,
      "grad_norm": 2.592968463897705,
      "learning_rate": 2.9564161659395834e-05,
      "loss": 0.197,
      "step": 2124
    },
    {
      "epoch": 0.04378893650295544,
      "grad_norm": 4.197905540466309,
      "learning_rate": 2.956333854638242e-05,
      "loss": 0.1582,
      "step": 2128
    },
    {
      "epoch": 0.04387124653397604,
      "grad_norm": 4.209228515625,
      "learning_rate": 2.9562515433369003e-05,
      "loss": 0.176,
      "step": 2132
    },
    {
      "epoch": 0.04395355656499663,
      "grad_norm": 3.599357843399048,
      "learning_rate": 2.9561692320355586e-05,
      "loss": 0.2151,
      "step": 2136
    },
    {
      "epoch": 0.04403586659601722,
      "grad_norm": 1.2051161527633667,
      "learning_rate": 2.9560869207342168e-05,
      "loss": 0.1005,
      "step": 2140
    },
    {
      "epoch": 0.04411817662703782,
      "grad_norm": 4.892416954040527,
      "learning_rate": 2.9560046094328754e-05,
      "loss": 0.2478,
      "step": 2144
    },
    {
      "epoch": 0.04420048665805841,
      "grad_norm": 2.476168155670166,
      "learning_rate": 2.9559222981315334e-05,
      "loss": 0.2048,
      "step": 2148
    },
    {
      "epoch": 0.044282796689079,
      "grad_norm": 2.7573904991149902,
      "learning_rate": 2.955839986830192e-05,
      "loss": 0.1581,
      "step": 2152
    },
    {
      "epoch": 0.04436510672009959,
      "grad_norm": 4.404926300048828,
      "learning_rate": 2.9557576755288502e-05,
      "loss": 0.2496,
      "step": 2156
    },
    {
      "epoch": 0.04444741675112019,
      "grad_norm": 4.940144062042236,
      "learning_rate": 2.9556753642275085e-05,
      "loss": 0.2351,
      "step": 2160
    },
    {
      "epoch": 0.04452972678214078,
      "grad_norm": 5.027849197387695,
      "learning_rate": 2.9555930529261667e-05,
      "loss": 0.1904,
      "step": 2164
    },
    {
      "epoch": 0.04461203681316137,
      "grad_norm": 1.612680435180664,
      "learning_rate": 2.9555107416248253e-05,
      "loss": 0.2121,
      "step": 2168
    },
    {
      "epoch": 0.04469434684418197,
      "grad_norm": 5.410962104797363,
      "learning_rate": 2.9554284303234833e-05,
      "loss": 0.1811,
      "step": 2172
    },
    {
      "epoch": 0.04477665687520256,
      "grad_norm": 4.639338970184326,
      "learning_rate": 2.955346119022142e-05,
      "loss": 0.2978,
      "step": 2176
    },
    {
      "epoch": 0.04485896690622315,
      "grad_norm": 2.225126028060913,
      "learning_rate": 2.9552638077208e-05,
      "loss": 0.1633,
      "step": 2180
    },
    {
      "epoch": 0.04494127693724374,
      "grad_norm": 6.447282791137695,
      "learning_rate": 2.9551814964194584e-05,
      "loss": 0.2909,
      "step": 2184
    },
    {
      "epoch": 0.04502358696826434,
      "grad_norm": 1.8426481485366821,
      "learning_rate": 2.9550991851181167e-05,
      "loss": 0.2077,
      "step": 2188
    },
    {
      "epoch": 0.04510589699928493,
      "grad_norm": 4.086153507232666,
      "learning_rate": 2.9550168738167753e-05,
      "loss": 0.2255,
      "step": 2192
    },
    {
      "epoch": 0.04518820703030552,
      "grad_norm": 1.8255237340927124,
      "learning_rate": 2.9549345625154335e-05,
      "loss": 0.1567,
      "step": 2196
    },
    {
      "epoch": 0.045270517061326114,
      "grad_norm": 4.171896457672119,
      "learning_rate": 2.9548522512140918e-05,
      "loss": 0.2862,
      "step": 2200
    },
    {
      "epoch": 0.04535282709234671,
      "grad_norm": 2.061678409576416,
      "learning_rate": 2.95476993991275e-05,
      "loss": 0.1472,
      "step": 2204
    },
    {
      "epoch": 0.0454351371233673,
      "grad_norm": 4.4423747062683105,
      "learning_rate": 2.9546876286114087e-05,
      "loss": 0.2646,
      "step": 2208
    },
    {
      "epoch": 0.045517447154387894,
      "grad_norm": 4.067996025085449,
      "learning_rate": 2.9546053173100666e-05,
      "loss": 0.2691,
      "step": 2212
    },
    {
      "epoch": 0.04559975718540849,
      "grad_norm": 4.006072044372559,
      "learning_rate": 2.9545230060087252e-05,
      "loss": 0.1497,
      "step": 2216
    },
    {
      "epoch": 0.04568206721642908,
      "grad_norm": 1.4480668306350708,
      "learning_rate": 2.9544406947073834e-05,
      "loss": 0.2363,
      "step": 2220
    },
    {
      "epoch": 0.045764377247449674,
      "grad_norm": 3.5536677837371826,
      "learning_rate": 2.9543583834060417e-05,
      "loss": 0.2079,
      "step": 2224
    },
    {
      "epoch": 0.045846687278470265,
      "grad_norm": 1.3839553594589233,
      "learning_rate": 2.9542760721047e-05,
      "loss": 0.2121,
      "step": 2228
    },
    {
      "epoch": 0.04592899730949086,
      "grad_norm": 3.8706276416778564,
      "learning_rate": 2.9541937608033586e-05,
      "loss": 0.2498,
      "step": 2232
    },
    {
      "epoch": 0.046011307340511454,
      "grad_norm": 5.665101051330566,
      "learning_rate": 2.9541114495020165e-05,
      "loss": 0.216,
      "step": 2236
    },
    {
      "epoch": 0.046093617371532045,
      "grad_norm": 4.185579299926758,
      "learning_rate": 2.954029138200675e-05,
      "loss": 0.2487,
      "step": 2240
    },
    {
      "epoch": 0.04617592740255264,
      "grad_norm": 0.416862428188324,
      "learning_rate": 2.9539468268993334e-05,
      "loss": 0.1856,
      "step": 2244
    },
    {
      "epoch": 0.046258237433573234,
      "grad_norm": 3.7072267532348633,
      "learning_rate": 2.9538645155979916e-05,
      "loss": 0.1389,
      "step": 2248
    },
    {
      "epoch": 0.046340547464593825,
      "grad_norm": 9.559494018554688,
      "learning_rate": 2.95378220429665e-05,
      "loss": 0.3289,
      "step": 2252
    },
    {
      "epoch": 0.046422857495614415,
      "grad_norm": 3.8423988819122314,
      "learning_rate": 2.9536998929953085e-05,
      "loss": 0.2075,
      "step": 2256
    },
    {
      "epoch": 0.04650516752663501,
      "grad_norm": 2.3872013092041016,
      "learning_rate": 2.9536175816939664e-05,
      "loss": 0.1646,
      "step": 2260
    },
    {
      "epoch": 0.046587477557655604,
      "grad_norm": 2.1892008781433105,
      "learning_rate": 2.953535270392625e-05,
      "loss": 0.2471,
      "step": 2264
    },
    {
      "epoch": 0.046669787588676195,
      "grad_norm": 2.5553624629974365,
      "learning_rate": 2.9534529590912833e-05,
      "loss": 0.1613,
      "step": 2268
    },
    {
      "epoch": 0.04675209761969679,
      "grad_norm": 4.356565952301025,
      "learning_rate": 2.9533706477899415e-05,
      "loss": 0.1281,
      "step": 2272
    },
    {
      "epoch": 0.046834407650717384,
      "grad_norm": 2.889578104019165,
      "learning_rate": 2.9532883364885998e-05,
      "loss": 0.234,
      "step": 2276
    },
    {
      "epoch": 0.046916717681737975,
      "grad_norm": 2.1747500896453857,
      "learning_rate": 2.9532060251872584e-05,
      "loss": 0.3019,
      "step": 2280
    },
    {
      "epoch": 0.046999027712758566,
      "grad_norm": 6.3422932624816895,
      "learning_rate": 2.9531237138859167e-05,
      "loss": 0.2344,
      "step": 2284
    },
    {
      "epoch": 0.047081337743779164,
      "grad_norm": 3.765509605407715,
      "learning_rate": 2.953041402584575e-05,
      "loss": 0.1903,
      "step": 2288
    },
    {
      "epoch": 0.047163647774799755,
      "grad_norm": 4.175619602203369,
      "learning_rate": 2.9529590912832332e-05,
      "loss": 0.1626,
      "step": 2292
    },
    {
      "epoch": 0.047245957805820346,
      "grad_norm": 1.4633303880691528,
      "learning_rate": 2.9528767799818918e-05,
      "loss": 0.1993,
      "step": 2296
    },
    {
      "epoch": 0.047328267836840944,
      "grad_norm": 1.7135566473007202,
      "learning_rate": 2.9527944686805497e-05,
      "loss": 0.1826,
      "step": 2300
    },
    {
      "epoch": 0.047410577867861535,
      "grad_norm": 0.7878522276878357,
      "learning_rate": 2.9527121573792083e-05,
      "loss": 0.164,
      "step": 2304
    },
    {
      "epoch": 0.047492887898882126,
      "grad_norm": 2.993090867996216,
      "learning_rate": 2.9526298460778666e-05,
      "loss": 0.2464,
      "step": 2308
    },
    {
      "epoch": 0.04757519792990272,
      "grad_norm": 3.238872528076172,
      "learning_rate": 2.952547534776525e-05,
      "loss": 0.2353,
      "step": 2312
    },
    {
      "epoch": 0.047657507960923315,
      "grad_norm": 3.709331512451172,
      "learning_rate": 2.952465223475183e-05,
      "loss": 0.1141,
      "step": 2316
    },
    {
      "epoch": 0.047739817991943906,
      "grad_norm": 4.773221015930176,
      "learning_rate": 2.9523829121738417e-05,
      "loss": 0.2042,
      "step": 2320
    },
    {
      "epoch": 0.0478221280229645,
      "grad_norm": 1.3200544118881226,
      "learning_rate": 2.9523006008724997e-05,
      "loss": 0.1988,
      "step": 2324
    },
    {
      "epoch": 0.047904438053985095,
      "grad_norm": 1.869384765625,
      "learning_rate": 2.9522182895711583e-05,
      "loss": 0.1973,
      "step": 2328
    },
    {
      "epoch": 0.047986748085005686,
      "grad_norm": 2.81982159614563,
      "learning_rate": 2.9521359782698165e-05,
      "loss": 0.2603,
      "step": 2332
    },
    {
      "epoch": 0.04806905811602628,
      "grad_norm": 4.9923577308654785,
      "learning_rate": 2.9520536669684748e-05,
      "loss": 0.2013,
      "step": 2336
    },
    {
      "epoch": 0.04815136814704687,
      "grad_norm": 3.5511529445648193,
      "learning_rate": 2.951971355667133e-05,
      "loss": 0.161,
      "step": 2340
    },
    {
      "epoch": 0.048233678178067466,
      "grad_norm": 1.3447500467300415,
      "learning_rate": 2.9518890443657916e-05,
      "loss": 0.1195,
      "step": 2344
    },
    {
      "epoch": 0.04831598820908806,
      "grad_norm": 3.1966423988342285,
      "learning_rate": 2.9518067330644496e-05,
      "loss": 0.2236,
      "step": 2348
    },
    {
      "epoch": 0.04839829824010865,
      "grad_norm": 2.6060776710510254,
      "learning_rate": 2.9517244217631082e-05,
      "loss": 0.1938,
      "step": 2352
    },
    {
      "epoch": 0.048480608271129245,
      "grad_norm": 3.7562472820281982,
      "learning_rate": 2.9516421104617664e-05,
      "loss": 0.2155,
      "step": 2356
    },
    {
      "epoch": 0.048562918302149836,
      "grad_norm": 3.998945951461792,
      "learning_rate": 2.9515597991604247e-05,
      "loss": 0.2578,
      "step": 2360
    },
    {
      "epoch": 0.04864522833317043,
      "grad_norm": 8.098663330078125,
      "learning_rate": 2.951477487859083e-05,
      "loss": 0.2583,
      "step": 2364
    },
    {
      "epoch": 0.04872753836419102,
      "grad_norm": 3.8760459423065186,
      "learning_rate": 2.9513951765577416e-05,
      "loss": 0.3015,
      "step": 2368
    },
    {
      "epoch": 0.048809848395211616,
      "grad_norm": 4.68671989440918,
      "learning_rate": 2.9513128652563995e-05,
      "loss": 0.2437,
      "step": 2372
    },
    {
      "epoch": 0.04889215842623221,
      "grad_norm": 2.5427377223968506,
      "learning_rate": 2.951230553955058e-05,
      "loss": 0.1557,
      "step": 2376
    },
    {
      "epoch": 0.0489744684572528,
      "grad_norm": 2.3960235118865967,
      "learning_rate": 2.9511482426537164e-05,
      "loss": 0.2079,
      "step": 2380
    },
    {
      "epoch": 0.049056778488273396,
      "grad_norm": 2.459749221801758,
      "learning_rate": 2.951065931352375e-05,
      "loss": 0.2063,
      "step": 2384
    },
    {
      "epoch": 0.04913908851929399,
      "grad_norm": 5.293313026428223,
      "learning_rate": 2.950983620051033e-05,
      "loss": 0.3009,
      "step": 2388
    },
    {
      "epoch": 0.04922139855031458,
      "grad_norm": 2.4027955532073975,
      "learning_rate": 2.9509013087496915e-05,
      "loss": 0.1632,
      "step": 2392
    },
    {
      "epoch": 0.04930370858133517,
      "grad_norm": 2.468688488006592,
      "learning_rate": 2.9508189974483497e-05,
      "loss": 0.1061,
      "step": 2396
    },
    {
      "epoch": 0.04938601861235577,
      "grad_norm": 2.904458999633789,
      "learning_rate": 2.950736686147008e-05,
      "loss": 0.2322,
      "step": 2400
    },
    {
      "epoch": 0.04946832864337636,
      "grad_norm": 4.079620838165283,
      "learning_rate": 2.9506543748456663e-05,
      "loss": 0.1288,
      "step": 2404
    },
    {
      "epoch": 0.04955063867439695,
      "grad_norm": 2.289558172225952,
      "learning_rate": 2.950572063544325e-05,
      "loss": 0.1603,
      "step": 2408
    },
    {
      "epoch": 0.04963294870541754,
      "grad_norm": 5.337399959564209,
      "learning_rate": 2.9504897522429828e-05,
      "loss": 0.281,
      "step": 2412
    },
    {
      "epoch": 0.04971525873643814,
      "grad_norm": 2.152923345565796,
      "learning_rate": 2.9504074409416414e-05,
      "loss": 0.1577,
      "step": 2416
    },
    {
      "epoch": 0.04979756876745873,
      "grad_norm": 1.7117092609405518,
      "learning_rate": 2.9503251296402997e-05,
      "loss": 0.1987,
      "step": 2420
    },
    {
      "epoch": 0.04987987879847932,
      "grad_norm": 2.1471621990203857,
      "learning_rate": 2.950242818338958e-05,
      "loss": 0.375,
      "step": 2424
    },
    {
      "epoch": 0.04996218882949992,
      "grad_norm": 2.384110450744629,
      "learning_rate": 2.9501605070376162e-05,
      "loss": 0.1407,
      "step": 2428
    },
    {
      "epoch": 0.05004449886052051,
      "grad_norm": 4.028308391571045,
      "learning_rate": 2.9500781957362748e-05,
      "loss": 0.2111,
      "step": 2432
    },
    {
      "epoch": 0.0501268088915411,
      "grad_norm": 4.435291290283203,
      "learning_rate": 2.9499958844349327e-05,
      "loss": 0.2906,
      "step": 2436
    },
    {
      "epoch": 0.05020911892256169,
      "grad_norm": 2.7006940841674805,
      "learning_rate": 2.9499135731335913e-05,
      "loss": 0.2276,
      "step": 2440
    },
    {
      "epoch": 0.05029142895358229,
      "grad_norm": 4.087854385375977,
      "learning_rate": 2.9498312618322496e-05,
      "loss": 0.2611,
      "step": 2444
    },
    {
      "epoch": 0.05037373898460288,
      "grad_norm": 4.056124210357666,
      "learning_rate": 2.949748950530908e-05,
      "loss": 0.2355,
      "step": 2448
    },
    {
      "epoch": 0.05045604901562347,
      "grad_norm": 3.371742010116577,
      "learning_rate": 2.949666639229566e-05,
      "loss": 0.2098,
      "step": 2452
    },
    {
      "epoch": 0.05053835904664407,
      "grad_norm": 4.662708282470703,
      "learning_rate": 2.9495843279282247e-05,
      "loss": 0.3181,
      "step": 2456
    },
    {
      "epoch": 0.05062066907766466,
      "grad_norm": 3.2737319469451904,
      "learning_rate": 2.9495020166268826e-05,
      "loss": 0.1536,
      "step": 2460
    },
    {
      "epoch": 0.05070297910868525,
      "grad_norm": 2.8397862911224365,
      "learning_rate": 2.9494197053255412e-05,
      "loss": 0.2271,
      "step": 2464
    },
    {
      "epoch": 0.05078528913970584,
      "grad_norm": 2.86641263961792,
      "learning_rate": 2.9493373940241995e-05,
      "loss": 0.321,
      "step": 2468
    },
    {
      "epoch": 0.05086759917072644,
      "grad_norm": 2.647101640701294,
      "learning_rate": 2.9492550827228578e-05,
      "loss": 0.145,
      "step": 2472
    },
    {
      "epoch": 0.05094990920174703,
      "grad_norm": 2.889883518218994,
      "learning_rate": 2.949172771421516e-05,
      "loss": 0.1069,
      "step": 2476
    },
    {
      "epoch": 0.05103221923276762,
      "grad_norm": 2.89815616607666,
      "learning_rate": 2.9490904601201746e-05,
      "loss": 0.2434,
      "step": 2480
    },
    {
      "epoch": 0.05111452926378822,
      "grad_norm": 2.5271551609039307,
      "learning_rate": 2.949008148818833e-05,
      "loss": 0.2344,
      "step": 2484
    },
    {
      "epoch": 0.05119683929480881,
      "grad_norm": 2.8933119773864746,
      "learning_rate": 2.948925837517491e-05,
      "loss": 0.1424,
      "step": 2488
    },
    {
      "epoch": 0.0512791493258294,
      "grad_norm": 2.8898494243621826,
      "learning_rate": 2.9488435262161494e-05,
      "loss": 0.1576,
      "step": 2492
    },
    {
      "epoch": 0.05136145935684999,
      "grad_norm": 1.1051698923110962,
      "learning_rate": 2.948761214914808e-05,
      "loss": 0.1264,
      "step": 2496
    },
    {
      "epoch": 0.05144376938787059,
      "grad_norm": 1.6354235410690308,
      "learning_rate": 2.948678903613466e-05,
      "loss": 0.155,
      "step": 2500
    },
    {
      "epoch": 0.05152607941889118,
      "grad_norm": 4.208775043487549,
      "learning_rate": 2.9485965923121246e-05,
      "loss": 0.2451,
      "step": 2504
    },
    {
      "epoch": 0.05160838944991177,
      "grad_norm": 1.635228157043457,
      "learning_rate": 2.948514281010783e-05,
      "loss": 0.2105,
      "step": 2508
    },
    {
      "epoch": 0.05169069948093237,
      "grad_norm": 5.145378112792969,
      "learning_rate": 2.948431969709441e-05,
      "loss": 0.322,
      "step": 2512
    },
    {
      "epoch": 0.05177300951195296,
      "grad_norm": 3.251441478729248,
      "learning_rate": 2.9483496584080997e-05,
      "loss": 0.1883,
      "step": 2516
    },
    {
      "epoch": 0.05185531954297355,
      "grad_norm": 2.8821001052856445,
      "learning_rate": 2.948267347106758e-05,
      "loss": 0.2171,
      "step": 2520
    },
    {
      "epoch": 0.05193762957399414,
      "grad_norm": 5.4596848487854,
      "learning_rate": 2.9481850358054162e-05,
      "loss": 0.2315,
      "step": 2524
    },
    {
      "epoch": 0.05201993960501474,
      "grad_norm": 3.1129133701324463,
      "learning_rate": 2.9481027245040745e-05,
      "loss": 0.1812,
      "step": 2528
    },
    {
      "epoch": 0.05210224963603533,
      "grad_norm": 2.131826877593994,
      "learning_rate": 2.948020413202733e-05,
      "loss": 0.1811,
      "step": 2532
    },
    {
      "epoch": 0.05218455966705592,
      "grad_norm": 1.1550321578979492,
      "learning_rate": 2.947938101901391e-05,
      "loss": 0.2089,
      "step": 2536
    },
    {
      "epoch": 0.05226686969807652,
      "grad_norm": 4.114323616027832,
      "learning_rate": 2.9478557906000496e-05,
      "loss": 0.1674,
      "step": 2540
    },
    {
      "epoch": 0.05234917972909711,
      "grad_norm": 2.6289384365081787,
      "learning_rate": 2.947773479298708e-05,
      "loss": 0.2042,
      "step": 2544
    },
    {
      "epoch": 0.0524314897601177,
      "grad_norm": 2.4649498462677,
      "learning_rate": 2.947691167997366e-05,
      "loss": 0.2106,
      "step": 2548
    },
    {
      "epoch": 0.052513799791138294,
      "grad_norm": 2.3852832317352295,
      "learning_rate": 2.9476088566960244e-05,
      "loss": 0.1865,
      "step": 2552
    },
    {
      "epoch": 0.05259610982215889,
      "grad_norm": 4.334300994873047,
      "learning_rate": 2.947526545394683e-05,
      "loss": 0.1322,
      "step": 2556
    },
    {
      "epoch": 0.05267841985317948,
      "grad_norm": 2.084216833114624,
      "learning_rate": 2.947444234093341e-05,
      "loss": 0.1467,
      "step": 2560
    },
    {
      "epoch": 0.052760729884200074,
      "grad_norm": 8.180485725402832,
      "learning_rate": 2.9473619227919995e-05,
      "loss": 0.3011,
      "step": 2564
    },
    {
      "epoch": 0.05284303991522067,
      "grad_norm": 4.482117176055908,
      "learning_rate": 2.9472796114906578e-05,
      "loss": 0.1601,
      "step": 2568
    },
    {
      "epoch": 0.05292534994624126,
      "grad_norm": 4.9166646003723145,
      "learning_rate": 2.947197300189316e-05,
      "loss": 0.2282,
      "step": 2572
    },
    {
      "epoch": 0.05300765997726185,
      "grad_norm": 3.6268372535705566,
      "learning_rate": 2.9471149888879743e-05,
      "loss": 0.1662,
      "step": 2576
    },
    {
      "epoch": 0.053089970008282444,
      "grad_norm": 2.744260787963867,
      "learning_rate": 2.947032677586633e-05,
      "loss": 0.2054,
      "step": 2580
    },
    {
      "epoch": 0.05317228003930304,
      "grad_norm": 2.4602270126342773,
      "learning_rate": 2.9469503662852912e-05,
      "loss": 0.246,
      "step": 2584
    },
    {
      "epoch": 0.05325459007032363,
      "grad_norm": 4.653938293457031,
      "learning_rate": 2.9468680549839494e-05,
      "loss": 0.2515,
      "step": 2588
    },
    {
      "epoch": 0.053336900101344224,
      "grad_norm": 4.153846263885498,
      "learning_rate": 2.9467857436826077e-05,
      "loss": 0.1461,
      "step": 2592
    },
    {
      "epoch": 0.053419210132364815,
      "grad_norm": 1.8484686613082886,
      "learning_rate": 2.9467034323812663e-05,
      "loss": 0.1071,
      "step": 2596
    },
    {
      "epoch": 0.05350152016338541,
      "grad_norm": 2.6769096851348877,
      "learning_rate": 2.9466211210799242e-05,
      "loss": 0.2106,
      "step": 2600
    },
    {
      "epoch": 0.053583830194406004,
      "grad_norm": 5.545498847961426,
      "learning_rate": 2.946538809778583e-05,
      "loss": 0.2559,
      "step": 2604
    },
    {
      "epoch": 0.053666140225426595,
      "grad_norm": 2.6207621097564697,
      "learning_rate": 2.946456498477241e-05,
      "loss": 0.2261,
      "step": 2608
    },
    {
      "epoch": 0.05374845025644719,
      "grad_norm": 1.8868772983551025,
      "learning_rate": 2.9463741871758994e-05,
      "loss": 0.1363,
      "step": 2612
    },
    {
      "epoch": 0.053830760287467784,
      "grad_norm": 4.512895584106445,
      "learning_rate": 2.9462918758745576e-05,
      "loss": 0.1725,
      "step": 2616
    },
    {
      "epoch": 0.053913070318488375,
      "grad_norm": 4.40834379196167,
      "learning_rate": 2.9462095645732162e-05,
      "loss": 0.1988,
      "step": 2620
    },
    {
      "epoch": 0.053995380349508966,
      "grad_norm": 1.7868751287460327,
      "learning_rate": 2.946127253271874e-05,
      "loss": 0.1489,
      "step": 2624
    },
    {
      "epoch": 0.054077690380529564,
      "grad_norm": 3.6804087162017822,
      "learning_rate": 2.9460449419705328e-05,
      "loss": 0.159,
      "step": 2628
    },
    {
      "epoch": 0.054160000411550155,
      "grad_norm": 2.7729547023773193,
      "learning_rate": 2.945962630669191e-05,
      "loss": 0.1821,
      "step": 2632
    },
    {
      "epoch": 0.054242310442570746,
      "grad_norm": 2.1187775135040283,
      "learning_rate": 2.9458803193678493e-05,
      "loss": 0.1395,
      "step": 2636
    },
    {
      "epoch": 0.054324620473591344,
      "grad_norm": 3.9804012775421143,
      "learning_rate": 2.9457980080665075e-05,
      "loss": 0.1489,
      "step": 2640
    },
    {
      "epoch": 0.054406930504611935,
      "grad_norm": 3.455122232437134,
      "learning_rate": 2.945715696765166e-05,
      "loss": 0.1584,
      "step": 2644
    },
    {
      "epoch": 0.054489240535632526,
      "grad_norm": 3.369502067565918,
      "learning_rate": 2.945633385463824e-05,
      "loss": 0.2283,
      "step": 2648
    },
    {
      "epoch": 0.05457155056665312,
      "grad_norm": 4.633930206298828,
      "learning_rate": 2.9455510741624827e-05,
      "loss": 0.1633,
      "step": 2652
    },
    {
      "epoch": 0.054653860597673715,
      "grad_norm": 5.251204967498779,
      "learning_rate": 2.945468762861141e-05,
      "loss": 0.3071,
      "step": 2656
    },
    {
      "epoch": 0.054736170628694306,
      "grad_norm": 2.2239222526550293,
      "learning_rate": 2.9453864515597992e-05,
      "loss": 0.2134,
      "step": 2660
    },
    {
      "epoch": 0.0548184806597149,
      "grad_norm": 2.5451982021331787,
      "learning_rate": 2.9453041402584575e-05,
      "loss": 0.0868,
      "step": 2664
    },
    {
      "epoch": 0.054900790690735495,
      "grad_norm": 4.077967166900635,
      "learning_rate": 2.945221828957116e-05,
      "loss": 0.2411,
      "step": 2668
    },
    {
      "epoch": 0.054983100721756085,
      "grad_norm": 1.8873964548110962,
      "learning_rate": 2.945139517655774e-05,
      "loss": 0.1614,
      "step": 2672
    },
    {
      "epoch": 0.055065410752776676,
      "grad_norm": 9.256129264831543,
      "learning_rate": 2.9450572063544326e-05,
      "loss": 0.2092,
      "step": 2676
    },
    {
      "epoch": 0.05514772078379727,
      "grad_norm": 0.9078986048698425,
      "learning_rate": 2.944974895053091e-05,
      "loss": 0.1173,
      "step": 2680
    },
    {
      "epoch": 0.055230030814817865,
      "grad_norm": 3.8009870052337646,
      "learning_rate": 2.9448925837517495e-05,
      "loss": 0.2586,
      "step": 2684
    },
    {
      "epoch": 0.055312340845838456,
      "grad_norm": 2.0941550731658936,
      "learning_rate": 2.9448102724504074e-05,
      "loss": 0.1907,
      "step": 2688
    },
    {
      "epoch": 0.05539465087685905,
      "grad_norm": 2.779406785964966,
      "learning_rate": 2.944727961149066e-05,
      "loss": 0.215,
      "step": 2692
    },
    {
      "epoch": 0.055476960907879645,
      "grad_norm": 4.550292015075684,
      "learning_rate": 2.9446456498477243e-05,
      "loss": 0.2355,
      "step": 2696
    },
    {
      "epoch": 0.055559270938900236,
      "grad_norm": 4.450928211212158,
      "learning_rate": 2.9445633385463825e-05,
      "loss": 0.1775,
      "step": 2700
    },
    {
      "epoch": 0.05564158096992083,
      "grad_norm": 4.455554485321045,
      "learning_rate": 2.9444810272450408e-05,
      "loss": 0.3494,
      "step": 2704
    },
    {
      "epoch": 0.05572389100094142,
      "grad_norm": 4.019886016845703,
      "learning_rate": 2.9443987159436994e-05,
      "loss": 0.209,
      "step": 2708
    },
    {
      "epoch": 0.055806201031962016,
      "grad_norm": 3.088379383087158,
      "learning_rate": 2.9443164046423573e-05,
      "loss": 0.2419,
      "step": 2712
    },
    {
      "epoch": 0.05588851106298261,
      "grad_norm": 1.9313607215881348,
      "learning_rate": 2.944234093341016e-05,
      "loss": 0.1703,
      "step": 2716
    },
    {
      "epoch": 0.0559708210940032,
      "grad_norm": 1.1943739652633667,
      "learning_rate": 2.9441517820396742e-05,
      "loss": 0.2097,
      "step": 2720
    },
    {
      "epoch": 0.056053131125023796,
      "grad_norm": 3.8677186965942383,
      "learning_rate": 2.9440694707383324e-05,
      "loss": 0.2412,
      "step": 2724
    },
    {
      "epoch": 0.05613544115604439,
      "grad_norm": 3.1438422203063965,
      "learning_rate": 2.9439871594369907e-05,
      "loss": 0.2251,
      "step": 2728
    },
    {
      "epoch": 0.05621775118706498,
      "grad_norm": 5.136385440826416,
      "learning_rate": 2.9439048481356493e-05,
      "loss": 0.3669,
      "step": 2732
    },
    {
      "epoch": 0.05630006121808557,
      "grad_norm": 1.444433569908142,
      "learning_rate": 2.9438225368343072e-05,
      "loss": 0.1159,
      "step": 2736
    },
    {
      "epoch": 0.05638237124910617,
      "grad_norm": 5.574786186218262,
      "learning_rate": 2.9437402255329658e-05,
      "loss": 0.2268,
      "step": 2740
    },
    {
      "epoch": 0.05646468128012676,
      "grad_norm": 6.158182144165039,
      "learning_rate": 2.943657914231624e-05,
      "loss": 0.4141,
      "step": 2744
    },
    {
      "epoch": 0.05654699131114735,
      "grad_norm": 3.4233341217041016,
      "learning_rate": 2.9435756029302824e-05,
      "loss": 0.3242,
      "step": 2748
    },
    {
      "epoch": 0.05662930134216795,
      "grad_norm": 4.423013687133789,
      "learning_rate": 2.9434932916289406e-05,
      "loss": 0.2443,
      "step": 2752
    },
    {
      "epoch": 0.05671161137318854,
      "grad_norm": 4.885928630828857,
      "learning_rate": 2.9434109803275992e-05,
      "loss": 0.1954,
      "step": 2756
    },
    {
      "epoch": 0.05679392140420913,
      "grad_norm": 3.317047119140625,
      "learning_rate": 2.943328669026257e-05,
      "loss": 0.1315,
      "step": 2760
    },
    {
      "epoch": 0.05687623143522972,
      "grad_norm": 3.1763200759887695,
      "learning_rate": 2.9432463577249157e-05,
      "loss": 0.165,
      "step": 2764
    },
    {
      "epoch": 0.05695854146625032,
      "grad_norm": 1.876122236251831,
      "learning_rate": 2.943164046423574e-05,
      "loss": 0.1248,
      "step": 2768
    },
    {
      "epoch": 0.05704085149727091,
      "grad_norm": 2.4392659664154053,
      "learning_rate": 2.9430817351222326e-05,
      "loss": 0.1551,
      "step": 2772
    },
    {
      "epoch": 0.0571231615282915,
      "grad_norm": 3.192141056060791,
      "learning_rate": 2.9429994238208905e-05,
      "loss": 0.2085,
      "step": 2776
    },
    {
      "epoch": 0.05720547155931209,
      "grad_norm": 2.4531466960906982,
      "learning_rate": 2.942917112519549e-05,
      "loss": 0.2578,
      "step": 2780
    },
    {
      "epoch": 0.05728778159033269,
      "grad_norm": 3.73323655128479,
      "learning_rate": 2.9428348012182074e-05,
      "loss": 0.1662,
      "step": 2784
    },
    {
      "epoch": 0.05737009162135328,
      "grad_norm": 2.9739315509796143,
      "learning_rate": 2.9427524899168657e-05,
      "loss": 0.2346,
      "step": 2788
    },
    {
      "epoch": 0.05745240165237387,
      "grad_norm": 1.3753323554992676,
      "learning_rate": 2.942670178615524e-05,
      "loss": 0.2044,
      "step": 2792
    },
    {
      "epoch": 0.05753471168339447,
      "grad_norm": 3.9708924293518066,
      "learning_rate": 2.9425878673141825e-05,
      "loss": 0.2623,
      "step": 2796
    },
    {
      "epoch": 0.05761702171441506,
      "grad_norm": 3.9353952407836914,
      "learning_rate": 2.9425055560128405e-05,
      "loss": 0.109,
      "step": 2800
    },
    {
      "epoch": 0.05769933174543565,
      "grad_norm": 1.0411633253097534,
      "learning_rate": 2.942423244711499e-05,
      "loss": 0.2149,
      "step": 2804
    },
    {
      "epoch": 0.05778164177645624,
      "grad_norm": 5.687469959259033,
      "learning_rate": 2.9423409334101573e-05,
      "loss": 0.2593,
      "step": 2808
    },
    {
      "epoch": 0.05786395180747684,
      "grad_norm": 5.1924052238464355,
      "learning_rate": 2.9422586221088156e-05,
      "loss": 0.3257,
      "step": 2812
    },
    {
      "epoch": 0.05794626183849743,
      "grad_norm": 3.8403639793395996,
      "learning_rate": 2.942176310807474e-05,
      "loss": 0.2242,
      "step": 2816
    },
    {
      "epoch": 0.05802857186951802,
      "grad_norm": 3.481855630874634,
      "learning_rate": 2.9420939995061324e-05,
      "loss": 0.2599,
      "step": 2820
    },
    {
      "epoch": 0.05811088190053862,
      "grad_norm": 2.9626402854919434,
      "learning_rate": 2.9420116882047904e-05,
      "loss": 0.1639,
      "step": 2824
    },
    {
      "epoch": 0.05819319193155921,
      "grad_norm": 2.9672701358795166,
      "learning_rate": 2.941929376903449e-05,
      "loss": 0.2338,
      "step": 2828
    },
    {
      "epoch": 0.0582755019625798,
      "grad_norm": 2.8695578575134277,
      "learning_rate": 2.9418470656021072e-05,
      "loss": 0.2379,
      "step": 2832
    },
    {
      "epoch": 0.05835781199360039,
      "grad_norm": 4.242014408111572,
      "learning_rate": 2.9417647543007655e-05,
      "loss": 0.2779,
      "step": 2836
    },
    {
      "epoch": 0.05844012202462099,
      "grad_norm": 1.6475404500961304,
      "learning_rate": 2.9416824429994238e-05,
      "loss": 0.1751,
      "step": 2840
    },
    {
      "epoch": 0.05852243205564158,
      "grad_norm": 3.9438843727111816,
      "learning_rate": 2.9416001316980824e-05,
      "loss": 0.1975,
      "step": 2844
    },
    {
      "epoch": 0.05860474208666217,
      "grad_norm": 3.0049338340759277,
      "learning_rate": 2.9415178203967403e-05,
      "loss": 0.1284,
      "step": 2848
    },
    {
      "epoch": 0.05868705211768277,
      "grad_norm": 3.0560779571533203,
      "learning_rate": 2.941435509095399e-05,
      "loss": 0.2216,
      "step": 2852
    },
    {
      "epoch": 0.05876936214870336,
      "grad_norm": 1.9815632104873657,
      "learning_rate": 2.941353197794057e-05,
      "loss": 0.2223,
      "step": 2856
    },
    {
      "epoch": 0.05885167217972395,
      "grad_norm": 3.012381076812744,
      "learning_rate": 2.9412708864927154e-05,
      "loss": 0.1799,
      "step": 2860
    },
    {
      "epoch": 0.05893398221074454,
      "grad_norm": 1.6933164596557617,
      "learning_rate": 2.9411885751913737e-05,
      "loss": 0.1005,
      "step": 2864
    },
    {
      "epoch": 0.05901629224176514,
      "grad_norm": 3.650883197784424,
      "learning_rate": 2.9411062638900323e-05,
      "loss": 0.1921,
      "step": 2868
    },
    {
      "epoch": 0.05909860227278573,
      "grad_norm": 3.548400402069092,
      "learning_rate": 2.9410239525886906e-05,
      "loss": 0.2013,
      "step": 2872
    },
    {
      "epoch": 0.05918091230380632,
      "grad_norm": 4.392889499664307,
      "learning_rate": 2.9409416412873488e-05,
      "loss": 0.3141,
      "step": 2876
    },
    {
      "epoch": 0.05926322233482692,
      "grad_norm": 3.4134023189544678,
      "learning_rate": 2.940859329986007e-05,
      "loss": 0.2,
      "step": 2880
    },
    {
      "epoch": 0.05934553236584751,
      "grad_norm": 2.507709264755249,
      "learning_rate": 2.9407770186846657e-05,
      "loss": 0.2412,
      "step": 2884
    },
    {
      "epoch": 0.0594278423968681,
      "grad_norm": 2.0256776809692383,
      "learning_rate": 2.9406947073833236e-05,
      "loss": 0.1346,
      "step": 2888
    },
    {
      "epoch": 0.05951015242788869,
      "grad_norm": 4.404237747192383,
      "learning_rate": 2.9406123960819822e-05,
      "loss": 0.1736,
      "step": 2892
    },
    {
      "epoch": 0.05959246245890929,
      "grad_norm": 1.9742685556411743,
      "learning_rate": 2.9405300847806405e-05,
      "loss": 0.1233,
      "step": 2896
    },
    {
      "epoch": 0.05967477248992988,
      "grad_norm": 2.522338390350342,
      "learning_rate": 2.9404477734792987e-05,
      "loss": 0.0958,
      "step": 2900
    },
    {
      "epoch": 0.05975708252095047,
      "grad_norm": 4.227574825286865,
      "learning_rate": 2.940365462177957e-05,
      "loss": 0.1842,
      "step": 2904
    },
    {
      "epoch": 0.05983939255197107,
      "grad_norm": 2.194978952407837,
      "learning_rate": 2.9402831508766156e-05,
      "loss": 0.1214,
      "step": 2908
    },
    {
      "epoch": 0.05992170258299166,
      "grad_norm": 3.394169330596924,
      "learning_rate": 2.9402008395752735e-05,
      "loss": 0.3351,
      "step": 2912
    },
    {
      "epoch": 0.06000401261401225,
      "grad_norm": 5.754903793334961,
      "learning_rate": 2.940118528273932e-05,
      "loss": 0.3613,
      "step": 2916
    },
    {
      "epoch": 0.060086322645032844,
      "grad_norm": 4.313179969787598,
      "learning_rate": 2.9400362169725904e-05,
      "loss": 0.1672,
      "step": 2920
    },
    {
      "epoch": 0.06016863267605344,
      "grad_norm": 4.921936988830566,
      "learning_rate": 2.9399539056712487e-05,
      "loss": 0.2209,
      "step": 2924
    },
    {
      "epoch": 0.06025094270707403,
      "grad_norm": 4.737155914306641,
      "learning_rate": 2.939871594369907e-05,
      "loss": 0.1697,
      "step": 2928
    },
    {
      "epoch": 0.060333252738094624,
      "grad_norm": 4.088864326477051,
      "learning_rate": 2.9397892830685655e-05,
      "loss": 0.2895,
      "step": 2932
    },
    {
      "epoch": 0.06041556276911522,
      "grad_norm": 2.535658359527588,
      "learning_rate": 2.9397069717672234e-05,
      "loss": 0.2583,
      "step": 2936
    },
    {
      "epoch": 0.06049787280013581,
      "grad_norm": 3.3959219455718994,
      "learning_rate": 2.939624660465882e-05,
      "loss": 0.2197,
      "step": 2940
    },
    {
      "epoch": 0.060580182831156404,
      "grad_norm": 3.866347312927246,
      "learning_rate": 2.9395423491645403e-05,
      "loss": 0.1811,
      "step": 2944
    },
    {
      "epoch": 0.060662492862176995,
      "grad_norm": 1.156787633895874,
      "learning_rate": 2.9394600378631986e-05,
      "loss": 0.1484,
      "step": 2948
    },
    {
      "epoch": 0.06074480289319759,
      "grad_norm": 1.094944953918457,
      "learning_rate": 2.939377726561857e-05,
      "loss": 0.2993,
      "step": 2952
    },
    {
      "epoch": 0.060827112924218184,
      "grad_norm": 3.974430799484253,
      "learning_rate": 2.9392954152605154e-05,
      "loss": 0.1491,
      "step": 2956
    },
    {
      "epoch": 0.060909422955238775,
      "grad_norm": 0.8286460638046265,
      "learning_rate": 2.9392131039591734e-05,
      "loss": 0.224,
      "step": 2960
    },
    {
      "epoch": 0.060991732986259366,
      "grad_norm": 4.123462200164795,
      "learning_rate": 2.939130792657832e-05,
      "loss": 0.1655,
      "step": 2964
    },
    {
      "epoch": 0.061074043017279964,
      "grad_norm": 3.4712870121002197,
      "learning_rate": 2.9390484813564902e-05,
      "loss": 0.254,
      "step": 2968
    },
    {
      "epoch": 0.061156353048300555,
      "grad_norm": 4.478811740875244,
      "learning_rate": 2.938966170055149e-05,
      "loss": 0.2526,
      "step": 2972
    },
    {
      "epoch": 0.061238663079321146,
      "grad_norm": 1.094692349433899,
      "learning_rate": 2.9388838587538068e-05,
      "loss": 0.3013,
      "step": 2976
    },
    {
      "epoch": 0.061320973110341744,
      "grad_norm": 3.7784533500671387,
      "learning_rate": 2.9388015474524654e-05,
      "loss": 0.2907,
      "step": 2980
    },
    {
      "epoch": 0.061403283141362335,
      "grad_norm": 4.850219249725342,
      "learning_rate": 2.9387192361511236e-05,
      "loss": 0.2606,
      "step": 2984
    },
    {
      "epoch": 0.061485593172382925,
      "grad_norm": 4.227150917053223,
      "learning_rate": 2.938636924849782e-05,
      "loss": 0.2753,
      "step": 2988
    },
    {
      "epoch": 0.061567903203403516,
      "grad_norm": 2.953310012817383,
      "learning_rate": 2.93855461354844e-05,
      "loss": 0.2078,
      "step": 2992
    },
    {
      "epoch": 0.061650213234424114,
      "grad_norm": 2.216418981552124,
      "learning_rate": 2.9384723022470988e-05,
      "loss": 0.2625,
      "step": 2996
    },
    {
      "epoch": 0.061732523265444705,
      "grad_norm": 5.8343048095703125,
      "learning_rate": 2.9383899909457567e-05,
      "loss": 0.3682,
      "step": 3000
    },
    {
      "epoch": 0.061814833296465296,
      "grad_norm": 2.2609057426452637,
      "learning_rate": 2.9383076796444153e-05,
      "loss": 0.146,
      "step": 3004
    },
    {
      "epoch": 0.061897143327485894,
      "grad_norm": 2.886291027069092,
      "learning_rate": 2.9382253683430735e-05,
      "loss": 0.1987,
      "step": 3008
    },
    {
      "epoch": 0.061979453358506485,
      "grad_norm": 1.3896586894989014,
      "learning_rate": 2.9381430570417318e-05,
      "loss": 0.0972,
      "step": 3012
    },
    {
      "epoch": 0.062061763389527076,
      "grad_norm": 1.8023580312728882,
      "learning_rate": 2.93806074574039e-05,
      "loss": 0.2062,
      "step": 3016
    },
    {
      "epoch": 0.06214407342054767,
      "grad_norm": 3.826019048690796,
      "learning_rate": 2.9379784344390487e-05,
      "loss": 0.2082,
      "step": 3020
    },
    {
      "epoch": 0.062226383451568265,
      "grad_norm": 3.490616798400879,
      "learning_rate": 2.9378961231377066e-05,
      "loss": 0.2405,
      "step": 3024
    },
    {
      "epoch": 0.062308693482588856,
      "grad_norm": 6.0805344581604,
      "learning_rate": 2.9378138118363652e-05,
      "loss": 0.2194,
      "step": 3028
    },
    {
      "epoch": 0.06239100351360945,
      "grad_norm": 3.981804847717285,
      "learning_rate": 2.9377315005350235e-05,
      "loss": 0.2206,
      "step": 3032
    },
    {
      "epoch": 0.062473313544630045,
      "grad_norm": 3.4479098320007324,
      "learning_rate": 2.9376491892336817e-05,
      "loss": 0.1716,
      "step": 3036
    },
    {
      "epoch": 0.06255562357565063,
      "grad_norm": 5.6251606941223145,
      "learning_rate": 2.93756687793234e-05,
      "loss": 0.276,
      "step": 3040
    },
    {
      "epoch": 0.06263793360667123,
      "grad_norm": 3.32987117767334,
      "learning_rate": 2.9374845666309986e-05,
      "loss": 0.1967,
      "step": 3044
    },
    {
      "epoch": 0.06272024363769182,
      "grad_norm": 3.9485623836517334,
      "learning_rate": 2.9374022553296565e-05,
      "loss": 0.2027,
      "step": 3048
    },
    {
      "epoch": 0.06280255366871242,
      "grad_norm": 2.8928496837615967,
      "learning_rate": 2.937319944028315e-05,
      "loss": 0.1646,
      "step": 3052
    },
    {
      "epoch": 0.062884863699733,
      "grad_norm": 4.483138084411621,
      "learning_rate": 2.9372376327269737e-05,
      "loss": 0.1747,
      "step": 3056
    },
    {
      "epoch": 0.0629671737307536,
      "grad_norm": 4.619414329528809,
      "learning_rate": 2.9371553214256316e-05,
      "loss": 0.3203,
      "step": 3060
    },
    {
      "epoch": 0.06304948376177419,
      "grad_norm": 3.4434523582458496,
      "learning_rate": 2.9370730101242902e-05,
      "loss": 0.1364,
      "step": 3064
    },
    {
      "epoch": 0.06313179379279478,
      "grad_norm": 2.9864609241485596,
      "learning_rate": 2.9369906988229485e-05,
      "loss": 0.1968,
      "step": 3068
    },
    {
      "epoch": 0.06321410382381538,
      "grad_norm": 4.9704742431640625,
      "learning_rate": 2.936908387521607e-05,
      "loss": 0.3221,
      "step": 3072
    },
    {
      "epoch": 0.06329641385483598,
      "grad_norm": 1.4894262552261353,
      "learning_rate": 2.936826076220265e-05,
      "loss": 0.2195,
      "step": 3076
    },
    {
      "epoch": 0.06337872388585657,
      "grad_norm": 2.475705623626709,
      "learning_rate": 2.9367437649189236e-05,
      "loss": 0.2792,
      "step": 3080
    },
    {
      "epoch": 0.06346103391687716,
      "grad_norm": 4.004283905029297,
      "learning_rate": 2.936661453617582e-05,
      "loss": 0.1689,
      "step": 3084
    },
    {
      "epoch": 0.06354334394789775,
      "grad_norm": 3.646597385406494,
      "learning_rate": 2.93657914231624e-05,
      "loss": 0.1385,
      "step": 3088
    },
    {
      "epoch": 0.06362565397891834,
      "grad_norm": 1.9939204454421997,
      "learning_rate": 2.9364968310148984e-05,
      "loss": 0.2286,
      "step": 3092
    },
    {
      "epoch": 0.06370796400993893,
      "grad_norm": 3.848527193069458,
      "learning_rate": 2.936414519713557e-05,
      "loss": 0.2202,
      "step": 3096
    },
    {
      "epoch": 0.06379027404095954,
      "grad_norm": 3.401256561279297,
      "learning_rate": 2.936332208412215e-05,
      "loss": 0.2105,
      "step": 3100
    },
    {
      "epoch": 0.06387258407198013,
      "grad_norm": 2.767362594604492,
      "learning_rate": 2.9362498971108736e-05,
      "loss": 0.2421,
      "step": 3104
    },
    {
      "epoch": 0.06395489410300072,
      "grad_norm": 4.90130090713501,
      "learning_rate": 2.9361675858095318e-05,
      "loss": 0.2499,
      "step": 3108
    },
    {
      "epoch": 0.06403720413402131,
      "grad_norm": 4.189779281616211,
      "learning_rate": 2.93608527450819e-05,
      "loss": 0.1929,
      "step": 3112
    },
    {
      "epoch": 0.0641195141650419,
      "grad_norm": 4.34321928024292,
      "learning_rate": 2.9360029632068483e-05,
      "loss": 0.1979,
      "step": 3116
    },
    {
      "epoch": 0.06420182419606249,
      "grad_norm": 4.142274379730225,
      "learning_rate": 2.935920651905507e-05,
      "loss": 0.2233,
      "step": 3120
    },
    {
      "epoch": 0.06428413422708308,
      "grad_norm": 3.4715194702148438,
      "learning_rate": 2.935838340604165e-05,
      "loss": 0.3047,
      "step": 3124
    },
    {
      "epoch": 0.06436644425810369,
      "grad_norm": 5.039921283721924,
      "learning_rate": 2.9357560293028235e-05,
      "loss": 0.1534,
      "step": 3128
    },
    {
      "epoch": 0.06444875428912428,
      "grad_norm": 2.4915366172790527,
      "learning_rate": 2.9356737180014817e-05,
      "loss": 0.371,
      "step": 3132
    },
    {
      "epoch": 0.06453106432014487,
      "grad_norm": 4.519489288330078,
      "learning_rate": 2.93559140670014e-05,
      "loss": 0.2365,
      "step": 3136
    },
    {
      "epoch": 0.06461337435116546,
      "grad_norm": 2.611680507659912,
      "learning_rate": 2.9355090953987983e-05,
      "loss": 0.1431,
      "step": 3140
    },
    {
      "epoch": 0.06469568438218605,
      "grad_norm": 3.5769643783569336,
      "learning_rate": 2.935426784097457e-05,
      "loss": 0.258,
      "step": 3144
    },
    {
      "epoch": 0.06477799441320664,
      "grad_norm": 2.8348920345306396,
      "learning_rate": 2.9353444727961148e-05,
      "loss": 0.2456,
      "step": 3148
    },
    {
      "epoch": 0.06486030444422723,
      "grad_norm": 2.9860644340515137,
      "learning_rate": 2.9352621614947734e-05,
      "loss": 0.1755,
      "step": 3152
    },
    {
      "epoch": 0.06494261447524784,
      "grad_norm": 2.290820360183716,
      "learning_rate": 2.9351798501934317e-05,
      "loss": 0.2444,
      "step": 3156
    },
    {
      "epoch": 0.06502492450626843,
      "grad_norm": 2.8888494968414307,
      "learning_rate": 2.93509753889209e-05,
      "loss": 0.1428,
      "step": 3160
    },
    {
      "epoch": 0.06510723453728902,
      "grad_norm": 4.459498882293701,
      "learning_rate": 2.9350152275907482e-05,
      "loss": 0.2878,
      "step": 3164
    },
    {
      "epoch": 0.06518954456830961,
      "grad_norm": 3.7014148235321045,
      "learning_rate": 2.9349329162894068e-05,
      "loss": 0.2048,
      "step": 3168
    },
    {
      "epoch": 0.0652718545993302,
      "grad_norm": 4.267571926116943,
      "learning_rate": 2.934850604988065e-05,
      "loss": 0.1504,
      "step": 3172
    },
    {
      "epoch": 0.06535416463035079,
      "grad_norm": 2.003934860229492,
      "learning_rate": 2.9347682936867233e-05,
      "loss": 0.2109,
      "step": 3176
    },
    {
      "epoch": 0.06543647466137138,
      "grad_norm": 7.95536470413208,
      "learning_rate": 2.9346859823853816e-05,
      "loss": 0.3687,
      "step": 3180
    },
    {
      "epoch": 0.06551878469239199,
      "grad_norm": 3.4451253414154053,
      "learning_rate": 2.9346036710840402e-05,
      "loss": 0.2356,
      "step": 3184
    },
    {
      "epoch": 0.06560109472341258,
      "grad_norm": 1.6690503358840942,
      "learning_rate": 2.934521359782698e-05,
      "loss": 0.2127,
      "step": 3188
    },
    {
      "epoch": 0.06568340475443317,
      "grad_norm": 10.003870964050293,
      "learning_rate": 2.9344390484813567e-05,
      "loss": 0.3443,
      "step": 3192
    },
    {
      "epoch": 0.06576571478545376,
      "grad_norm": 4.134960174560547,
      "learning_rate": 2.934356737180015e-05,
      "loss": 0.1735,
      "step": 3196
    },
    {
      "epoch": 0.06584802481647435,
      "grad_norm": 1.545384168624878,
      "learning_rate": 2.9342744258786732e-05,
      "loss": 0.1548,
      "step": 3200
    },
    {
      "epoch": 0.06593033484749494,
      "grad_norm": 2.877241373062134,
      "learning_rate": 2.9341921145773315e-05,
      "loss": 0.3066,
      "step": 3204
    },
    {
      "epoch": 0.06601264487851553,
      "grad_norm": 1.7986069917678833,
      "learning_rate": 2.93410980327599e-05,
      "loss": 0.1608,
      "step": 3208
    },
    {
      "epoch": 0.06609495490953614,
      "grad_norm": 2.9254512786865234,
      "learning_rate": 2.934027491974648e-05,
      "loss": 0.1673,
      "step": 3212
    },
    {
      "epoch": 0.06617726494055673,
      "grad_norm": 1.281424641609192,
      "learning_rate": 2.9339451806733066e-05,
      "loss": 0.076,
      "step": 3216
    },
    {
      "epoch": 0.06625957497157732,
      "grad_norm": 3.3414552211761475,
      "learning_rate": 2.933862869371965e-05,
      "loss": 0.2233,
      "step": 3220
    },
    {
      "epoch": 0.06634188500259791,
      "grad_norm": 2.9732697010040283,
      "learning_rate": 2.933780558070623e-05,
      "loss": 0.2792,
      "step": 3224
    },
    {
      "epoch": 0.0664241950336185,
      "grad_norm": 4.158509731292725,
      "learning_rate": 2.9336982467692814e-05,
      "loss": 0.1378,
      "step": 3228
    },
    {
      "epoch": 0.0665065050646391,
      "grad_norm": 6.499851226806641,
      "learning_rate": 2.93361593546794e-05,
      "loss": 0.2699,
      "step": 3232
    },
    {
      "epoch": 0.06658881509565968,
      "grad_norm": 1.065902590751648,
      "learning_rate": 2.933533624166598e-05,
      "loss": 0.1881,
      "step": 3236
    },
    {
      "epoch": 0.06667112512668029,
      "grad_norm": 0.5179650783538818,
      "learning_rate": 2.9334513128652565e-05,
      "loss": 0.2126,
      "step": 3240
    },
    {
      "epoch": 0.06675343515770088,
      "grad_norm": 1.6133393049240112,
      "learning_rate": 2.9333690015639148e-05,
      "loss": 0.1644,
      "step": 3244
    },
    {
      "epoch": 0.06683574518872147,
      "grad_norm": 6.689751148223877,
      "learning_rate": 2.933286690262573e-05,
      "loss": 0.2046,
      "step": 3248
    },
    {
      "epoch": 0.06691805521974206,
      "grad_norm": 1.9498661756515503,
      "learning_rate": 2.9332043789612313e-05,
      "loss": 0.2031,
      "step": 3252
    },
    {
      "epoch": 0.06700036525076265,
      "grad_norm": 2.2429146766662598,
      "learning_rate": 2.93312206765989e-05,
      "loss": 0.1652,
      "step": 3256
    },
    {
      "epoch": 0.06708267528178324,
      "grad_norm": 2.804356575012207,
      "learning_rate": 2.9330397563585482e-05,
      "loss": 0.1655,
      "step": 3260
    },
    {
      "epoch": 0.06716498531280383,
      "grad_norm": 1.7176929712295532,
      "learning_rate": 2.9329574450572065e-05,
      "loss": 0.1382,
      "step": 3264
    },
    {
      "epoch": 0.06724729534382443,
      "grad_norm": 2.859619379043579,
      "learning_rate": 2.9328751337558647e-05,
      "loss": 0.1632,
      "step": 3268
    },
    {
      "epoch": 0.06732960537484503,
      "grad_norm": 5.39078426361084,
      "learning_rate": 2.9327928224545233e-05,
      "loss": 0.2108,
      "step": 3272
    },
    {
      "epoch": 0.06741191540586562,
      "grad_norm": 3.431110382080078,
      "learning_rate": 2.9327105111531813e-05,
      "loss": 0.3005,
      "step": 3276
    },
    {
      "epoch": 0.06749422543688621,
      "grad_norm": 3.7455499172210693,
      "learning_rate": 2.93262819985184e-05,
      "loss": 0.2071,
      "step": 3280
    },
    {
      "epoch": 0.0675765354679068,
      "grad_norm": 3.830552339553833,
      "learning_rate": 2.932545888550498e-05,
      "loss": 0.3167,
      "step": 3284
    },
    {
      "epoch": 0.0676588454989274,
      "grad_norm": 0.7116944193840027,
      "learning_rate": 2.9324635772491564e-05,
      "loss": 0.201,
      "step": 3288
    },
    {
      "epoch": 0.06774115552994799,
      "grad_norm": 3.4782018661499023,
      "learning_rate": 2.9323812659478147e-05,
      "loss": 0.2277,
      "step": 3292
    },
    {
      "epoch": 0.06782346556096858,
      "grad_norm": 2.546717643737793,
      "learning_rate": 2.9322989546464733e-05,
      "loss": 0.1735,
      "step": 3296
    },
    {
      "epoch": 0.06790577559198918,
      "grad_norm": 3.2133476734161377,
      "learning_rate": 2.9322166433451312e-05,
      "loss": 0.23,
      "step": 3300
    },
    {
      "epoch": 0.06798808562300977,
      "grad_norm": 1.8434884548187256,
      "learning_rate": 2.9321343320437898e-05,
      "loss": 0.1819,
      "step": 3304
    },
    {
      "epoch": 0.06807039565403036,
      "grad_norm": 2.387847900390625,
      "learning_rate": 2.932052020742448e-05,
      "loss": 0.2305,
      "step": 3308
    },
    {
      "epoch": 0.06815270568505095,
      "grad_norm": 3.78495717048645,
      "learning_rate": 2.9319697094411063e-05,
      "loss": 0.2756,
      "step": 3312
    },
    {
      "epoch": 0.06823501571607155,
      "grad_norm": 2.377808094024658,
      "learning_rate": 2.9318873981397646e-05,
      "loss": 0.1605,
      "step": 3316
    },
    {
      "epoch": 0.06831732574709214,
      "grad_norm": 2.7220935821533203,
      "learning_rate": 2.9318050868384232e-05,
      "loss": 0.1458,
      "step": 3320
    },
    {
      "epoch": 0.06839963577811273,
      "grad_norm": 2.502157688140869,
      "learning_rate": 2.931722775537081e-05,
      "loss": 0.2007,
      "step": 3324
    },
    {
      "epoch": 0.06848194580913333,
      "grad_norm": 8.423420906066895,
      "learning_rate": 2.9316404642357397e-05,
      "loss": 0.1903,
      "step": 3328
    },
    {
      "epoch": 0.06856425584015392,
      "grad_norm": 3.9599826335906982,
      "learning_rate": 2.931558152934398e-05,
      "loss": 0.1402,
      "step": 3332
    },
    {
      "epoch": 0.06864656587117451,
      "grad_norm": 6.555347919464111,
      "learning_rate": 2.9314758416330562e-05,
      "loss": 0.2932,
      "step": 3336
    },
    {
      "epoch": 0.0687288759021951,
      "grad_norm": 3.908775568008423,
      "learning_rate": 2.9313935303317145e-05,
      "loss": 0.2512,
      "step": 3340
    },
    {
      "epoch": 0.0688111859332157,
      "grad_norm": 3.3552727699279785,
      "learning_rate": 2.931311219030373e-05,
      "loss": 0.2888,
      "step": 3344
    },
    {
      "epoch": 0.06889349596423629,
      "grad_norm": 2.4061055183410645,
      "learning_rate": 2.931228907729031e-05,
      "loss": 0.158,
      "step": 3348
    },
    {
      "epoch": 0.06897580599525688,
      "grad_norm": 2.6168606281280518,
      "learning_rate": 2.9311465964276896e-05,
      "loss": 0.1862,
      "step": 3352
    },
    {
      "epoch": 0.06905811602627748,
      "grad_norm": 4.684395790100098,
      "learning_rate": 2.931064285126348e-05,
      "loss": 0.1735,
      "step": 3356
    },
    {
      "epoch": 0.06914042605729807,
      "grad_norm": 2.656599521636963,
      "learning_rate": 2.9309819738250065e-05,
      "loss": 0.1865,
      "step": 3360
    },
    {
      "epoch": 0.06922273608831866,
      "grad_norm": 3.5678629875183105,
      "learning_rate": 2.9308996625236644e-05,
      "loss": 0.1736,
      "step": 3364
    },
    {
      "epoch": 0.06930504611933926,
      "grad_norm": 2.8447370529174805,
      "learning_rate": 2.930817351222323e-05,
      "loss": 0.2759,
      "step": 3368
    },
    {
      "epoch": 0.06938735615035985,
      "grad_norm": 2.875119924545288,
      "learning_rate": 2.9307350399209813e-05,
      "loss": 0.197,
      "step": 3372
    },
    {
      "epoch": 0.06946966618138044,
      "grad_norm": 3.930722713470459,
      "learning_rate": 2.9306527286196395e-05,
      "loss": 0.2643,
      "step": 3376
    },
    {
      "epoch": 0.06955197621240103,
      "grad_norm": 3.466723918914795,
      "learning_rate": 2.9305704173182978e-05,
      "loss": 0.235,
      "step": 3380
    },
    {
      "epoch": 0.06963428624342163,
      "grad_norm": 2.3719284534454346,
      "learning_rate": 2.9304881060169564e-05,
      "loss": 0.3371,
      "step": 3384
    },
    {
      "epoch": 0.06971659627444222,
      "grad_norm": 3.219484329223633,
      "learning_rate": 2.9304057947156143e-05,
      "loss": 0.3151,
      "step": 3388
    },
    {
      "epoch": 0.06979890630546282,
      "grad_norm": 9.369479179382324,
      "learning_rate": 2.930323483414273e-05,
      "loss": 0.2526,
      "step": 3392
    },
    {
      "epoch": 0.0698812163364834,
      "grad_norm": 3.6309313774108887,
      "learning_rate": 2.9302411721129312e-05,
      "loss": 0.3229,
      "step": 3396
    },
    {
      "epoch": 0.069963526367504,
      "grad_norm": 3.759768486022949,
      "learning_rate": 2.9301588608115895e-05,
      "loss": 0.1701,
      "step": 3400
    },
    {
      "epoch": 0.07004583639852459,
      "grad_norm": 2.6487395763397217,
      "learning_rate": 2.9300765495102477e-05,
      "loss": 0.2179,
      "step": 3404
    },
    {
      "epoch": 0.07012814642954518,
      "grad_norm": 1.6256314516067505,
      "learning_rate": 2.9299942382089063e-05,
      "loss": 0.1224,
      "step": 3408
    },
    {
      "epoch": 0.07021045646056578,
      "grad_norm": 1.8459997177124023,
      "learning_rate": 2.9299119269075642e-05,
      "loss": 0.1654,
      "step": 3412
    },
    {
      "epoch": 0.07029276649158638,
      "grad_norm": 1.8202626705169678,
      "learning_rate": 2.929829615606223e-05,
      "loss": 0.1844,
      "step": 3416
    },
    {
      "epoch": 0.07037507652260697,
      "grad_norm": 3.6817626953125,
      "learning_rate": 2.929747304304881e-05,
      "loss": 0.2641,
      "step": 3420
    },
    {
      "epoch": 0.07045738655362756,
      "grad_norm": 3.2463560104370117,
      "learning_rate": 2.9296649930035394e-05,
      "loss": 0.2091,
      "step": 3424
    },
    {
      "epoch": 0.07053969658464815,
      "grad_norm": 2.9180243015289307,
      "learning_rate": 2.9295826817021976e-05,
      "loss": 0.2295,
      "step": 3428
    },
    {
      "epoch": 0.07062200661566874,
      "grad_norm": 3.622257947921753,
      "learning_rate": 2.9295003704008562e-05,
      "loss": 0.1613,
      "step": 3432
    },
    {
      "epoch": 0.07070431664668933,
      "grad_norm": 3.517237424850464,
      "learning_rate": 2.929418059099514e-05,
      "loss": 0.2527,
      "step": 3436
    },
    {
      "epoch": 0.07078662667770994,
      "grad_norm": 2.810192823410034,
      "learning_rate": 2.9293357477981728e-05,
      "loss": 0.1585,
      "step": 3440
    },
    {
      "epoch": 0.07086893670873053,
      "grad_norm": 3.0787763595581055,
      "learning_rate": 2.929253436496831e-05,
      "loss": 0.1666,
      "step": 3444
    },
    {
      "epoch": 0.07095124673975112,
      "grad_norm": 2.6102888584136963,
      "learning_rate": 2.9291711251954893e-05,
      "loss": 0.1471,
      "step": 3448
    },
    {
      "epoch": 0.07103355677077171,
      "grad_norm": 0.8350645303726196,
      "learning_rate": 2.9290888138941476e-05,
      "loss": 0.1475,
      "step": 3452
    },
    {
      "epoch": 0.0711158668017923,
      "grad_norm": 1.5383524894714355,
      "learning_rate": 2.929006502592806e-05,
      "loss": 0.1189,
      "step": 3456
    },
    {
      "epoch": 0.07119817683281289,
      "grad_norm": 1.6506035327911377,
      "learning_rate": 2.9289241912914644e-05,
      "loss": 0.1916,
      "step": 3460
    },
    {
      "epoch": 0.07128048686383348,
      "grad_norm": 4.076479434967041,
      "learning_rate": 2.9288418799901227e-05,
      "loss": 0.1718,
      "step": 3464
    },
    {
      "epoch": 0.07136279689485409,
      "grad_norm": 4.04267692565918,
      "learning_rate": 2.928759568688781e-05,
      "loss": 0.2115,
      "step": 3468
    },
    {
      "epoch": 0.07144510692587468,
      "grad_norm": 2.9254863262176514,
      "learning_rate": 2.9286772573874396e-05,
      "loss": 0.2017,
      "step": 3472
    },
    {
      "epoch": 0.07152741695689527,
      "grad_norm": 2.030491828918457,
      "learning_rate": 2.9285949460860975e-05,
      "loss": 0.1858,
      "step": 3476
    },
    {
      "epoch": 0.07160972698791586,
      "grad_norm": 4.029189109802246,
      "learning_rate": 2.928512634784756e-05,
      "loss": 0.1974,
      "step": 3480
    },
    {
      "epoch": 0.07169203701893645,
      "grad_norm": 2.6913671493530273,
      "learning_rate": 2.9284303234834143e-05,
      "loss": 0.2764,
      "step": 3484
    },
    {
      "epoch": 0.07177434704995704,
      "grad_norm": 4.0718817710876465,
      "learning_rate": 2.9283480121820726e-05,
      "loss": 0.2349,
      "step": 3488
    },
    {
      "epoch": 0.07185665708097763,
      "grad_norm": 4.736425876617432,
      "learning_rate": 2.928265700880731e-05,
      "loss": 0.2395,
      "step": 3492
    },
    {
      "epoch": 0.07193896711199824,
      "grad_norm": 2.542687177658081,
      "learning_rate": 2.9281833895793895e-05,
      "loss": 0.375,
      "step": 3496
    },
    {
      "epoch": 0.07202127714301883,
      "grad_norm": 2.5274062156677246,
      "learning_rate": 2.9281010782780474e-05,
      "loss": 0.2333,
      "step": 3500
    },
    {
      "epoch": 0.07210358717403942,
      "grad_norm": 2.327338933944702,
      "learning_rate": 2.928018766976706e-05,
      "loss": 0.1888,
      "step": 3504
    },
    {
      "epoch": 0.07218589720506001,
      "grad_norm": 2.043769121170044,
      "learning_rate": 2.9279364556753643e-05,
      "loss": 0.1588,
      "step": 3508
    },
    {
      "epoch": 0.0722682072360806,
      "grad_norm": 2.3275105953216553,
      "learning_rate": 2.9278541443740225e-05,
      "loss": 0.1929,
      "step": 3512
    },
    {
      "epoch": 0.07235051726710119,
      "grad_norm": 4.081077575683594,
      "learning_rate": 2.9277718330726808e-05,
      "loss": 0.2425,
      "step": 3516
    },
    {
      "epoch": 0.07243282729812178,
      "grad_norm": 3.227666139602661,
      "learning_rate": 2.9276895217713394e-05,
      "loss": 0.226,
      "step": 3520
    },
    {
      "epoch": 0.07251513732914239,
      "grad_norm": 1.8222225904464722,
      "learning_rate": 2.9276072104699973e-05,
      "loss": 0.1764,
      "step": 3524
    },
    {
      "epoch": 0.07259744736016298,
      "grad_norm": 1.1487219333648682,
      "learning_rate": 2.927524899168656e-05,
      "loss": 0.1907,
      "step": 3528
    },
    {
      "epoch": 0.07267975739118357,
      "grad_norm": 4.844520568847656,
      "learning_rate": 2.9274425878673142e-05,
      "loss": 0.219,
      "step": 3532
    },
    {
      "epoch": 0.07276206742220416,
      "grad_norm": 3.3377010822296143,
      "learning_rate": 2.9273602765659724e-05,
      "loss": 0.1826,
      "step": 3536
    },
    {
      "epoch": 0.07284437745322475,
      "grad_norm": 1.5722949504852295,
      "learning_rate": 2.9272779652646307e-05,
      "loss": 0.203,
      "step": 3540
    },
    {
      "epoch": 0.07292668748424534,
      "grad_norm": 2.8576998710632324,
      "learning_rate": 2.9271956539632893e-05,
      "loss": 0.1413,
      "step": 3544
    },
    {
      "epoch": 0.07300899751526593,
      "grad_norm": 1.839444637298584,
      "learning_rate": 2.9271133426619476e-05,
      "loss": 0.1467,
      "step": 3548
    },
    {
      "epoch": 0.07309130754628654,
      "grad_norm": 3.648792028427124,
      "learning_rate": 2.927031031360606e-05,
      "loss": 0.191,
      "step": 3552
    },
    {
      "epoch": 0.07317361757730713,
      "grad_norm": 4.820374965667725,
      "learning_rate": 2.926948720059264e-05,
      "loss": 0.2876,
      "step": 3556
    },
    {
      "epoch": 0.07325592760832772,
      "grad_norm": 2.1959686279296875,
      "learning_rate": 2.9268664087579227e-05,
      "loss": 0.1694,
      "step": 3560
    },
    {
      "epoch": 0.07333823763934831,
      "grad_norm": 3.2968862056732178,
      "learning_rate": 2.9267840974565806e-05,
      "loss": 0.2066,
      "step": 3564
    },
    {
      "epoch": 0.0734205476703689,
      "grad_norm": 6.54557466506958,
      "learning_rate": 2.9267017861552392e-05,
      "loss": 0.1613,
      "step": 3568
    },
    {
      "epoch": 0.07350285770138949,
      "grad_norm": 1.9118313789367676,
      "learning_rate": 2.9266194748538975e-05,
      "loss": 0.1479,
      "step": 3572
    },
    {
      "epoch": 0.07358516773241008,
      "grad_norm": 2.431215763092041,
      "learning_rate": 2.9265371635525558e-05,
      "loss": 0.1628,
      "step": 3576
    },
    {
      "epoch": 0.07366747776343069,
      "grad_norm": 0.7412313222885132,
      "learning_rate": 2.926454852251214e-05,
      "loss": 0.2298,
      "step": 3580
    },
    {
      "epoch": 0.07374978779445128,
      "grad_norm": 3.0620579719543457,
      "learning_rate": 2.9263725409498726e-05,
      "loss": 0.1554,
      "step": 3584
    },
    {
      "epoch": 0.07383209782547187,
      "grad_norm": 3.01739501953125,
      "learning_rate": 2.9262902296485305e-05,
      "loss": 0.1686,
      "step": 3588
    },
    {
      "epoch": 0.07391440785649246,
      "grad_norm": 2.36051607131958,
      "learning_rate": 2.926207918347189e-05,
      "loss": 0.1388,
      "step": 3592
    },
    {
      "epoch": 0.07399671788751305,
      "grad_norm": 4.614140510559082,
      "learning_rate": 2.9261256070458474e-05,
      "loss": 0.2022,
      "step": 3596
    },
    {
      "epoch": 0.07407902791853364,
      "grad_norm": 3.791046380996704,
      "learning_rate": 2.9260432957445057e-05,
      "loss": 0.2803,
      "step": 3600
    },
    {
      "epoch": 0.07416133794955423,
      "grad_norm": 2.3650805950164795,
      "learning_rate": 2.925960984443164e-05,
      "loss": 0.2244,
      "step": 3604
    },
    {
      "epoch": 0.07424364798057484,
      "grad_norm": 5.875844478607178,
      "learning_rate": 2.9258786731418225e-05,
      "loss": 0.2885,
      "step": 3608
    },
    {
      "epoch": 0.07432595801159543,
      "grad_norm": 4.252248287200928,
      "learning_rate": 2.9257963618404808e-05,
      "loss": 0.2105,
      "step": 3612
    },
    {
      "epoch": 0.07440826804261602,
      "grad_norm": 2.350069522857666,
      "learning_rate": 2.925714050539139e-05,
      "loss": 0.1804,
      "step": 3616
    },
    {
      "epoch": 0.07449057807363661,
      "grad_norm": 3.0882019996643066,
      "learning_rate": 2.9256317392377977e-05,
      "loss": 0.2818,
      "step": 3620
    },
    {
      "epoch": 0.0745728881046572,
      "grad_norm": 4.402738571166992,
      "learning_rate": 2.9255494279364556e-05,
      "loss": 0.3233,
      "step": 3624
    },
    {
      "epoch": 0.0746551981356778,
      "grad_norm": 3.6141064167022705,
      "learning_rate": 2.9254671166351142e-05,
      "loss": 0.1854,
      "step": 3628
    },
    {
      "epoch": 0.07473750816669839,
      "grad_norm": 1.8359664678573608,
      "learning_rate": 2.9253848053337725e-05,
      "loss": 0.3097,
      "step": 3632
    },
    {
      "epoch": 0.07481981819771898,
      "grad_norm": 2.2875101566314697,
      "learning_rate": 2.9253024940324307e-05,
      "loss": 0.1125,
      "step": 3636
    },
    {
      "epoch": 0.07490212822873958,
      "grad_norm": 3.2856531143188477,
      "learning_rate": 2.925220182731089e-05,
      "loss": 0.2034,
      "step": 3640
    },
    {
      "epoch": 0.07498443825976017,
      "grad_norm": 3.5614054203033447,
      "learning_rate": 2.9251378714297476e-05,
      "loss": 0.122,
      "step": 3644
    },
    {
      "epoch": 0.07506674829078076,
      "grad_norm": 0.6812973618507385,
      "learning_rate": 2.925055560128406e-05,
      "loss": 0.1972,
      "step": 3648
    },
    {
      "epoch": 0.07514905832180135,
      "grad_norm": 2.6906044483184814,
      "learning_rate": 2.924973248827064e-05,
      "loss": 0.1476,
      "step": 3652
    },
    {
      "epoch": 0.07523136835282195,
      "grad_norm": 4.104124546051025,
      "learning_rate": 2.9248909375257224e-05,
      "loss": 0.2183,
      "step": 3656
    },
    {
      "epoch": 0.07531367838384254,
      "grad_norm": 2.9223129749298096,
      "learning_rate": 2.924808626224381e-05,
      "loss": 0.1507,
      "step": 3660
    },
    {
      "epoch": 0.07539598841486313,
      "grad_norm": 1.7101939916610718,
      "learning_rate": 2.924726314923039e-05,
      "loss": 0.1611,
      "step": 3664
    },
    {
      "epoch": 0.07547829844588373,
      "grad_norm": 3.364605665206909,
      "learning_rate": 2.9246440036216975e-05,
      "loss": 0.2785,
      "step": 3668
    },
    {
      "epoch": 0.07556060847690432,
      "grad_norm": 3.597175121307373,
      "learning_rate": 2.9245616923203558e-05,
      "loss": 0.336,
      "step": 3672
    },
    {
      "epoch": 0.07564291850792491,
      "grad_norm": 3.9316532611846924,
      "learning_rate": 2.924479381019014e-05,
      "loss": 0.248,
      "step": 3676
    },
    {
      "epoch": 0.0757252285389455,
      "grad_norm": 4.125204086303711,
      "learning_rate": 2.9243970697176723e-05,
      "loss": 0.2148,
      "step": 3680
    },
    {
      "epoch": 0.0758075385699661,
      "grad_norm": 4.437196731567383,
      "learning_rate": 2.924314758416331e-05,
      "loss": 0.2914,
      "step": 3684
    },
    {
      "epoch": 0.07588984860098669,
      "grad_norm": 3.1693081855773926,
      "learning_rate": 2.9242324471149888e-05,
      "loss": 0.1625,
      "step": 3688
    },
    {
      "epoch": 0.07597215863200728,
      "grad_norm": 4.293983459472656,
      "learning_rate": 2.9241501358136474e-05,
      "loss": 0.2706,
      "step": 3692
    },
    {
      "epoch": 0.07605446866302788,
      "grad_norm": 2.097968578338623,
      "learning_rate": 2.9240678245123057e-05,
      "loss": 0.2683,
      "step": 3696
    },
    {
      "epoch": 0.07613677869404847,
      "grad_norm": 3.497936248779297,
      "learning_rate": 2.923985513210964e-05,
      "loss": 0.1714,
      "step": 3700
    },
    {
      "epoch": 0.07621908872506906,
      "grad_norm": 3.6404519081115723,
      "learning_rate": 2.9239032019096222e-05,
      "loss": 0.1739,
      "step": 3704
    },
    {
      "epoch": 0.07630139875608966,
      "grad_norm": 4.0645527839660645,
      "learning_rate": 2.9238208906082808e-05,
      "loss": 0.1388,
      "step": 3708
    },
    {
      "epoch": 0.07638370878711025,
      "grad_norm": 3.7763519287109375,
      "learning_rate": 2.9237385793069387e-05,
      "loss": 0.2605,
      "step": 3712
    },
    {
      "epoch": 0.07646601881813084,
      "grad_norm": 4.0917744636535645,
      "learning_rate": 2.9236562680055974e-05,
      "loss": 0.3105,
      "step": 3716
    },
    {
      "epoch": 0.07654832884915143,
      "grad_norm": 2.8032498359680176,
      "learning_rate": 2.9235739567042556e-05,
      "loss": 0.1547,
      "step": 3720
    },
    {
      "epoch": 0.07663063888017203,
      "grad_norm": 2.546647548675537,
      "learning_rate": 2.923491645402914e-05,
      "loss": 0.0715,
      "step": 3724
    },
    {
      "epoch": 0.07671294891119262,
      "grad_norm": 2.818263292312622,
      "learning_rate": 2.923409334101572e-05,
      "loss": 0.2341,
      "step": 3728
    },
    {
      "epoch": 0.07679525894221322,
      "grad_norm": 6.378322601318359,
      "learning_rate": 2.9233270228002307e-05,
      "loss": 0.2689,
      "step": 3732
    },
    {
      "epoch": 0.0768775689732338,
      "grad_norm": 2.946320056915283,
      "learning_rate": 2.9232447114988887e-05,
      "loss": 0.2263,
      "step": 3736
    },
    {
      "epoch": 0.0769598790042544,
      "grad_norm": 2.7079017162323,
      "learning_rate": 2.9231624001975473e-05,
      "loss": 0.2944,
      "step": 3740
    },
    {
      "epoch": 0.07704218903527499,
      "grad_norm": 3.257384777069092,
      "learning_rate": 2.9230800888962055e-05,
      "loss": 0.2321,
      "step": 3744
    },
    {
      "epoch": 0.07712449906629558,
      "grad_norm": 2.8880248069763184,
      "learning_rate": 2.922997777594864e-05,
      "loss": 0.2718,
      "step": 3748
    },
    {
      "epoch": 0.07720680909731618,
      "grad_norm": 2.4144394397735596,
      "learning_rate": 2.922915466293522e-05,
      "loss": 0.2222,
      "step": 3752
    },
    {
      "epoch": 0.07728911912833678,
      "grad_norm": 3.4918479919433594,
      "learning_rate": 2.9228331549921807e-05,
      "loss": 0.233,
      "step": 3756
    },
    {
      "epoch": 0.07737142915935737,
      "grad_norm": 3.355207681655884,
      "learning_rate": 2.922750843690839e-05,
      "loss": 0.1193,
      "step": 3760
    },
    {
      "epoch": 0.07745373919037796,
      "grad_norm": 0.9803644418716431,
      "learning_rate": 2.9226685323894972e-05,
      "loss": 0.083,
      "step": 3764
    },
    {
      "epoch": 0.07753604922139855,
      "grad_norm": 3.135093927383423,
      "learning_rate": 2.9225862210881555e-05,
      "loss": 0.2055,
      "step": 3768
    },
    {
      "epoch": 0.07761835925241914,
      "grad_norm": 3.0114328861236572,
      "learning_rate": 2.922503909786814e-05,
      "loss": 0.1187,
      "step": 3772
    },
    {
      "epoch": 0.07770066928343973,
      "grad_norm": 4.107099533081055,
      "learning_rate": 2.922421598485472e-05,
      "loss": 0.1761,
      "step": 3776
    },
    {
      "epoch": 0.07778297931446033,
      "grad_norm": 3.54232120513916,
      "learning_rate": 2.9223392871841306e-05,
      "loss": 0.1675,
      "step": 3780
    },
    {
      "epoch": 0.07786528934548093,
      "grad_norm": 2.388202428817749,
      "learning_rate": 2.922256975882789e-05,
      "loss": 0.1451,
      "step": 3784
    },
    {
      "epoch": 0.07794759937650152,
      "grad_norm": 5.267263412475586,
      "learning_rate": 2.922174664581447e-05,
      "loss": 0.2104,
      "step": 3788
    },
    {
      "epoch": 0.07802990940752211,
      "grad_norm": 4.613691806793213,
      "learning_rate": 2.9220923532801054e-05,
      "loss": 0.2855,
      "step": 3792
    },
    {
      "epoch": 0.0781122194385427,
      "grad_norm": 5.008017063140869,
      "learning_rate": 2.922010041978764e-05,
      "loss": 0.1958,
      "step": 3796
    },
    {
      "epoch": 0.07819452946956329,
      "grad_norm": 0.8964542150497437,
      "learning_rate": 2.921927730677422e-05,
      "loss": 0.1741,
      "step": 3800
    },
    {
      "epoch": 0.07827683950058388,
      "grad_norm": 5.735024929046631,
      "learning_rate": 2.9218454193760805e-05,
      "loss": 0.1375,
      "step": 3804
    },
    {
      "epoch": 0.07835914953160449,
      "grad_norm": 2.4487180709838867,
      "learning_rate": 2.9217631080747388e-05,
      "loss": 0.1184,
      "step": 3808
    },
    {
      "epoch": 0.07844145956262508,
      "grad_norm": 3.470822334289551,
      "learning_rate": 2.921680796773397e-05,
      "loss": 0.1893,
      "step": 3812
    },
    {
      "epoch": 0.07852376959364567,
      "grad_norm": 4.930121421813965,
      "learning_rate": 2.9215984854720553e-05,
      "loss": 0.1737,
      "step": 3816
    },
    {
      "epoch": 0.07860607962466626,
      "grad_norm": 1.9510023593902588,
      "learning_rate": 2.921516174170714e-05,
      "loss": 0.1669,
      "step": 3820
    },
    {
      "epoch": 0.07868838965568685,
      "grad_norm": 4.7661590576171875,
      "learning_rate": 2.9214338628693718e-05,
      "loss": 0.1884,
      "step": 3824
    },
    {
      "epoch": 0.07877069968670744,
      "grad_norm": 2.8608322143554688,
      "learning_rate": 2.9213515515680304e-05,
      "loss": 0.1313,
      "step": 3828
    },
    {
      "epoch": 0.07885300971772803,
      "grad_norm": 3.763859748840332,
      "learning_rate": 2.9212692402666887e-05,
      "loss": 0.2071,
      "step": 3832
    },
    {
      "epoch": 0.07893531974874864,
      "grad_norm": 3.463176727294922,
      "learning_rate": 2.921186928965347e-05,
      "loss": 0.14,
      "step": 3836
    },
    {
      "epoch": 0.07901762977976923,
      "grad_norm": 1.6975231170654297,
      "learning_rate": 2.9211046176640052e-05,
      "loss": 0.2202,
      "step": 3840
    },
    {
      "epoch": 0.07909993981078982,
      "grad_norm": 6.546504497528076,
      "learning_rate": 2.9210223063626638e-05,
      "loss": 0.2109,
      "step": 3844
    },
    {
      "epoch": 0.07918224984181041,
      "grad_norm": 2.7359893321990967,
      "learning_rate": 2.920939995061322e-05,
      "loss": 0.3483,
      "step": 3848
    },
    {
      "epoch": 0.079264559872831,
      "grad_norm": 2.6048755645751953,
      "learning_rate": 2.9208576837599803e-05,
      "loss": 0.1763,
      "step": 3852
    },
    {
      "epoch": 0.07934686990385159,
      "grad_norm": 3.503635883331299,
      "learning_rate": 2.9207753724586386e-05,
      "loss": 0.2723,
      "step": 3856
    },
    {
      "epoch": 0.07942917993487218,
      "grad_norm": 2.727112054824829,
      "learning_rate": 2.9206930611572972e-05,
      "loss": 0.2863,
      "step": 3860
    },
    {
      "epoch": 0.07951148996589279,
      "grad_norm": 1.308228611946106,
      "learning_rate": 2.920610749855955e-05,
      "loss": 0.1137,
      "step": 3864
    },
    {
      "epoch": 0.07959379999691338,
      "grad_norm": 2.574676990509033,
      "learning_rate": 2.9205284385546137e-05,
      "loss": 0.1616,
      "step": 3868
    },
    {
      "epoch": 0.07967611002793397,
      "grad_norm": 1.1266311407089233,
      "learning_rate": 2.920446127253272e-05,
      "loss": 0.1415,
      "step": 3872
    },
    {
      "epoch": 0.07975842005895456,
      "grad_norm": 3.2804341316223145,
      "learning_rate": 2.9203638159519303e-05,
      "loss": 0.1119,
      "step": 3876
    },
    {
      "epoch": 0.07984073008997515,
      "grad_norm": 1.9898625612258911,
      "learning_rate": 2.9202815046505885e-05,
      "loss": 0.1608,
      "step": 3880
    },
    {
      "epoch": 0.07992304012099574,
      "grad_norm": 5.9004058837890625,
      "learning_rate": 2.920199193349247e-05,
      "loss": 0.3424,
      "step": 3884
    },
    {
      "epoch": 0.08000535015201633,
      "grad_norm": 3.1668288707733154,
      "learning_rate": 2.920116882047905e-05,
      "loss": 0.2802,
      "step": 3888
    },
    {
      "epoch": 0.08008766018303694,
      "grad_norm": 5.720523834228516,
      "learning_rate": 2.9200345707465637e-05,
      "loss": 0.2465,
      "step": 3892
    },
    {
      "epoch": 0.08016997021405753,
      "grad_norm": 2.0726356506347656,
      "learning_rate": 2.919952259445222e-05,
      "loss": 0.2228,
      "step": 3896
    },
    {
      "epoch": 0.08025228024507812,
      "grad_norm": 2.9915359020233154,
      "learning_rate": 2.9198699481438802e-05,
      "loss": 0.2325,
      "step": 3900
    },
    {
      "epoch": 0.08033459027609871,
      "grad_norm": 2.1258411407470703,
      "learning_rate": 2.9197876368425384e-05,
      "loss": 0.2144,
      "step": 3904
    },
    {
      "epoch": 0.0804169003071193,
      "grad_norm": 2.2090859413146973,
      "learning_rate": 2.919705325541197e-05,
      "loss": 0.1446,
      "step": 3908
    },
    {
      "epoch": 0.08049921033813989,
      "grad_norm": 4.164085865020752,
      "learning_rate": 2.919623014239855e-05,
      "loss": 0.2204,
      "step": 3912
    },
    {
      "epoch": 0.08058152036916048,
      "grad_norm": 3.757157564163208,
      "learning_rate": 2.9195407029385136e-05,
      "loss": 0.1683,
      "step": 3916
    },
    {
      "epoch": 0.08066383040018109,
      "grad_norm": 2.4206886291503906,
      "learning_rate": 2.919458391637172e-05,
      "loss": 0.2188,
      "step": 3920
    },
    {
      "epoch": 0.08074614043120168,
      "grad_norm": 2.054926633834839,
      "learning_rate": 2.91937608033583e-05,
      "loss": 0.1544,
      "step": 3924
    },
    {
      "epoch": 0.08082845046222227,
      "grad_norm": 2.2119669914245605,
      "learning_rate": 2.9192937690344884e-05,
      "loss": 0.1468,
      "step": 3928
    },
    {
      "epoch": 0.08091076049324286,
      "grad_norm": 3.4648985862731934,
      "learning_rate": 2.919211457733147e-05,
      "loss": 0.2896,
      "step": 3932
    },
    {
      "epoch": 0.08099307052426345,
      "grad_norm": 2.9330978393554688,
      "learning_rate": 2.9191291464318052e-05,
      "loss": 0.2456,
      "step": 3936
    },
    {
      "epoch": 0.08107538055528404,
      "grad_norm": 1.644677996635437,
      "learning_rate": 2.9190468351304635e-05,
      "loss": 0.2207,
      "step": 3940
    },
    {
      "epoch": 0.08115769058630463,
      "grad_norm": 4.3226141929626465,
      "learning_rate": 2.9189645238291218e-05,
      "loss": 0.1885,
      "step": 3944
    },
    {
      "epoch": 0.08124000061732524,
      "grad_norm": 2.798656702041626,
      "learning_rate": 2.9188822125277804e-05,
      "loss": 0.1786,
      "step": 3948
    },
    {
      "epoch": 0.08132231064834583,
      "grad_norm": 1.8263486623764038,
      "learning_rate": 2.9187999012264383e-05,
      "loss": 0.1339,
      "step": 3952
    },
    {
      "epoch": 0.08140462067936642,
      "grad_norm": 2.9017250537872314,
      "learning_rate": 2.918717589925097e-05,
      "loss": 0.146,
      "step": 3956
    },
    {
      "epoch": 0.08148693071038701,
      "grad_norm": 3.53621244430542,
      "learning_rate": 2.918635278623755e-05,
      "loss": 0.2995,
      "step": 3960
    },
    {
      "epoch": 0.0815692407414076,
      "grad_norm": 3.905925989151001,
      "learning_rate": 2.9185529673224134e-05,
      "loss": 0.2032,
      "step": 3964
    },
    {
      "epoch": 0.0816515507724282,
      "grad_norm": 3.3002235889434814,
      "learning_rate": 2.9184706560210717e-05,
      "loss": 0.1162,
      "step": 3968
    },
    {
      "epoch": 0.08173386080344879,
      "grad_norm": 4.299098968505859,
      "learning_rate": 2.9183883447197303e-05,
      "loss": 0.1133,
      "step": 3972
    },
    {
      "epoch": 0.08181617083446939,
      "grad_norm": 3.742870330810547,
      "learning_rate": 2.9183060334183882e-05,
      "loss": 0.1482,
      "step": 3976
    },
    {
      "epoch": 0.08189848086548998,
      "grad_norm": 5.005033493041992,
      "learning_rate": 2.9182237221170468e-05,
      "loss": 0.28,
      "step": 3980
    },
    {
      "epoch": 0.08198079089651057,
      "grad_norm": 7.050082683563232,
      "learning_rate": 2.918141410815705e-05,
      "loss": 0.2187,
      "step": 3984
    },
    {
      "epoch": 0.08206310092753116,
      "grad_norm": 0.7928245067596436,
      "learning_rate": 2.9180590995143633e-05,
      "loss": 0.1184,
      "step": 3988
    },
    {
      "epoch": 0.08214541095855175,
      "grad_norm": 3.1891088485717773,
      "learning_rate": 2.9179767882130216e-05,
      "loss": 0.1641,
      "step": 3992
    },
    {
      "epoch": 0.08222772098957234,
      "grad_norm": 2.045647382736206,
      "learning_rate": 2.9178944769116802e-05,
      "loss": 0.1149,
      "step": 3996
    },
    {
      "epoch": 0.08231003102059294,
      "grad_norm": 3.8926308155059814,
      "learning_rate": 2.917812165610338e-05,
      "loss": 0.1716,
      "step": 4000
    },
    {
      "epoch": 0.08239234105161354,
      "grad_norm": 4.68396520614624,
      "learning_rate": 2.9177298543089967e-05,
      "loss": 0.2146,
      "step": 4004
    },
    {
      "epoch": 0.08247465108263413,
      "grad_norm": 2.8593802452087402,
      "learning_rate": 2.917647543007655e-05,
      "loss": 0.187,
      "step": 4008
    },
    {
      "epoch": 0.08255696111365472,
      "grad_norm": 4.0781073570251465,
      "learning_rate": 2.9175652317063133e-05,
      "loss": 0.2515,
      "step": 4012
    },
    {
      "epoch": 0.08263927114467531,
      "grad_norm": 5.162424564361572,
      "learning_rate": 2.9174829204049715e-05,
      "loss": 0.126,
      "step": 4016
    },
    {
      "epoch": 0.0827215811756959,
      "grad_norm": 3.579360246658325,
      "learning_rate": 2.91740060910363e-05,
      "loss": 0.1564,
      "step": 4020
    },
    {
      "epoch": 0.0828038912067165,
      "grad_norm": 6.706088066101074,
      "learning_rate": 2.917318297802288e-05,
      "loss": 0.2537,
      "step": 4024
    },
    {
      "epoch": 0.08288620123773709,
      "grad_norm": 6.9759345054626465,
      "learning_rate": 2.9172359865009466e-05,
      "loss": 0.2397,
      "step": 4028
    },
    {
      "epoch": 0.08296851126875768,
      "grad_norm": 4.348701000213623,
      "learning_rate": 2.917153675199605e-05,
      "loss": 0.2207,
      "step": 4032
    },
    {
      "epoch": 0.08305082129977828,
      "grad_norm": 4.36627721786499,
      "learning_rate": 2.9170713638982635e-05,
      "loss": 0.2621,
      "step": 4036
    },
    {
      "epoch": 0.08313313133079887,
      "grad_norm": 2.7750744819641113,
      "learning_rate": 2.9169890525969214e-05,
      "loss": 0.2793,
      "step": 4040
    },
    {
      "epoch": 0.08321544136181946,
      "grad_norm": 5.7525715827941895,
      "learning_rate": 2.91690674129558e-05,
      "loss": 0.2802,
      "step": 4044
    },
    {
      "epoch": 0.08329775139284006,
      "grad_norm": 6.998669624328613,
      "learning_rate": 2.9168244299942383e-05,
      "loss": 0.1966,
      "step": 4048
    },
    {
      "epoch": 0.08338006142386065,
      "grad_norm": 2.0367143154144287,
      "learning_rate": 2.9167421186928966e-05,
      "loss": 0.2099,
      "step": 4052
    },
    {
      "epoch": 0.08346237145488124,
      "grad_norm": 4.006913185119629,
      "learning_rate": 2.9166598073915548e-05,
      "loss": 0.2664,
      "step": 4056
    },
    {
      "epoch": 0.08354468148590183,
      "grad_norm": 4.110896110534668,
      "learning_rate": 2.9165774960902134e-05,
      "loss": 0.295,
      "step": 4060
    },
    {
      "epoch": 0.08362699151692243,
      "grad_norm": 1.8938586711883545,
      "learning_rate": 2.9164951847888714e-05,
      "loss": 0.1662,
      "step": 4064
    },
    {
      "epoch": 0.08370930154794302,
      "grad_norm": 4.971877574920654,
      "learning_rate": 2.91641287348753e-05,
      "loss": 0.133,
      "step": 4068
    },
    {
      "epoch": 0.08379161157896362,
      "grad_norm": 2.9804794788360596,
      "learning_rate": 2.9163305621861882e-05,
      "loss": 0.1538,
      "step": 4072
    },
    {
      "epoch": 0.0838739216099842,
      "grad_norm": 7.442843437194824,
      "learning_rate": 2.9162482508848465e-05,
      "loss": 0.237,
      "step": 4076
    },
    {
      "epoch": 0.0839562316410048,
      "grad_norm": 3.8297784328460693,
      "learning_rate": 2.9161659395835047e-05,
      "loss": 0.1674,
      "step": 4080
    },
    {
      "epoch": 0.08403854167202539,
      "grad_norm": 2.2575795650482178,
      "learning_rate": 2.9160836282821633e-05,
      "loss": 0.199,
      "step": 4084
    },
    {
      "epoch": 0.08412085170304598,
      "grad_norm": 2.004037857055664,
      "learning_rate": 2.9160013169808213e-05,
      "loss": 0.1118,
      "step": 4088
    },
    {
      "epoch": 0.08420316173406658,
      "grad_norm": 2.23944354057312,
      "learning_rate": 2.91591900567948e-05,
      "loss": 0.1017,
      "step": 4092
    },
    {
      "epoch": 0.08428547176508717,
      "grad_norm": 2.5932092666625977,
      "learning_rate": 2.915836694378138e-05,
      "loss": 0.3431,
      "step": 4096
    },
    {
      "epoch": 0.08436778179610777,
      "grad_norm": 2.783031463623047,
      "learning_rate": 2.9157543830767964e-05,
      "loss": 0.2164,
      "step": 4100
    },
    {
      "epoch": 0.08445009182712836,
      "grad_norm": 1.6800857782363892,
      "learning_rate": 2.9156720717754547e-05,
      "loss": 0.2812,
      "step": 4104
    },
    {
      "epoch": 0.08453240185814895,
      "grad_norm": 4.513492107391357,
      "learning_rate": 2.9155897604741133e-05,
      "loss": 0.2466,
      "step": 4108
    },
    {
      "epoch": 0.08461471188916954,
      "grad_norm": 4.308421611785889,
      "learning_rate": 2.9155074491727712e-05,
      "loss": 0.2281,
      "step": 4112
    },
    {
      "epoch": 0.08469702192019013,
      "grad_norm": 3.2352395057678223,
      "learning_rate": 2.9154251378714298e-05,
      "loss": 0.1724,
      "step": 4116
    },
    {
      "epoch": 0.08477933195121073,
      "grad_norm": 5.555069446563721,
      "learning_rate": 2.915342826570088e-05,
      "loss": 0.2879,
      "step": 4120
    },
    {
      "epoch": 0.08486164198223133,
      "grad_norm": 3.3700637817382812,
      "learning_rate": 2.9152605152687463e-05,
      "loss": 0.203,
      "step": 4124
    },
    {
      "epoch": 0.08494395201325192,
      "grad_norm": 4.306897163391113,
      "learning_rate": 2.9151782039674046e-05,
      "loss": 0.1803,
      "step": 4128
    },
    {
      "epoch": 0.08502626204427251,
      "grad_norm": 1.1185060739517212,
      "learning_rate": 2.9150958926660632e-05,
      "loss": 0.185,
      "step": 4132
    },
    {
      "epoch": 0.0851085720752931,
      "grad_norm": 1.2017515897750854,
      "learning_rate": 2.9150135813647214e-05,
      "loss": 0.1542,
      "step": 4136
    },
    {
      "epoch": 0.08519088210631369,
      "grad_norm": 5.1556596755981445,
      "learning_rate": 2.9149312700633797e-05,
      "loss": 0.2169,
      "step": 4140
    },
    {
      "epoch": 0.08527319213733428,
      "grad_norm": 2.1103146076202393,
      "learning_rate": 2.914848958762038e-05,
      "loss": 0.1217,
      "step": 4144
    },
    {
      "epoch": 0.08535550216835489,
      "grad_norm": 2.6089062690734863,
      "learning_rate": 2.9147666474606966e-05,
      "loss": 0.1712,
      "step": 4148
    },
    {
      "epoch": 0.08543781219937548,
      "grad_norm": 0.836816668510437,
      "learning_rate": 2.9146843361593545e-05,
      "loss": 0.0975,
      "step": 4152
    },
    {
      "epoch": 0.08552012223039607,
      "grad_norm": 2.958997964859009,
      "learning_rate": 2.914602024858013e-05,
      "loss": 0.1847,
      "step": 4156
    },
    {
      "epoch": 0.08560243226141666,
      "grad_norm": 2.0277159214019775,
      "learning_rate": 2.9145197135566714e-05,
      "loss": 0.0783,
      "step": 4160
    },
    {
      "epoch": 0.08568474229243725,
      "grad_norm": 3.566011428833008,
      "learning_rate": 2.9144374022553296e-05,
      "loss": 0.1857,
      "step": 4164
    },
    {
      "epoch": 0.08576705232345784,
      "grad_norm": 2.128107786178589,
      "learning_rate": 2.9143550909539882e-05,
      "loss": 0.1639,
      "step": 4168
    },
    {
      "epoch": 0.08584936235447843,
      "grad_norm": 4.88594913482666,
      "learning_rate": 2.9142933574779816e-05,
      "loss": 0.2813,
      "step": 4172
    },
    {
      "epoch": 0.08593167238549904,
      "grad_norm": 1.3318198919296265,
      "learning_rate": 2.9142110461766402e-05,
      "loss": 0.2548,
      "step": 4176
    },
    {
      "epoch": 0.08601398241651963,
      "grad_norm": 6.432431697845459,
      "learning_rate": 2.9141287348752985e-05,
      "loss": 0.2621,
      "step": 4180
    },
    {
      "epoch": 0.08609629244754022,
      "grad_norm": 4.859138011932373,
      "learning_rate": 2.914046423573957e-05,
      "loss": 0.1743,
      "step": 4184
    },
    {
      "epoch": 0.08617860247856081,
      "grad_norm": 2.1127469539642334,
      "learning_rate": 2.913964112272615e-05,
      "loss": 0.2451,
      "step": 4188
    },
    {
      "epoch": 0.0862609125095814,
      "grad_norm": 5.556999206542969,
      "learning_rate": 2.9138818009712736e-05,
      "loss": 0.4372,
      "step": 4192
    },
    {
      "epoch": 0.08634322254060199,
      "grad_norm": 4.618354320526123,
      "learning_rate": 2.913799489669932e-05,
      "loss": 0.2126,
      "step": 4196
    },
    {
      "epoch": 0.08642553257162258,
      "grad_norm": 1.6364612579345703,
      "learning_rate": 2.91371717836859e-05,
      "loss": 0.1407,
      "step": 4200
    },
    {
      "epoch": 0.08650784260264319,
      "grad_norm": 3.0511364936828613,
      "learning_rate": 2.9136348670672484e-05,
      "loss": 0.2049,
      "step": 4204
    },
    {
      "epoch": 0.08659015263366378,
      "grad_norm": 2.7189743518829346,
      "learning_rate": 2.913552555765907e-05,
      "loss": 0.3406,
      "step": 4208
    },
    {
      "epoch": 0.08667246266468437,
      "grad_norm": 3.292597532272339,
      "learning_rate": 2.913470244464565e-05,
      "loss": 0.2583,
      "step": 4212
    },
    {
      "epoch": 0.08675477269570496,
      "grad_norm": 2.5492172241210938,
      "learning_rate": 2.9133879331632235e-05,
      "loss": 0.1429,
      "step": 4216
    },
    {
      "epoch": 0.08683708272672555,
      "grad_norm": 1.8623034954071045,
      "learning_rate": 2.9133056218618818e-05,
      "loss": 0.2227,
      "step": 4220
    },
    {
      "epoch": 0.08691939275774614,
      "grad_norm": 4.033331871032715,
      "learning_rate": 2.91322331056054e-05,
      "loss": 0.1862,
      "step": 4224
    },
    {
      "epoch": 0.08700170278876673,
      "grad_norm": 3.4423580169677734,
      "learning_rate": 2.9131409992591983e-05,
      "loss": 0.1963,
      "step": 4228
    },
    {
      "epoch": 0.08708401281978734,
      "grad_norm": 2.7819340229034424,
      "learning_rate": 2.913058687957857e-05,
      "loss": 0.2227,
      "step": 4232
    },
    {
      "epoch": 0.08716632285080793,
      "grad_norm": 3.371857166290283,
      "learning_rate": 2.9129763766565148e-05,
      "loss": 0.1952,
      "step": 4236
    },
    {
      "epoch": 0.08724863288182852,
      "grad_norm": 4.097681999206543,
      "learning_rate": 2.9128940653551734e-05,
      "loss": 0.127,
      "step": 4240
    },
    {
      "epoch": 0.08733094291284911,
      "grad_norm": 1.570418119430542,
      "learning_rate": 2.9128117540538317e-05,
      "loss": 0.1013,
      "step": 4244
    },
    {
      "epoch": 0.0874132529438697,
      "grad_norm": 3.067967414855957,
      "learning_rate": 2.91272944275249e-05,
      "loss": 0.1267,
      "step": 4248
    },
    {
      "epoch": 0.08749556297489029,
      "grad_norm": 2.742635726928711,
      "learning_rate": 2.9126471314511482e-05,
      "loss": 0.1561,
      "step": 4252
    },
    {
      "epoch": 0.08757787300591088,
      "grad_norm": 4.573103904724121,
      "learning_rate": 2.9125648201498068e-05,
      "loss": 0.2041,
      "step": 4256
    },
    {
      "epoch": 0.08766018303693149,
      "grad_norm": 3.1662302017211914,
      "learning_rate": 2.9124825088484647e-05,
      "loss": 0.1553,
      "step": 4260
    },
    {
      "epoch": 0.08774249306795208,
      "grad_norm": 1.9627699851989746,
      "learning_rate": 2.9124001975471233e-05,
      "loss": 0.2375,
      "step": 4264
    },
    {
      "epoch": 0.08782480309897267,
      "grad_norm": 1.7147630453109741,
      "learning_rate": 2.9123178862457816e-05,
      "loss": 0.1554,
      "step": 4268
    },
    {
      "epoch": 0.08790711312999326,
      "grad_norm": 2.0498929023742676,
      "learning_rate": 2.91223557494444e-05,
      "loss": 0.2187,
      "step": 4272
    },
    {
      "epoch": 0.08798942316101385,
      "grad_norm": 7.07098913192749,
      "learning_rate": 2.912153263643098e-05,
      "loss": 0.3791,
      "step": 4276
    },
    {
      "epoch": 0.08807173319203444,
      "grad_norm": 2.189319610595703,
      "learning_rate": 2.9120709523417567e-05,
      "loss": 0.1802,
      "step": 4280
    },
    {
      "epoch": 0.08815404322305503,
      "grad_norm": 3.5804672241210938,
      "learning_rate": 2.911988641040415e-05,
      "loss": 0.2413,
      "step": 4284
    },
    {
      "epoch": 0.08823635325407564,
      "grad_norm": 4.291969299316406,
      "learning_rate": 2.9119063297390733e-05,
      "loss": 0.3222,
      "step": 4288
    },
    {
      "epoch": 0.08831866328509623,
      "grad_norm": 4.313268184661865,
      "learning_rate": 2.9118240184377315e-05,
      "loss": 0.2328,
      "step": 4292
    },
    {
      "epoch": 0.08840097331611682,
      "grad_norm": 3.294964075088501,
      "learning_rate": 2.91174170713639e-05,
      "loss": 0.2764,
      "step": 4296
    },
    {
      "epoch": 0.08848328334713741,
      "grad_norm": 3.31783390045166,
      "learning_rate": 2.911659395835048e-05,
      "loss": 0.1598,
      "step": 4300
    },
    {
      "epoch": 0.088565593378158,
      "grad_norm": 4.745218753814697,
      "learning_rate": 2.9115770845337067e-05,
      "loss": 0.3045,
      "step": 4304
    },
    {
      "epoch": 0.0886479034091786,
      "grad_norm": 2.705794334411621,
      "learning_rate": 2.911494773232365e-05,
      "loss": 0.1432,
      "step": 4308
    },
    {
      "epoch": 0.08873021344019918,
      "grad_norm": 2.9715192317962646,
      "learning_rate": 2.9114124619310232e-05,
      "loss": 0.1917,
      "step": 4312
    },
    {
      "epoch": 0.08881252347121979,
      "grad_norm": 5.8095831871032715,
      "learning_rate": 2.9113301506296814e-05,
      "loss": 0.1402,
      "step": 4316
    },
    {
      "epoch": 0.08889483350224038,
      "grad_norm": 2.292820453643799,
      "learning_rate": 2.91124783932834e-05,
      "loss": 0.0839,
      "step": 4320
    },
    {
      "epoch": 0.08897714353326097,
      "grad_norm": 1.6739941835403442,
      "learning_rate": 2.911165528026998e-05,
      "loss": 0.1554,
      "step": 4324
    },
    {
      "epoch": 0.08905945356428156,
      "grad_norm": 5.922647476196289,
      "learning_rate": 2.9110832167256566e-05,
      "loss": 0.1834,
      "step": 4328
    },
    {
      "epoch": 0.08914176359530215,
      "grad_norm": 4.4636430740356445,
      "learning_rate": 2.911000905424315e-05,
      "loss": 0.2209,
      "step": 4332
    },
    {
      "epoch": 0.08922407362632274,
      "grad_norm": 3.7776904106140137,
      "learning_rate": 2.910918594122973e-05,
      "loss": 0.2036,
      "step": 4336
    },
    {
      "epoch": 0.08930638365734334,
      "grad_norm": 3.399146318435669,
      "learning_rate": 2.9108362828216314e-05,
      "loss": 0.1551,
      "step": 4340
    },
    {
      "epoch": 0.08938869368836394,
      "grad_norm": 4.629281997680664,
      "learning_rate": 2.91075397152029e-05,
      "loss": 0.1817,
      "step": 4344
    },
    {
      "epoch": 0.08947100371938453,
      "grad_norm": 4.076229572296143,
      "learning_rate": 2.910671660218948e-05,
      "loss": 0.1438,
      "step": 4348
    },
    {
      "epoch": 0.08955331375040512,
      "grad_norm": 3.223811388015747,
      "learning_rate": 2.9105893489176065e-05,
      "loss": 0.1982,
      "step": 4352
    },
    {
      "epoch": 0.08963562378142571,
      "grad_norm": 4.045995235443115,
      "learning_rate": 2.9105070376162648e-05,
      "loss": 0.2653,
      "step": 4356
    },
    {
      "epoch": 0.0897179338124463,
      "grad_norm": 5.509838581085205,
      "learning_rate": 2.910424726314923e-05,
      "loss": 0.201,
      "step": 4360
    },
    {
      "epoch": 0.0898002438434669,
      "grad_norm": 1.3312076330184937,
      "learning_rate": 2.9103424150135813e-05,
      "loss": 0.1207,
      "step": 4364
    },
    {
      "epoch": 0.08988255387448749,
      "grad_norm": 4.76387357711792,
      "learning_rate": 2.91026010371224e-05,
      "loss": 0.2402,
      "step": 4368
    },
    {
      "epoch": 0.08996486390550809,
      "grad_norm": 4.235236167907715,
      "learning_rate": 2.910177792410898e-05,
      "loss": 0.2934,
      "step": 4372
    },
    {
      "epoch": 0.09004717393652868,
      "grad_norm": 2.486865520477295,
      "learning_rate": 2.9100954811095564e-05,
      "loss": 0.1388,
      "step": 4376
    },
    {
      "epoch": 0.09012948396754927,
      "grad_norm": 0.8809165954589844,
      "learning_rate": 2.9100131698082147e-05,
      "loss": 0.1791,
      "step": 4380
    },
    {
      "epoch": 0.09021179399856986,
      "grad_norm": 4.90332555770874,
      "learning_rate": 2.9099308585068733e-05,
      "loss": 0.1837,
      "step": 4384
    },
    {
      "epoch": 0.09029410402959046,
      "grad_norm": 2.5086100101470947,
      "learning_rate": 2.9098485472055312e-05,
      "loss": 0.1141,
      "step": 4388
    },
    {
      "epoch": 0.09037641406061105,
      "grad_norm": 3.556950807571411,
      "learning_rate": 2.9097662359041898e-05,
      "loss": 0.2368,
      "step": 4392
    },
    {
      "epoch": 0.09045872409163164,
      "grad_norm": 1.4075571298599243,
      "learning_rate": 2.909683924602848e-05,
      "loss": 0.256,
      "step": 4396
    },
    {
      "epoch": 0.09054103412265223,
      "grad_norm": 3.2817108631134033,
      "learning_rate": 2.9096016133015063e-05,
      "loss": 0.1505,
      "step": 4400
    },
    {
      "epoch": 0.09062334415367283,
      "grad_norm": 2.460705280303955,
      "learning_rate": 2.9095193020001646e-05,
      "loss": 0.1735,
      "step": 4404
    },
    {
      "epoch": 0.09070565418469342,
      "grad_norm": 2.3059282302856445,
      "learning_rate": 2.9094369906988232e-05,
      "loss": 0.273,
      "step": 4408
    },
    {
      "epoch": 0.09078796421571401,
      "grad_norm": 3.48378586769104,
      "learning_rate": 2.909354679397481e-05,
      "loss": 0.2024,
      "step": 4412
    },
    {
      "epoch": 0.0908702742467346,
      "grad_norm": 2.3493611812591553,
      "learning_rate": 2.9092723680961397e-05,
      "loss": 0.1036,
      "step": 4416
    },
    {
      "epoch": 0.0909525842777552,
      "grad_norm": 9.713871955871582,
      "learning_rate": 2.909190056794798e-05,
      "loss": 0.2057,
      "step": 4420
    },
    {
      "epoch": 0.09103489430877579,
      "grad_norm": 5.636959552764893,
      "learning_rate": 2.9091077454934563e-05,
      "loss": 0.21,
      "step": 4424
    },
    {
      "epoch": 0.09111720433979638,
      "grad_norm": 2.3342697620391846,
      "learning_rate": 2.9090254341921145e-05,
      "loss": 0.1714,
      "step": 4428
    },
    {
      "epoch": 0.09119951437081698,
      "grad_norm": 2.293586015701294,
      "learning_rate": 2.908943122890773e-05,
      "loss": 0.2466,
      "step": 4432
    },
    {
      "epoch": 0.09128182440183757,
      "grad_norm": 2.7374207973480225,
      "learning_rate": 2.908860811589431e-05,
      "loss": 0.1728,
      "step": 4436
    },
    {
      "epoch": 0.09136413443285817,
      "grad_norm": 3.5756540298461914,
      "learning_rate": 2.9087785002880896e-05,
      "loss": 0.2267,
      "step": 4440
    },
    {
      "epoch": 0.09144644446387876,
      "grad_norm": 8.877321243286133,
      "learning_rate": 2.908696188986748e-05,
      "loss": 0.1895,
      "step": 4444
    },
    {
      "epoch": 0.09152875449489935,
      "grad_norm": 1.6029236316680908,
      "learning_rate": 2.9086138776854062e-05,
      "loss": 0.1122,
      "step": 4448
    },
    {
      "epoch": 0.09161106452591994,
      "grad_norm": 3.5597386360168457,
      "learning_rate": 2.9085315663840644e-05,
      "loss": 0.2969,
      "step": 4452
    },
    {
      "epoch": 0.09169337455694053,
      "grad_norm": 0.5598472356796265,
      "learning_rate": 2.908449255082723e-05,
      "loss": 0.0874,
      "step": 4456
    },
    {
      "epoch": 0.09177568458796113,
      "grad_norm": 4.676029205322266,
      "learning_rate": 2.908366943781381e-05,
      "loss": 0.2541,
      "step": 4460
    },
    {
      "epoch": 0.09185799461898173,
      "grad_norm": 3.223513126373291,
      "learning_rate": 2.9082846324800396e-05,
      "loss": 0.2128,
      "step": 4464
    },
    {
      "epoch": 0.09194030465000232,
      "grad_norm": 4.493041515350342,
      "learning_rate": 2.908202321178698e-05,
      "loss": 0.2733,
      "step": 4468
    },
    {
      "epoch": 0.09202261468102291,
      "grad_norm": 1.8594872951507568,
      "learning_rate": 2.9081200098773564e-05,
      "loss": 0.1362,
      "step": 4472
    },
    {
      "epoch": 0.0921049247120435,
      "grad_norm": 4.098476886749268,
      "learning_rate": 2.9080376985760144e-05,
      "loss": 0.2049,
      "step": 4476
    },
    {
      "epoch": 0.09218723474306409,
      "grad_norm": 2.66329288482666,
      "learning_rate": 2.907955387274673e-05,
      "loss": 0.2961,
      "step": 4480
    },
    {
      "epoch": 0.09226954477408468,
      "grad_norm": 3.78948974609375,
      "learning_rate": 2.9078730759733312e-05,
      "loss": 0.2889,
      "step": 4484
    },
    {
      "epoch": 0.09235185480510529,
      "grad_norm": 1.945991039276123,
      "learning_rate": 2.9077907646719895e-05,
      "loss": 0.2079,
      "step": 4488
    },
    {
      "epoch": 0.09243416483612588,
      "grad_norm": 5.0040788650512695,
      "learning_rate": 2.9077084533706478e-05,
      "loss": 0.1447,
      "step": 4492
    },
    {
      "epoch": 0.09251647486714647,
      "grad_norm": 2.857161521911621,
      "learning_rate": 2.9076261420693064e-05,
      "loss": 0.1837,
      "step": 4496
    },
    {
      "epoch": 0.09259878489816706,
      "grad_norm": 3.2540228366851807,
      "learning_rate": 2.9075438307679643e-05,
      "loss": 0.1906,
      "step": 4500
    },
    {
      "epoch": 0.09268109492918765,
      "grad_norm": 3.979529857635498,
      "learning_rate": 2.907461519466623e-05,
      "loss": 0.2126,
      "step": 4504
    },
    {
      "epoch": 0.09276340496020824,
      "grad_norm": 3.3997385501861572,
      "learning_rate": 2.907379208165281e-05,
      "loss": 0.1631,
      "step": 4508
    },
    {
      "epoch": 0.09284571499122883,
      "grad_norm": 5.664732456207275,
      "learning_rate": 2.9072968968639394e-05,
      "loss": 0.2565,
      "step": 4512
    },
    {
      "epoch": 0.09292802502224944,
      "grad_norm": 3.603647232055664,
      "learning_rate": 2.9072145855625977e-05,
      "loss": 0.2548,
      "step": 4516
    },
    {
      "epoch": 0.09301033505327003,
      "grad_norm": 4.969916343688965,
      "learning_rate": 2.9071322742612563e-05,
      "loss": 0.1589,
      "step": 4520
    },
    {
      "epoch": 0.09309264508429062,
      "grad_norm": 3.509202480316162,
      "learning_rate": 2.9070499629599142e-05,
      "loss": 0.2205,
      "step": 4524
    },
    {
      "epoch": 0.09317495511531121,
      "grad_norm": 2.69004487991333,
      "learning_rate": 2.9069676516585728e-05,
      "loss": 0.1365,
      "step": 4528
    },
    {
      "epoch": 0.0932572651463318,
      "grad_norm": 2.906144380569458,
      "learning_rate": 2.906885340357231e-05,
      "loss": 0.1836,
      "step": 4532
    },
    {
      "epoch": 0.09333957517735239,
      "grad_norm": 4.744387626647949,
      "learning_rate": 2.9068030290558893e-05,
      "loss": 0.2355,
      "step": 4536
    },
    {
      "epoch": 0.09342188520837298,
      "grad_norm": 2.7729930877685547,
      "learning_rate": 2.9067207177545476e-05,
      "loss": 0.1747,
      "step": 4540
    },
    {
      "epoch": 0.09350419523939359,
      "grad_norm": 3.599212408065796,
      "learning_rate": 2.9066384064532062e-05,
      "loss": 0.2078,
      "step": 4544
    },
    {
      "epoch": 0.09358650527041418,
      "grad_norm": 2.4040799140930176,
      "learning_rate": 2.906556095151864e-05,
      "loss": 0.1728,
      "step": 4548
    },
    {
      "epoch": 0.09366881530143477,
      "grad_norm": 6.501150608062744,
      "learning_rate": 2.9064737838505227e-05,
      "loss": 0.1732,
      "step": 4552
    },
    {
      "epoch": 0.09375112533245536,
      "grad_norm": 1.1725598573684692,
      "learning_rate": 2.906391472549181e-05,
      "loss": 0.254,
      "step": 4556
    },
    {
      "epoch": 0.09383343536347595,
      "grad_norm": 4.963306427001953,
      "learning_rate": 2.9063091612478392e-05,
      "loss": 0.3084,
      "step": 4560
    },
    {
      "epoch": 0.09391574539449654,
      "grad_norm": 4.921037673950195,
      "learning_rate": 2.9062268499464975e-05,
      "loss": 0.1813,
      "step": 4564
    },
    {
      "epoch": 0.09399805542551713,
      "grad_norm": 3.323596954345703,
      "learning_rate": 2.906144538645156e-05,
      "loss": 0.1471,
      "step": 4568
    },
    {
      "epoch": 0.09408036545653774,
      "grad_norm": 4.63095760345459,
      "learning_rate": 2.9060622273438144e-05,
      "loss": 0.24,
      "step": 4572
    },
    {
      "epoch": 0.09416267548755833,
      "grad_norm": 3.098975658416748,
      "learning_rate": 2.9059799160424726e-05,
      "loss": 0.1338,
      "step": 4576
    },
    {
      "epoch": 0.09424498551857892,
      "grad_norm": 4.997817516326904,
      "learning_rate": 2.905897604741131e-05,
      "loss": 0.1613,
      "step": 4580
    },
    {
      "epoch": 0.09432729554959951,
      "grad_norm": 3.8745522499084473,
      "learning_rate": 2.9058152934397895e-05,
      "loss": 0.1749,
      "step": 4584
    },
    {
      "epoch": 0.0944096055806201,
      "grad_norm": 5.273826599121094,
      "learning_rate": 2.9057329821384478e-05,
      "loss": 0.2038,
      "step": 4588
    },
    {
      "epoch": 0.09449191561164069,
      "grad_norm": 6.209875583648682,
      "learning_rate": 2.905650670837106e-05,
      "loss": 0.2948,
      "step": 4592
    },
    {
      "epoch": 0.09457422564266128,
      "grad_norm": 3.488166570663452,
      "learning_rate": 2.9055683595357646e-05,
      "loss": 0.211,
      "step": 4596
    },
    {
      "epoch": 0.09465653567368189,
      "grad_norm": 2.3379194736480713,
      "learning_rate": 2.9054860482344226e-05,
      "loss": 0.207,
      "step": 4600
    },
    {
      "epoch": 0.09473884570470248,
      "grad_norm": 3.8035569190979004,
      "learning_rate": 2.905403736933081e-05,
      "loss": 0.2115,
      "step": 4604
    },
    {
      "epoch": 0.09482115573572307,
      "grad_norm": 4.161762714385986,
      "learning_rate": 2.9053214256317394e-05,
      "loss": 0.2248,
      "step": 4608
    },
    {
      "epoch": 0.09490346576674366,
      "grad_norm": 1.3037179708480835,
      "learning_rate": 2.9052391143303977e-05,
      "loss": 0.1728,
      "step": 4612
    },
    {
      "epoch": 0.09498577579776425,
      "grad_norm": 3.330632448196411,
      "learning_rate": 2.905156803029056e-05,
      "loss": 0.1554,
      "step": 4616
    },
    {
      "epoch": 0.09506808582878484,
      "grad_norm": 3.260706901550293,
      "learning_rate": 2.9050744917277146e-05,
      "loss": 0.1261,
      "step": 4620
    },
    {
      "epoch": 0.09515039585980543,
      "grad_norm": 3.307729721069336,
      "learning_rate": 2.9049921804263725e-05,
      "loss": 0.0978,
      "step": 4624
    },
    {
      "epoch": 0.09523270589082604,
      "grad_norm": 1.1945858001708984,
      "learning_rate": 2.904909869125031e-05,
      "loss": 0.2957,
      "step": 4628
    },
    {
      "epoch": 0.09531501592184663,
      "grad_norm": 5.279629707336426,
      "learning_rate": 2.9048275578236893e-05,
      "loss": 0.1874,
      "step": 4632
    },
    {
      "epoch": 0.09539732595286722,
      "grad_norm": 4.02772331237793,
      "learning_rate": 2.9047452465223476e-05,
      "loss": 0.2306,
      "step": 4636
    },
    {
      "epoch": 0.09547963598388781,
      "grad_norm": 3.2464394569396973,
      "learning_rate": 2.904662935221006e-05,
      "loss": 0.2582,
      "step": 4640
    },
    {
      "epoch": 0.0955619460149084,
      "grad_norm": 3.1130104064941406,
      "learning_rate": 2.9045806239196645e-05,
      "loss": 0.1253,
      "step": 4644
    },
    {
      "epoch": 0.095644256045929,
      "grad_norm": 6.032740116119385,
      "learning_rate": 2.9044983126183224e-05,
      "loss": 0.2224,
      "step": 4648
    },
    {
      "epoch": 0.09572656607694958,
      "grad_norm": 2.39851713180542,
      "learning_rate": 2.904416001316981e-05,
      "loss": 0.2162,
      "step": 4652
    },
    {
      "epoch": 0.09580887610797019,
      "grad_norm": 3.470148801803589,
      "learning_rate": 2.9043336900156393e-05,
      "loss": 0.1714,
      "step": 4656
    },
    {
      "epoch": 0.09589118613899078,
      "grad_norm": 3.041318655014038,
      "learning_rate": 2.9042513787142975e-05,
      "loss": 0.1907,
      "step": 4660
    },
    {
      "epoch": 0.09597349617001137,
      "grad_norm": 3.6121037006378174,
      "learning_rate": 2.9041690674129558e-05,
      "loss": 0.248,
      "step": 4664
    },
    {
      "epoch": 0.09605580620103196,
      "grad_norm": 3.3990185260772705,
      "learning_rate": 2.9040867561116144e-05,
      "loss": 0.2178,
      "step": 4668
    },
    {
      "epoch": 0.09613811623205255,
      "grad_norm": 2.491018295288086,
      "learning_rate": 2.9040044448102727e-05,
      "loss": 0.1558,
      "step": 4672
    },
    {
      "epoch": 0.09622042626307314,
      "grad_norm": 9.656523704528809,
      "learning_rate": 2.903922133508931e-05,
      "loss": 0.2332,
      "step": 4676
    },
    {
      "epoch": 0.09630273629409374,
      "grad_norm": 2.3634092807769775,
      "learning_rate": 2.9038398222075892e-05,
      "loss": 0.0828,
      "step": 4680
    },
    {
      "epoch": 0.09638504632511434,
      "grad_norm": 6.034159183502197,
      "learning_rate": 2.9037575109062478e-05,
      "loss": 0.2062,
      "step": 4684
    },
    {
      "epoch": 0.09646735635613493,
      "grad_norm": 2.4857680797576904,
      "learning_rate": 2.9036751996049057e-05,
      "loss": 0.2044,
      "step": 4688
    },
    {
      "epoch": 0.09654966638715552,
      "grad_norm": 3.482257127761841,
      "learning_rate": 2.9035928883035643e-05,
      "loss": 0.2999,
      "step": 4692
    },
    {
      "epoch": 0.09663197641817611,
      "grad_norm": 3.920545816421509,
      "learning_rate": 2.9035105770022226e-05,
      "loss": 0.2066,
      "step": 4696
    },
    {
      "epoch": 0.0967142864491967,
      "grad_norm": 5.127849102020264,
      "learning_rate": 2.903428265700881e-05,
      "loss": 0.2373,
      "step": 4700
    },
    {
      "epoch": 0.0967965964802173,
      "grad_norm": 2.3389570713043213,
      "learning_rate": 2.903345954399539e-05,
      "loss": 0.1233,
      "step": 4704
    },
    {
      "epoch": 0.09687890651123789,
      "grad_norm": 3.429894208908081,
      "learning_rate": 2.9032636430981977e-05,
      "loss": 0.2727,
      "step": 4708
    },
    {
      "epoch": 0.09696121654225849,
      "grad_norm": 1.2355283498764038,
      "learning_rate": 2.9031813317968556e-05,
      "loss": 0.2755,
      "step": 4712
    },
    {
      "epoch": 0.09704352657327908,
      "grad_norm": 3.9285800457000732,
      "learning_rate": 2.9030990204955142e-05,
      "loss": 0.1635,
      "step": 4716
    },
    {
      "epoch": 0.09712583660429967,
      "grad_norm": 1.8800212144851685,
      "learning_rate": 2.9030167091941725e-05,
      "loss": 0.2305,
      "step": 4720
    },
    {
      "epoch": 0.09720814663532026,
      "grad_norm": 5.61126184463501,
      "learning_rate": 2.9029343978928308e-05,
      "loss": 0.2641,
      "step": 4724
    },
    {
      "epoch": 0.09729045666634085,
      "grad_norm": 3.374668836593628,
      "learning_rate": 2.902852086591489e-05,
      "loss": 0.1728,
      "step": 4728
    },
    {
      "epoch": 0.09737276669736145,
      "grad_norm": 2.481966495513916,
      "learning_rate": 2.9027697752901476e-05,
      "loss": 0.1357,
      "step": 4732
    },
    {
      "epoch": 0.09745507672838204,
      "grad_norm": 3.6838581562042236,
      "learning_rate": 2.9026874639888055e-05,
      "loss": 0.2449,
      "step": 4736
    },
    {
      "epoch": 0.09753738675940264,
      "grad_norm": 3.9580132961273193,
      "learning_rate": 2.902605152687464e-05,
      "loss": 0.241,
      "step": 4740
    },
    {
      "epoch": 0.09761969679042323,
      "grad_norm": 4.273646354675293,
      "learning_rate": 2.9025228413861224e-05,
      "loss": 0.2684,
      "step": 4744
    },
    {
      "epoch": 0.09770200682144382,
      "grad_norm": 3.3351590633392334,
      "learning_rate": 2.9024405300847807e-05,
      "loss": 0.1611,
      "step": 4748
    },
    {
      "epoch": 0.09778431685246441,
      "grad_norm": 2.481174945831299,
      "learning_rate": 2.902358218783439e-05,
      "loss": 0.1306,
      "step": 4752
    },
    {
      "epoch": 0.097866626883485,
      "grad_norm": 2.55610728263855,
      "learning_rate": 2.9022759074820975e-05,
      "loss": 0.1893,
      "step": 4756
    },
    {
      "epoch": 0.0979489369145056,
      "grad_norm": 4.518423080444336,
      "learning_rate": 2.9021935961807558e-05,
      "loss": 0.3448,
      "step": 4760
    },
    {
      "epoch": 0.09803124694552619,
      "grad_norm": 4.278171539306641,
      "learning_rate": 2.902111284879414e-05,
      "loss": 0.1817,
      "step": 4764
    },
    {
      "epoch": 0.09811355697654679,
      "grad_norm": 2.912397623062134,
      "learning_rate": 2.9020289735780723e-05,
      "loss": 0.1888,
      "step": 4768
    },
    {
      "epoch": 0.09819586700756738,
      "grad_norm": 3.5783605575561523,
      "learning_rate": 2.901946662276731e-05,
      "loss": 0.1747,
      "step": 4772
    },
    {
      "epoch": 0.09827817703858797,
      "grad_norm": 3.8827900886535645,
      "learning_rate": 2.901864350975389e-05,
      "loss": 0.3321,
      "step": 4776
    },
    {
      "epoch": 0.09836048706960857,
      "grad_norm": 2.081385374069214,
      "learning_rate": 2.9017820396740475e-05,
      "loss": 0.1572,
      "step": 4780
    },
    {
      "epoch": 0.09844279710062916,
      "grad_norm": 2.6113874912261963,
      "learning_rate": 2.9016997283727057e-05,
      "loss": 0.2272,
      "step": 4784
    },
    {
      "epoch": 0.09852510713164975,
      "grad_norm": 2.420642375946045,
      "learning_rate": 2.901617417071364e-05,
      "loss": 0.2316,
      "step": 4788
    },
    {
      "epoch": 0.09860741716267034,
      "grad_norm": 0.9343392848968506,
      "learning_rate": 2.9015351057700223e-05,
      "loss": 0.2798,
      "step": 4792
    },
    {
      "epoch": 0.09868972719369093,
      "grad_norm": 5.07680082321167,
      "learning_rate": 2.901452794468681e-05,
      "loss": 0.2589,
      "step": 4796
    },
    {
      "epoch": 0.09877203722471153,
      "grad_norm": 3.1776657104492188,
      "learning_rate": 2.9013704831673388e-05,
      "loss": 0.1524,
      "step": 4800
    },
    {
      "epoch": 0.09885434725573213,
      "grad_norm": 3.3537588119506836,
      "learning_rate": 2.9012881718659974e-05,
      "loss": 0.2087,
      "step": 4804
    },
    {
      "epoch": 0.09893665728675272,
      "grad_norm": 2.65725040435791,
      "learning_rate": 2.9012058605646556e-05,
      "loss": 0.2474,
      "step": 4808
    },
    {
      "epoch": 0.09901896731777331,
      "grad_norm": 6.418918609619141,
      "learning_rate": 2.901123549263314e-05,
      "loss": 0.2587,
      "step": 4812
    },
    {
      "epoch": 0.0991012773487939,
      "grad_norm": 3.5380499362945557,
      "learning_rate": 2.9010412379619722e-05,
      "loss": 0.127,
      "step": 4816
    },
    {
      "epoch": 0.09918358737981449,
      "grad_norm": 3.157053232192993,
      "learning_rate": 2.9009589266606308e-05,
      "loss": 0.2726,
      "step": 4820
    },
    {
      "epoch": 0.09926589741083508,
      "grad_norm": 3.9957809448242188,
      "learning_rate": 2.9008766153592887e-05,
      "loss": 0.2389,
      "step": 4824
    },
    {
      "epoch": 0.09934820744185568,
      "grad_norm": 2.7822272777557373,
      "learning_rate": 2.9007943040579473e-05,
      "loss": 0.1755,
      "step": 4828
    },
    {
      "epoch": 0.09943051747287628,
      "grad_norm": 1.358303427696228,
      "learning_rate": 2.9007119927566056e-05,
      "loss": 0.2016,
      "step": 4832
    },
    {
      "epoch": 0.09951282750389687,
      "grad_norm": 1.9588581323623657,
      "learning_rate": 2.9006296814552638e-05,
      "loss": 0.1398,
      "step": 4836
    },
    {
      "epoch": 0.09959513753491746,
      "grad_norm": 4.1988396644592285,
      "learning_rate": 2.900547370153922e-05,
      "loss": 0.2324,
      "step": 4840
    },
    {
      "epoch": 0.09967744756593805,
      "grad_norm": 2.109598398208618,
      "learning_rate": 2.9004650588525807e-05,
      "loss": 0.1372,
      "step": 4844
    },
    {
      "epoch": 0.09975975759695864,
      "grad_norm": 2.138282060623169,
      "learning_rate": 2.9003827475512386e-05,
      "loss": 0.1115,
      "step": 4848
    },
    {
      "epoch": 0.09984206762797923,
      "grad_norm": 3.36067533493042,
      "learning_rate": 2.9003004362498972e-05,
      "loss": 0.1379,
      "step": 4852
    },
    {
      "epoch": 0.09992437765899984,
      "grad_norm": 5.821135520935059,
      "learning_rate": 2.9002181249485555e-05,
      "loss": 0.4056,
      "step": 4856
    },
    {
      "epoch": 0.10000668769002043,
      "grad_norm": 2.399479627609253,
      "learning_rate": 2.900135813647214e-05,
      "loss": 0.1542,
      "step": 4860
    },
    {
      "epoch": 0.10008899772104102,
      "grad_norm": 1.884459137916565,
      "learning_rate": 2.900053502345872e-05,
      "loss": 0.2411,
      "step": 4864
    },
    {
      "epoch": 0.10017130775206161,
      "grad_norm": 5.477142333984375,
      "learning_rate": 2.8999711910445306e-05,
      "loss": 0.2094,
      "step": 4868
    },
    {
      "epoch": 0.1002536177830822,
      "grad_norm": 5.559103965759277,
      "learning_rate": 2.899888879743189e-05,
      "loss": 0.2934,
      "step": 4872
    },
    {
      "epoch": 0.10033592781410279,
      "grad_norm": 3.3824076652526855,
      "learning_rate": 2.899806568441847e-05,
      "loss": 0.1783,
      "step": 4876
    },
    {
      "epoch": 0.10041823784512338,
      "grad_norm": 5.184551239013672,
      "learning_rate": 2.8997242571405054e-05,
      "loss": 0.3437,
      "step": 4880
    },
    {
      "epoch": 0.10050054787614399,
      "grad_norm": 2.850158452987671,
      "learning_rate": 2.899641945839164e-05,
      "loss": 0.2499,
      "step": 4884
    },
    {
      "epoch": 0.10058285790716458,
      "grad_norm": 3.324599266052246,
      "learning_rate": 2.899559634537822e-05,
      "loss": 0.2516,
      "step": 4888
    },
    {
      "epoch": 0.10066516793818517,
      "grad_norm": 3.0080814361572266,
      "learning_rate": 2.8994773232364805e-05,
      "loss": 0.242,
      "step": 4892
    },
    {
      "epoch": 0.10074747796920576,
      "grad_norm": 4.017634868621826,
      "learning_rate": 2.8993950119351388e-05,
      "loss": 0.1884,
      "step": 4896
    },
    {
      "epoch": 0.10082978800022635,
      "grad_norm": 5.354060649871826,
      "learning_rate": 2.899312700633797e-05,
      "loss": 0.2216,
      "step": 4900
    },
    {
      "epoch": 0.10091209803124694,
      "grad_norm": 1.4479007720947266,
      "learning_rate": 2.8992303893324553e-05,
      "loss": 0.1627,
      "step": 4904
    },
    {
      "epoch": 0.10099440806226753,
      "grad_norm": 5.113185405731201,
      "learning_rate": 2.899148078031114e-05,
      "loss": 0.2015,
      "step": 4908
    },
    {
      "epoch": 0.10107671809328814,
      "grad_norm": 3.807187080383301,
      "learning_rate": 2.899065766729772e-05,
      "loss": 0.2078,
      "step": 4912
    },
    {
      "epoch": 0.10115902812430873,
      "grad_norm": 3.6428239345550537,
      "learning_rate": 2.8989834554284305e-05,
      "loss": 0.1659,
      "step": 4916
    },
    {
      "epoch": 0.10124133815532932,
      "grad_norm": 3.45322585105896,
      "learning_rate": 2.8989011441270887e-05,
      "loss": 0.2636,
      "step": 4920
    },
    {
      "epoch": 0.10132364818634991,
      "grad_norm": 3.195192813873291,
      "learning_rate": 2.898818832825747e-05,
      "loss": 0.2556,
      "step": 4924
    },
    {
      "epoch": 0.1014059582173705,
      "grad_norm": 6.905516624450684,
      "learning_rate": 2.8987365215244052e-05,
      "loss": 0.2346,
      "step": 4928
    },
    {
      "epoch": 0.10148826824839109,
      "grad_norm": 2.557628631591797,
      "learning_rate": 2.898654210223064e-05,
      "loss": 0.1801,
      "step": 4932
    },
    {
      "epoch": 0.10157057827941168,
      "grad_norm": 3.4756557941436768,
      "learning_rate": 2.8985718989217218e-05,
      "loss": 0.2378,
      "step": 4936
    },
    {
      "epoch": 0.10165288831043229,
      "grad_norm": 2.257444143295288,
      "learning_rate": 2.8984895876203804e-05,
      "loss": 0.1082,
      "step": 4940
    },
    {
      "epoch": 0.10173519834145288,
      "grad_norm": 3.580035448074341,
      "learning_rate": 2.8984072763190386e-05,
      "loss": 0.1544,
      "step": 4944
    },
    {
      "epoch": 0.10181750837247347,
      "grad_norm": 3.148451805114746,
      "learning_rate": 2.898324965017697e-05,
      "loss": 0.2863,
      "step": 4948
    },
    {
      "epoch": 0.10189981840349406,
      "grad_norm": 1.6063344478607178,
      "learning_rate": 2.898242653716355e-05,
      "loss": 0.2452,
      "step": 4952
    },
    {
      "epoch": 0.10198212843451465,
      "grad_norm": 5.384809970855713,
      "learning_rate": 2.8981603424150138e-05,
      "loss": 0.2542,
      "step": 4956
    },
    {
      "epoch": 0.10206443846553524,
      "grad_norm": 4.449751377105713,
      "learning_rate": 2.898078031113672e-05,
      "loss": 0.1937,
      "step": 4960
    },
    {
      "epoch": 0.10214674849655583,
      "grad_norm": 3.5534300804138184,
      "learning_rate": 2.8979957198123303e-05,
      "loss": 0.2504,
      "step": 4964
    },
    {
      "epoch": 0.10222905852757644,
      "grad_norm": 3.018007755279541,
      "learning_rate": 2.8979134085109886e-05,
      "loss": 0.2551,
      "step": 4968
    },
    {
      "epoch": 0.10231136855859703,
      "grad_norm": 1.9022318124771118,
      "learning_rate": 2.897831097209647e-05,
      "loss": 0.3013,
      "step": 4972
    },
    {
      "epoch": 0.10239367858961762,
      "grad_norm": 3.6156108379364014,
      "learning_rate": 2.897748785908305e-05,
      "loss": 0.1955,
      "step": 4976
    },
    {
      "epoch": 0.10247598862063821,
      "grad_norm": 1.7995946407318115,
      "learning_rate": 2.8976664746069637e-05,
      "loss": 0.1598,
      "step": 4980
    },
    {
      "epoch": 0.1025582986516588,
      "grad_norm": 8.734416961669922,
      "learning_rate": 2.897584163305622e-05,
      "loss": 0.2155,
      "step": 4984
    },
    {
      "epoch": 0.1026406086826794,
      "grad_norm": 2.900226354598999,
      "learning_rate": 2.8975018520042802e-05,
      "loss": 0.2846,
      "step": 4988
    },
    {
      "epoch": 0.10272291871369998,
      "grad_norm": 5.01643705368042,
      "learning_rate": 2.8974195407029385e-05,
      "loss": 0.1923,
      "step": 4992
    },
    {
      "epoch": 0.10280522874472059,
      "grad_norm": 4.442188739776611,
      "learning_rate": 2.897337229401597e-05,
      "loss": 0.2214,
      "step": 4996
    },
    {
      "epoch": 0.10288753877574118,
      "grad_norm": 2.6697118282318115,
      "learning_rate": 2.897254918100255e-05,
      "loss": 0.1557,
      "step": 5000
    },
    {
      "epoch": 0.10296984880676177,
      "grad_norm": 2.4506373405456543,
      "learning_rate": 2.8971726067989136e-05,
      "loss": 0.3349,
      "step": 5004
    },
    {
      "epoch": 0.10305215883778236,
      "grad_norm": 4.097248077392578,
      "learning_rate": 2.897090295497572e-05,
      "loss": 0.1961,
      "step": 5008
    },
    {
      "epoch": 0.10313446886880295,
      "grad_norm": 2.257465362548828,
      "learning_rate": 2.89700798419623e-05,
      "loss": 0.2565,
      "step": 5012
    },
    {
      "epoch": 0.10321677889982354,
      "grad_norm": 3.7020318508148193,
      "learning_rate": 2.8969256728948884e-05,
      "loss": 0.2202,
      "step": 5016
    },
    {
      "epoch": 0.10329908893084414,
      "grad_norm": 5.280993461608887,
      "learning_rate": 2.896843361593547e-05,
      "loss": 0.2751,
      "step": 5020
    },
    {
      "epoch": 0.10338139896186474,
      "grad_norm": 1.1973671913146973,
      "learning_rate": 2.896761050292205e-05,
      "loss": 0.1448,
      "step": 5024
    },
    {
      "epoch": 0.10346370899288533,
      "grad_norm": 2.997708320617676,
      "learning_rate": 2.8966787389908635e-05,
      "loss": 0.2205,
      "step": 5028
    },
    {
      "epoch": 0.10354601902390592,
      "grad_norm": 5.547914028167725,
      "learning_rate": 2.8965964276895218e-05,
      "loss": 0.2449,
      "step": 5032
    },
    {
      "epoch": 0.10362832905492651,
      "grad_norm": 2.5064778327941895,
      "learning_rate": 2.89651411638818e-05,
      "loss": 0.1868,
      "step": 5036
    },
    {
      "epoch": 0.1037106390859471,
      "grad_norm": 4.09097146987915,
      "learning_rate": 2.8964318050868383e-05,
      "loss": 0.1973,
      "step": 5040
    },
    {
      "epoch": 0.1037929491169677,
      "grad_norm": 1.8020141124725342,
      "learning_rate": 2.896349493785497e-05,
      "loss": 0.2002,
      "step": 5044
    },
    {
      "epoch": 0.10387525914798829,
      "grad_norm": 4.489996910095215,
      "learning_rate": 2.896267182484155e-05,
      "loss": 0.2197,
      "step": 5048
    },
    {
      "epoch": 0.10395756917900889,
      "grad_norm": 4.505594730377197,
      "learning_rate": 2.8961848711828134e-05,
      "loss": 0.1387,
      "step": 5052
    },
    {
      "epoch": 0.10403987921002948,
      "grad_norm": 4.778872489929199,
      "learning_rate": 2.8961025598814717e-05,
      "loss": 0.2882,
      "step": 5056
    },
    {
      "epoch": 0.10412218924105007,
      "grad_norm": 1.4623900651931763,
      "learning_rate": 2.8960202485801303e-05,
      "loss": 0.164,
      "step": 5060
    },
    {
      "epoch": 0.10420449927207066,
      "grad_norm": 3.5185725688934326,
      "learning_rate": 2.8959379372787882e-05,
      "loss": 0.2183,
      "step": 5064
    },
    {
      "epoch": 0.10428680930309125,
      "grad_norm": 3.852997064590454,
      "learning_rate": 2.895855625977447e-05,
      "loss": 0.2885,
      "step": 5068
    },
    {
      "epoch": 0.10436911933411185,
      "grad_norm": 4.770626068115234,
      "learning_rate": 2.895773314676105e-05,
      "loss": 0.1599,
      "step": 5072
    },
    {
      "epoch": 0.10445142936513244,
      "grad_norm": 3.7555625438690186,
      "learning_rate": 2.8956910033747634e-05,
      "loss": 0.1866,
      "step": 5076
    },
    {
      "epoch": 0.10453373939615304,
      "grad_norm": 2.822387933731079,
      "learning_rate": 2.8956086920734216e-05,
      "loss": 0.184,
      "step": 5080
    },
    {
      "epoch": 0.10461604942717363,
      "grad_norm": 2.20068097114563,
      "learning_rate": 2.8955263807720802e-05,
      "loss": 0.1223,
      "step": 5084
    },
    {
      "epoch": 0.10469835945819422,
      "grad_norm": 2.2272684574127197,
      "learning_rate": 2.895444069470738e-05,
      "loss": 0.1964,
      "step": 5088
    },
    {
      "epoch": 0.10478066948921481,
      "grad_norm": 2.9405107498168945,
      "learning_rate": 2.8953617581693968e-05,
      "loss": 0.2763,
      "step": 5092
    },
    {
      "epoch": 0.1048629795202354,
      "grad_norm": 1.3681493997573853,
      "learning_rate": 2.895279446868055e-05,
      "loss": 0.1461,
      "step": 5096
    },
    {
      "epoch": 0.104945289551256,
      "grad_norm": 3.096040725708008,
      "learning_rate": 2.8951971355667133e-05,
      "loss": 0.2073,
      "step": 5100
    },
    {
      "epoch": 0.10502759958227659,
      "grad_norm": 4.353878021240234,
      "learning_rate": 2.8951148242653715e-05,
      "loss": 0.2758,
      "step": 5104
    },
    {
      "epoch": 0.10510990961329719,
      "grad_norm": 0.8939232230186462,
      "learning_rate": 2.89503251296403e-05,
      "loss": 0.2333,
      "step": 5108
    },
    {
      "epoch": 0.10519221964431778,
      "grad_norm": 2.2212045192718506,
      "learning_rate": 2.894950201662688e-05,
      "loss": 0.2641,
      "step": 5112
    },
    {
      "epoch": 0.10527452967533837,
      "grad_norm": 1.3846988677978516,
      "learning_rate": 2.8948678903613467e-05,
      "loss": 0.1419,
      "step": 5116
    },
    {
      "epoch": 0.10535683970635897,
      "grad_norm": 3.7517006397247314,
      "learning_rate": 2.894785579060005e-05,
      "loss": 0.2143,
      "step": 5120
    },
    {
      "epoch": 0.10543914973737956,
      "grad_norm": 3.0154356956481934,
      "learning_rate": 2.8947032677586632e-05,
      "loss": 0.2355,
      "step": 5124
    },
    {
      "epoch": 0.10552145976840015,
      "grad_norm": 2.418285608291626,
      "learning_rate": 2.8946209564573215e-05,
      "loss": 0.1833,
      "step": 5128
    },
    {
      "epoch": 0.10560376979942074,
      "grad_norm": 4.355790138244629,
      "learning_rate": 2.89453864515598e-05,
      "loss": 0.1896,
      "step": 5132
    },
    {
      "epoch": 0.10568607983044134,
      "grad_norm": 2.839027166366577,
      "learning_rate": 2.8944563338546383e-05,
      "loss": 0.2698,
      "step": 5136
    },
    {
      "epoch": 0.10576838986146193,
      "grad_norm": 2.453226089477539,
      "learning_rate": 2.8943740225532966e-05,
      "loss": 0.1879,
      "step": 5140
    },
    {
      "epoch": 0.10585069989248252,
      "grad_norm": 2.2901809215545654,
      "learning_rate": 2.8942917112519552e-05,
      "loss": 0.1696,
      "step": 5144
    },
    {
      "epoch": 0.10593300992350312,
      "grad_norm": 2.551609754562378,
      "learning_rate": 2.8942093999506135e-05,
      "loss": 0.123,
      "step": 5148
    },
    {
      "epoch": 0.1060153199545237,
      "grad_norm": 4.875731468200684,
      "learning_rate": 2.8941270886492717e-05,
      "loss": 0.2408,
      "step": 5152
    },
    {
      "epoch": 0.1060976299855443,
      "grad_norm": 2.846099376678467,
      "learning_rate": 2.89404477734793e-05,
      "loss": 0.1238,
      "step": 5156
    },
    {
      "epoch": 0.10617994001656489,
      "grad_norm": 4.035289287567139,
      "learning_rate": 2.8939624660465886e-05,
      "loss": 0.3138,
      "step": 5160
    },
    {
      "epoch": 0.10626225004758548,
      "grad_norm": 5.777090072631836,
      "learning_rate": 2.8938801547452465e-05,
      "loss": 0.2667,
      "step": 5164
    },
    {
      "epoch": 0.10634456007860608,
      "grad_norm": 2.676652431488037,
      "learning_rate": 2.893797843443905e-05,
      "loss": 0.2365,
      "step": 5168
    },
    {
      "epoch": 0.10642687010962668,
      "grad_norm": 3.372743844985962,
      "learning_rate": 2.8937155321425634e-05,
      "loss": 0.2055,
      "step": 5172
    },
    {
      "epoch": 0.10650918014064727,
      "grad_norm": 3.7119667530059814,
      "learning_rate": 2.8936332208412216e-05,
      "loss": 0.1248,
      "step": 5176
    },
    {
      "epoch": 0.10659149017166786,
      "grad_norm": 2.387638568878174,
      "learning_rate": 2.89355090953988e-05,
      "loss": 0.1837,
      "step": 5180
    },
    {
      "epoch": 0.10667380020268845,
      "grad_norm": 2.846367359161377,
      "learning_rate": 2.8934685982385385e-05,
      "loss": 0.2394,
      "step": 5184
    },
    {
      "epoch": 0.10675611023370904,
      "grad_norm": 4.324822902679443,
      "learning_rate": 2.8933862869371964e-05,
      "loss": 0.235,
      "step": 5188
    },
    {
      "epoch": 0.10683842026472963,
      "grad_norm": 2.200814723968506,
      "learning_rate": 2.893303975635855e-05,
      "loss": 0.2571,
      "step": 5192
    },
    {
      "epoch": 0.10692073029575024,
      "grad_norm": 1.5194278955459595,
      "learning_rate": 2.8932216643345133e-05,
      "loss": 0.2503,
      "step": 5196
    },
    {
      "epoch": 0.10700304032677083,
      "grad_norm": 0.6512715816497803,
      "learning_rate": 2.8931393530331716e-05,
      "loss": 0.1784,
      "step": 5200
    },
    {
      "epoch": 0.10708535035779142,
      "grad_norm": 1.270443081855774,
      "learning_rate": 2.8930570417318298e-05,
      "loss": 0.1315,
      "step": 5204
    },
    {
      "epoch": 0.10716766038881201,
      "grad_norm": 3.2324981689453125,
      "learning_rate": 2.8929747304304884e-05,
      "loss": 0.2187,
      "step": 5208
    },
    {
      "epoch": 0.1072499704198326,
      "grad_norm": 0.8209890723228455,
      "learning_rate": 2.8928924191291464e-05,
      "loss": 0.0968,
      "step": 5212
    },
    {
      "epoch": 0.10733228045085319,
      "grad_norm": 2.113173484802246,
      "learning_rate": 2.892810107827805e-05,
      "loss": 0.2934,
      "step": 5216
    },
    {
      "epoch": 0.10741459048187378,
      "grad_norm": 3.5661230087280273,
      "learning_rate": 2.8927277965264632e-05,
      "loss": 0.175,
      "step": 5220
    },
    {
      "epoch": 0.10749690051289439,
      "grad_norm": 1.806100845336914,
      "learning_rate": 2.8926454852251215e-05,
      "loss": 0.1618,
      "step": 5224
    },
    {
      "epoch": 0.10757921054391498,
      "grad_norm": 1.2387820482254028,
      "learning_rate": 2.8925631739237797e-05,
      "loss": 0.1666,
      "step": 5228
    },
    {
      "epoch": 0.10766152057493557,
      "grad_norm": 3.1707966327667236,
      "learning_rate": 2.8924808626224383e-05,
      "loss": 0.1919,
      "step": 5232
    },
    {
      "epoch": 0.10774383060595616,
      "grad_norm": 0.5577617883682251,
      "learning_rate": 2.8923985513210963e-05,
      "loss": 0.2167,
      "step": 5236
    },
    {
      "epoch": 0.10782614063697675,
      "grad_norm": 5.501692295074463,
      "learning_rate": 2.892316240019755e-05,
      "loss": 0.2349,
      "step": 5240
    },
    {
      "epoch": 0.10790845066799734,
      "grad_norm": 2.574068546295166,
      "learning_rate": 2.892233928718413e-05,
      "loss": 0.2084,
      "step": 5244
    },
    {
      "epoch": 0.10799076069901793,
      "grad_norm": 1.0887959003448486,
      "learning_rate": 2.8921516174170717e-05,
      "loss": 0.1314,
      "step": 5248
    },
    {
      "epoch": 0.10807307073003854,
      "grad_norm": 4.970674991607666,
      "learning_rate": 2.8920693061157297e-05,
      "loss": 0.1507,
      "step": 5252
    },
    {
      "epoch": 0.10815538076105913,
      "grad_norm": 1.6664674282073975,
      "learning_rate": 2.8919869948143883e-05,
      "loss": 0.1075,
      "step": 5256
    },
    {
      "epoch": 0.10823769079207972,
      "grad_norm": 2.767139196395874,
      "learning_rate": 2.8919046835130465e-05,
      "loss": 0.2379,
      "step": 5260
    },
    {
      "epoch": 0.10832000082310031,
      "grad_norm": 1.6084238290786743,
      "learning_rate": 2.8918223722117048e-05,
      "loss": 0.1803,
      "step": 5264
    },
    {
      "epoch": 0.1084023108541209,
      "grad_norm": 1.162005066871643,
      "learning_rate": 2.891740060910363e-05,
      "loss": 0.0705,
      "step": 5268
    },
    {
      "epoch": 0.10848462088514149,
      "grad_norm": 2.360109567642212,
      "learning_rate": 2.8916577496090217e-05,
      "loss": 0.1511,
      "step": 5272
    },
    {
      "epoch": 0.10856693091616208,
      "grad_norm": 2.9346747398376465,
      "learning_rate": 2.8915754383076796e-05,
      "loss": 0.1339,
      "step": 5276
    },
    {
      "epoch": 0.10864924094718269,
      "grad_norm": 3.7724380493164062,
      "learning_rate": 2.8914931270063382e-05,
      "loss": 0.1498,
      "step": 5280
    },
    {
      "epoch": 0.10873155097820328,
      "grad_norm": 2.08526349067688,
      "learning_rate": 2.8914108157049964e-05,
      "loss": 0.1394,
      "step": 5284
    },
    {
      "epoch": 0.10881386100922387,
      "grad_norm": 3.8576831817626953,
      "learning_rate": 2.8913285044036547e-05,
      "loss": 0.1654,
      "step": 5288
    },
    {
      "epoch": 0.10889617104024446,
      "grad_norm": 2.080660343170166,
      "learning_rate": 2.891246193102313e-05,
      "loss": 0.167,
      "step": 5292
    },
    {
      "epoch": 0.10897848107126505,
      "grad_norm": 2.66300106048584,
      "learning_rate": 2.8911638818009716e-05,
      "loss": 0.2038,
      "step": 5296
    },
    {
      "epoch": 0.10906079110228564,
      "grad_norm": 1.3726869821548462,
      "learning_rate": 2.8910815704996295e-05,
      "loss": 0.1385,
      "step": 5300
    },
    {
      "epoch": 0.10914310113330623,
      "grad_norm": 8.987632751464844,
      "learning_rate": 2.890999259198288e-05,
      "loss": 0.3463,
      "step": 5304
    },
    {
      "epoch": 0.10922541116432684,
      "grad_norm": 2.4916000366210938,
      "learning_rate": 2.8909169478969464e-05,
      "loss": 0.1603,
      "step": 5308
    },
    {
      "epoch": 0.10930772119534743,
      "grad_norm": 3.929588794708252,
      "learning_rate": 2.8908346365956046e-05,
      "loss": 0.141,
      "step": 5312
    },
    {
      "epoch": 0.10939003122636802,
      "grad_norm": 2.5000784397125244,
      "learning_rate": 2.890752325294263e-05,
      "loss": 0.1551,
      "step": 5316
    },
    {
      "epoch": 0.10947234125738861,
      "grad_norm": 1.3750439882278442,
      "learning_rate": 2.8906700139929215e-05,
      "loss": 0.1776,
      "step": 5320
    },
    {
      "epoch": 0.1095546512884092,
      "grad_norm": 4.138673305511475,
      "learning_rate": 2.8905877026915794e-05,
      "loss": 0.288,
      "step": 5324
    },
    {
      "epoch": 0.1096369613194298,
      "grad_norm": 3.243128776550293,
      "learning_rate": 2.890505391390238e-05,
      "loss": 0.1454,
      "step": 5328
    },
    {
      "epoch": 0.10971927135045038,
      "grad_norm": 3.330501079559326,
      "learning_rate": 2.8904230800888963e-05,
      "loss": 0.2942,
      "step": 5332
    },
    {
      "epoch": 0.10980158138147099,
      "grad_norm": 2.3569445610046387,
      "learning_rate": 2.8903407687875545e-05,
      "loss": 0.1702,
      "step": 5336
    },
    {
      "epoch": 0.10988389141249158,
      "grad_norm": 3.1955363750457764,
      "learning_rate": 2.8902584574862128e-05,
      "loss": 0.2176,
      "step": 5340
    },
    {
      "epoch": 0.10996620144351217,
      "grad_norm": 1.3506207466125488,
      "learning_rate": 2.8901761461848714e-05,
      "loss": 0.2275,
      "step": 5344
    },
    {
      "epoch": 0.11004851147453276,
      "grad_norm": 1.949223518371582,
      "learning_rate": 2.8900938348835297e-05,
      "loss": 0.1833,
      "step": 5348
    },
    {
      "epoch": 0.11013082150555335,
      "grad_norm": 5.100759506225586,
      "learning_rate": 2.890011523582188e-05,
      "loss": 0.1893,
      "step": 5352
    },
    {
      "epoch": 0.11021313153657394,
      "grad_norm": 6.8376898765563965,
      "learning_rate": 2.8899292122808462e-05,
      "loss": 0.1854,
      "step": 5356
    },
    {
      "epoch": 0.11029544156759453,
      "grad_norm": 4.965372085571289,
      "learning_rate": 2.8898469009795048e-05,
      "loss": 0.236,
      "step": 5360
    },
    {
      "epoch": 0.11037775159861514,
      "grad_norm": 4.313083171844482,
      "learning_rate": 2.8897645896781627e-05,
      "loss": 0.1418,
      "step": 5364
    },
    {
      "epoch": 0.11046006162963573,
      "grad_norm": 4.406164646148682,
      "learning_rate": 2.8896822783768213e-05,
      "loss": 0.2223,
      "step": 5368
    },
    {
      "epoch": 0.11054237166065632,
      "grad_norm": 4.742865085601807,
      "learning_rate": 2.8895999670754796e-05,
      "loss": 0.1565,
      "step": 5372
    },
    {
      "epoch": 0.11062468169167691,
      "grad_norm": 4.649102210998535,
      "learning_rate": 2.889517655774138e-05,
      "loss": 0.2527,
      "step": 5376
    },
    {
      "epoch": 0.1107069917226975,
      "grad_norm": 3.393552541732788,
      "learning_rate": 2.889435344472796e-05,
      "loss": 0.1991,
      "step": 5380
    },
    {
      "epoch": 0.1107893017537181,
      "grad_norm": 3.787729263305664,
      "learning_rate": 2.8893530331714547e-05,
      "loss": 0.2104,
      "step": 5384
    },
    {
      "epoch": 0.11087161178473869,
      "grad_norm": 3.3491644859313965,
      "learning_rate": 2.8892707218701127e-05,
      "loss": 0.181,
      "step": 5388
    },
    {
      "epoch": 0.11095392181575929,
      "grad_norm": 2.059586524963379,
      "learning_rate": 2.8891884105687713e-05,
      "loss": 0.1512,
      "step": 5392
    },
    {
      "epoch": 0.11103623184677988,
      "grad_norm": 3.4384491443634033,
      "learning_rate": 2.8891060992674295e-05,
      "loss": 0.3327,
      "step": 5396
    },
    {
      "epoch": 0.11111854187780047,
      "grad_norm": 2.7949604988098145,
      "learning_rate": 2.8890237879660878e-05,
      "loss": 0.2531,
      "step": 5400
    },
    {
      "epoch": 0.11120085190882106,
      "grad_norm": 3.9976296424865723,
      "learning_rate": 2.888941476664746e-05,
      "loss": 0.26,
      "step": 5404
    },
    {
      "epoch": 0.11128316193984165,
      "grad_norm": 2.9434056282043457,
      "learning_rate": 2.8888591653634046e-05,
      "loss": 0.1385,
      "step": 5408
    },
    {
      "epoch": 0.11136547197086225,
      "grad_norm": 3.401653528213501,
      "learning_rate": 2.8887768540620626e-05,
      "loss": 0.256,
      "step": 5412
    },
    {
      "epoch": 0.11144778200188284,
      "grad_norm": 2.5227863788604736,
      "learning_rate": 2.8886945427607212e-05,
      "loss": 0.2857,
      "step": 5416
    },
    {
      "epoch": 0.11153009203290344,
      "grad_norm": 2.4890129566192627,
      "learning_rate": 2.8886122314593794e-05,
      "loss": 0.2323,
      "step": 5420
    },
    {
      "epoch": 0.11161240206392403,
      "grad_norm": 3.1941440105438232,
      "learning_rate": 2.8885299201580377e-05,
      "loss": 0.119,
      "step": 5424
    },
    {
      "epoch": 0.11169471209494462,
      "grad_norm": 2.8873629570007324,
      "learning_rate": 2.888447608856696e-05,
      "loss": 0.1713,
      "step": 5428
    },
    {
      "epoch": 0.11177702212596521,
      "grad_norm": 4.484821319580078,
      "learning_rate": 2.8883652975553546e-05,
      "loss": 0.2926,
      "step": 5432
    },
    {
      "epoch": 0.1118593321569858,
      "grad_norm": 2.6233866214752197,
      "learning_rate": 2.8882829862540125e-05,
      "loss": 0.1414,
      "step": 5436
    },
    {
      "epoch": 0.1119416421880064,
      "grad_norm": 3.4516658782958984,
      "learning_rate": 2.888200674952671e-05,
      "loss": 0.1577,
      "step": 5440
    },
    {
      "epoch": 0.11202395221902699,
      "grad_norm": 1.3383896350860596,
      "learning_rate": 2.8881183636513294e-05,
      "loss": 0.2437,
      "step": 5444
    },
    {
      "epoch": 0.11210626225004759,
      "grad_norm": 1.2550415992736816,
      "learning_rate": 2.888036052349988e-05,
      "loss": 0.1301,
      "step": 5448
    },
    {
      "epoch": 0.11218857228106818,
      "grad_norm": 5.954796314239502,
      "learning_rate": 2.887953741048646e-05,
      "loss": 0.2003,
      "step": 5452
    },
    {
      "epoch": 0.11227088231208877,
      "grad_norm": 4.8155412673950195,
      "learning_rate": 2.8878714297473045e-05,
      "loss": 0.2042,
      "step": 5456
    },
    {
      "epoch": 0.11235319234310936,
      "grad_norm": 4.33258581161499,
      "learning_rate": 2.8877891184459627e-05,
      "loss": 0.3057,
      "step": 5460
    },
    {
      "epoch": 0.11243550237412996,
      "grad_norm": 2.467249631881714,
      "learning_rate": 2.887706807144621e-05,
      "loss": 0.2446,
      "step": 5464
    },
    {
      "epoch": 0.11251781240515055,
      "grad_norm": 2.1506879329681396,
      "learning_rate": 2.8876244958432793e-05,
      "loss": 0.3781,
      "step": 5468
    },
    {
      "epoch": 0.11260012243617114,
      "grad_norm": 2.1501624584198,
      "learning_rate": 2.887542184541938e-05,
      "loss": 0.1618,
      "step": 5472
    },
    {
      "epoch": 0.11268243246719174,
      "grad_norm": 2.4995217323303223,
      "learning_rate": 2.8874598732405958e-05,
      "loss": 0.1524,
      "step": 5476
    },
    {
      "epoch": 0.11276474249821233,
      "grad_norm": 4.02574348449707,
      "learning_rate": 2.8873775619392544e-05,
      "loss": 0.1869,
      "step": 5480
    },
    {
      "epoch": 0.11284705252923292,
      "grad_norm": 4.164315223693848,
      "learning_rate": 2.8872952506379127e-05,
      "loss": 0.2846,
      "step": 5484
    },
    {
      "epoch": 0.11292936256025352,
      "grad_norm": 3.8904621601104736,
      "learning_rate": 2.887212939336571e-05,
      "loss": 0.2226,
      "step": 5488
    },
    {
      "epoch": 0.1130116725912741,
      "grad_norm": 3.310523509979248,
      "learning_rate": 2.8871306280352292e-05,
      "loss": 0.2133,
      "step": 5492
    },
    {
      "epoch": 0.1130939826222947,
      "grad_norm": 3.6276986598968506,
      "learning_rate": 2.8870483167338878e-05,
      "loss": 0.1867,
      "step": 5496
    },
    {
      "epoch": 0.11317629265331529,
      "grad_norm": 4.950505256652832,
      "learning_rate": 2.8869660054325457e-05,
      "loss": 0.256,
      "step": 5500
    },
    {
      "epoch": 0.1132586026843359,
      "grad_norm": 3.992061138153076,
      "learning_rate": 2.8868836941312043e-05,
      "loss": 0.1475,
      "step": 5504
    },
    {
      "epoch": 0.11334091271535648,
      "grad_norm": 2.9609556198120117,
      "learning_rate": 2.8868013828298626e-05,
      "loss": 0.2928,
      "step": 5508
    },
    {
      "epoch": 0.11342322274637708,
      "grad_norm": 6.013339042663574,
      "learning_rate": 2.886719071528521e-05,
      "loss": 0.2067,
      "step": 5512
    },
    {
      "epoch": 0.11350553277739767,
      "grad_norm": 3.0246715545654297,
      "learning_rate": 2.886636760227179e-05,
      "loss": 0.1823,
      "step": 5516
    },
    {
      "epoch": 0.11358784280841826,
      "grad_norm": 6.452965259552002,
      "learning_rate": 2.8865544489258377e-05,
      "loss": 0.1515,
      "step": 5520
    },
    {
      "epoch": 0.11367015283943885,
      "grad_norm": 3.3266990184783936,
      "learning_rate": 2.8864721376244956e-05,
      "loss": 0.1929,
      "step": 5524
    },
    {
      "epoch": 0.11375246287045944,
      "grad_norm": 4.000183582305908,
      "learning_rate": 2.8863898263231542e-05,
      "loss": 0.2371,
      "step": 5528
    },
    {
      "epoch": 0.11383477290148004,
      "grad_norm": 4.009788990020752,
      "learning_rate": 2.8863075150218125e-05,
      "loss": 0.2971,
      "step": 5532
    },
    {
      "epoch": 0.11391708293250064,
      "grad_norm": 3.9796836376190186,
      "learning_rate": 2.8862252037204708e-05,
      "loss": 0.1553,
      "step": 5536
    },
    {
      "epoch": 0.11399939296352123,
      "grad_norm": 2.5995702743530273,
      "learning_rate": 2.886142892419129e-05,
      "loss": 0.2638,
      "step": 5540
    },
    {
      "epoch": 0.11408170299454182,
      "grad_norm": 2.8290421962738037,
      "learning_rate": 2.8860605811177876e-05,
      "loss": 0.2044,
      "step": 5544
    },
    {
      "epoch": 0.11416401302556241,
      "grad_norm": 2.59670090675354,
      "learning_rate": 2.885978269816446e-05,
      "loss": 0.1344,
      "step": 5548
    },
    {
      "epoch": 0.114246323056583,
      "grad_norm": 1.5608737468719482,
      "learning_rate": 2.885895958515104e-05,
      "loss": 0.2473,
      "step": 5552
    },
    {
      "epoch": 0.11432863308760359,
      "grad_norm": 1.7535061836242676,
      "learning_rate": 2.8858136472137624e-05,
      "loss": 0.1066,
      "step": 5556
    },
    {
      "epoch": 0.11441094311862418,
      "grad_norm": 1.8711605072021484,
      "learning_rate": 2.885731335912421e-05,
      "loss": 0.0983,
      "step": 5560
    },
    {
      "epoch": 0.11449325314964479,
      "grad_norm": 2.721827507019043,
      "learning_rate": 2.885649024611079e-05,
      "loss": 0.1507,
      "step": 5564
    },
    {
      "epoch": 0.11457556318066538,
      "grad_norm": 2.7158138751983643,
      "learning_rate": 2.8855667133097376e-05,
      "loss": 0.2324,
      "step": 5568
    },
    {
      "epoch": 0.11465787321168597,
      "grad_norm": 2.663468360900879,
      "learning_rate": 2.8854844020083958e-05,
      "loss": 0.2292,
      "step": 5572
    },
    {
      "epoch": 0.11474018324270656,
      "grad_norm": 2.4752185344696045,
      "learning_rate": 2.885402090707054e-05,
      "loss": 0.1399,
      "step": 5576
    },
    {
      "epoch": 0.11482249327372715,
      "grad_norm": 2.554399251937866,
      "learning_rate": 2.8853197794057123e-05,
      "loss": 0.2359,
      "step": 5580
    },
    {
      "epoch": 0.11490480330474774,
      "grad_norm": 3.7549118995666504,
      "learning_rate": 2.885237468104371e-05,
      "loss": 0.2545,
      "step": 5584
    },
    {
      "epoch": 0.11498711333576833,
      "grad_norm": 3.896185874938965,
      "learning_rate": 2.885155156803029e-05,
      "loss": 0.1771,
      "step": 5588
    },
    {
      "epoch": 0.11506942336678894,
      "grad_norm": 4.063407897949219,
      "learning_rate": 2.8850728455016875e-05,
      "loss": 0.2245,
      "step": 5592
    },
    {
      "epoch": 0.11515173339780953,
      "grad_norm": 5.313538551330566,
      "learning_rate": 2.8849905342003457e-05,
      "loss": 0.2216,
      "step": 5596
    },
    {
      "epoch": 0.11523404342883012,
      "grad_norm": 3.689256429672241,
      "learning_rate": 2.884908222899004e-05,
      "loss": 0.2311,
      "step": 5600
    },
    {
      "epoch": 0.11531635345985071,
      "grad_norm": 2.343987226486206,
      "learning_rate": 2.8848259115976623e-05,
      "loss": 0.2138,
      "step": 5604
    },
    {
      "epoch": 0.1153986634908713,
      "grad_norm": 3.8740832805633545,
      "learning_rate": 2.884743600296321e-05,
      "loss": 0.2725,
      "step": 5608
    },
    {
      "epoch": 0.11548097352189189,
      "grad_norm": 1.1582502126693726,
      "learning_rate": 2.8846612889949788e-05,
      "loss": 0.0998,
      "step": 5612
    },
    {
      "epoch": 0.11556328355291248,
      "grad_norm": 2.8561794757843018,
      "learning_rate": 2.8845789776936374e-05,
      "loss": 0.2052,
      "step": 5616
    },
    {
      "epoch": 0.11564559358393309,
      "grad_norm": 3.997819423675537,
      "learning_rate": 2.8844966663922957e-05,
      "loss": 0.2635,
      "step": 5620
    },
    {
      "epoch": 0.11572790361495368,
      "grad_norm": 1.246023416519165,
      "learning_rate": 2.884414355090954e-05,
      "loss": 0.0911,
      "step": 5624
    },
    {
      "epoch": 0.11581021364597427,
      "grad_norm": 4.764558792114258,
      "learning_rate": 2.8843320437896122e-05,
      "loss": 0.27,
      "step": 5628
    },
    {
      "epoch": 0.11589252367699486,
      "grad_norm": 5.116897106170654,
      "learning_rate": 2.8842497324882708e-05,
      "loss": 0.1823,
      "step": 5632
    },
    {
      "epoch": 0.11597483370801545,
      "grad_norm": 3.2875707149505615,
      "learning_rate": 2.884167421186929e-05,
      "loss": 0.1807,
      "step": 5636
    },
    {
      "epoch": 0.11605714373903604,
      "grad_norm": 3.276962995529175,
      "learning_rate": 2.8840851098855873e-05,
      "loss": 0.1615,
      "step": 5640
    },
    {
      "epoch": 0.11613945377005663,
      "grad_norm": 3.3722164630889893,
      "learning_rate": 2.8840027985842456e-05,
      "loss": 0.1547,
      "step": 5644
    },
    {
      "epoch": 0.11622176380107724,
      "grad_norm": 4.4977521896362305,
      "learning_rate": 2.8839204872829042e-05,
      "loss": 0.2367,
      "step": 5648
    },
    {
      "epoch": 0.11630407383209783,
      "grad_norm": 2.902327060699463,
      "learning_rate": 2.883838175981562e-05,
      "loss": 0.1835,
      "step": 5652
    },
    {
      "epoch": 0.11638638386311842,
      "grad_norm": 4.4673848152160645,
      "learning_rate": 2.8837558646802207e-05,
      "loss": 0.2968,
      "step": 5656
    },
    {
      "epoch": 0.11646869389413901,
      "grad_norm": 3.567960500717163,
      "learning_rate": 2.883673553378879e-05,
      "loss": 0.2009,
      "step": 5660
    },
    {
      "epoch": 0.1165510039251596,
      "grad_norm": 5.042069435119629,
      "learning_rate": 2.8835912420775372e-05,
      "loss": 0.1819,
      "step": 5664
    },
    {
      "epoch": 0.11663331395618019,
      "grad_norm": 7.521784782409668,
      "learning_rate": 2.8835089307761955e-05,
      "loss": 0.3339,
      "step": 5668
    },
    {
      "epoch": 0.11671562398720078,
      "grad_norm": 0.6969194412231445,
      "learning_rate": 2.883426619474854e-05,
      "loss": 0.1139,
      "step": 5672
    },
    {
      "epoch": 0.11679793401822139,
      "grad_norm": 1.8480297327041626,
      "learning_rate": 2.883344308173512e-05,
      "loss": 0.1644,
      "step": 5676
    },
    {
      "epoch": 0.11688024404924198,
      "grad_norm": 4.185808181762695,
      "learning_rate": 2.8832619968721706e-05,
      "loss": 0.1833,
      "step": 5680
    },
    {
      "epoch": 0.11696255408026257,
      "grad_norm": 4.769192695617676,
      "learning_rate": 2.883179685570829e-05,
      "loss": 0.1851,
      "step": 5684
    },
    {
      "epoch": 0.11704486411128316,
      "grad_norm": 5.080068588256836,
      "learning_rate": 2.883097374269487e-05,
      "loss": 0.3034,
      "step": 5688
    },
    {
      "epoch": 0.11712717414230375,
      "grad_norm": 3.2071309089660645,
      "learning_rate": 2.8830150629681458e-05,
      "loss": 0.2334,
      "step": 5692
    },
    {
      "epoch": 0.11720948417332434,
      "grad_norm": 2.4734818935394287,
      "learning_rate": 2.882932751666804e-05,
      "loss": 0.2662,
      "step": 5696
    },
    {
      "epoch": 0.11729179420434493,
      "grad_norm": 4.6781792640686035,
      "learning_rate": 2.8828504403654623e-05,
      "loss": 0.1804,
      "step": 5700
    },
    {
      "epoch": 0.11737410423536554,
      "grad_norm": 4.367606163024902,
      "learning_rate": 2.8827681290641205e-05,
      "loss": 0.2421,
      "step": 5704
    },
    {
      "epoch": 0.11745641426638613,
      "grad_norm": 2.451810121536255,
      "learning_rate": 2.882685817762779e-05,
      "loss": 0.0941,
      "step": 5708
    },
    {
      "epoch": 0.11753872429740672,
      "grad_norm": 2.212754964828491,
      "learning_rate": 2.882603506461437e-05,
      "loss": 0.2478,
      "step": 5712
    },
    {
      "epoch": 0.11762103432842731,
      "grad_norm": 4.717925548553467,
      "learning_rate": 2.8825211951600957e-05,
      "loss": 0.2688,
      "step": 5716
    },
    {
      "epoch": 0.1177033443594479,
      "grad_norm": 3.5971741676330566,
      "learning_rate": 2.882438883858754e-05,
      "loss": 0.1753,
      "step": 5720
    },
    {
      "epoch": 0.1177856543904685,
      "grad_norm": 9.612916946411133,
      "learning_rate": 2.8823565725574122e-05,
      "loss": 0.287,
      "step": 5724
    },
    {
      "epoch": 0.11786796442148909,
      "grad_norm": 4.111320972442627,
      "learning_rate": 2.8822742612560705e-05,
      "loss": 0.2697,
      "step": 5728
    },
    {
      "epoch": 0.11795027445250969,
      "grad_norm": 4.038549423217773,
      "learning_rate": 2.882191949954729e-05,
      "loss": 0.2391,
      "step": 5732
    },
    {
      "epoch": 0.11803258448353028,
      "grad_norm": 3.113957405090332,
      "learning_rate": 2.8821096386533873e-05,
      "loss": 0.3634,
      "step": 5736
    },
    {
      "epoch": 0.11811489451455087,
      "grad_norm": 2.714195966720581,
      "learning_rate": 2.8820273273520456e-05,
      "loss": 0.2021,
      "step": 5740
    },
    {
      "epoch": 0.11819720454557146,
      "grad_norm": 1.9728453159332275,
      "learning_rate": 2.881945016050704e-05,
      "loss": 0.2111,
      "step": 5744
    },
    {
      "epoch": 0.11827951457659205,
      "grad_norm": 5.9227800369262695,
      "learning_rate": 2.8818627047493625e-05,
      "loss": 0.2476,
      "step": 5748
    },
    {
      "epoch": 0.11836182460761265,
      "grad_norm": 2.137594699859619,
      "learning_rate": 2.8817803934480204e-05,
      "loss": 0.1529,
      "step": 5752
    },
    {
      "epoch": 0.11844413463863324,
      "grad_norm": 1.8538181781768799,
      "learning_rate": 2.881698082146679e-05,
      "loss": 0.1648,
      "step": 5756
    },
    {
      "epoch": 0.11852644466965384,
      "grad_norm": 1.68874192237854,
      "learning_rate": 2.8816157708453373e-05,
      "loss": 0.1752,
      "step": 5760
    },
    {
      "epoch": 0.11860875470067443,
      "grad_norm": 6.522332668304443,
      "learning_rate": 2.8815334595439955e-05,
      "loss": 0.3046,
      "step": 5764
    },
    {
      "epoch": 0.11869106473169502,
      "grad_norm": 1.9298288822174072,
      "learning_rate": 2.8814511482426538e-05,
      "loss": 0.1482,
      "step": 5768
    },
    {
      "epoch": 0.11877337476271561,
      "grad_norm": 0.8880293369293213,
      "learning_rate": 2.8813688369413124e-05,
      "loss": 0.1552,
      "step": 5772
    },
    {
      "epoch": 0.1188556847937362,
      "grad_norm": 1.5182199478149414,
      "learning_rate": 2.8812865256399703e-05,
      "loss": 0.109,
      "step": 5776
    },
    {
      "epoch": 0.1189379948247568,
      "grad_norm": 3.449707269668579,
      "learning_rate": 2.881204214338629e-05,
      "loss": 0.1989,
      "step": 5780
    },
    {
      "epoch": 0.11902030485577739,
      "grad_norm": 2.902693748474121,
      "learning_rate": 2.8811219030372872e-05,
      "loss": 0.1953,
      "step": 5784
    },
    {
      "epoch": 0.11910261488679799,
      "grad_norm": 4.669979095458984,
      "learning_rate": 2.8810395917359454e-05,
      "loss": 0.3005,
      "step": 5788
    },
    {
      "epoch": 0.11918492491781858,
      "grad_norm": 4.2324395179748535,
      "learning_rate": 2.8809572804346037e-05,
      "loss": 0.1863,
      "step": 5792
    },
    {
      "epoch": 0.11926723494883917,
      "grad_norm": 4.245121002197266,
      "learning_rate": 2.8808749691332623e-05,
      "loss": 0.2086,
      "step": 5796
    },
    {
      "epoch": 0.11934954497985976,
      "grad_norm": 4.986168384552002,
      "learning_rate": 2.8807926578319202e-05,
      "loss": 0.283,
      "step": 5800
    },
    {
      "epoch": 0.11943185501088036,
      "grad_norm": 4.011320114135742,
      "learning_rate": 2.8807103465305788e-05,
      "loss": 0.1839,
      "step": 5804
    },
    {
      "epoch": 0.11951416504190095,
      "grad_norm": 4.971421718597412,
      "learning_rate": 2.880628035229237e-05,
      "loss": 0.2003,
      "step": 5808
    },
    {
      "epoch": 0.11959647507292154,
      "grad_norm": 2.8333370685577393,
      "learning_rate": 2.8805457239278954e-05,
      "loss": 0.121,
      "step": 5812
    },
    {
      "epoch": 0.11967878510394214,
      "grad_norm": 2.5472006797790527,
      "learning_rate": 2.8804634126265536e-05,
      "loss": 0.1875,
      "step": 5816
    },
    {
      "epoch": 0.11976109513496273,
      "grad_norm": 3.1156911849975586,
      "learning_rate": 2.8803811013252122e-05,
      "loss": 0.1518,
      "step": 5820
    },
    {
      "epoch": 0.11984340516598332,
      "grad_norm": 6.0840325355529785,
      "learning_rate": 2.88029879002387e-05,
      "loss": 0.2325,
      "step": 5824
    },
    {
      "epoch": 0.11992571519700392,
      "grad_norm": 3.9457759857177734,
      "learning_rate": 2.8802164787225287e-05,
      "loss": 0.1403,
      "step": 5828
    },
    {
      "epoch": 0.1200080252280245,
      "grad_norm": 1.2588467597961426,
      "learning_rate": 2.880134167421187e-05,
      "loss": 0.1591,
      "step": 5832
    },
    {
      "epoch": 0.1200903352590451,
      "grad_norm": 3.982412338256836,
      "learning_rate": 2.8800518561198456e-05,
      "loss": 0.1615,
      "step": 5836
    },
    {
      "epoch": 0.12017264529006569,
      "grad_norm": 2.8322949409484863,
      "learning_rate": 2.8799695448185035e-05,
      "loss": 0.232,
      "step": 5840
    },
    {
      "epoch": 0.1202549553210863,
      "grad_norm": 4.392844200134277,
      "learning_rate": 2.879887233517162e-05,
      "loss": 0.1339,
      "step": 5844
    },
    {
      "epoch": 0.12033726535210688,
      "grad_norm": 3.237078905105591,
      "learning_rate": 2.8798049222158204e-05,
      "loss": 0.1545,
      "step": 5848
    },
    {
      "epoch": 0.12041957538312748,
      "grad_norm": 3.4578471183776855,
      "learning_rate": 2.8797226109144787e-05,
      "loss": 0.266,
      "step": 5852
    },
    {
      "epoch": 0.12050188541414807,
      "grad_norm": 1.3713412284851074,
      "learning_rate": 2.879640299613137e-05,
      "loss": 0.0694,
      "step": 5856
    },
    {
      "epoch": 0.12058419544516866,
      "grad_norm": 5.20269775390625,
      "learning_rate": 2.8795579883117955e-05,
      "loss": 0.2894,
      "step": 5860
    },
    {
      "epoch": 0.12066650547618925,
      "grad_norm": 2.8365800380706787,
      "learning_rate": 2.8794756770104535e-05,
      "loss": 0.2282,
      "step": 5864
    },
    {
      "epoch": 0.12074881550720984,
      "grad_norm": 4.547875881195068,
      "learning_rate": 2.879393365709112e-05,
      "loss": 0.1664,
      "step": 5868
    },
    {
      "epoch": 0.12083112553823044,
      "grad_norm": 1.7760114669799805,
      "learning_rate": 2.8793110544077703e-05,
      "loss": 0.3489,
      "step": 5872
    },
    {
      "epoch": 0.12091343556925103,
      "grad_norm": 2.139759063720703,
      "learning_rate": 2.8792287431064286e-05,
      "loss": 0.2993,
      "step": 5876
    },
    {
      "epoch": 0.12099574560027163,
      "grad_norm": 1.1132872104644775,
      "learning_rate": 2.879146431805087e-05,
      "loss": 0.1619,
      "step": 5880
    },
    {
      "epoch": 0.12107805563129222,
      "grad_norm": 3.0579442977905273,
      "learning_rate": 2.8790641205037454e-05,
      "loss": 0.2867,
      "step": 5884
    },
    {
      "epoch": 0.12116036566231281,
      "grad_norm": 3.822634696960449,
      "learning_rate": 2.8789818092024034e-05,
      "loss": 0.2589,
      "step": 5888
    },
    {
      "epoch": 0.1212426756933334,
      "grad_norm": 5.569231986999512,
      "learning_rate": 2.878899497901062e-05,
      "loss": 0.2197,
      "step": 5892
    },
    {
      "epoch": 0.12132498572435399,
      "grad_norm": 3.610246181488037,
      "learning_rate": 2.8788171865997202e-05,
      "loss": 0.2626,
      "step": 5896
    },
    {
      "epoch": 0.1214072957553746,
      "grad_norm": 1.3963425159454346,
      "learning_rate": 2.8787348752983785e-05,
      "loss": 0.1612,
      "step": 5900
    },
    {
      "epoch": 0.12148960578639519,
      "grad_norm": 5.385947227478027,
      "learning_rate": 2.8786525639970368e-05,
      "loss": 0.3018,
      "step": 5904
    },
    {
      "epoch": 0.12157191581741578,
      "grad_norm": 3.8394176959991455,
      "learning_rate": 2.8785702526956954e-05,
      "loss": 0.21,
      "step": 5908
    },
    {
      "epoch": 0.12165422584843637,
      "grad_norm": 3.9233357906341553,
      "learning_rate": 2.8784879413943533e-05,
      "loss": 0.2069,
      "step": 5912
    },
    {
      "epoch": 0.12173653587945696,
      "grad_norm": 4.963622093200684,
      "learning_rate": 2.878405630093012e-05,
      "loss": 0.2043,
      "step": 5916
    },
    {
      "epoch": 0.12181884591047755,
      "grad_norm": 5.765074253082275,
      "learning_rate": 2.87832331879167e-05,
      "loss": 0.365,
      "step": 5920
    },
    {
      "epoch": 0.12190115594149814,
      "grad_norm": 5.5764265060424805,
      "learning_rate": 2.8782410074903284e-05,
      "loss": 0.2385,
      "step": 5924
    },
    {
      "epoch": 0.12198346597251873,
      "grad_norm": 2.5566442012786865,
      "learning_rate": 2.8781586961889867e-05,
      "loss": 0.1339,
      "step": 5928
    },
    {
      "epoch": 0.12206577600353934,
      "grad_norm": 1.033523678779602,
      "learning_rate": 2.8780763848876453e-05,
      "loss": 0.2944,
      "step": 5932
    },
    {
      "epoch": 0.12214808603455993,
      "grad_norm": 5.299746036529541,
      "learning_rate": 2.8779940735863036e-05,
      "loss": 0.2924,
      "step": 5936
    },
    {
      "epoch": 0.12223039606558052,
      "grad_norm": 2.7893643379211426,
      "learning_rate": 2.8779117622849618e-05,
      "loss": 0.2302,
      "step": 5940
    },
    {
      "epoch": 0.12231270609660111,
      "grad_norm": 1.4067152738571167,
      "learning_rate": 2.87782945098362e-05,
      "loss": 0.1738,
      "step": 5944
    },
    {
      "epoch": 0.1223950161276217,
      "grad_norm": 3.0038864612579346,
      "learning_rate": 2.8777471396822787e-05,
      "loss": 0.2111,
      "step": 5948
    },
    {
      "epoch": 0.12247732615864229,
      "grad_norm": 2.2304131984710693,
      "learning_rate": 2.8776648283809366e-05,
      "loss": 0.1876,
      "step": 5952
    },
    {
      "epoch": 0.12255963618966288,
      "grad_norm": 1.6632875204086304,
      "learning_rate": 2.8775825170795952e-05,
      "loss": 0.1336,
      "step": 5956
    },
    {
      "epoch": 0.12264194622068349,
      "grad_norm": 1.8939930200576782,
      "learning_rate": 2.8775002057782535e-05,
      "loss": 0.2396,
      "step": 5960
    },
    {
      "epoch": 0.12272425625170408,
      "grad_norm": 2.987011432647705,
      "learning_rate": 2.8774178944769117e-05,
      "loss": 0.22,
      "step": 5964
    },
    {
      "epoch": 0.12280656628272467,
      "grad_norm": 2.3618481159210205,
      "learning_rate": 2.87733558317557e-05,
      "loss": 0.1979,
      "step": 5968
    },
    {
      "epoch": 0.12288887631374526,
      "grad_norm": 6.3549580574035645,
      "learning_rate": 2.8772532718742286e-05,
      "loss": 0.2765,
      "step": 5972
    },
    {
      "epoch": 0.12297118634476585,
      "grad_norm": 5.589334487915039,
      "learning_rate": 2.8771709605728865e-05,
      "loss": 0.2692,
      "step": 5976
    },
    {
      "epoch": 0.12305349637578644,
      "grad_norm": 3.045898675918579,
      "learning_rate": 2.877088649271545e-05,
      "loss": 0.1283,
      "step": 5980
    },
    {
      "epoch": 0.12313580640680703,
      "grad_norm": 5.898799419403076,
      "learning_rate": 2.8770063379702034e-05,
      "loss": 0.1916,
      "step": 5984
    },
    {
      "epoch": 0.12321811643782764,
      "grad_norm": 4.553197860717773,
      "learning_rate": 2.8769240266688617e-05,
      "loss": 0.242,
      "step": 5988
    },
    {
      "epoch": 0.12330042646884823,
      "grad_norm": 2.5994699001312256,
      "learning_rate": 2.87684171536752e-05,
      "loss": 0.0962,
      "step": 5992
    },
    {
      "epoch": 0.12338273649986882,
      "grad_norm": 2.9825987815856934,
      "learning_rate": 2.8767594040661785e-05,
      "loss": 0.2569,
      "step": 5996
    },
    {
      "epoch": 0.12346504653088941,
      "grad_norm": 4.061031341552734,
      "learning_rate": 2.8766770927648364e-05,
      "loss": 0.2612,
      "step": 6000
    },
    {
      "epoch": 0.12354735656191,
      "grad_norm": 2.470162868499756,
      "learning_rate": 2.876594781463495e-05,
      "loss": 0.1669,
      "step": 6004
    },
    {
      "epoch": 0.12362966659293059,
      "grad_norm": 2.1768665313720703,
      "learning_rate": 2.8765124701621533e-05,
      "loss": 0.1185,
      "step": 6008
    },
    {
      "epoch": 0.12371197662395118,
      "grad_norm": 4.525310516357422,
      "learning_rate": 2.8764301588608116e-05,
      "loss": 0.2326,
      "step": 6012
    },
    {
      "epoch": 0.12379428665497179,
      "grad_norm": 1.6040220260620117,
      "learning_rate": 2.87634784755947e-05,
      "loss": 0.3051,
      "step": 6016
    },
    {
      "epoch": 0.12387659668599238,
      "grad_norm": 1.7118340730667114,
      "learning_rate": 2.8762655362581284e-05,
      "loss": 0.2047,
      "step": 6020
    },
    {
      "epoch": 0.12395890671701297,
      "grad_norm": 1.3210598230361938,
      "learning_rate": 2.8761832249567867e-05,
      "loss": 0.1209,
      "step": 6024
    },
    {
      "epoch": 0.12404121674803356,
      "grad_norm": 5.678856372833252,
      "learning_rate": 2.876100913655445e-05,
      "loss": 0.2394,
      "step": 6028
    },
    {
      "epoch": 0.12412352677905415,
      "grad_norm": 4.224027156829834,
      "learning_rate": 2.8760186023541032e-05,
      "loss": 0.1967,
      "step": 6032
    },
    {
      "epoch": 0.12420583681007474,
      "grad_norm": 3.922109842300415,
      "learning_rate": 2.875936291052762e-05,
      "loss": 0.2116,
      "step": 6036
    },
    {
      "epoch": 0.12428814684109533,
      "grad_norm": 1.595228672027588,
      "learning_rate": 2.8758539797514198e-05,
      "loss": 0.1397,
      "step": 6040
    },
    {
      "epoch": 0.12437045687211594,
      "grad_norm": 3.618196725845337,
      "learning_rate": 2.8757716684500784e-05,
      "loss": 0.2193,
      "step": 6044
    },
    {
      "epoch": 0.12445276690313653,
      "grad_norm": 2.515111207962036,
      "learning_rate": 2.8756893571487366e-05,
      "loss": 0.1811,
      "step": 6048
    },
    {
      "epoch": 0.12453507693415712,
      "grad_norm": 3.949829578399658,
      "learning_rate": 2.875607045847395e-05,
      "loss": 0.1634,
      "step": 6052
    },
    {
      "epoch": 0.12461738696517771,
      "grad_norm": 1.4657810926437378,
      "learning_rate": 2.875524734546053e-05,
      "loss": 0.1374,
      "step": 6056
    },
    {
      "epoch": 0.1246996969961983,
      "grad_norm": 2.90207576751709,
      "learning_rate": 2.8754424232447118e-05,
      "loss": 0.1734,
      "step": 6060
    },
    {
      "epoch": 0.1247820070272189,
      "grad_norm": 4.648775100708008,
      "learning_rate": 2.8753601119433697e-05,
      "loss": 0.1892,
      "step": 6064
    },
    {
      "epoch": 0.12486431705823949,
      "grad_norm": 1.9077526330947876,
      "learning_rate": 2.8752778006420283e-05,
      "loss": 0.2051,
      "step": 6068
    },
    {
      "epoch": 0.12494662708926009,
      "grad_norm": 0.8938823938369751,
      "learning_rate": 2.8751954893406865e-05,
      "loss": 0.193,
      "step": 6072
    },
    {
      "epoch": 0.12502893712028068,
      "grad_norm": 3.725639820098877,
      "learning_rate": 2.8751131780393448e-05,
      "loss": 0.2212,
      "step": 6076
    },
    {
      "epoch": 0.12511124715130126,
      "grad_norm": 2.3358824253082275,
      "learning_rate": 2.875030866738003e-05,
      "loss": 0.2181,
      "step": 6080
    },
    {
      "epoch": 0.12519355718232186,
      "grad_norm": 4.578064918518066,
      "learning_rate": 2.8749485554366617e-05,
      "loss": 0.2851,
      "step": 6084
    },
    {
      "epoch": 0.12527586721334247,
      "grad_norm": 3.8414323329925537,
      "learning_rate": 2.8748662441353196e-05,
      "loss": 0.2167,
      "step": 6088
    },
    {
      "epoch": 0.12535817724436304,
      "grad_norm": 1.293778657913208,
      "learning_rate": 2.8747839328339782e-05,
      "loss": 0.1186,
      "step": 6092
    },
    {
      "epoch": 0.12544048727538365,
      "grad_norm": 1.7492750883102417,
      "learning_rate": 2.8747016215326365e-05,
      "loss": 0.1306,
      "step": 6096
    },
    {
      "epoch": 0.12552279730640423,
      "grad_norm": 5.466887950897217,
      "learning_rate": 2.8746193102312947e-05,
      "loss": 0.3772,
      "step": 6100
    },
    {
      "epoch": 0.12560510733742483,
      "grad_norm": 3.3116676807403564,
      "learning_rate": 2.874536998929953e-05,
      "loss": 0.2114,
      "step": 6104
    },
    {
      "epoch": 0.1256874173684454,
      "grad_norm": 3.155846118927002,
      "learning_rate": 2.8744546876286116e-05,
      "loss": 0.155,
      "step": 6108
    },
    {
      "epoch": 0.125769727399466,
      "grad_norm": 3.1671764850616455,
      "learning_rate": 2.8743723763272695e-05,
      "loss": 0.0697,
      "step": 6112
    },
    {
      "epoch": 0.12585203743048662,
      "grad_norm": 0.7525452971458435,
      "learning_rate": 2.874290065025928e-05,
      "loss": 0.2473,
      "step": 6116
    },
    {
      "epoch": 0.1259343474615072,
      "grad_norm": 2.6196608543395996,
      "learning_rate": 2.8742077537245864e-05,
      "loss": 0.3187,
      "step": 6120
    },
    {
      "epoch": 0.1260166574925278,
      "grad_norm": 5.127924919128418,
      "learning_rate": 2.874125442423245e-05,
      "loss": 0.1893,
      "step": 6124
    },
    {
      "epoch": 0.12609896752354838,
      "grad_norm": 4.377749443054199,
      "learning_rate": 2.874043131121903e-05,
      "loss": 0.167,
      "step": 6128
    },
    {
      "epoch": 0.12618127755456898,
      "grad_norm": 0.89821457862854,
      "learning_rate": 2.8739608198205615e-05,
      "loss": 0.1223,
      "step": 6132
    },
    {
      "epoch": 0.12626358758558956,
      "grad_norm": 2.07768177986145,
      "learning_rate": 2.8738785085192198e-05,
      "loss": 0.2882,
      "step": 6136
    },
    {
      "epoch": 0.12634589761661016,
      "grad_norm": 4.453267574310303,
      "learning_rate": 2.873796197217878e-05,
      "loss": 0.1978,
      "step": 6140
    },
    {
      "epoch": 0.12642820764763077,
      "grad_norm": 2.9967079162597656,
      "learning_rate": 2.8737138859165363e-05,
      "loss": 0.1855,
      "step": 6144
    },
    {
      "epoch": 0.12651051767865135,
      "grad_norm": 3.5736489295959473,
      "learning_rate": 2.873631574615195e-05,
      "loss": 0.2208,
      "step": 6148
    },
    {
      "epoch": 0.12659282770967195,
      "grad_norm": 3.2756435871124268,
      "learning_rate": 2.8735492633138528e-05,
      "loss": 0.119,
      "step": 6152
    },
    {
      "epoch": 0.12667513774069253,
      "grad_norm": 3.91664981842041,
      "learning_rate": 2.8734669520125114e-05,
      "loss": 0.1522,
      "step": 6156
    },
    {
      "epoch": 0.12675744777171313,
      "grad_norm": 4.7321696281433105,
      "learning_rate": 2.8733846407111697e-05,
      "loss": 0.2625,
      "step": 6160
    },
    {
      "epoch": 0.1268397578027337,
      "grad_norm": 3.8762688636779785,
      "learning_rate": 2.873302329409828e-05,
      "loss": 0.2183,
      "step": 6164
    },
    {
      "epoch": 0.12692206783375432,
      "grad_norm": 0.9462467432022095,
      "learning_rate": 2.8732200181084862e-05,
      "loss": 0.109,
      "step": 6168
    },
    {
      "epoch": 0.12700437786477492,
      "grad_norm": 3.9836795330047607,
      "learning_rate": 2.8731377068071448e-05,
      "loss": 0.1476,
      "step": 6172
    },
    {
      "epoch": 0.1270866878957955,
      "grad_norm": 2.9733331203460693,
      "learning_rate": 2.8730553955058027e-05,
      "loss": 0.2802,
      "step": 6176
    },
    {
      "epoch": 0.1271689979268161,
      "grad_norm": 4.228543758392334,
      "learning_rate": 2.8729730842044613e-05,
      "loss": 0.1687,
      "step": 6180
    },
    {
      "epoch": 0.12725130795783668,
      "grad_norm": 5.065915107727051,
      "learning_rate": 2.8728907729031196e-05,
      "loss": 0.1801,
      "step": 6184
    },
    {
      "epoch": 0.12733361798885728,
      "grad_norm": 3.4320452213287354,
      "learning_rate": 2.872808461601778e-05,
      "loss": 0.1572,
      "step": 6188
    },
    {
      "epoch": 0.12741592801987786,
      "grad_norm": 4.522571086883545,
      "learning_rate": 2.872726150300436e-05,
      "loss": 0.2931,
      "step": 6192
    },
    {
      "epoch": 0.12749823805089847,
      "grad_norm": 1.9091734886169434,
      "learning_rate": 2.8726438389990947e-05,
      "loss": 0.1497,
      "step": 6196
    },
    {
      "epoch": 0.12758054808191907,
      "grad_norm": 1.9783756732940674,
      "learning_rate": 2.8725821055230884e-05,
      "loss": 0.198,
      "step": 6200
    },
    {
      "epoch": 0.12766285811293965,
      "grad_norm": 4.782546043395996,
      "learning_rate": 2.8724997942217467e-05,
      "loss": 0.2024,
      "step": 6204
    },
    {
      "epoch": 0.12774516814396025,
      "grad_norm": 3.3264243602752686,
      "learning_rate": 2.8724174829204053e-05,
      "loss": 0.2394,
      "step": 6208
    },
    {
      "epoch": 0.12782747817498083,
      "grad_norm": 2.5256333351135254,
      "learning_rate": 2.8723351716190632e-05,
      "loss": 0.2336,
      "step": 6212
    },
    {
      "epoch": 0.12790978820600143,
      "grad_norm": 2.7930116653442383,
      "learning_rate": 2.872252860317722e-05,
      "loss": 0.1845,
      "step": 6216
    },
    {
      "epoch": 0.127992098237022,
      "grad_norm": 3.0500078201293945,
      "learning_rate": 2.87217054901638e-05,
      "loss": 0.2687,
      "step": 6220
    },
    {
      "epoch": 0.12807440826804262,
      "grad_norm": 2.353914260864258,
      "learning_rate": 2.8720882377150384e-05,
      "loss": 0.133,
      "step": 6224
    },
    {
      "epoch": 0.12815671829906322,
      "grad_norm": 4.385916709899902,
      "learning_rate": 2.8720059264136966e-05,
      "loss": 0.2335,
      "step": 6228
    },
    {
      "epoch": 0.1282390283300838,
      "grad_norm": 3.219428777694702,
      "learning_rate": 2.8719236151123552e-05,
      "loss": 0.3355,
      "step": 6232
    },
    {
      "epoch": 0.1283213383611044,
      "grad_norm": 3.553426504135132,
      "learning_rate": 2.871841303811013e-05,
      "loss": 0.1826,
      "step": 6236
    },
    {
      "epoch": 0.12840364839212498,
      "grad_norm": 2.076437473297119,
      "learning_rate": 2.8717589925096718e-05,
      "loss": 0.2547,
      "step": 6240
    },
    {
      "epoch": 0.12848595842314559,
      "grad_norm": 5.703651428222656,
      "learning_rate": 2.87167668120833e-05,
      "loss": 0.1822,
      "step": 6244
    },
    {
      "epoch": 0.12856826845416616,
      "grad_norm": 0.5281721353530884,
      "learning_rate": 2.8715943699069883e-05,
      "loss": 0.1235,
      "step": 6248
    },
    {
      "epoch": 0.12865057848518677,
      "grad_norm": 3.3553466796875,
      "learning_rate": 2.8715120586056465e-05,
      "loss": 0.2592,
      "step": 6252
    },
    {
      "epoch": 0.12873288851620737,
      "grad_norm": 1.3553491830825806,
      "learning_rate": 2.871429747304305e-05,
      "loss": 0.2276,
      "step": 6256
    },
    {
      "epoch": 0.12881519854722795,
      "grad_norm": 2.3991501331329346,
      "learning_rate": 2.871347436002963e-05,
      "loss": 0.1942,
      "step": 6260
    },
    {
      "epoch": 0.12889750857824855,
      "grad_norm": 3.9836580753326416,
      "learning_rate": 2.8712651247016217e-05,
      "loss": 0.3666,
      "step": 6264
    },
    {
      "epoch": 0.12897981860926913,
      "grad_norm": 3.2587249279022217,
      "learning_rate": 2.87118281340028e-05,
      "loss": 0.2418,
      "step": 6268
    },
    {
      "epoch": 0.12906212864028974,
      "grad_norm": 3.999404191970825,
      "learning_rate": 2.8711005020989385e-05,
      "loss": 0.1633,
      "step": 6272
    },
    {
      "epoch": 0.1291444386713103,
      "grad_norm": 3.029247522354126,
      "learning_rate": 2.8710181907975965e-05,
      "loss": 0.1956,
      "step": 6276
    },
    {
      "epoch": 0.12922674870233092,
      "grad_norm": 3.3328843116760254,
      "learning_rate": 2.870935879496255e-05,
      "loss": 0.2107,
      "step": 6280
    },
    {
      "epoch": 0.12930905873335152,
      "grad_norm": 3.2406578063964844,
      "learning_rate": 2.8708535681949133e-05,
      "loss": 0.212,
      "step": 6284
    },
    {
      "epoch": 0.1293913687643721,
      "grad_norm": 4.3532209396362305,
      "learning_rate": 2.8707712568935716e-05,
      "loss": 0.2392,
      "step": 6288
    },
    {
      "epoch": 0.1294736787953927,
      "grad_norm": 5.1855340003967285,
      "learning_rate": 2.87068894559223e-05,
      "loss": 0.2413,
      "step": 6292
    },
    {
      "epoch": 0.12955598882641328,
      "grad_norm": 3.3315422534942627,
      "learning_rate": 2.8706066342908885e-05,
      "loss": 0.1777,
      "step": 6296
    },
    {
      "epoch": 0.1296382988574339,
      "grad_norm": 4.112135887145996,
      "learning_rate": 2.8705243229895464e-05,
      "loss": 0.2119,
      "step": 6300
    },
    {
      "epoch": 0.12972060888845446,
      "grad_norm": 2.305838108062744,
      "learning_rate": 2.870442011688205e-05,
      "loss": 0.2426,
      "step": 6304
    },
    {
      "epoch": 0.12980291891947507,
      "grad_norm": 2.3770322799682617,
      "learning_rate": 2.8703597003868632e-05,
      "loss": 0.2068,
      "step": 6308
    },
    {
      "epoch": 0.12988522895049567,
      "grad_norm": 1.6963642835617065,
      "learning_rate": 2.8702773890855215e-05,
      "loss": 0.1862,
      "step": 6312
    },
    {
      "epoch": 0.12996753898151625,
      "grad_norm": 2.1774024963378906,
      "learning_rate": 2.8701950777841798e-05,
      "loss": 0.2583,
      "step": 6316
    },
    {
      "epoch": 0.13004984901253686,
      "grad_norm": 6.048376083374023,
      "learning_rate": 2.8701127664828384e-05,
      "loss": 0.2438,
      "step": 6320
    },
    {
      "epoch": 0.13013215904355743,
      "grad_norm": 7.934964656829834,
      "learning_rate": 2.8700304551814963e-05,
      "loss": 0.2067,
      "step": 6324
    },
    {
      "epoch": 0.13021446907457804,
      "grad_norm": 0.7581052184104919,
      "learning_rate": 2.869948143880155e-05,
      "loss": 0.1564,
      "step": 6328
    },
    {
      "epoch": 0.13029677910559861,
      "grad_norm": 4.901032447814941,
      "learning_rate": 2.869865832578813e-05,
      "loss": 0.2003,
      "step": 6332
    },
    {
      "epoch": 0.13037908913661922,
      "grad_norm": 4.526727199554443,
      "learning_rate": 2.8697835212774714e-05,
      "loss": 0.1632,
      "step": 6336
    },
    {
      "epoch": 0.13046139916763982,
      "grad_norm": 3.5836575031280518,
      "learning_rate": 2.8697012099761297e-05,
      "loss": 0.1859,
      "step": 6340
    },
    {
      "epoch": 0.1305437091986604,
      "grad_norm": 4.455111980438232,
      "learning_rate": 2.8696188986747883e-05,
      "loss": 0.2497,
      "step": 6344
    },
    {
      "epoch": 0.130626019229681,
      "grad_norm": 2.087186574935913,
      "learning_rate": 2.8695365873734462e-05,
      "loss": 0.1987,
      "step": 6348
    },
    {
      "epoch": 0.13070832926070158,
      "grad_norm": 3.1861376762390137,
      "learning_rate": 2.8694542760721048e-05,
      "loss": 0.1966,
      "step": 6352
    },
    {
      "epoch": 0.1307906392917222,
      "grad_norm": 3.9149081707000732,
      "learning_rate": 2.869371964770763e-05,
      "loss": 0.2838,
      "step": 6356
    },
    {
      "epoch": 0.13087294932274277,
      "grad_norm": 3.765094041824341,
      "learning_rate": 2.8692896534694213e-05,
      "loss": 0.1564,
      "step": 6360
    },
    {
      "epoch": 0.13095525935376337,
      "grad_norm": 2.392852783203125,
      "learning_rate": 2.8692073421680796e-05,
      "loss": 0.1517,
      "step": 6364
    },
    {
      "epoch": 0.13103756938478398,
      "grad_norm": 2.6128804683685303,
      "learning_rate": 2.8691250308667382e-05,
      "loss": 0.1252,
      "step": 6368
    },
    {
      "epoch": 0.13111987941580455,
      "grad_norm": 3.119365692138672,
      "learning_rate": 2.8690427195653965e-05,
      "loss": 0.1547,
      "step": 6372
    },
    {
      "epoch": 0.13120218944682516,
      "grad_norm": 4.120260238647461,
      "learning_rate": 2.8689604082640547e-05,
      "loss": 0.1384,
      "step": 6376
    },
    {
      "epoch": 0.13128449947784573,
      "grad_norm": 7.258214473724365,
      "learning_rate": 2.868878096962713e-05,
      "loss": 0.3192,
      "step": 6380
    },
    {
      "epoch": 0.13136680950886634,
      "grad_norm": 1.6400994062423706,
      "learning_rate": 2.8687957856613716e-05,
      "loss": 0.1329,
      "step": 6384
    },
    {
      "epoch": 0.13144911953988692,
      "grad_norm": 2.0310001373291016,
      "learning_rate": 2.8687134743600295e-05,
      "loss": 0.1225,
      "step": 6388
    },
    {
      "epoch": 0.13153142957090752,
      "grad_norm": 3.943150043487549,
      "learning_rate": 2.868631163058688e-05,
      "loss": 0.1994,
      "step": 6392
    },
    {
      "epoch": 0.13161373960192813,
      "grad_norm": 2.8103015422821045,
      "learning_rate": 2.8685488517573464e-05,
      "loss": 0.1617,
      "step": 6396
    },
    {
      "epoch": 0.1316960496329487,
      "grad_norm": 2.8444385528564453,
      "learning_rate": 2.8684665404560047e-05,
      "loss": 0.1817,
      "step": 6400
    },
    {
      "epoch": 0.1317783596639693,
      "grad_norm": 4.381380081176758,
      "learning_rate": 2.868384229154663e-05,
      "loss": 0.1499,
      "step": 6404
    },
    {
      "epoch": 0.13186066969498988,
      "grad_norm": 3.8130040168762207,
      "learning_rate": 2.8683019178533215e-05,
      "loss": 0.0994,
      "step": 6408
    },
    {
      "epoch": 0.1319429797260105,
      "grad_norm": 5.875711441040039,
      "learning_rate": 2.8682196065519795e-05,
      "loss": 0.2263,
      "step": 6412
    },
    {
      "epoch": 0.13202528975703107,
      "grad_norm": 7.2585978507995605,
      "learning_rate": 2.868137295250638e-05,
      "loss": 0.4189,
      "step": 6416
    },
    {
      "epoch": 0.13210759978805167,
      "grad_norm": 1.8594186305999756,
      "learning_rate": 2.8680549839492963e-05,
      "loss": 0.2267,
      "step": 6420
    },
    {
      "epoch": 0.13218990981907228,
      "grad_norm": 4.245288848876953,
      "learning_rate": 2.8679726726479546e-05,
      "loss": 0.1474,
      "step": 6424
    },
    {
      "epoch": 0.13227221985009285,
      "grad_norm": 1.6501175165176392,
      "learning_rate": 2.867890361346613e-05,
      "loss": 0.3117,
      "step": 6428
    },
    {
      "epoch": 0.13235452988111346,
      "grad_norm": 3.5745725631713867,
      "learning_rate": 2.8678080500452714e-05,
      "loss": 0.0746,
      "step": 6432
    },
    {
      "epoch": 0.13243683991213404,
      "grad_norm": 4.001665115356445,
      "learning_rate": 2.8677257387439294e-05,
      "loss": 0.125,
      "step": 6436
    },
    {
      "epoch": 0.13251914994315464,
      "grad_norm": 3.061640977859497,
      "learning_rate": 2.867643427442588e-05,
      "loss": 0.2982,
      "step": 6440
    },
    {
      "epoch": 0.13260145997417522,
      "grad_norm": 5.5060319900512695,
      "learning_rate": 2.8675611161412462e-05,
      "loss": 0.2954,
      "step": 6444
    },
    {
      "epoch": 0.13268377000519582,
      "grad_norm": 1.0645266771316528,
      "learning_rate": 2.8674788048399045e-05,
      "loss": 0.2233,
      "step": 6448
    },
    {
      "epoch": 0.13276608003621643,
      "grad_norm": 3.1286840438842773,
      "learning_rate": 2.8673964935385628e-05,
      "loss": 0.3123,
      "step": 6452
    },
    {
      "epoch": 0.132848390067237,
      "grad_norm": 3.141568422317505,
      "learning_rate": 2.8673141822372214e-05,
      "loss": 0.2202,
      "step": 6456
    },
    {
      "epoch": 0.1329307000982576,
      "grad_norm": 2.037992477416992,
      "learning_rate": 2.8672318709358796e-05,
      "loss": 0.2336,
      "step": 6460
    },
    {
      "epoch": 0.1330130101292782,
      "grad_norm": 2.2744524478912354,
      "learning_rate": 2.867149559634538e-05,
      "loss": 0.2388,
      "step": 6464
    },
    {
      "epoch": 0.1330953201602988,
      "grad_norm": 3.328336000442505,
      "learning_rate": 2.867067248333196e-05,
      "loss": 0.1961,
      "step": 6468
    },
    {
      "epoch": 0.13317763019131937,
      "grad_norm": 6.500069618225098,
      "learning_rate": 2.8669849370318548e-05,
      "loss": 0.2719,
      "step": 6472
    },
    {
      "epoch": 0.13325994022233997,
      "grad_norm": 1.935662031173706,
      "learning_rate": 2.8669026257305127e-05,
      "loss": 0.3327,
      "step": 6476
    },
    {
      "epoch": 0.13334225025336058,
      "grad_norm": 3.6590232849121094,
      "learning_rate": 2.8668203144291713e-05,
      "loss": 0.2752,
      "step": 6480
    },
    {
      "epoch": 0.13342456028438116,
      "grad_norm": 2.31014084815979,
      "learning_rate": 2.8667380031278295e-05,
      "loss": 0.1193,
      "step": 6484
    },
    {
      "epoch": 0.13350687031540176,
      "grad_norm": 0.34263306856155396,
      "learning_rate": 2.8666556918264878e-05,
      "loss": 0.1485,
      "step": 6488
    },
    {
      "epoch": 0.13358918034642234,
      "grad_norm": 4.739346981048584,
      "learning_rate": 2.866573380525146e-05,
      "loss": 0.1825,
      "step": 6492
    },
    {
      "epoch": 0.13367149037744294,
      "grad_norm": 1.3137637376785278,
      "learning_rate": 2.8664910692238047e-05,
      "loss": 0.1738,
      "step": 6496
    },
    {
      "epoch": 0.13375380040846352,
      "grad_norm": 1.550441026687622,
      "learning_rate": 2.8664087579224626e-05,
      "loss": 0.188,
      "step": 6500
    },
    {
      "epoch": 0.13383611043948412,
      "grad_norm": 3.2051925659179688,
      "learning_rate": 2.8663264466211212e-05,
      "loss": 0.1197,
      "step": 6504
    },
    {
      "epoch": 0.1339184204705047,
      "grad_norm": 3.293250322341919,
      "learning_rate": 2.8662441353197795e-05,
      "loss": 0.3069,
      "step": 6508
    },
    {
      "epoch": 0.1340007305015253,
      "grad_norm": 2.2049121856689453,
      "learning_rate": 2.8661618240184377e-05,
      "loss": 0.1513,
      "step": 6512
    },
    {
      "epoch": 0.1340830405325459,
      "grad_norm": 4.426640033721924,
      "learning_rate": 2.866079512717096e-05,
      "loss": 0.1985,
      "step": 6516
    },
    {
      "epoch": 0.1341653505635665,
      "grad_norm": 3.756190299987793,
      "learning_rate": 2.8659972014157546e-05,
      "loss": 0.1999,
      "step": 6520
    },
    {
      "epoch": 0.1342476605945871,
      "grad_norm": 2.6023569107055664,
      "learning_rate": 2.8659148901144125e-05,
      "loss": 0.2217,
      "step": 6524
    },
    {
      "epoch": 0.13432997062560767,
      "grad_norm": 3.7163493633270264,
      "learning_rate": 2.865832578813071e-05,
      "loss": 0.273,
      "step": 6528
    },
    {
      "epoch": 0.13441228065662827,
      "grad_norm": 2.496264696121216,
      "learning_rate": 2.8657502675117294e-05,
      "loss": 0.2151,
      "step": 6532
    },
    {
      "epoch": 0.13449459068764885,
      "grad_norm": 3.113208293914795,
      "learning_rate": 2.8656679562103876e-05,
      "loss": 0.2207,
      "step": 6536
    },
    {
      "epoch": 0.13457690071866946,
      "grad_norm": 3.2897326946258545,
      "learning_rate": 2.865585644909046e-05,
      "loss": 0.17,
      "step": 6540
    },
    {
      "epoch": 0.13465921074969006,
      "grad_norm": 1.9509540796279907,
      "learning_rate": 2.8655033336077045e-05,
      "loss": 0.135,
      "step": 6544
    },
    {
      "epoch": 0.13474152078071064,
      "grad_norm": 4.845377445220947,
      "learning_rate": 2.8654210223063624e-05,
      "loss": 0.2942,
      "step": 6548
    },
    {
      "epoch": 0.13482383081173124,
      "grad_norm": 4.330718040466309,
      "learning_rate": 2.865338711005021e-05,
      "loss": 0.192,
      "step": 6552
    },
    {
      "epoch": 0.13490614084275182,
      "grad_norm": 3.163234233856201,
      "learning_rate": 2.8652563997036793e-05,
      "loss": 0.2134,
      "step": 6556
    },
    {
      "epoch": 0.13498845087377243,
      "grad_norm": 3.477818250656128,
      "learning_rate": 2.865174088402338e-05,
      "loss": 0.2961,
      "step": 6560
    },
    {
      "epoch": 0.135070760904793,
      "grad_norm": 4.478714942932129,
      "learning_rate": 2.865091777100996e-05,
      "loss": 0.1664,
      "step": 6564
    },
    {
      "epoch": 0.1351530709358136,
      "grad_norm": 2.9569475650787354,
      "learning_rate": 2.8650094657996544e-05,
      "loss": 0.2369,
      "step": 6568
    },
    {
      "epoch": 0.1352353809668342,
      "grad_norm": 2.5753540992736816,
      "learning_rate": 2.8649271544983127e-05,
      "loss": 0.1798,
      "step": 6572
    },
    {
      "epoch": 0.1353176909978548,
      "grad_norm": 3.601162910461426,
      "learning_rate": 2.864844843196971e-05,
      "loss": 0.1702,
      "step": 6576
    },
    {
      "epoch": 0.1354000010288754,
      "grad_norm": 1.6973628997802734,
      "learning_rate": 2.8647625318956292e-05,
      "loss": 0.159,
      "step": 6580
    },
    {
      "epoch": 0.13548231105989597,
      "grad_norm": 1.5393449068069458,
      "learning_rate": 2.8646802205942878e-05,
      "loss": 0.2171,
      "step": 6584
    },
    {
      "epoch": 0.13556462109091658,
      "grad_norm": 2.8314099311828613,
      "learning_rate": 2.8645979092929458e-05,
      "loss": 0.1423,
      "step": 6588
    },
    {
      "epoch": 0.13564693112193715,
      "grad_norm": 5.585623264312744,
      "learning_rate": 2.8645155979916044e-05,
      "loss": 0.1385,
      "step": 6592
    },
    {
      "epoch": 0.13572924115295776,
      "grad_norm": 2.811389207839966,
      "learning_rate": 2.8644332866902626e-05,
      "loss": 0.1553,
      "step": 6596
    },
    {
      "epoch": 0.13581155118397836,
      "grad_norm": 2.663808584213257,
      "learning_rate": 2.864350975388921e-05,
      "loss": 0.1348,
      "step": 6600
    },
    {
      "epoch": 0.13589386121499894,
      "grad_norm": 0.5479487180709839,
      "learning_rate": 2.864268664087579e-05,
      "loss": 0.1605,
      "step": 6604
    },
    {
      "epoch": 0.13597617124601954,
      "grad_norm": 2.3177809715270996,
      "learning_rate": 2.8641863527862377e-05,
      "loss": 0.2953,
      "step": 6608
    },
    {
      "epoch": 0.13605848127704012,
      "grad_norm": 3.180537462234497,
      "learning_rate": 2.8641040414848957e-05,
      "loss": 0.1356,
      "step": 6612
    },
    {
      "epoch": 0.13614079130806073,
      "grad_norm": 2.2884891033172607,
      "learning_rate": 2.8640217301835543e-05,
      "loss": 0.2425,
      "step": 6616
    },
    {
      "epoch": 0.1362231013390813,
      "grad_norm": 1.6034693717956543,
      "learning_rate": 2.8639394188822125e-05,
      "loss": 0.1352,
      "step": 6620
    },
    {
      "epoch": 0.1363054113701019,
      "grad_norm": 3.30985164642334,
      "learning_rate": 2.8638571075808708e-05,
      "loss": 0.1849,
      "step": 6624
    },
    {
      "epoch": 0.1363877214011225,
      "grad_norm": 2.280825138092041,
      "learning_rate": 2.863774796279529e-05,
      "loss": 0.2171,
      "step": 6628
    },
    {
      "epoch": 0.1364700314321431,
      "grad_norm": 1.8779088258743286,
      "learning_rate": 2.8636924849781877e-05,
      "loss": 0.1829,
      "step": 6632
    },
    {
      "epoch": 0.1365523414631637,
      "grad_norm": 2.3247642517089844,
      "learning_rate": 2.8636101736768456e-05,
      "loss": 0.1275,
      "step": 6636
    },
    {
      "epoch": 0.13663465149418427,
      "grad_norm": 4.5708465576171875,
      "learning_rate": 2.8635278623755042e-05,
      "loss": 0.173,
      "step": 6640
    },
    {
      "epoch": 0.13671696152520488,
      "grad_norm": 4.799285888671875,
      "learning_rate": 2.8634455510741625e-05,
      "loss": 0.1867,
      "step": 6644
    },
    {
      "epoch": 0.13679927155622545,
      "grad_norm": 3.7580368518829346,
      "learning_rate": 2.8633632397728207e-05,
      "loss": 0.1892,
      "step": 6648
    },
    {
      "epoch": 0.13688158158724606,
      "grad_norm": 3.709902286529541,
      "learning_rate": 2.863280928471479e-05,
      "loss": 0.2739,
      "step": 6652
    },
    {
      "epoch": 0.13696389161826666,
      "grad_norm": 2.6739847660064697,
      "learning_rate": 2.8631986171701376e-05,
      "loss": 0.2154,
      "step": 6656
    },
    {
      "epoch": 0.13704620164928724,
      "grad_norm": 2.7876062393188477,
      "learning_rate": 2.8631163058687962e-05,
      "loss": 0.1707,
      "step": 6660
    },
    {
      "epoch": 0.13712851168030785,
      "grad_norm": 4.463708400726318,
      "learning_rate": 2.863033994567454e-05,
      "loss": 0.2356,
      "step": 6664
    },
    {
      "epoch": 0.13721082171132842,
      "grad_norm": 2.6212282180786133,
      "learning_rate": 2.8629516832661127e-05,
      "loss": 0.2024,
      "step": 6668
    },
    {
      "epoch": 0.13729313174234903,
      "grad_norm": 1.9764951467514038,
      "learning_rate": 2.862869371964771e-05,
      "loss": 0.1392,
      "step": 6672
    },
    {
      "epoch": 0.1373754417733696,
      "grad_norm": 3.7759082317352295,
      "learning_rate": 2.8627870606634292e-05,
      "loss": 0.2215,
      "step": 6676
    },
    {
      "epoch": 0.1374577518043902,
      "grad_norm": 3.539238452911377,
      "learning_rate": 2.8627047493620875e-05,
      "loss": 0.261,
      "step": 6680
    },
    {
      "epoch": 0.13754006183541082,
      "grad_norm": 5.354743003845215,
      "learning_rate": 2.862622438060746e-05,
      "loss": 0.2652,
      "step": 6684
    },
    {
      "epoch": 0.1376223718664314,
      "grad_norm": 4.062238693237305,
      "learning_rate": 2.862540126759404e-05,
      "loss": 0.1898,
      "step": 6688
    },
    {
      "epoch": 0.137704681897452,
      "grad_norm": 2.314862012863159,
      "learning_rate": 2.8624578154580626e-05,
      "loss": 0.208,
      "step": 6692
    },
    {
      "epoch": 0.13778699192847257,
      "grad_norm": 6.847209930419922,
      "learning_rate": 2.862375504156721e-05,
      "loss": 0.3476,
      "step": 6696
    },
    {
      "epoch": 0.13786930195949318,
      "grad_norm": 3.0956079959869385,
      "learning_rate": 2.862293192855379e-05,
      "loss": 0.1605,
      "step": 6700
    },
    {
      "epoch": 0.13795161199051376,
      "grad_norm": 3.8116812705993652,
      "learning_rate": 2.8622108815540374e-05,
      "loss": 0.292,
      "step": 6704
    },
    {
      "epoch": 0.13803392202153436,
      "grad_norm": 1.4515643119812012,
      "learning_rate": 2.862128570252696e-05,
      "loss": 0.1421,
      "step": 6708
    },
    {
      "epoch": 0.13811623205255497,
      "grad_norm": 1.675549030303955,
      "learning_rate": 2.862046258951354e-05,
      "loss": 0.309,
      "step": 6712
    },
    {
      "epoch": 0.13819854208357554,
      "grad_norm": 3.9715301990509033,
      "learning_rate": 2.8619639476500126e-05,
      "loss": 0.2319,
      "step": 6716
    },
    {
      "epoch": 0.13828085211459615,
      "grad_norm": 4.17227840423584,
      "learning_rate": 2.8618816363486708e-05,
      "loss": 0.2249,
      "step": 6720
    },
    {
      "epoch": 0.13836316214561672,
      "grad_norm": 1.3127973079681396,
      "learning_rate": 2.861799325047329e-05,
      "loss": 0.1512,
      "step": 6724
    },
    {
      "epoch": 0.13844547217663733,
      "grad_norm": 1.6677172183990479,
      "learning_rate": 2.8617170137459873e-05,
      "loss": 0.1472,
      "step": 6728
    },
    {
      "epoch": 0.1385277822076579,
      "grad_norm": 1.3297204971313477,
      "learning_rate": 2.861634702444646e-05,
      "loss": 0.2463,
      "step": 6732
    },
    {
      "epoch": 0.1386100922386785,
      "grad_norm": 1.215304970741272,
      "learning_rate": 2.861552391143304e-05,
      "loss": 0.165,
      "step": 6736
    },
    {
      "epoch": 0.13869240226969912,
      "grad_norm": 5.124242782592773,
      "learning_rate": 2.8614700798419625e-05,
      "loss": 0.2807,
      "step": 6740
    },
    {
      "epoch": 0.1387747123007197,
      "grad_norm": 2.026531457901001,
      "learning_rate": 2.8613877685406207e-05,
      "loss": 0.207,
      "step": 6744
    },
    {
      "epoch": 0.1388570223317403,
      "grad_norm": 3.27740740776062,
      "learning_rate": 2.861305457239279e-05,
      "loss": 0.233,
      "step": 6748
    },
    {
      "epoch": 0.13893933236276088,
      "grad_norm": 1.598720908164978,
      "learning_rate": 2.8612231459379373e-05,
      "loss": 0.1522,
      "step": 6752
    },
    {
      "epoch": 0.13902164239378148,
      "grad_norm": 1.723636507987976,
      "learning_rate": 2.861140834636596e-05,
      "loss": 0.2934,
      "step": 6756
    },
    {
      "epoch": 0.13910395242480206,
      "grad_norm": 3.3994057178497314,
      "learning_rate": 2.861058523335254e-05,
      "loss": 0.2584,
      "step": 6760
    },
    {
      "epoch": 0.13918626245582266,
      "grad_norm": 2.5394015312194824,
      "learning_rate": 2.8609762120339124e-05,
      "loss": 0.192,
      "step": 6764
    },
    {
      "epoch": 0.13926857248684327,
      "grad_norm": 2.9516072273254395,
      "learning_rate": 2.8608939007325707e-05,
      "loss": 0.174,
      "step": 6768
    },
    {
      "epoch": 0.13935088251786384,
      "grad_norm": 4.542248725891113,
      "learning_rate": 2.8608115894312293e-05,
      "loss": 0.1108,
      "step": 6772
    },
    {
      "epoch": 0.13943319254888445,
      "grad_norm": 2.169802188873291,
      "learning_rate": 2.8607292781298872e-05,
      "loss": 0.1716,
      "step": 6776
    },
    {
      "epoch": 0.13951550257990503,
      "grad_norm": 4.678183555603027,
      "learning_rate": 2.8606469668285458e-05,
      "loss": 0.1961,
      "step": 6780
    },
    {
      "epoch": 0.13959781261092563,
      "grad_norm": 3.74814772605896,
      "learning_rate": 2.860564655527204e-05,
      "loss": 0.1366,
      "step": 6784
    },
    {
      "epoch": 0.1396801226419462,
      "grad_norm": 2.3638646602630615,
      "learning_rate": 2.8604823442258623e-05,
      "loss": 0.1888,
      "step": 6788
    },
    {
      "epoch": 0.1397624326729668,
      "grad_norm": 5.7198166847229,
      "learning_rate": 2.8604000329245206e-05,
      "loss": 0.163,
      "step": 6792
    },
    {
      "epoch": 0.13984474270398742,
      "grad_norm": 3.1218764781951904,
      "learning_rate": 2.8603177216231792e-05,
      "loss": 0.1515,
      "step": 6796
    },
    {
      "epoch": 0.139927052735008,
      "grad_norm": 3.268425703048706,
      "learning_rate": 2.860235410321837e-05,
      "loss": 0.2423,
      "step": 6800
    },
    {
      "epoch": 0.1400093627660286,
      "grad_norm": 2.3283910751342773,
      "learning_rate": 2.8601530990204957e-05,
      "loss": 0.112,
      "step": 6804
    },
    {
      "epoch": 0.14009167279704918,
      "grad_norm": 3.826871633529663,
      "learning_rate": 2.860070787719154e-05,
      "loss": 0.2418,
      "step": 6808
    },
    {
      "epoch": 0.14017398282806978,
      "grad_norm": 4.072598457336426,
      "learning_rate": 2.8599884764178122e-05,
      "loss": 0.1215,
      "step": 6812
    },
    {
      "epoch": 0.14025629285909036,
      "grad_norm": 3.246814012527466,
      "learning_rate": 2.8599061651164705e-05,
      "loss": 0.1325,
      "step": 6816
    },
    {
      "epoch": 0.14033860289011096,
      "grad_norm": 3.4257946014404297,
      "learning_rate": 2.859823853815129e-05,
      "loss": 0.2044,
      "step": 6820
    },
    {
      "epoch": 0.14042091292113157,
      "grad_norm": 1.8996087312698364,
      "learning_rate": 2.859741542513787e-05,
      "loss": 0.1269,
      "step": 6824
    },
    {
      "epoch": 0.14050322295215215,
      "grad_norm": 1.9883430004119873,
      "learning_rate": 2.8596592312124456e-05,
      "loss": 0.1421,
      "step": 6828
    },
    {
      "epoch": 0.14058553298317275,
      "grad_norm": 4.115809917449951,
      "learning_rate": 2.859576919911104e-05,
      "loss": 0.2432,
      "step": 6832
    },
    {
      "epoch": 0.14066784301419333,
      "grad_norm": 5.573153018951416,
      "learning_rate": 2.859494608609762e-05,
      "loss": 0.2402,
      "step": 6836
    },
    {
      "epoch": 0.14075015304521393,
      "grad_norm": 2.7888171672821045,
      "learning_rate": 2.8594122973084204e-05,
      "loss": 0.2644,
      "step": 6840
    },
    {
      "epoch": 0.1408324630762345,
      "grad_norm": 5.021162509918213,
      "learning_rate": 2.859329986007079e-05,
      "loss": 0.2135,
      "step": 6844
    },
    {
      "epoch": 0.14091477310725511,
      "grad_norm": 4.357215404510498,
      "learning_rate": 2.8592476747057373e-05,
      "loss": 0.1905,
      "step": 6848
    },
    {
      "epoch": 0.14099708313827572,
      "grad_norm": 2.762423276901245,
      "learning_rate": 2.8591653634043955e-05,
      "loss": 0.1939,
      "step": 6852
    },
    {
      "epoch": 0.1410793931692963,
      "grad_norm": 1.4341939687728882,
      "learning_rate": 2.8590830521030538e-05,
      "loss": 0.2453,
      "step": 6856
    },
    {
      "epoch": 0.1411617032003169,
      "grad_norm": 0.8116101622581482,
      "learning_rate": 2.8590007408017124e-05,
      "loss": 0.1956,
      "step": 6860
    },
    {
      "epoch": 0.14124401323133748,
      "grad_norm": 4.024964809417725,
      "learning_rate": 2.8589184295003703e-05,
      "loss": 0.1795,
      "step": 6864
    },
    {
      "epoch": 0.14132632326235808,
      "grad_norm": 1.4421131610870361,
      "learning_rate": 2.858836118199029e-05,
      "loss": 0.1208,
      "step": 6868
    },
    {
      "epoch": 0.14140863329337866,
      "grad_norm": 2.6646928787231445,
      "learning_rate": 2.8587538068976872e-05,
      "loss": 0.1325,
      "step": 6872
    },
    {
      "epoch": 0.14149094332439927,
      "grad_norm": 0.9323031902313232,
      "learning_rate": 2.8586714955963455e-05,
      "loss": 0.1596,
      "step": 6876
    },
    {
      "epoch": 0.14157325335541987,
      "grad_norm": 1.1367298364639282,
      "learning_rate": 2.8585891842950037e-05,
      "loss": 0.2745,
      "step": 6880
    },
    {
      "epoch": 0.14165556338644045,
      "grad_norm": 1.9107457399368286,
      "learning_rate": 2.8585068729936623e-05,
      "loss": 0.1666,
      "step": 6884
    },
    {
      "epoch": 0.14173787341746105,
      "grad_norm": 0.9872499704360962,
      "learning_rate": 2.8584245616923203e-05,
      "loss": 0.0963,
      "step": 6888
    },
    {
      "epoch": 0.14182018344848163,
      "grad_norm": 4.363161087036133,
      "learning_rate": 2.858342250390979e-05,
      "loss": 0.2927,
      "step": 6892
    },
    {
      "epoch": 0.14190249347950223,
      "grad_norm": 3.3582446575164795,
      "learning_rate": 2.858259939089637e-05,
      "loss": 0.1626,
      "step": 6896
    },
    {
      "epoch": 0.1419848035105228,
      "grad_norm": 0.8625519275665283,
      "learning_rate": 2.8581776277882954e-05,
      "loss": 0.148,
      "step": 6900
    },
    {
      "epoch": 0.14206711354154342,
      "grad_norm": 5.3692522048950195,
      "learning_rate": 2.8580953164869536e-05,
      "loss": 0.163,
      "step": 6904
    },
    {
      "epoch": 0.14214942357256402,
      "grad_norm": 1.8923897743225098,
      "learning_rate": 2.8580130051856122e-05,
      "loss": 0.1997,
      "step": 6908
    },
    {
      "epoch": 0.1422317336035846,
      "grad_norm": 3.6436784267425537,
      "learning_rate": 2.8579306938842702e-05,
      "loss": 0.1775,
      "step": 6912
    },
    {
      "epoch": 0.1423140436346052,
      "grad_norm": 2.4199225902557373,
      "learning_rate": 2.8578483825829288e-05,
      "loss": 0.1932,
      "step": 6916
    },
    {
      "epoch": 0.14239635366562578,
      "grad_norm": 4.021955966949463,
      "learning_rate": 2.857766071281587e-05,
      "loss": 0.2535,
      "step": 6920
    },
    {
      "epoch": 0.14247866369664638,
      "grad_norm": 4.762160778045654,
      "learning_rate": 2.8576837599802453e-05,
      "loss": 0.1885,
      "step": 6924
    },
    {
      "epoch": 0.14256097372766696,
      "grad_norm": 4.798266887664795,
      "learning_rate": 2.8576014486789036e-05,
      "loss": 0.2051,
      "step": 6928
    },
    {
      "epoch": 0.14264328375868757,
      "grad_norm": 2.6287569999694824,
      "learning_rate": 2.857519137377562e-05,
      "loss": 0.139,
      "step": 6932
    },
    {
      "epoch": 0.14272559378970817,
      "grad_norm": 1.7068936824798584,
      "learning_rate": 2.85743682607622e-05,
      "loss": 0.119,
      "step": 6936
    },
    {
      "epoch": 0.14280790382072875,
      "grad_norm": 3.9907846450805664,
      "learning_rate": 2.8573545147748787e-05,
      "loss": 0.1909,
      "step": 6940
    },
    {
      "epoch": 0.14289021385174935,
      "grad_norm": 2.8089029788970947,
      "learning_rate": 2.857272203473537e-05,
      "loss": 0.2807,
      "step": 6944
    },
    {
      "epoch": 0.14297252388276993,
      "grad_norm": 2.4890739917755127,
      "learning_rate": 2.8571898921721956e-05,
      "loss": 0.0881,
      "step": 6948
    },
    {
      "epoch": 0.14305483391379054,
      "grad_norm": 4.752174377441406,
      "learning_rate": 2.8571075808708535e-05,
      "loss": 0.2449,
      "step": 6952
    },
    {
      "epoch": 0.1431371439448111,
      "grad_norm": 4.662342548370361,
      "learning_rate": 2.857025269569512e-05,
      "loss": 0.1548,
      "step": 6956
    },
    {
      "epoch": 0.14321945397583172,
      "grad_norm": 7.3089447021484375,
      "learning_rate": 2.8569429582681704e-05,
      "loss": 0.245,
      "step": 6960
    },
    {
      "epoch": 0.14330176400685232,
      "grad_norm": 3.8265159130096436,
      "learning_rate": 2.8568606469668286e-05,
      "loss": 0.2833,
      "step": 6964
    },
    {
      "epoch": 0.1433840740378729,
      "grad_norm": 2.7124009132385254,
      "learning_rate": 2.856778335665487e-05,
      "loss": 0.2472,
      "step": 6968
    },
    {
      "epoch": 0.1434663840688935,
      "grad_norm": 3.0702950954437256,
      "learning_rate": 2.8566960243641455e-05,
      "loss": 0.1999,
      "step": 6972
    },
    {
      "epoch": 0.14354869409991408,
      "grad_norm": 2.3732428550720215,
      "learning_rate": 2.8566137130628034e-05,
      "loss": 0.226,
      "step": 6976
    },
    {
      "epoch": 0.1436310041309347,
      "grad_norm": 3.7295498847961426,
      "learning_rate": 2.856531401761462e-05,
      "loss": 0.1504,
      "step": 6980
    },
    {
      "epoch": 0.14371331416195526,
      "grad_norm": 2.5913209915161133,
      "learning_rate": 2.8564490904601203e-05,
      "loss": 0.2506,
      "step": 6984
    },
    {
      "epoch": 0.14379562419297587,
      "grad_norm": 4.134459972381592,
      "learning_rate": 2.8563667791587785e-05,
      "loss": 0.1916,
      "step": 6988
    },
    {
      "epoch": 0.14387793422399647,
      "grad_norm": 0.29499468207359314,
      "learning_rate": 2.8562844678574368e-05,
      "loss": 0.0569,
      "step": 6992
    },
    {
      "epoch": 0.14396024425501705,
      "grad_norm": 3.7743706703186035,
      "learning_rate": 2.8562021565560954e-05,
      "loss": 0.2554,
      "step": 6996
    },
    {
      "epoch": 0.14404255428603766,
      "grad_norm": 8.620019912719727,
      "learning_rate": 2.8561198452547533e-05,
      "loss": 0.1438,
      "step": 7000
    },
    {
      "epoch": 0.14412486431705823,
      "grad_norm": 3.6777515411376953,
      "learning_rate": 2.856037533953412e-05,
      "loss": 0.169,
      "step": 7004
    },
    {
      "epoch": 0.14420717434807884,
      "grad_norm": 3.332850456237793,
      "learning_rate": 2.8559552226520702e-05,
      "loss": 0.2005,
      "step": 7008
    },
    {
      "epoch": 0.14428948437909941,
      "grad_norm": 3.876319408416748,
      "learning_rate": 2.8558729113507285e-05,
      "loss": 0.2219,
      "step": 7012
    },
    {
      "epoch": 0.14437179441012002,
      "grad_norm": 3.5670957565307617,
      "learning_rate": 2.8557906000493867e-05,
      "loss": 0.1882,
      "step": 7016
    },
    {
      "epoch": 0.14445410444114062,
      "grad_norm": 4.968513488769531,
      "learning_rate": 2.8557082887480453e-05,
      "loss": 0.1808,
      "step": 7020
    },
    {
      "epoch": 0.1445364144721612,
      "grad_norm": 3.969876289367676,
      "learning_rate": 2.8556259774467032e-05,
      "loss": 0.217,
      "step": 7024
    },
    {
      "epoch": 0.1446187245031818,
      "grad_norm": 1.8594506978988647,
      "learning_rate": 2.855543666145362e-05,
      "loss": 0.18,
      "step": 7028
    },
    {
      "epoch": 0.14470103453420238,
      "grad_norm": 3.84375262260437,
      "learning_rate": 2.85546135484402e-05,
      "loss": 0.1958,
      "step": 7032
    },
    {
      "epoch": 0.144783344565223,
      "grad_norm": 1.9858206510543823,
      "learning_rate": 2.8553790435426784e-05,
      "loss": 0.1699,
      "step": 7036
    },
    {
      "epoch": 0.14486565459624356,
      "grad_norm": 1.827606201171875,
      "learning_rate": 2.8552967322413366e-05,
      "loss": 0.1509,
      "step": 7040
    },
    {
      "epoch": 0.14494796462726417,
      "grad_norm": 3.116020917892456,
      "learning_rate": 2.8552144209399952e-05,
      "loss": 0.1024,
      "step": 7044
    },
    {
      "epoch": 0.14503027465828477,
      "grad_norm": 4.010015487670898,
      "learning_rate": 2.8551321096386535e-05,
      "loss": 0.1972,
      "step": 7048
    },
    {
      "epoch": 0.14511258468930535,
      "grad_norm": 3.0292906761169434,
      "learning_rate": 2.8550497983373118e-05,
      "loss": 0.159,
      "step": 7052
    },
    {
      "epoch": 0.14519489472032596,
      "grad_norm": 5.733258247375488,
      "learning_rate": 2.85496748703597e-05,
      "loss": 0.346,
      "step": 7056
    },
    {
      "epoch": 0.14527720475134653,
      "grad_norm": 3.6047656536102295,
      "learning_rate": 2.8548851757346286e-05,
      "loss": 0.2927,
      "step": 7060
    },
    {
      "epoch": 0.14535951478236714,
      "grad_norm": 4.7379536628723145,
      "learning_rate": 2.8548028644332866e-05,
      "loss": 0.2429,
      "step": 7064
    },
    {
      "epoch": 0.14544182481338772,
      "grad_norm": 4.171732425689697,
      "learning_rate": 2.854720553131945e-05,
      "loss": 0.2703,
      "step": 7068
    },
    {
      "epoch": 0.14552413484440832,
      "grad_norm": 4.295077800750732,
      "learning_rate": 2.8546382418306034e-05,
      "loss": 0.2319,
      "step": 7072
    },
    {
      "epoch": 0.14560644487542893,
      "grad_norm": 3.098491668701172,
      "learning_rate": 2.8545559305292617e-05,
      "loss": 0.1421,
      "step": 7076
    },
    {
      "epoch": 0.1456887549064495,
      "grad_norm": 2.6890735626220703,
      "learning_rate": 2.85447361922792e-05,
      "loss": 0.2106,
      "step": 7080
    },
    {
      "epoch": 0.1457710649374701,
      "grad_norm": 5.292430400848389,
      "learning_rate": 2.8543913079265785e-05,
      "loss": 0.1832,
      "step": 7084
    },
    {
      "epoch": 0.14585337496849068,
      "grad_norm": 2.3907735347747803,
      "learning_rate": 2.8543089966252365e-05,
      "loss": 0.0944,
      "step": 7088
    },
    {
      "epoch": 0.1459356849995113,
      "grad_norm": 3.2977514266967773,
      "learning_rate": 2.854226685323895e-05,
      "loss": 0.2373,
      "step": 7092
    },
    {
      "epoch": 0.14601799503053187,
      "grad_norm": 0.2962850034236908,
      "learning_rate": 2.8541443740225533e-05,
      "loss": 0.1411,
      "step": 7096
    },
    {
      "epoch": 0.14610030506155247,
      "grad_norm": 3.252699851989746,
      "learning_rate": 2.8540620627212116e-05,
      "loss": 0.211,
      "step": 7100
    },
    {
      "epoch": 0.14618261509257308,
      "grad_norm": 5.701294422149658,
      "learning_rate": 2.85397975141987e-05,
      "loss": 0.203,
      "step": 7104
    },
    {
      "epoch": 0.14626492512359365,
      "grad_norm": 1.3692336082458496,
      "learning_rate": 2.8538974401185285e-05,
      "loss": 0.1734,
      "step": 7108
    },
    {
      "epoch": 0.14634723515461426,
      "grad_norm": 1.1446577310562134,
      "learning_rate": 2.8538151288171864e-05,
      "loss": 0.1644,
      "step": 7112
    },
    {
      "epoch": 0.14642954518563484,
      "grad_norm": 2.2023894786834717,
      "learning_rate": 2.853732817515845e-05,
      "loss": 0.1701,
      "step": 7116
    },
    {
      "epoch": 0.14651185521665544,
      "grad_norm": 3.472074031829834,
      "learning_rate": 2.8536505062145033e-05,
      "loss": 0.2936,
      "step": 7120
    },
    {
      "epoch": 0.14659416524767602,
      "grad_norm": 2.939239740371704,
      "learning_rate": 2.8535681949131615e-05,
      "loss": 0.2287,
      "step": 7124
    },
    {
      "epoch": 0.14667647527869662,
      "grad_norm": 2.810455799102783,
      "learning_rate": 2.8534858836118198e-05,
      "loss": 0.1402,
      "step": 7128
    },
    {
      "epoch": 0.14675878530971723,
      "grad_norm": 3.1814510822296143,
      "learning_rate": 2.8534035723104784e-05,
      "loss": 0.1408,
      "step": 7132
    },
    {
      "epoch": 0.1468410953407378,
      "grad_norm": 1.481276035308838,
      "learning_rate": 2.8533212610091367e-05,
      "loss": 0.2035,
      "step": 7136
    },
    {
      "epoch": 0.1469234053717584,
      "grad_norm": 1.9393128156661987,
      "learning_rate": 2.853238949707795e-05,
      "loss": 0.1467,
      "step": 7140
    },
    {
      "epoch": 0.14700571540277899,
      "grad_norm": 3.5603933334350586,
      "learning_rate": 2.8531566384064532e-05,
      "loss": 0.2705,
      "step": 7144
    },
    {
      "epoch": 0.1470880254337996,
      "grad_norm": 2.9648277759552,
      "learning_rate": 2.8530743271051118e-05,
      "loss": 0.2028,
      "step": 7148
    },
    {
      "epoch": 0.14717033546482017,
      "grad_norm": 2.6428182125091553,
      "learning_rate": 2.8529920158037697e-05,
      "loss": 0.1621,
      "step": 7152
    },
    {
      "epoch": 0.14725264549584077,
      "grad_norm": 3.7695133686065674,
      "learning_rate": 2.8529097045024283e-05,
      "loss": 0.2573,
      "step": 7156
    },
    {
      "epoch": 0.14733495552686138,
      "grad_norm": 2.4425406455993652,
      "learning_rate": 2.8528273932010866e-05,
      "loss": 0.2446,
      "step": 7160
    },
    {
      "epoch": 0.14741726555788195,
      "grad_norm": 4.962401390075684,
      "learning_rate": 2.852745081899745e-05,
      "loss": 0.1701,
      "step": 7164
    },
    {
      "epoch": 0.14749957558890256,
      "grad_norm": 3.37689208984375,
      "learning_rate": 2.852662770598403e-05,
      "loss": 0.1075,
      "step": 7168
    },
    {
      "epoch": 0.14758188561992314,
      "grad_norm": 3.990945339202881,
      "learning_rate": 2.8525804592970617e-05,
      "loss": 0.1866,
      "step": 7172
    },
    {
      "epoch": 0.14766419565094374,
      "grad_norm": 2.0148444175720215,
      "learning_rate": 2.8524981479957196e-05,
      "loss": 0.1311,
      "step": 7176
    },
    {
      "epoch": 0.14774650568196432,
      "grad_norm": 6.287438869476318,
      "learning_rate": 2.8524158366943782e-05,
      "loss": 0.2355,
      "step": 7180
    },
    {
      "epoch": 0.14782881571298492,
      "grad_norm": 4.195134162902832,
      "learning_rate": 2.8523335253930365e-05,
      "loss": 0.3039,
      "step": 7184
    },
    {
      "epoch": 0.14791112574400553,
      "grad_norm": 4.858381748199463,
      "learning_rate": 2.8522512140916948e-05,
      "loss": 0.193,
      "step": 7188
    },
    {
      "epoch": 0.1479934357750261,
      "grad_norm": 3.7327823638916016,
      "learning_rate": 2.852168902790353e-05,
      "loss": 0.1842,
      "step": 7192
    },
    {
      "epoch": 0.1480757458060467,
      "grad_norm": 0.42285144329071045,
      "learning_rate": 2.8520865914890116e-05,
      "loss": 0.1609,
      "step": 7196
    },
    {
      "epoch": 0.1481580558370673,
      "grad_norm": 2.5076258182525635,
      "learning_rate": 2.8520042801876695e-05,
      "loss": 0.1068,
      "step": 7200
    },
    {
      "epoch": 0.1482403658680879,
      "grad_norm": 4.588447570800781,
      "learning_rate": 2.851921968886328e-05,
      "loss": 0.2022,
      "step": 7204
    },
    {
      "epoch": 0.14832267589910847,
      "grad_norm": 3.0484049320220947,
      "learning_rate": 2.8518396575849864e-05,
      "loss": 0.1762,
      "step": 7208
    },
    {
      "epoch": 0.14840498593012907,
      "grad_norm": 1.5900346040725708,
      "learning_rate": 2.8517573462836447e-05,
      "loss": 0.2031,
      "step": 7212
    },
    {
      "epoch": 0.14848729596114968,
      "grad_norm": 2.394179105758667,
      "learning_rate": 2.8516750349823033e-05,
      "loss": 0.1197,
      "step": 7216
    },
    {
      "epoch": 0.14856960599217026,
      "grad_norm": 2.9843738079071045,
      "learning_rate": 2.8515927236809615e-05,
      "loss": 0.1741,
      "step": 7220
    },
    {
      "epoch": 0.14865191602319086,
      "grad_norm": 1.2530642747879028,
      "learning_rate": 2.8515104123796198e-05,
      "loss": 0.1527,
      "step": 7224
    },
    {
      "epoch": 0.14873422605421144,
      "grad_norm": 2.155468225479126,
      "learning_rate": 2.851428101078278e-05,
      "loss": 0.1349,
      "step": 7228
    },
    {
      "epoch": 0.14881653608523204,
      "grad_norm": 2.374217987060547,
      "learning_rate": 2.8513457897769367e-05,
      "loss": 0.1319,
      "step": 7232
    },
    {
      "epoch": 0.14889884611625262,
      "grad_norm": 0.6054452657699585,
      "learning_rate": 2.851263478475595e-05,
      "loss": 0.1227,
      "step": 7236
    },
    {
      "epoch": 0.14898115614727322,
      "grad_norm": 3.8096365928649902,
      "learning_rate": 2.8511811671742532e-05,
      "loss": 0.3293,
      "step": 7240
    },
    {
      "epoch": 0.14906346617829383,
      "grad_norm": 0.23168949782848358,
      "learning_rate": 2.8510988558729115e-05,
      "loss": 0.0714,
      "step": 7244
    },
    {
      "epoch": 0.1491457762093144,
      "grad_norm": 1.1557769775390625,
      "learning_rate": 2.85101654457157e-05,
      "loss": 0.0838,
      "step": 7248
    },
    {
      "epoch": 0.149228086240335,
      "grad_norm": 1.9705004692077637,
      "learning_rate": 2.850934233270228e-05,
      "loss": 0.1776,
      "step": 7252
    },
    {
      "epoch": 0.1493103962713556,
      "grad_norm": 3.2322611808776855,
      "learning_rate": 2.8508519219688866e-05,
      "loss": 0.1942,
      "step": 7256
    },
    {
      "epoch": 0.1493927063023762,
      "grad_norm": 4.7446184158325195,
      "learning_rate": 2.850769610667545e-05,
      "loss": 0.2119,
      "step": 7260
    },
    {
      "epoch": 0.14947501633339677,
      "grad_norm": 1.928514838218689,
      "learning_rate": 2.850687299366203e-05,
      "loss": 0.1781,
      "step": 7264
    },
    {
      "epoch": 0.14955732636441738,
      "grad_norm": 0.9341807961463928,
      "learning_rate": 2.8506049880648614e-05,
      "loss": 0.1159,
      "step": 7268
    },
    {
      "epoch": 0.14963963639543795,
      "grad_norm": 1.84316885471344,
      "learning_rate": 2.85052267676352e-05,
      "loss": 0.1212,
      "step": 7272
    },
    {
      "epoch": 0.14972194642645856,
      "grad_norm": 3.400024652481079,
      "learning_rate": 2.850440365462178e-05,
      "loss": 0.3276,
      "step": 7276
    },
    {
      "epoch": 0.14980425645747916,
      "grad_norm": 4.4615960121154785,
      "learning_rate": 2.8503580541608365e-05,
      "loss": 0.1842,
      "step": 7280
    },
    {
      "epoch": 0.14988656648849974,
      "grad_norm": 2.178910970687866,
      "learning_rate": 2.8502757428594948e-05,
      "loss": 0.1167,
      "step": 7284
    },
    {
      "epoch": 0.14996887651952034,
      "grad_norm": 3.7872259616851807,
      "learning_rate": 2.850193431558153e-05,
      "loss": 0.2024,
      "step": 7288
    },
    {
      "epoch": 0.15005118655054092,
      "grad_norm": 2.709597110748291,
      "learning_rate": 2.8501111202568113e-05,
      "loss": 0.0877,
      "step": 7292
    },
    {
      "epoch": 0.15013349658156153,
      "grad_norm": 4.603013515472412,
      "learning_rate": 2.85002880895547e-05,
      "loss": 0.2729,
      "step": 7296
    },
    {
      "epoch": 0.1502158066125821,
      "grad_norm": 2.2818479537963867,
      "learning_rate": 2.8499464976541278e-05,
      "loss": 0.2483,
      "step": 7300
    },
    {
      "epoch": 0.1502981166436027,
      "grad_norm": 5.64240837097168,
      "learning_rate": 2.8498641863527864e-05,
      "loss": 0.1355,
      "step": 7304
    },
    {
      "epoch": 0.1503804266746233,
      "grad_norm": 1.7398935556411743,
      "learning_rate": 2.8497818750514447e-05,
      "loss": 0.1941,
      "step": 7308
    },
    {
      "epoch": 0.1504627367056439,
      "grad_norm": 0.8853734135627747,
      "learning_rate": 2.849699563750103e-05,
      "loss": 0.3096,
      "step": 7312
    },
    {
      "epoch": 0.1505450467366645,
      "grad_norm": 4.422512531280518,
      "learning_rate": 2.8496172524487612e-05,
      "loss": 0.2033,
      "step": 7316
    },
    {
      "epoch": 0.15062735676768507,
      "grad_norm": 3.844999074935913,
      "learning_rate": 2.8495349411474198e-05,
      "loss": 0.1096,
      "step": 7320
    },
    {
      "epoch": 0.15070966679870568,
      "grad_norm": 3.1544923782348633,
      "learning_rate": 2.8494526298460777e-05,
      "loss": 0.1331,
      "step": 7324
    },
    {
      "epoch": 0.15079197682972625,
      "grad_norm": 6.015010356903076,
      "learning_rate": 2.8493703185447363e-05,
      "loss": 0.2694,
      "step": 7328
    },
    {
      "epoch": 0.15087428686074686,
      "grad_norm": 2.546417236328125,
      "learning_rate": 2.8492880072433946e-05,
      "loss": 0.1318,
      "step": 7332
    },
    {
      "epoch": 0.15095659689176746,
      "grad_norm": 4.923101425170898,
      "learning_rate": 2.8492056959420532e-05,
      "loss": 0.0959,
      "step": 7336
    },
    {
      "epoch": 0.15103890692278804,
      "grad_norm": 1.2071317434310913,
      "learning_rate": 2.849123384640711e-05,
      "loss": 0.213,
      "step": 7340
    },
    {
      "epoch": 0.15112121695380865,
      "grad_norm": 2.734276533126831,
      "learning_rate": 2.8490410733393697e-05,
      "loss": 0.1531,
      "step": 7344
    },
    {
      "epoch": 0.15120352698482922,
      "grad_norm": 2.4372658729553223,
      "learning_rate": 2.848958762038028e-05,
      "loss": 0.1437,
      "step": 7348
    },
    {
      "epoch": 0.15128583701584983,
      "grad_norm": 4.547619819641113,
      "learning_rate": 2.8488764507366863e-05,
      "loss": 0.1272,
      "step": 7352
    },
    {
      "epoch": 0.1513681470468704,
      "grad_norm": 3.7339701652526855,
      "learning_rate": 2.8487941394353445e-05,
      "loss": 0.244,
      "step": 7356
    },
    {
      "epoch": 0.151450457077891,
      "grad_norm": 5.371131420135498,
      "learning_rate": 2.848711828134003e-05,
      "loss": 0.1557,
      "step": 7360
    },
    {
      "epoch": 0.15153276710891161,
      "grad_norm": 1.5179331302642822,
      "learning_rate": 2.848629516832661e-05,
      "loss": 0.2082,
      "step": 7364
    },
    {
      "epoch": 0.1516150771399322,
      "grad_norm": 2.0478055477142334,
      "learning_rate": 2.8485472055313197e-05,
      "loss": 0.2976,
      "step": 7368
    },
    {
      "epoch": 0.1516973871709528,
      "grad_norm": 5.711310386657715,
      "learning_rate": 2.848464894229978e-05,
      "loss": 0.2738,
      "step": 7372
    },
    {
      "epoch": 0.15177969720197337,
      "grad_norm": 4.8702569007873535,
      "learning_rate": 2.8483825829286362e-05,
      "loss": 0.1982,
      "step": 7376
    },
    {
      "epoch": 0.15186200723299398,
      "grad_norm": 5.328328609466553,
      "learning_rate": 2.8483002716272944e-05,
      "loss": 0.1636,
      "step": 7380
    },
    {
      "epoch": 0.15194431726401456,
      "grad_norm": 3.871572732925415,
      "learning_rate": 2.848217960325953e-05,
      "loss": 0.2053,
      "step": 7384
    },
    {
      "epoch": 0.15202662729503516,
      "grad_norm": 3.8816044330596924,
      "learning_rate": 2.848135649024611e-05,
      "loss": 0.3069,
      "step": 7388
    },
    {
      "epoch": 0.15210893732605577,
      "grad_norm": 1.784589171409607,
      "learning_rate": 2.8480533377232696e-05,
      "loss": 0.1737,
      "step": 7392
    },
    {
      "epoch": 0.15219124735707634,
      "grad_norm": 4.000981330871582,
      "learning_rate": 2.847971026421928e-05,
      "loss": 0.291,
      "step": 7396
    },
    {
      "epoch": 0.15227355738809695,
      "grad_norm": 2.5622549057006836,
      "learning_rate": 2.847888715120586e-05,
      "loss": 0.208,
      "step": 7400
    },
    {
      "epoch": 0.15433130816361176,
      "grad_norm": 4.16848087310791,
      "learning_rate": 2.845830932587044e-05,
      "loss": 0.2227,
      "step": 7500
    },
    {
      "epoch": 0.15638905893912658,
      "grad_norm": 2.670987844467163,
      "learning_rate": 2.8437731500535023e-05,
      "loss": 0.1877,
      "step": 7600
    },
    {
      "epoch": 0.15844680971464142,
      "grad_norm": 2.311633348464966,
      "learning_rate": 2.8417153675199603e-05,
      "loss": 0.1885,
      "step": 7700
    },
    {
      "epoch": 0.16050456049015624,
      "grad_norm": 5.565046787261963,
      "learning_rate": 2.8396575849864185e-05,
      "loss": 0.1934,
      "step": 7800
    },
    {
      "epoch": 0.16256231126567106,
      "grad_norm": 2.5519750118255615,
      "learning_rate": 2.8375998024528768e-05,
      "loss": 0.1862,
      "step": 7900
    },
    {
      "epoch": 0.16462006204118587,
      "grad_norm": 5.168220043182373,
      "learning_rate": 2.8355420199193348e-05,
      "loss": 0.1989,
      "step": 8000
    },
    {
      "epoch": 0.16667781281670072,
      "grad_norm": 1.4762985706329346,
      "learning_rate": 2.833484237385793e-05,
      "loss": 0.2239,
      "step": 8100
    },
    {
      "epoch": 0.16873556359221553,
      "grad_norm": 3.3428428173065186,
      "learning_rate": 2.831426454852251e-05,
      "loss": 0.1965,
      "step": 8200
    },
    {
      "epoch": 0.17079331436773035,
      "grad_norm": 3.514024496078491,
      "learning_rate": 2.8293892501440447e-05,
      "loss": 0.2093,
      "step": 8300
    },
    {
      "epoch": 0.17285106514324516,
      "grad_norm": 3.6303911209106445,
      "learning_rate": 2.827331467610503e-05,
      "loss": 0.2009,
      "step": 8400
    },
    {
      "epoch": 0.17490881591876,
      "grad_norm": 5.338726997375488,
      "learning_rate": 2.825273685076961e-05,
      "loss": 0.1678,
      "step": 8500
    },
    {
      "epoch": 0.17696656669427482,
      "grad_norm": 2.2731285095214844,
      "learning_rate": 2.8232159025434192e-05,
      "loss": 0.2034,
      "step": 8600
    },
    {
      "epoch": 0.17902431746978964,
      "grad_norm": 3.4676990509033203,
      "learning_rate": 2.821158120009877e-05,
      "loss": 0.2199,
      "step": 8700
    },
    {
      "epoch": 0.18108206824530446,
      "grad_norm": 2.450274705886841,
      "learning_rate": 2.8191003374763354e-05,
      "loss": 0.2035,
      "step": 8800
    },
    {
      "epoch": 0.1831398190208193,
      "grad_norm": 2.887402296066284,
      "learning_rate": 2.8170425549427937e-05,
      "loss": 0.2086,
      "step": 8900
    },
    {
      "epoch": 0.18519756979633412,
      "grad_norm": 4.485464096069336,
      "learning_rate": 2.8149847724092516e-05,
      "loss": 0.1986,
      "step": 9000
    },
    {
      "epoch": 0.18725532057184893,
      "grad_norm": 1.7532386779785156,
      "learning_rate": 2.81292698987571e-05,
      "loss": 0.2203,
      "step": 9100
    },
    {
      "epoch": 0.18931307134736378,
      "grad_norm": 1.6432838439941406,
      "learning_rate": 2.810869207342168e-05,
      "loss": 0.2014,
      "step": 9200
    },
    {
      "epoch": 0.1913708221228786,
      "grad_norm": 5.915217399597168,
      "learning_rate": 2.808811424808626e-05,
      "loss": 0.2095,
      "step": 9300
    },
    {
      "epoch": 0.1934285728983934,
      "grad_norm": 3.025728940963745,
      "learning_rate": 2.8067536422750844e-05,
      "loss": 0.1949,
      "step": 9400
    },
    {
      "epoch": 0.19548632367390822,
      "grad_norm": 3.610612154006958,
      "learning_rate": 2.8046958597415424e-05,
      "loss": 0.2002,
      "step": 9500
    },
    {
      "epoch": 0.19754407444942307,
      "grad_norm": 2.553983449935913,
      "learning_rate": 2.8026380772080006e-05,
      "loss": 0.182,
      "step": 9600
    },
    {
      "epoch": 0.19960182522493788,
      "grad_norm": 2.679781436920166,
      "learning_rate": 2.8005802946744586e-05,
      "loss": 0.2078,
      "step": 9700
    },
    {
      "epoch": 0.2016595760004527,
      "grad_norm": 3.6668009757995605,
      "learning_rate": 2.798522512140917e-05,
      "loss": 0.2058,
      "step": 9800
    },
    {
      "epoch": 0.20371732677596752,
      "grad_norm": 4.165266036987305,
      "learning_rate": 2.796464729607375e-05,
      "loss": 0.1968,
      "step": 9900
    },
    {
      "epoch": 0.20577507755148236,
      "grad_norm": 2.5704195499420166,
      "learning_rate": 2.7944069470738334e-05,
      "loss": 0.1974,
      "step": 10000
    },
    {
      "epoch": 0.20577507755148236,
      "eval_accuracy": 0.8156822810590632,
      "eval_f1_contradiction": 0.8208005985783764,
      "eval_loss": 0.16779214143753052,
      "eval_runtime": 75.2517,
      "eval_samples_per_second": 52.198,
      "eval_steps_per_second": 6.525,
      "step": 10000
    },
    {
      "epoch": 0.20783282832699718,
      "grad_norm": 3.4096038341522217,
      "learning_rate": 2.7923491645402917e-05,
      "loss": 0.1766,
      "step": 10100
    },
    {
      "epoch": 0.209890579102512,
      "grad_norm": 1.6826812028884888,
      "learning_rate": 2.7902913820067497e-05,
      "loss": 0.1986,
      "step": 10200
    },
    {
      "epoch": 0.21194832987802684,
      "grad_norm": 2.6400632858276367,
      "learning_rate": 2.788233599473208e-05,
      "loss": 0.1918,
      "step": 10300
    },
    {
      "epoch": 0.21400608065354165,
      "grad_norm": 1.76787269115448,
      "learning_rate": 2.7861963947650013e-05,
      "loss": 0.2163,
      "step": 10400
    },
    {
      "epoch": 0.21606383142905647,
      "grad_norm": 2.373075246810913,
      "learning_rate": 2.7841386122314592e-05,
      "loss": 0.1877,
      "step": 10500
    },
    {
      "epoch": 0.21812158220457128,
      "grad_norm": 2.271413803100586,
      "learning_rate": 2.7820808296979175e-05,
      "loss": 0.2047,
      "step": 10600
    },
    {
      "epoch": 0.22017933298008613,
      "grad_norm": 2.409369468688965,
      "learning_rate": 2.7800230471643755e-05,
      "loss": 0.2138,
      "step": 10700
    },
    {
      "epoch": 0.22223708375560094,
      "grad_norm": 3.614201545715332,
      "learning_rate": 2.7779652646308337e-05,
      "loss": 0.2137,
      "step": 10800
    },
    {
      "epoch": 0.22429483453111576,
      "grad_norm": 7.339828014373779,
      "learning_rate": 2.775907482097292e-05,
      "loss": 0.2022,
      "step": 10900
    },
    {
      "epoch": 0.22635258530663058,
      "grad_norm": 3.8052115440368652,
      "learning_rate": 2.77384969956375e-05,
      "loss": 0.2059,
      "step": 11000
    },
    {
      "epoch": 0.22841033608214542,
      "grad_norm": 7.512882709503174,
      "learning_rate": 2.7717919170302083e-05,
      "loss": 0.1849,
      "step": 11100
    },
    {
      "epoch": 0.23046808685766024,
      "grad_norm": 2.4055943489074707,
      "learning_rate": 2.7697341344966662e-05,
      "loss": 0.192,
      "step": 11200
    },
    {
      "epoch": 0.23252583763317505,
      "grad_norm": 5.314785480499268,
      "learning_rate": 2.7676763519631245e-05,
      "loss": 0.1821,
      "step": 11300
    },
    {
      "epoch": 0.23458358840868987,
      "grad_norm": 3.40118408203125,
      "learning_rate": 2.7656185694295828e-05,
      "loss": 0.1812,
      "step": 11400
    },
    {
      "epoch": 0.2366413391842047,
      "grad_norm": 2.245877981185913,
      "learning_rate": 2.7635607868960407e-05,
      "loss": 0.2014,
      "step": 11500
    },
    {
      "epoch": 0.23869908995971953,
      "grad_norm": 6.7418694496154785,
      "learning_rate": 2.761503004362499e-05,
      "loss": 0.2127,
      "step": 11600
    },
    {
      "epoch": 0.24075684073523435,
      "grad_norm": 1.9985101222991943,
      "learning_rate": 2.7594452218289573e-05,
      "loss": 0.1852,
      "step": 11700
    },
    {
      "epoch": 0.2428145915107492,
      "grad_norm": 2.875586748123169,
      "learning_rate": 2.7573874392954155e-05,
      "loss": 0.1987,
      "step": 11800
    },
    {
      "epoch": 0.244872342286264,
      "grad_norm": 2.0268678665161133,
      "learning_rate": 2.7553296567618735e-05,
      "loss": 0.2088,
      "step": 11900
    },
    {
      "epoch": 0.24693009306177882,
      "grad_norm": 2.241525173187256,
      "learning_rate": 2.7532718742283318e-05,
      "loss": 0.1879,
      "step": 12000
    },
    {
      "epoch": 0.24898784383729364,
      "grad_norm": 5.802016258239746,
      "learning_rate": 2.75121409169479e-05,
      "loss": 0.1838,
      "step": 12100
    },
    {
      "epoch": 0.25104559461280845,
      "grad_norm": 3.8576812744140625,
      "learning_rate": 2.749156309161248e-05,
      "loss": 0.2059,
      "step": 12200
    },
    {
      "epoch": 0.2531033453883233,
      "grad_norm": 3.1094555854797363,
      "learning_rate": 2.7470985266277063e-05,
      "loss": 0.2086,
      "step": 12300
    },
    {
      "epoch": 0.25516109616383814,
      "grad_norm": 2.3084487915039062,
      "learning_rate": 2.7450613219194996e-05,
      "loss": 0.2086,
      "step": 12400
    },
    {
      "epoch": 0.25721884693935293,
      "grad_norm": 3.8002452850341797,
      "learning_rate": 2.7430035393859576e-05,
      "loss": 0.1954,
      "step": 12500
    },
    {
      "epoch": 0.2592765977148678,
      "grad_norm": 2.4216835498809814,
      "learning_rate": 2.740945756852416e-05,
      "loss": 0.1927,
      "step": 12600
    },
    {
      "epoch": 0.26133434849038256,
      "grad_norm": 2.3724141120910645,
      "learning_rate": 2.7388879743188738e-05,
      "loss": 0.1847,
      "step": 12700
    },
    {
      "epoch": 0.2633920992658974,
      "grad_norm": 1.7779245376586914,
      "learning_rate": 2.736830191785332e-05,
      "loss": 0.2039,
      "step": 12800
    },
    {
      "epoch": 0.26544985004141225,
      "grad_norm": 2.8208391666412354,
      "learning_rate": 2.7347724092517904e-05,
      "loss": 0.17,
      "step": 12900
    },
    {
      "epoch": 0.26750760081692704,
      "grad_norm": 2.2652902603149414,
      "learning_rate": 2.7327146267182483e-05,
      "loss": 0.1981,
      "step": 13000
    },
    {
      "epoch": 0.2695653515924419,
      "grad_norm": 2.1517927646636963,
      "learning_rate": 2.7306568441847066e-05,
      "loss": 0.1885,
      "step": 13100
    },
    {
      "epoch": 0.2716231023679567,
      "grad_norm": 3.3097269535064697,
      "learning_rate": 2.7285990616511645e-05,
      "loss": 0.2041,
      "step": 13200
    },
    {
      "epoch": 0.2736808531434715,
      "grad_norm": 2.246605157852173,
      "learning_rate": 2.7265412791176228e-05,
      "loss": 0.1777,
      "step": 13300
    },
    {
      "epoch": 0.27573860391898636,
      "grad_norm": 4.665107250213623,
      "learning_rate": 2.724483496584081e-05,
      "loss": 0.1888,
      "step": 13400
    },
    {
      "epoch": 0.2777963546945012,
      "grad_norm": 3.237395763397217,
      "learning_rate": 2.7224257140505394e-05,
      "loss": 0.189,
      "step": 13500
    },
    {
      "epoch": 0.279854105470016,
      "grad_norm": 3.8359732627868652,
      "learning_rate": 2.7203679315169976e-05,
      "loss": 0.1977,
      "step": 13600
    },
    {
      "epoch": 0.28191185624553083,
      "grad_norm": 2.972494602203369,
      "learning_rate": 2.7183101489834556e-05,
      "loss": 0.1902,
      "step": 13700
    },
    {
      "epoch": 0.2839696070210456,
      "grad_norm": 1.2587032318115234,
      "learning_rate": 2.716252366449914e-05,
      "loss": 0.1996,
      "step": 13800
    },
    {
      "epoch": 0.28602735779656047,
      "grad_norm": 3.2599592208862305,
      "learning_rate": 2.7141945839163718e-05,
      "loss": 0.1987,
      "step": 13900
    },
    {
      "epoch": 0.2880851085720753,
      "grad_norm": 3.4540562629699707,
      "learning_rate": 2.71213680138283e-05,
      "loss": 0.1967,
      "step": 14000
    },
    {
      "epoch": 0.2901428593475901,
      "grad_norm": 2.6043341159820557,
      "learning_rate": 2.7100790188492884e-05,
      "loss": 0.2074,
      "step": 14100
    },
    {
      "epoch": 0.29220061012310494,
      "grad_norm": 2.3572189807891846,
      "learning_rate": 2.7080212363157463e-05,
      "loss": 0.1951,
      "step": 14200
    },
    {
      "epoch": 0.2942583608986198,
      "grad_norm": 3.7968034744262695,
      "learning_rate": 2.7059634537822046e-05,
      "loss": 0.1997,
      "step": 14300
    },
    {
      "epoch": 0.2963161116741346,
      "grad_norm": 1.3907908201217651,
      "learning_rate": 2.7039262490739976e-05,
      "loss": 0.1866,
      "step": 14400
    },
    {
      "epoch": 0.2983738624496494,
      "grad_norm": 3.14227032661438,
      "learning_rate": 2.701868466540456e-05,
      "loss": 0.1907,
      "step": 14500
    },
    {
      "epoch": 0.3004316132251642,
      "grad_norm": 1.8387454748153687,
      "learning_rate": 2.6998106840069142e-05,
      "loss": 0.1895,
      "step": 14600
    },
    {
      "epoch": 0.30248936400067905,
      "grad_norm": 1.9847354888916016,
      "learning_rate": 2.697752901473372e-05,
      "loss": 0.2057,
      "step": 14700
    },
    {
      "epoch": 0.3045471147761939,
      "grad_norm": 1.3851755857467651,
      "learning_rate": 2.6956951189398304e-05,
      "loss": 0.2012,
      "step": 14800
    },
    {
      "epoch": 0.3066048655517087,
      "grad_norm": 5.548762321472168,
      "learning_rate": 2.6936373364062887e-05,
      "loss": 0.1934,
      "step": 14900
    },
    {
      "epoch": 0.3086626163272235,
      "grad_norm": 3.161489725112915,
      "learning_rate": 2.691579553872747e-05,
      "loss": 0.218,
      "step": 15000
    },
    {
      "epoch": 0.31072036710273837,
      "grad_norm": 2.377377986907959,
      "learning_rate": 2.6895217713392052e-05,
      "loss": 0.2006,
      "step": 15100
    },
    {
      "epoch": 0.31277811787825316,
      "grad_norm": 1.941603422164917,
      "learning_rate": 2.6874639888056632e-05,
      "loss": 0.2085,
      "step": 15200
    },
    {
      "epoch": 0.314835868653768,
      "grad_norm": 0.5956428647041321,
      "learning_rate": 2.6854062062721215e-05,
      "loss": 0.2103,
      "step": 15300
    },
    {
      "epoch": 0.31689361942928285,
      "grad_norm": 0.8981931805610657,
      "learning_rate": 2.6833484237385794e-05,
      "loss": 0.1858,
      "step": 15400
    },
    {
      "epoch": 0.31895137020479764,
      "grad_norm": 3.520805835723877,
      "learning_rate": 2.6812906412050377e-05,
      "loss": 0.1894,
      "step": 15500
    },
    {
      "epoch": 0.3210091209803125,
      "grad_norm": 1.9243024587631226,
      "learning_rate": 2.679232858671496e-05,
      "loss": 0.2116,
      "step": 15600
    },
    {
      "epoch": 0.32306687175582727,
      "grad_norm": 1.4565207958221436,
      "learning_rate": 2.677175076137954e-05,
      "loss": 0.2121,
      "step": 15700
    },
    {
      "epoch": 0.3251246225313421,
      "grad_norm": 2.102353811264038,
      "learning_rate": 2.6751172936044122e-05,
      "loss": 0.2097,
      "step": 15800
    },
    {
      "epoch": 0.32718237330685696,
      "grad_norm": 4.608922481536865,
      "learning_rate": 2.67305951107087e-05,
      "loss": 0.1968,
      "step": 15900
    },
    {
      "epoch": 0.32924012408237174,
      "grad_norm": 2.244983673095703,
      "learning_rate": 2.6710017285373284e-05,
      "loss": 0.1929,
      "step": 16000
    },
    {
      "epoch": 0.3312978748578866,
      "grad_norm": 4.439730644226074,
      "learning_rate": 2.6689439460037867e-05,
      "loss": 0.208,
      "step": 16100
    },
    {
      "epoch": 0.33335562563340143,
      "grad_norm": 2.752918243408203,
      "learning_rate": 2.6668861634702446e-05,
      "loss": 0.1889,
      "step": 16200
    },
    {
      "epoch": 0.3354133764089162,
      "grad_norm": 3.1468305587768555,
      "learning_rate": 2.664828380936703e-05,
      "loss": 0.1983,
      "step": 16300
    },
    {
      "epoch": 0.33747112718443106,
      "grad_norm": 3.520955801010132,
      "learning_rate": 2.662791176228496e-05,
      "loss": 0.2237,
      "step": 16400
    },
    {
      "epoch": 0.3395288779599459,
      "grad_norm": 2.641416311264038,
      "learning_rate": 2.6607333936949542e-05,
      "loss": 0.1932,
      "step": 16500
    },
    {
      "epoch": 0.3415866287354607,
      "grad_norm": 0.884343683719635,
      "learning_rate": 2.6586756111614125e-05,
      "loss": 0.1948,
      "step": 16600
    },
    {
      "epoch": 0.34364437951097554,
      "grad_norm": 4.62520170211792,
      "learning_rate": 2.6566178286278708e-05,
      "loss": 0.1974,
      "step": 16700
    },
    {
      "epoch": 0.34570213028649033,
      "grad_norm": 2.8157732486724854,
      "learning_rate": 2.654560046094329e-05,
      "loss": 0.2209,
      "step": 16800
    },
    {
      "epoch": 0.34775988106200517,
      "grad_norm": 2.4066662788391113,
      "learning_rate": 2.652502263560787e-05,
      "loss": 0.1845,
      "step": 16900
    },
    {
      "epoch": 0.34981763183752,
      "grad_norm": 5.121257781982422,
      "learning_rate": 2.6504444810272453e-05,
      "loss": 0.2124,
      "step": 17000
    },
    {
      "epoch": 0.3518753826130348,
      "grad_norm": 2.9216442108154297,
      "learning_rate": 2.6483866984937036e-05,
      "loss": 0.1936,
      "step": 17100
    },
    {
      "epoch": 0.35393313338854965,
      "grad_norm": 1.1893188953399658,
      "learning_rate": 2.6463289159601615e-05,
      "loss": 0.2012,
      "step": 17200
    },
    {
      "epoch": 0.3559908841640645,
      "grad_norm": 3.5515711307525635,
      "learning_rate": 2.6442711334266198e-05,
      "loss": 0.1987,
      "step": 17300
    },
    {
      "epoch": 0.3580486349395793,
      "grad_norm": 1.6271849870681763,
      "learning_rate": 2.6422133508930777e-05,
      "loss": 0.192,
      "step": 17400
    },
    {
      "epoch": 0.3601063857150941,
      "grad_norm": 3.5153348445892334,
      "learning_rate": 2.640155568359536e-05,
      "loss": 0.2088,
      "step": 17500
    },
    {
      "epoch": 0.3621641364906089,
      "grad_norm": 4.663618564605713,
      "learning_rate": 2.638097785825994e-05,
      "loss": 0.1876,
      "step": 17600
    },
    {
      "epoch": 0.36422188726612376,
      "grad_norm": 4.2806477546691895,
      "learning_rate": 2.6360400032924522e-05,
      "loss": 0.1953,
      "step": 17700
    },
    {
      "epoch": 0.3662796380416386,
      "grad_norm": 1.263420820236206,
      "learning_rate": 2.6339822207589105e-05,
      "loss": 0.1968,
      "step": 17800
    },
    {
      "epoch": 0.3683373888171534,
      "grad_norm": 2.0361835956573486,
      "learning_rate": 2.6319244382253684e-05,
      "loss": 0.2105,
      "step": 17900
    },
    {
      "epoch": 0.37039513959266823,
      "grad_norm": 4.494352340698242,
      "learning_rate": 2.6298666556918267e-05,
      "loss": 0.1963,
      "step": 18000
    },
    {
      "epoch": 0.3724528903681831,
      "grad_norm": 4.175388336181641,
      "learning_rate": 2.6278088731582847e-05,
      "loss": 0.2091,
      "step": 18100
    },
    {
      "epoch": 0.37451064114369786,
      "grad_norm": 1.455458641052246,
      "learning_rate": 2.625751090624743e-05,
      "loss": 0.1912,
      "step": 18200
    },
    {
      "epoch": 0.3765683919192127,
      "grad_norm": 1.837651014328003,
      "learning_rate": 2.6236933080912012e-05,
      "loss": 0.2,
      "step": 18300
    },
    {
      "epoch": 0.37862614269472755,
      "grad_norm": 3.0282647609710693,
      "learning_rate": 2.6216561033829946e-05,
      "loss": 0.1993,
      "step": 18400
    },
    {
      "epoch": 0.38068389347024234,
      "grad_norm": 6.626607894897461,
      "learning_rate": 2.619598320849453e-05,
      "loss": 0.191,
      "step": 18500
    },
    {
      "epoch": 0.3827416442457572,
      "grad_norm": 2.1450514793395996,
      "learning_rate": 2.617540538315911e-05,
      "loss": 0.2016,
      "step": 18600
    },
    {
      "epoch": 0.384799395021272,
      "grad_norm": 3.591054916381836,
      "learning_rate": 2.615482755782369e-05,
      "loss": 0.1898,
      "step": 18700
    },
    {
      "epoch": 0.3868571457967868,
      "grad_norm": 2.174769878387451,
      "learning_rate": 2.6134249732488274e-05,
      "loss": 0.2013,
      "step": 18800
    },
    {
      "epoch": 0.38891489657230166,
      "grad_norm": 1.7890617847442627,
      "learning_rate": 2.6113671907152853e-05,
      "loss": 0.2133,
      "step": 18900
    },
    {
      "epoch": 0.39097264734781645,
      "grad_norm": 1.6745831966400146,
      "learning_rate": 2.6093094081817436e-05,
      "loss": 0.1974,
      "step": 19000
    },
    {
      "epoch": 0.3930303981233313,
      "grad_norm": 0.7367063164710999,
      "learning_rate": 2.6072516256482015e-05,
      "loss": 0.1879,
      "step": 19100
    },
    {
      "epoch": 0.39508814889884614,
      "grad_norm": 5.106443881988525,
      "learning_rate": 2.6051938431146598e-05,
      "loss": 0.1912,
      "step": 19200
    },
    {
      "epoch": 0.3971458996743609,
      "grad_norm": 2.0838801860809326,
      "learning_rate": 2.603136060581118e-05,
      "loss": 0.1988,
      "step": 19300
    },
    {
      "epoch": 0.39920365044987577,
      "grad_norm": 2.104299545288086,
      "learning_rate": 2.601078278047576e-05,
      "loss": 0.204,
      "step": 19400
    },
    {
      "epoch": 0.4012614012253906,
      "grad_norm": 5.039995193481445,
      "learning_rate": 2.5990204955140343e-05,
      "loss": 0.2163,
      "step": 19500
    },
    {
      "epoch": 0.4033191520009054,
      "grad_norm": 4.628454208374023,
      "learning_rate": 2.5969627129804923e-05,
      "loss": 0.1708,
      "step": 19600
    },
    {
      "epoch": 0.40537690277642024,
      "grad_norm": 2.995248317718506,
      "learning_rate": 2.5949049304469505e-05,
      "loss": 0.1826,
      "step": 19700
    },
    {
      "epoch": 0.40743465355193503,
      "grad_norm": 3.4796950817108154,
      "learning_rate": 2.5928471479134088e-05,
      "loss": 0.1921,
      "step": 19800
    },
    {
      "epoch": 0.4094924043274499,
      "grad_norm": 4.608234882354736,
      "learning_rate": 2.5907893653798668e-05,
      "loss": 0.1819,
      "step": 19900
    },
    {
      "epoch": 0.4115501551029647,
      "grad_norm": 4.178213119506836,
      "learning_rate": 2.588731582846325e-05,
      "loss": 0.1912,
      "step": 20000
    },
    {
      "epoch": 0.4115501551029647,
      "eval_accuracy": 0.8177189409368636,
      "eval_f1_contradiction": 0.8223538119911177,
      "eval_loss": 0.1681743860244751,
      "eval_runtime": 73.6159,
      "eval_samples_per_second": 53.358,
      "eval_steps_per_second": 6.67,
      "step": 20000
    },
    {
      "epoch": 0.4136079058784795,
      "grad_norm": 5.451493263244629,
      "learning_rate": 2.586673800312783e-05,
      "loss": 0.2006,
      "step": 20100
    },
    {
      "epoch": 0.41566565665399435,
      "grad_norm": 3.052129030227661,
      "learning_rate": 2.5846160177792413e-05,
      "loss": 0.1798,
      "step": 20200
    },
    {
      "epoch": 0.4177234074295092,
      "grad_norm": 1.9765440225601196,
      "learning_rate": 2.5825582352456996e-05,
      "loss": 0.1894,
      "step": 20300
    },
    {
      "epoch": 0.419781158205024,
      "grad_norm": 0.6047333478927612,
      "learning_rate": 2.580521030537493e-05,
      "loss": 0.1956,
      "step": 20400
    },
    {
      "epoch": 0.42183890898053883,
      "grad_norm": 1.615740180015564,
      "learning_rate": 2.5784632480039512e-05,
      "loss": 0.1985,
      "step": 20500
    },
    {
      "epoch": 0.4238966597560537,
      "grad_norm": 1.1223667860031128,
      "learning_rate": 2.576405465470409e-05,
      "loss": 0.1758,
      "step": 20600
    },
    {
      "epoch": 0.42595441053156846,
      "grad_norm": 2.064995765686035,
      "learning_rate": 2.5743476829368674e-05,
      "loss": 0.1801,
      "step": 20700
    },
    {
      "epoch": 0.4280121613070833,
      "grad_norm": 1.9698399305343628,
      "learning_rate": 2.5722899004033257e-05,
      "loss": 0.1902,
      "step": 20800
    },
    {
      "epoch": 0.4300699120825981,
      "grad_norm": 2.268869161605835,
      "learning_rate": 2.5702321178697836e-05,
      "loss": 0.1889,
      "step": 20900
    },
    {
      "epoch": 0.43212766285811294,
      "grad_norm": 2.194920539855957,
      "learning_rate": 2.568174335336242e-05,
      "loss": 0.1884,
      "step": 21000
    },
    {
      "epoch": 0.4341854136336278,
      "grad_norm": 3.5384793281555176,
      "learning_rate": 2.5661165528027e-05,
      "loss": 0.1939,
      "step": 21100
    },
    {
      "epoch": 0.43624316440914257,
      "grad_norm": 2.2164103984832764,
      "learning_rate": 2.564058770269158e-05,
      "loss": 0.1903,
      "step": 21200
    },
    {
      "epoch": 0.4383009151846574,
      "grad_norm": 3.9504714012145996,
      "learning_rate": 2.5620009877356164e-05,
      "loss": 0.1892,
      "step": 21300
    },
    {
      "epoch": 0.44035866596017226,
      "grad_norm": 3.290588617324829,
      "learning_rate": 2.5599432052020744e-05,
      "loss": 0.1957,
      "step": 21400
    },
    {
      "epoch": 0.44241641673568705,
      "grad_norm": 3.8699474334716797,
      "learning_rate": 2.5578854226685327e-05,
      "loss": 0.1968,
      "step": 21500
    },
    {
      "epoch": 0.4444741675112019,
      "grad_norm": 1.8125741481781006,
      "learning_rate": 2.5558276401349906e-05,
      "loss": 0.1898,
      "step": 21600
    },
    {
      "epoch": 0.4465319182867167,
      "grad_norm": 6.039109706878662,
      "learning_rate": 2.553769857601449e-05,
      "loss": 0.1965,
      "step": 21700
    },
    {
      "epoch": 0.4485896690622315,
      "grad_norm": 2.1000282764434814,
      "learning_rate": 2.551712075067907e-05,
      "loss": 0.1871,
      "step": 21800
    },
    {
      "epoch": 0.45064741983774637,
      "grad_norm": 1.4992866516113281,
      "learning_rate": 2.549654292534365e-05,
      "loss": 0.2073,
      "step": 21900
    },
    {
      "epoch": 0.45270517061326115,
      "grad_norm": 1.4603430032730103,
      "learning_rate": 2.5475965100008234e-05,
      "loss": 0.1795,
      "step": 22000
    },
    {
      "epoch": 0.454762921388776,
      "grad_norm": 2.5196022987365723,
      "learning_rate": 2.5455387274672813e-05,
      "loss": 0.1869,
      "step": 22100
    },
    {
      "epoch": 0.45682067216429084,
      "grad_norm": 1.6540063619613647,
      "learning_rate": 2.5434809449337396e-05,
      "loss": 0.1808,
      "step": 22200
    },
    {
      "epoch": 0.45887842293980563,
      "grad_norm": 2.390448570251465,
      "learning_rate": 2.5414231624001975e-05,
      "loss": 0.1896,
      "step": 22300
    },
    {
      "epoch": 0.4609361737153205,
      "grad_norm": 4.951191425323486,
      "learning_rate": 2.5393653798666558e-05,
      "loss": 0.1995,
      "step": 22400
    },
    {
      "epoch": 0.4629939244908353,
      "grad_norm": 3.4067983627319336,
      "learning_rate": 2.5373281751584495e-05,
      "loss": 0.1865,
      "step": 22500
    },
    {
      "epoch": 0.4650516752663501,
      "grad_norm": 2.7723729610443115,
      "learning_rate": 2.5352703926249075e-05,
      "loss": 0.2014,
      "step": 22600
    },
    {
      "epoch": 0.46710942604186495,
      "grad_norm": 4.0578532218933105,
      "learning_rate": 2.5332126100913658e-05,
      "loss": 0.1943,
      "step": 22700
    },
    {
      "epoch": 0.46916717681737974,
      "grad_norm": 1.5049164295196533,
      "learning_rate": 2.531154827557824e-05,
      "loss": 0.2095,
      "step": 22800
    },
    {
      "epoch": 0.4712249275928946,
      "grad_norm": 1.809144139289856,
      "learning_rate": 2.529097045024282e-05,
      "loss": 0.1915,
      "step": 22900
    },
    {
      "epoch": 0.4732826783684094,
      "grad_norm": 3.098051071166992,
      "learning_rate": 2.5270392624907403e-05,
      "loss": 0.2007,
      "step": 23000
    },
    {
      "epoch": 0.4753404291439242,
      "grad_norm": 2.9851009845733643,
      "learning_rate": 2.5249814799571982e-05,
      "loss": 0.1987,
      "step": 23100
    },
    {
      "epoch": 0.47739817991943906,
      "grad_norm": 4.596197605133057,
      "learning_rate": 2.5229236974236565e-05,
      "loss": 0.1864,
      "step": 23200
    },
    {
      "epoch": 0.4794559306949539,
      "grad_norm": 3.268078565597534,
      "learning_rate": 2.5208659148901148e-05,
      "loss": 0.1881,
      "step": 23300
    },
    {
      "epoch": 0.4815136814704687,
      "grad_norm": 0.43502938747406006,
      "learning_rate": 2.5188081323565727e-05,
      "loss": 0.1968,
      "step": 23400
    },
    {
      "epoch": 0.48357143224598353,
      "grad_norm": 2.152418375015259,
      "learning_rate": 2.516750349823031e-05,
      "loss": 0.1993,
      "step": 23500
    },
    {
      "epoch": 0.4856291830214984,
      "grad_norm": 0.792445957660675,
      "learning_rate": 2.514692567289489e-05,
      "loss": 0.2049,
      "step": 23600
    },
    {
      "epoch": 0.48768693379701317,
      "grad_norm": 5.745007038116455,
      "learning_rate": 2.5126347847559472e-05,
      "loss": 0.1991,
      "step": 23700
    },
    {
      "epoch": 0.489744684572528,
      "grad_norm": 3.7745320796966553,
      "learning_rate": 2.510577002222405e-05,
      "loss": 0.1912,
      "step": 23800
    },
    {
      "epoch": 0.4918024353480428,
      "grad_norm": 2.3211822509765625,
      "learning_rate": 2.5085192196888634e-05,
      "loss": 0.1738,
      "step": 23900
    },
    {
      "epoch": 0.49386018612355764,
      "grad_norm": 2.1055328845977783,
      "learning_rate": 2.5064614371553217e-05,
      "loss": 0.1831,
      "step": 24000
    },
    {
      "epoch": 0.4959179368990725,
      "grad_norm": 1.8678240776062012,
      "learning_rate": 2.5044036546217796e-05,
      "loss": 0.1851,
      "step": 24100
    },
    {
      "epoch": 0.4979756876745873,
      "grad_norm": 2.88457989692688,
      "learning_rate": 2.502345872088238e-05,
      "loss": 0.1848,
      "step": 24200
    },
    {
      "epoch": 0.5000334384501021,
      "grad_norm": 3.4380404949188232,
      "learning_rate": 2.500288089554696e-05,
      "loss": 0.2034,
      "step": 24300
    },
    {
      "epoch": 0.5020911892256169,
      "grad_norm": 3.924811601638794,
      "learning_rate": 2.498230307021154e-05,
      "loss": 0.1805,
      "step": 24400
    },
    {
      "epoch": 0.5041489400011318,
      "grad_norm": 4.795147895812988,
      "learning_rate": 2.496193102312948e-05,
      "loss": 0.2033,
      "step": 24500
    },
    {
      "epoch": 0.5062066907766466,
      "grad_norm": 2.7442800998687744,
      "learning_rate": 2.4941353197794058e-05,
      "loss": 0.1789,
      "step": 24600
    },
    {
      "epoch": 0.5082644415521614,
      "grad_norm": 4.112823009490967,
      "learning_rate": 2.492077537245864e-05,
      "loss": 0.1988,
      "step": 24700
    },
    {
      "epoch": 0.5103221923276763,
      "grad_norm": 2.1233103275299072,
      "learning_rate": 2.490019754712322e-05,
      "loss": 0.1751,
      "step": 24800
    },
    {
      "epoch": 0.512379943103191,
      "grad_norm": 2.776611089706421,
      "learning_rate": 2.4879619721787803e-05,
      "loss": 0.184,
      "step": 24900
    },
    {
      "epoch": 0.5144376938787059,
      "grad_norm": 4.659400463104248,
      "learning_rate": 2.4859041896452386e-05,
      "loss": 0.1931,
      "step": 25000
    },
    {
      "epoch": 0.5164954446542207,
      "grad_norm": 1.8790545463562012,
      "learning_rate": 2.4838464071116965e-05,
      "loss": 0.1863,
      "step": 25100
    },
    {
      "epoch": 0.5185531954297355,
      "grad_norm": 2.134387254714966,
      "learning_rate": 2.4817886245781548e-05,
      "loss": 0.2078,
      "step": 25200
    },
    {
      "epoch": 0.5206109462052504,
      "grad_norm": 1.7669569253921509,
      "learning_rate": 2.4797308420446127e-05,
      "loss": 0.1874,
      "step": 25300
    },
    {
      "epoch": 0.5226686969807651,
      "grad_norm": 2.9504523277282715,
      "learning_rate": 2.477673059511071e-05,
      "loss": 0.1978,
      "step": 25400
    },
    {
      "epoch": 0.52472644775628,
      "grad_norm": 0.7264575958251953,
      "learning_rate": 2.4756152769775293e-05,
      "loss": 0.1696,
      "step": 25500
    },
    {
      "epoch": 0.5267841985317948,
      "grad_norm": 2.185326337814331,
      "learning_rate": 2.4735574944439872e-05,
      "loss": 0.1979,
      "step": 25600
    },
    {
      "epoch": 0.5288419493073097,
      "grad_norm": 1.944861888885498,
      "learning_rate": 2.4714997119104455e-05,
      "loss": 0.1854,
      "step": 25700
    },
    {
      "epoch": 0.5308997000828245,
      "grad_norm": 3.304910898208618,
      "learning_rate": 2.4694419293769035e-05,
      "loss": 0.1865,
      "step": 25800
    },
    {
      "epoch": 0.5329574508583393,
      "grad_norm": 1.921889066696167,
      "learning_rate": 2.4673841468433617e-05,
      "loss": 0.1858,
      "step": 25900
    },
    {
      "epoch": 0.5350152016338541,
      "grad_norm": 2.5480051040649414,
      "learning_rate": 2.46532636430982e-05,
      "loss": 0.2016,
      "step": 26000
    },
    {
      "epoch": 0.5370729524093689,
      "grad_norm": 2.082712173461914,
      "learning_rate": 2.463268581776278e-05,
      "loss": 0.1908,
      "step": 26100
    },
    {
      "epoch": 0.5391307031848838,
      "grad_norm": 2.2224068641662598,
      "learning_rate": 2.4612107992427362e-05,
      "loss": 0.1977,
      "step": 26200
    },
    {
      "epoch": 0.5411884539603986,
      "grad_norm": 3.542280435562134,
      "learning_rate": 2.4591530167091942e-05,
      "loss": 0.1975,
      "step": 26300
    },
    {
      "epoch": 0.5432462047359135,
      "grad_norm": 0.8464691638946533,
      "learning_rate": 2.4570952341756525e-05,
      "loss": 0.1991,
      "step": 26400
    },
    {
      "epoch": 0.5453039555114282,
      "grad_norm": 3.8915910720825195,
      "learning_rate": 2.4550580294674462e-05,
      "loss": 0.1976,
      "step": 26500
    },
    {
      "epoch": 0.547361706286943,
      "grad_norm": 3.4982802867889404,
      "learning_rate": 2.453000246933904e-05,
      "loss": 0.1836,
      "step": 26600
    },
    {
      "epoch": 0.5494194570624579,
      "grad_norm": 3.772723436355591,
      "learning_rate": 2.4509424644003624e-05,
      "loss": 0.1986,
      "step": 26700
    },
    {
      "epoch": 0.5514772078379727,
      "grad_norm": 1.9917850494384766,
      "learning_rate": 2.4488846818668203e-05,
      "loss": 0.1857,
      "step": 26800
    },
    {
      "epoch": 0.5535349586134876,
      "grad_norm": 3.957503080368042,
      "learning_rate": 2.4468268993332786e-05,
      "loss": 0.1959,
      "step": 26900
    },
    {
      "epoch": 0.5555927093890024,
      "grad_norm": 5.024342060089111,
      "learning_rate": 2.444769116799737e-05,
      "loss": 0.1944,
      "step": 27000
    },
    {
      "epoch": 0.5576504601645171,
      "grad_norm": 11.592134475708008,
      "learning_rate": 2.442711334266195e-05,
      "loss": 0.2028,
      "step": 27100
    },
    {
      "epoch": 0.559708210940032,
      "grad_norm": 0.9082778096199036,
      "learning_rate": 2.440653551732653e-05,
      "loss": 0.1978,
      "step": 27200
    },
    {
      "epoch": 0.5617659617155468,
      "grad_norm": 2.2812142372131348,
      "learning_rate": 2.438595769199111e-05,
      "loss": 0.1912,
      "step": 27300
    },
    {
      "epoch": 0.5638237124910617,
      "grad_norm": 4.122884750366211,
      "learning_rate": 2.4365379866655693e-05,
      "loss": 0.19,
      "step": 27400
    },
    {
      "epoch": 0.5658814632665765,
      "grad_norm": 5.357790470123291,
      "learning_rate": 2.4344802041320276e-05,
      "loss": 0.1897,
      "step": 27500
    },
    {
      "epoch": 0.5679392140420912,
      "grad_norm": 1.356374740600586,
      "learning_rate": 2.4324224215984856e-05,
      "loss": 0.1874,
      "step": 27600
    },
    {
      "epoch": 0.5699969648176061,
      "grad_norm": 4.803624153137207,
      "learning_rate": 2.430364639064944e-05,
      "loss": 0.1979,
      "step": 27700
    },
    {
      "epoch": 0.5720547155931209,
      "grad_norm": 2.576606512069702,
      "learning_rate": 2.4283068565314018e-05,
      "loss": 0.1908,
      "step": 27800
    },
    {
      "epoch": 0.5741124663686358,
      "grad_norm": 1.3937040567398071,
      "learning_rate": 2.42624907399786e-05,
      "loss": 0.176,
      "step": 27900
    },
    {
      "epoch": 0.5761702171441506,
      "grad_norm": 2.514112710952759,
      "learning_rate": 2.424191291464318e-05,
      "loss": 0.1751,
      "step": 28000
    },
    {
      "epoch": 0.5782279679196655,
      "grad_norm": 2.302473783493042,
      "learning_rate": 2.4221335089307763e-05,
      "loss": 0.2031,
      "step": 28100
    },
    {
      "epoch": 0.5802857186951802,
      "grad_norm": 3.5069148540496826,
      "learning_rate": 2.4200757263972346e-05,
      "loss": 0.1858,
      "step": 28200
    },
    {
      "epoch": 0.582343469470695,
      "grad_norm": 2.856424570083618,
      "learning_rate": 2.4180179438636925e-05,
      "loss": 0.1858,
      "step": 28300
    },
    {
      "epoch": 0.5844012202462099,
      "grad_norm": 2.021608829498291,
      "learning_rate": 2.4159601613301508e-05,
      "loss": 0.1903,
      "step": 28400
    },
    {
      "epoch": 0.5864589710217247,
      "grad_norm": 2.4824986457824707,
      "learning_rate": 2.4139023787966087e-05,
      "loss": 0.187,
      "step": 28500
    },
    {
      "epoch": 0.5885167217972396,
      "grad_norm": 2.2259809970855713,
      "learning_rate": 2.4118651740884024e-05,
      "loss": 0.2028,
      "step": 28600
    },
    {
      "epoch": 0.5905744725727543,
      "grad_norm": 0.8591119050979614,
      "learning_rate": 2.4098073915548607e-05,
      "loss": 0.1801,
      "step": 28700
    },
    {
      "epoch": 0.5926322233482691,
      "grad_norm": 1.4057648181915283,
      "learning_rate": 2.4077496090213187e-05,
      "loss": 0.1831,
      "step": 28800
    },
    {
      "epoch": 0.594689974123784,
      "grad_norm": 6.553940296173096,
      "learning_rate": 2.405691826487777e-05,
      "loss": 0.1895,
      "step": 28900
    },
    {
      "epoch": 0.5967477248992988,
      "grad_norm": 4.12054967880249,
      "learning_rate": 2.4036340439542352e-05,
      "loss": 0.1837,
      "step": 29000
    },
    {
      "epoch": 0.5988054756748137,
      "grad_norm": 1.8394503593444824,
      "learning_rate": 2.401576261420693e-05,
      "loss": 0.1802,
      "step": 29100
    },
    {
      "epoch": 0.6008632264503284,
      "grad_norm": 2.7601003646850586,
      "learning_rate": 2.3995184788871514e-05,
      "loss": 0.2064,
      "step": 29200
    },
    {
      "epoch": 0.6029209772258433,
      "grad_norm": 3.5736169815063477,
      "learning_rate": 2.3974606963536094e-05,
      "loss": 0.1941,
      "step": 29300
    },
    {
      "epoch": 0.6049787280013581,
      "grad_norm": 3.285214424133301,
      "learning_rate": 2.3954029138200677e-05,
      "loss": 0.1884,
      "step": 29400
    },
    {
      "epoch": 0.607036478776873,
      "grad_norm": 3.955016613006592,
      "learning_rate": 2.3933451312865256e-05,
      "loss": 0.1724,
      "step": 29500
    },
    {
      "epoch": 0.6090942295523878,
      "grad_norm": 1.4517812728881836,
      "learning_rate": 2.391287348752984e-05,
      "loss": 0.1943,
      "step": 29600
    },
    {
      "epoch": 0.6111519803279026,
      "grad_norm": 2.6135149002075195,
      "learning_rate": 2.389229566219442e-05,
      "loss": 0.1947,
      "step": 29700
    },
    {
      "epoch": 0.6132097311034174,
      "grad_norm": 2.7093541622161865,
      "learning_rate": 2.3871717836859e-05,
      "loss": 0.1985,
      "step": 29800
    },
    {
      "epoch": 0.6152674818789322,
      "grad_norm": 6.000955104827881,
      "learning_rate": 2.3851140011523584e-05,
      "loss": 0.1878,
      "step": 29900
    },
    {
      "epoch": 0.617325232654447,
      "grad_norm": 2.9640815258026123,
      "learning_rate": 2.3830562186188163e-05,
      "loss": 0.1934,
      "step": 30000
    },
    {
      "epoch": 0.617325232654447,
      "eval_accuracy": 0.8220468431771895,
      "eval_f1_contradiction": 0.8255382331106161,
      "eval_loss": 0.1636635810136795,
      "eval_runtime": 70.3166,
      "eval_samples_per_second": 55.862,
      "eval_steps_per_second": 6.983,
      "step": 30000
    },
    {
      "epoch": 0.6193829834299619,
      "grad_norm": 2.5237700939178467,
      "learning_rate": 2.3809984360852746e-05,
      "loss": 0.1802,
      "step": 30100
    },
    {
      "epoch": 0.6214407342054767,
      "grad_norm": 1.362589716911316,
      "learning_rate": 2.378940653551733e-05,
      "loss": 0.1898,
      "step": 30200
    },
    {
      "epoch": 0.6234984849809915,
      "grad_norm": 2.831005573272705,
      "learning_rate": 2.3768828710181908e-05,
      "loss": 0.1968,
      "step": 30300
    },
    {
      "epoch": 0.6255562357565063,
      "grad_norm": 3.4966623783111572,
      "learning_rate": 2.374825088484649e-05,
      "loss": 0.1929,
      "step": 30400
    },
    {
      "epoch": 0.6276139865320212,
      "grad_norm": 3.082853078842163,
      "learning_rate": 2.372767305951107e-05,
      "loss": 0.2072,
      "step": 30500
    },
    {
      "epoch": 0.629671737307536,
      "grad_norm": 3.3259682655334473,
      "learning_rate": 2.3707095234175653e-05,
      "loss": 0.1816,
      "step": 30600
    },
    {
      "epoch": 0.6317294880830508,
      "grad_norm": 0.8146833181381226,
      "learning_rate": 2.368672318709359e-05,
      "loss": 0.1983,
      "step": 30700
    },
    {
      "epoch": 0.6337872388585657,
      "grad_norm": 4.070823669433594,
      "learning_rate": 2.366614536175817e-05,
      "loss": 0.1849,
      "step": 30800
    },
    {
      "epoch": 0.6358449896340804,
      "grad_norm": 3.0030558109283447,
      "learning_rate": 2.3645567536422753e-05,
      "loss": 0.1812,
      "step": 30900
    },
    {
      "epoch": 0.6379027404095953,
      "grad_norm": 3.332982301712036,
      "learning_rate": 2.3624989711087332e-05,
      "loss": 0.1957,
      "step": 31000
    },
    {
      "epoch": 0.6399604911851101,
      "grad_norm": 0.535247266292572,
      "learning_rate": 2.3604411885751915e-05,
      "loss": 0.19,
      "step": 31100
    },
    {
      "epoch": 0.642018241960625,
      "grad_norm": 2.866194725036621,
      "learning_rate": 2.3583834060416498e-05,
      "loss": 0.1844,
      "step": 31200
    },
    {
      "epoch": 0.6440759927361398,
      "grad_norm": 0.9041299819946289,
      "learning_rate": 2.3563256235081077e-05,
      "loss": 0.1831,
      "step": 31300
    },
    {
      "epoch": 0.6461337435116545,
      "grad_norm": 1.6676520109176636,
      "learning_rate": 2.354267840974566e-05,
      "loss": 0.1884,
      "step": 31400
    },
    {
      "epoch": 0.6481914942871694,
      "grad_norm": 1.9669337272644043,
      "learning_rate": 2.352210058441024e-05,
      "loss": 0.1786,
      "step": 31500
    },
    {
      "epoch": 0.6502492450626842,
      "grad_norm": 2.386798143386841,
      "learning_rate": 2.3501522759074822e-05,
      "loss": 0.2074,
      "step": 31600
    },
    {
      "epoch": 0.6523069958381991,
      "grad_norm": 6.0919718742370605,
      "learning_rate": 2.3480944933739405e-05,
      "loss": 0.1577,
      "step": 31700
    },
    {
      "epoch": 0.6543647466137139,
      "grad_norm": 4.3990068435668945,
      "learning_rate": 2.3460367108403984e-05,
      "loss": 0.1957,
      "step": 31800
    },
    {
      "epoch": 0.6564224973892288,
      "grad_norm": 1.7930762767791748,
      "learning_rate": 2.3439789283068567e-05,
      "loss": 0.2002,
      "step": 31900
    },
    {
      "epoch": 0.6584802481647435,
      "grad_norm": 4.533722400665283,
      "learning_rate": 2.3419211457733147e-05,
      "loss": 0.1963,
      "step": 32000
    },
    {
      "epoch": 0.6605379989402583,
      "grad_norm": 1.7864103317260742,
      "learning_rate": 2.339863363239773e-05,
      "loss": 0.1941,
      "step": 32100
    },
    {
      "epoch": 0.6625957497157732,
      "grad_norm": 1.0857921838760376,
      "learning_rate": 2.3378055807062312e-05,
      "loss": 0.1974,
      "step": 32200
    },
    {
      "epoch": 0.664653500491288,
      "grad_norm": 2.6491527557373047,
      "learning_rate": 2.335747798172689e-05,
      "loss": 0.1971,
      "step": 32300
    },
    {
      "epoch": 0.6667112512668029,
      "grad_norm": 2.1068227291107178,
      "learning_rate": 2.3336900156391474e-05,
      "loss": 0.1777,
      "step": 32400
    },
    {
      "epoch": 0.6687690020423176,
      "grad_norm": 4.685959339141846,
      "learning_rate": 2.3316322331056054e-05,
      "loss": 0.1653,
      "step": 32500
    },
    {
      "epoch": 0.6708267528178324,
      "grad_norm": 3.2948262691497803,
      "learning_rate": 2.3295744505720637e-05,
      "loss": 0.1929,
      "step": 32600
    },
    {
      "epoch": 0.6728845035933473,
      "grad_norm": 0.30863863229751587,
      "learning_rate": 2.3275372458638574e-05,
      "loss": 0.1905,
      "step": 32700
    },
    {
      "epoch": 0.6749422543688621,
      "grad_norm": 1.8940277099609375,
      "learning_rate": 2.3254794633303153e-05,
      "loss": 0.1686,
      "step": 32800
    },
    {
      "epoch": 0.677000005144377,
      "grad_norm": 5.256535053253174,
      "learning_rate": 2.3234216807967736e-05,
      "loss": 0.1979,
      "step": 32900
    },
    {
      "epoch": 0.6790577559198918,
      "grad_norm": 2.171840190887451,
      "learning_rate": 2.3213638982632315e-05,
      "loss": 0.1874,
      "step": 33000
    },
    {
      "epoch": 0.6811155066954065,
      "grad_norm": 2.288583755493164,
      "learning_rate": 2.3193061157296898e-05,
      "loss": 0.1802,
      "step": 33100
    },
    {
      "epoch": 0.6831732574709214,
      "grad_norm": 2.159882068634033,
      "learning_rate": 2.317248333196148e-05,
      "loss": 0.1689,
      "step": 33200
    },
    {
      "epoch": 0.6852310082464362,
      "grad_norm": 1.3569201231002808,
      "learning_rate": 2.315190550662606e-05,
      "loss": 0.1883,
      "step": 33300
    },
    {
      "epoch": 0.6872887590219511,
      "grad_norm": 4.013789176940918,
      "learning_rate": 2.3131327681290643e-05,
      "loss": 0.1788,
      "step": 33400
    },
    {
      "epoch": 0.6893465097974659,
      "grad_norm": 2.1840696334838867,
      "learning_rate": 2.3110749855955223e-05,
      "loss": 0.1954,
      "step": 33500
    },
    {
      "epoch": 0.6914042605729807,
      "grad_norm": 1.8045395612716675,
      "learning_rate": 2.3090172030619805e-05,
      "loss": 0.1899,
      "step": 33600
    },
    {
      "epoch": 0.6934620113484955,
      "grad_norm": 3.377393960952759,
      "learning_rate": 2.3069594205284388e-05,
      "loss": 0.1689,
      "step": 33700
    },
    {
      "epoch": 0.6955197621240103,
      "grad_norm": 3.1132349967956543,
      "learning_rate": 2.3049016379948968e-05,
      "loss": 0.2,
      "step": 33800
    },
    {
      "epoch": 0.6975775128995252,
      "grad_norm": 3.1502904891967773,
      "learning_rate": 2.302843855461355e-05,
      "loss": 0.2,
      "step": 33900
    },
    {
      "epoch": 0.69963526367504,
      "grad_norm": 2.702005386352539,
      "learning_rate": 2.300786072927813e-05,
      "loss": 0.1904,
      "step": 34000
    },
    {
      "epoch": 0.7016930144505549,
      "grad_norm": 2.2679009437561035,
      "learning_rate": 2.2987282903942713e-05,
      "loss": 0.177,
      "step": 34100
    },
    {
      "epoch": 0.7037507652260696,
      "grad_norm": 5.146179676055908,
      "learning_rate": 2.2966705078607292e-05,
      "loss": 0.1861,
      "step": 34200
    },
    {
      "epoch": 0.7058085160015845,
      "grad_norm": 3.844367504119873,
      "learning_rate": 2.2946127253271875e-05,
      "loss": 0.2022,
      "step": 34300
    },
    {
      "epoch": 0.7078662667770993,
      "grad_norm": 4.445619106292725,
      "learning_rate": 2.2925549427936458e-05,
      "loss": 0.1889,
      "step": 34400
    },
    {
      "epoch": 0.7099240175526141,
      "grad_norm": 2.905644655227661,
      "learning_rate": 2.2904971602601037e-05,
      "loss": 0.1944,
      "step": 34500
    },
    {
      "epoch": 0.711981768328129,
      "grad_norm": 3.1258187294006348,
      "learning_rate": 2.288439377726562e-05,
      "loss": 0.1923,
      "step": 34600
    },
    {
      "epoch": 0.7140395191036437,
      "grad_norm": 4.395269870758057,
      "learning_rate": 2.2864021730183557e-05,
      "loss": 0.1789,
      "step": 34700
    },
    {
      "epoch": 0.7160972698791586,
      "grad_norm": 3.3399899005889893,
      "learning_rate": 2.2843443904848136e-05,
      "loss": 0.1812,
      "step": 34800
    },
    {
      "epoch": 0.7181550206546734,
      "grad_norm": 3.9489707946777344,
      "learning_rate": 2.282286607951272e-05,
      "loss": 0.1858,
      "step": 34900
    },
    {
      "epoch": 0.7202127714301882,
      "grad_norm": 2.3481502532958984,
      "learning_rate": 2.28022882541773e-05,
      "loss": 0.2024,
      "step": 35000
    },
    {
      "epoch": 0.7222705222057031,
      "grad_norm": 2.2289247512817383,
      "learning_rate": 2.278171042884188e-05,
      "loss": 0.1991,
      "step": 35100
    },
    {
      "epoch": 0.7243282729812178,
      "grad_norm": 2.960649251937866,
      "learning_rate": 2.276113260350646e-05,
      "loss": 0.1881,
      "step": 35200
    },
    {
      "epoch": 0.7263860237567327,
      "grad_norm": 4.874574661254883,
      "learning_rate": 2.2740554778171044e-05,
      "loss": 0.1897,
      "step": 35300
    },
    {
      "epoch": 0.7284437745322475,
      "grad_norm": 3.220625638961792,
      "learning_rate": 2.2719976952835626e-05,
      "loss": 0.1943,
      "step": 35400
    },
    {
      "epoch": 0.7305015253077624,
      "grad_norm": 2.791870355606079,
      "learning_rate": 2.2699399127500206e-05,
      "loss": 0.1995,
      "step": 35500
    },
    {
      "epoch": 0.7325592760832772,
      "grad_norm": 1.4708760976791382,
      "learning_rate": 2.267882130216479e-05,
      "loss": 0.1949,
      "step": 35600
    },
    {
      "epoch": 0.734617026858792,
      "grad_norm": 5.8809685707092285,
      "learning_rate": 2.2658243476829368e-05,
      "loss": 0.1709,
      "step": 35700
    },
    {
      "epoch": 0.7366747776343068,
      "grad_norm": 2.9118881225585938,
      "learning_rate": 2.263766565149395e-05,
      "loss": 0.171,
      "step": 35800
    },
    {
      "epoch": 0.7387325284098216,
      "grad_norm": 1.4308161735534668,
      "learning_rate": 2.2617087826158534e-05,
      "loss": 0.2003,
      "step": 35900
    },
    {
      "epoch": 0.7407902791853365,
      "grad_norm": 3.084150552749634,
      "learning_rate": 2.2596510000823113e-05,
      "loss": 0.1791,
      "step": 36000
    },
    {
      "epoch": 0.7428480299608513,
      "grad_norm": 1.0734997987747192,
      "learning_rate": 2.2575932175487696e-05,
      "loss": 0.1722,
      "step": 36100
    },
    {
      "epoch": 0.7449057807363662,
      "grad_norm": 1.4397586584091187,
      "learning_rate": 2.2555354350152275e-05,
      "loss": 0.187,
      "step": 36200
    },
    {
      "epoch": 0.7469635315118809,
      "grad_norm": 2.6129038333892822,
      "learning_rate": 2.2534776524816858e-05,
      "loss": 0.1869,
      "step": 36300
    },
    {
      "epoch": 0.7490212822873957,
      "grad_norm": 0.4226629436016083,
      "learning_rate": 2.251419869948144e-05,
      "loss": 0.1891,
      "step": 36400
    },
    {
      "epoch": 0.7510790330629106,
      "grad_norm": 5.191504955291748,
      "learning_rate": 2.249362087414602e-05,
      "loss": 0.1942,
      "step": 36500
    },
    {
      "epoch": 0.7531367838384254,
      "grad_norm": 3.0827736854553223,
      "learning_rate": 2.2473043048810603e-05,
      "loss": 0.1928,
      "step": 36600
    },
    {
      "epoch": 0.7551945346139403,
      "grad_norm": 2.6052286624908447,
      "learning_rate": 2.2452671001728537e-05,
      "loss": 0.1803,
      "step": 36700
    },
    {
      "epoch": 0.7572522853894551,
      "grad_norm": 7.198373317718506,
      "learning_rate": 2.243209317639312e-05,
      "loss": 0.1797,
      "step": 36800
    },
    {
      "epoch": 0.7593100361649698,
      "grad_norm": 3.0979087352752686,
      "learning_rate": 2.2411515351057702e-05,
      "loss": 0.1937,
      "step": 36900
    },
    {
      "epoch": 0.7613677869404847,
      "grad_norm": 3.9381189346313477,
      "learning_rate": 2.2390937525722282e-05,
      "loss": 0.2019,
      "step": 37000
    },
    {
      "epoch": 0.7634255377159995,
      "grad_norm": 2.4941604137420654,
      "learning_rate": 2.2370359700386865e-05,
      "loss": 0.1841,
      "step": 37100
    },
    {
      "epoch": 0.7654832884915144,
      "grad_norm": 2.06943416595459,
      "learning_rate": 2.2349781875051444e-05,
      "loss": 0.2149,
      "step": 37200
    },
    {
      "epoch": 0.7675410392670292,
      "grad_norm": 3.3194661140441895,
      "learning_rate": 2.2329204049716027e-05,
      "loss": 0.19,
      "step": 37300
    },
    {
      "epoch": 0.769598790042544,
      "grad_norm": 2.6052722930908203,
      "learning_rate": 2.230862622438061e-05,
      "loss": 0.1719,
      "step": 37400
    },
    {
      "epoch": 0.7716565408180588,
      "grad_norm": 2.812450885772705,
      "learning_rate": 2.228804839904519e-05,
      "loss": 0.1846,
      "step": 37500
    },
    {
      "epoch": 0.7737142915935736,
      "grad_norm": 6.511944770812988,
      "learning_rate": 2.2267470573709772e-05,
      "loss": 0.2006,
      "step": 37600
    },
    {
      "epoch": 0.7757720423690885,
      "grad_norm": 0.8022149801254272,
      "learning_rate": 2.224689274837435e-05,
      "loss": 0.1864,
      "step": 37700
    },
    {
      "epoch": 0.7778297931446033,
      "grad_norm": 2.1930387020111084,
      "learning_rate": 2.2226314923038934e-05,
      "loss": 0.1953,
      "step": 37800
    },
    {
      "epoch": 0.7798875439201182,
      "grad_norm": 1.641904354095459,
      "learning_rate": 2.2205737097703517e-05,
      "loss": 0.1961,
      "step": 37900
    },
    {
      "epoch": 0.7819452946956329,
      "grad_norm": 3.6019482612609863,
      "learning_rate": 2.2185159272368096e-05,
      "loss": 0.1856,
      "step": 38000
    },
    {
      "epoch": 0.7840030454711477,
      "grad_norm": 4.537036895751953,
      "learning_rate": 2.216458144703268e-05,
      "loss": 0.1926,
      "step": 38100
    },
    {
      "epoch": 0.7860607962466626,
      "grad_norm": 12.189424514770508,
      "learning_rate": 2.214400362169726e-05,
      "loss": 0.1749,
      "step": 38200
    },
    {
      "epoch": 0.7881185470221774,
      "grad_norm": 0.7881425619125366,
      "learning_rate": 2.212342579636184e-05,
      "loss": 0.1898,
      "step": 38300
    },
    {
      "epoch": 0.7901762977976923,
      "grad_norm": 2.285583257675171,
      "learning_rate": 2.210284797102642e-05,
      "loss": 0.1808,
      "step": 38400
    },
    {
      "epoch": 0.792234048573207,
      "grad_norm": 4.006258964538574,
      "learning_rate": 2.2082270145691003e-05,
      "loss": 0.174,
      "step": 38500
    },
    {
      "epoch": 0.7942917993487218,
      "grad_norm": 3.4298081398010254,
      "learning_rate": 2.2061692320355586e-05,
      "loss": 0.2106,
      "step": 38600
    },
    {
      "epoch": 0.7963495501242367,
      "grad_norm": 2.7874186038970947,
      "learning_rate": 2.2041114495020166e-05,
      "loss": 0.1829,
      "step": 38700
    },
    {
      "epoch": 0.7984073008997515,
      "grad_norm": 2.282886028289795,
      "learning_rate": 2.2020742447938103e-05,
      "loss": 0.1798,
      "step": 38800
    },
    {
      "epoch": 0.8004650516752664,
      "grad_norm": 1.9901652336120605,
      "learning_rate": 2.2000164622602686e-05,
      "loss": 0.1823,
      "step": 38900
    },
    {
      "epoch": 0.8025228024507812,
      "grad_norm": 0.7812921404838562,
      "learning_rate": 2.1979586797267265e-05,
      "loss": 0.1791,
      "step": 39000
    },
    {
      "epoch": 0.804580553226296,
      "grad_norm": 0.8915594816207886,
      "learning_rate": 2.1959008971931848e-05,
      "loss": 0.1992,
      "step": 39100
    },
    {
      "epoch": 0.8066383040018108,
      "grad_norm": 1.719951868057251,
      "learning_rate": 2.1938431146596427e-05,
      "loss": 0.189,
      "step": 39200
    },
    {
      "epoch": 0.8086960547773256,
      "grad_norm": 1.4967879056930542,
      "learning_rate": 2.191785332126101e-05,
      "loss": 0.1744,
      "step": 39300
    },
    {
      "epoch": 0.8107538055528405,
      "grad_norm": 3.05924916267395,
      "learning_rate": 2.1897275495925593e-05,
      "loss": 0.1811,
      "step": 39400
    },
    {
      "epoch": 0.8128115563283553,
      "grad_norm": 3.903557300567627,
      "learning_rate": 2.1876697670590172e-05,
      "loss": 0.1978,
      "step": 39500
    },
    {
      "epoch": 0.8148693071038701,
      "grad_norm": 1.5858086347579956,
      "learning_rate": 2.1856119845254755e-05,
      "loss": 0.2078,
      "step": 39600
    },
    {
      "epoch": 0.8169270578793849,
      "grad_norm": 2.464062213897705,
      "learning_rate": 2.1835542019919334e-05,
      "loss": 0.2072,
      "step": 39700
    },
    {
      "epoch": 0.8189848086548998,
      "grad_norm": 2.265120029449463,
      "learning_rate": 2.1814964194583917e-05,
      "loss": 0.1835,
      "step": 39800
    },
    {
      "epoch": 0.8210425594304146,
      "grad_norm": 3.355455160140991,
      "learning_rate": 2.1794386369248497e-05,
      "loss": 0.2069,
      "step": 39900
    },
    {
      "epoch": 0.8231003102059294,
      "grad_norm": 3.0329861640930176,
      "learning_rate": 2.177380854391308e-05,
      "loss": 0.182,
      "step": 40000
    },
    {
      "epoch": 0.8231003102059294,
      "eval_accuracy": 0.8286659877800407,
      "eval_f1_contradiction": 0.8381171067738232,
      "eval_loss": 0.1572066694498062,
      "eval_runtime": 75.3771,
      "eval_samples_per_second": 52.111,
      "eval_steps_per_second": 6.514,
      "step": 40000
    },
    {
      "epoch": 0.8251580609814443,
      "grad_norm": 2.0215835571289062,
      "learning_rate": 2.1753230718577662e-05,
      "loss": 0.1904,
      "step": 40100
    },
    {
      "epoch": 0.827215811756959,
      "grad_norm": 3.7577667236328125,
      "learning_rate": 2.173265289324224e-05,
      "loss": 0.1759,
      "step": 40200
    },
    {
      "epoch": 0.8292735625324739,
      "grad_norm": 1.5687172412872314,
      "learning_rate": 2.1712075067906824e-05,
      "loss": 0.1889,
      "step": 40300
    },
    {
      "epoch": 0.8313313133079887,
      "grad_norm": 0.7457268238067627,
      "learning_rate": 2.1691497242571404e-05,
      "loss": 0.1954,
      "step": 40400
    },
    {
      "epoch": 0.8333890640835036,
      "grad_norm": 1.9528080224990845,
      "learning_rate": 2.1670919417235987e-05,
      "loss": 0.203,
      "step": 40500
    },
    {
      "epoch": 0.8354468148590184,
      "grad_norm": 4.436086654663086,
      "learning_rate": 2.165034159190057e-05,
      "loss": 0.1887,
      "step": 40600
    },
    {
      "epoch": 0.8375045656345331,
      "grad_norm": 3.936619520187378,
      "learning_rate": 2.162976376656515e-05,
      "loss": 0.1661,
      "step": 40700
    },
    {
      "epoch": 0.839562316410048,
      "grad_norm": 2.707706928253174,
      "learning_rate": 2.1609391719483086e-05,
      "loss": 0.2068,
      "step": 40800
    },
    {
      "epoch": 0.8416200671855628,
      "grad_norm": 1.365237832069397,
      "learning_rate": 2.1588813894147665e-05,
      "loss": 0.1872,
      "step": 40900
    },
    {
      "epoch": 0.8436778179610777,
      "grad_norm": 2.698730707168579,
      "learning_rate": 2.1568236068812248e-05,
      "loss": 0.204,
      "step": 41000
    },
    {
      "epoch": 0.8457355687365925,
      "grad_norm": 2.767209053039551,
      "learning_rate": 2.154765824347683e-05,
      "loss": 0.1962,
      "step": 41100
    },
    {
      "epoch": 0.8477933195121073,
      "grad_norm": 3.3945791721343994,
      "learning_rate": 2.152708041814141e-05,
      "loss": 0.1709,
      "step": 41200
    },
    {
      "epoch": 0.8498510702876221,
      "grad_norm": 2.924196243286133,
      "learning_rate": 2.1506502592805993e-05,
      "loss": 0.1922,
      "step": 41300
    },
    {
      "epoch": 0.8519088210631369,
      "grad_norm": 1.6068767309188843,
      "learning_rate": 2.1485924767470573e-05,
      "loss": 0.1705,
      "step": 41400
    },
    {
      "epoch": 0.8539665718386518,
      "grad_norm": 3.0608572959899902,
      "learning_rate": 2.1465346942135155e-05,
      "loss": 0.1703,
      "step": 41500
    },
    {
      "epoch": 0.8560243226141666,
      "grad_norm": 3.0453040599823,
      "learning_rate": 2.1444769116799738e-05,
      "loss": 0.1919,
      "step": 41600
    },
    {
      "epoch": 0.8580820733896815,
      "grad_norm": 4.5914788246154785,
      "learning_rate": 2.1424191291464318e-05,
      "loss": 0.1763,
      "step": 41700
    },
    {
      "epoch": 0.8601398241651962,
      "grad_norm": 2.08541202545166,
      "learning_rate": 2.14036134661289e-05,
      "loss": 0.2084,
      "step": 41800
    },
    {
      "epoch": 0.862197574940711,
      "grad_norm": 1.158259630203247,
      "learning_rate": 2.138303564079348e-05,
      "loss": 0.2103,
      "step": 41900
    },
    {
      "epoch": 0.8642553257162259,
      "grad_norm": 1.8865814208984375,
      "learning_rate": 2.1362457815458063e-05,
      "loss": 0.1821,
      "step": 42000
    },
    {
      "epoch": 0.8663130764917407,
      "grad_norm": 1.919177532196045,
      "learning_rate": 2.1341879990122646e-05,
      "loss": 0.1964,
      "step": 42100
    },
    {
      "epoch": 0.8683708272672556,
      "grad_norm": 2.148803472518921,
      "learning_rate": 2.1321302164787225e-05,
      "loss": 0.1705,
      "step": 42200
    },
    {
      "epoch": 0.8704285780427703,
      "grad_norm": 1.6986349821090698,
      "learning_rate": 2.1300724339451808e-05,
      "loss": 0.1752,
      "step": 42300
    },
    {
      "epoch": 0.8724863288182851,
      "grad_norm": 4.177494049072266,
      "learning_rate": 2.1280146514116387e-05,
      "loss": 0.1682,
      "step": 42400
    },
    {
      "epoch": 0.8745440795938,
      "grad_norm": 1.4616743326187134,
      "learning_rate": 2.125956868878097e-05,
      "loss": 0.1773,
      "step": 42500
    },
    {
      "epoch": 0.8766018303693148,
      "grad_norm": 2.615098714828491,
      "learning_rate": 2.1238990863445553e-05,
      "loss": 0.1825,
      "step": 42600
    },
    {
      "epoch": 0.8786595811448297,
      "grad_norm": 2.614208459854126,
      "learning_rate": 2.1218413038110132e-05,
      "loss": 0.1975,
      "step": 42700
    },
    {
      "epoch": 0.8807173319203445,
      "grad_norm": 2.312068462371826,
      "learning_rate": 2.1197835212774715e-05,
      "loss": 0.1665,
      "step": 42800
    },
    {
      "epoch": 0.8827750826958592,
      "grad_norm": 3.7855100631713867,
      "learning_rate": 2.117746316569265e-05,
      "loss": 0.1909,
      "step": 42900
    },
    {
      "epoch": 0.8848328334713741,
      "grad_norm": 4.700412750244141,
      "learning_rate": 2.115688534035723e-05,
      "loss": 0.1751,
      "step": 43000
    },
    {
      "epoch": 0.8868905842468889,
      "grad_norm": 3.690661668777466,
      "learning_rate": 2.1136307515021814e-05,
      "loss": 0.1806,
      "step": 43100
    },
    {
      "epoch": 0.8889483350224038,
      "grad_norm": 2.2968451976776123,
      "learning_rate": 2.1115729689686394e-05,
      "loss": 0.1898,
      "step": 43200
    },
    {
      "epoch": 0.8910060857979186,
      "grad_norm": 4.080636501312256,
      "learning_rate": 2.1095151864350977e-05,
      "loss": 0.1919,
      "step": 43300
    },
    {
      "epoch": 0.8930638365734334,
      "grad_norm": 1.7839082479476929,
      "learning_rate": 2.1074574039015556e-05,
      "loss": 0.1825,
      "step": 43400
    },
    {
      "epoch": 0.8951215873489482,
      "grad_norm": 5.0682525634765625,
      "learning_rate": 2.105399621368014e-05,
      "loss": 0.1534,
      "step": 43500
    },
    {
      "epoch": 0.897179338124463,
      "grad_norm": 5.787235736846924,
      "learning_rate": 2.103341838834472e-05,
      "loss": 0.1801,
      "step": 43600
    },
    {
      "epoch": 0.8992370888999779,
      "grad_norm": 2.682523012161255,
      "learning_rate": 2.10128405630093e-05,
      "loss": 0.1744,
      "step": 43700
    },
    {
      "epoch": 0.9012948396754927,
      "grad_norm": 1.9958289861679077,
      "learning_rate": 2.0992262737673884e-05,
      "loss": 0.1853,
      "step": 43800
    },
    {
      "epoch": 0.9033525904510076,
      "grad_norm": 5.747924327850342,
      "learning_rate": 2.0971684912338463e-05,
      "loss": 0.1869,
      "step": 43900
    },
    {
      "epoch": 0.9054103412265223,
      "grad_norm": 3.2669477462768555,
      "learning_rate": 2.0951107087003046e-05,
      "loss": 0.1924,
      "step": 44000
    },
    {
      "epoch": 0.9074680920020372,
      "grad_norm": 1.1780214309692383,
      "learning_rate": 2.093052926166763e-05,
      "loss": 0.1828,
      "step": 44100
    },
    {
      "epoch": 0.909525842777552,
      "grad_norm": 4.275105953216553,
      "learning_rate": 2.0909951436332208e-05,
      "loss": 0.21,
      "step": 44200
    },
    {
      "epoch": 0.9115835935530668,
      "grad_norm": 4.029910087585449,
      "learning_rate": 2.088937361099679e-05,
      "loss": 0.1907,
      "step": 44300
    },
    {
      "epoch": 0.9136413443285817,
      "grad_norm": 2.0021936893463135,
      "learning_rate": 2.086879578566137e-05,
      "loss": 0.1998,
      "step": 44400
    },
    {
      "epoch": 0.9156990951040964,
      "grad_norm": 3.1613831520080566,
      "learning_rate": 2.0848217960325953e-05,
      "loss": 0.1658,
      "step": 44500
    },
    {
      "epoch": 0.9177568458796113,
      "grad_norm": 1.5240346193313599,
      "learning_rate": 2.0827640134990533e-05,
      "loss": 0.1952,
      "step": 44600
    },
    {
      "epoch": 0.9198145966551261,
      "grad_norm": 4.200692653656006,
      "learning_rate": 2.0807062309655115e-05,
      "loss": 0.1862,
      "step": 44700
    },
    {
      "epoch": 0.921872347430641,
      "grad_norm": 1.1474950313568115,
      "learning_rate": 2.0786484484319698e-05,
      "loss": 0.1802,
      "step": 44800
    },
    {
      "epoch": 0.9239300982061558,
      "grad_norm": 1.9140337705612183,
      "learning_rate": 2.0766112437237632e-05,
      "loss": 0.1983,
      "step": 44900
    },
    {
      "epoch": 0.9259878489816706,
      "grad_norm": 2.6268317699432373,
      "learning_rate": 2.0745534611902215e-05,
      "loss": 0.1791,
      "step": 45000
    },
    {
      "epoch": 0.9280455997571854,
      "grad_norm": 2.1867947578430176,
      "learning_rate": 2.0724956786566798e-05,
      "loss": 0.1946,
      "step": 45100
    },
    {
      "epoch": 0.9301033505327002,
      "grad_norm": 2.3214473724365234,
      "learning_rate": 2.0704378961231377e-05,
      "loss": 0.1811,
      "step": 45200
    },
    {
      "epoch": 0.9321611013082151,
      "grad_norm": 6.683265686035156,
      "learning_rate": 2.068380113589596e-05,
      "loss": 0.1604,
      "step": 45300
    },
    {
      "epoch": 0.9342188520837299,
      "grad_norm": 2.901439905166626,
      "learning_rate": 2.066322331056054e-05,
      "loss": 0.1927,
      "step": 45400
    },
    {
      "epoch": 0.9362766028592447,
      "grad_norm": 0.5114686489105225,
      "learning_rate": 2.0642645485225122e-05,
      "loss": 0.1783,
      "step": 45500
    },
    {
      "epoch": 0.9383343536347595,
      "grad_norm": 6.195287704467773,
      "learning_rate": 2.06220676598897e-05,
      "loss": 0.1679,
      "step": 45600
    },
    {
      "epoch": 0.9403921044102743,
      "grad_norm": 2.0955147743225098,
      "learning_rate": 2.0601489834554284e-05,
      "loss": 0.1936,
      "step": 45700
    },
    {
      "epoch": 0.9424498551857892,
      "grad_norm": 2.407975673675537,
      "learning_rate": 2.0580912009218867e-05,
      "loss": 0.1815,
      "step": 45800
    },
    {
      "epoch": 0.944507605961304,
      "grad_norm": 3.893747329711914,
      "learning_rate": 2.0560334183883446e-05,
      "loss": 0.2034,
      "step": 45900
    },
    {
      "epoch": 0.9465653567368189,
      "grad_norm": 2.5659711360931396,
      "learning_rate": 2.053975635854803e-05,
      "loss": 0.2151,
      "step": 46000
    },
    {
      "epoch": 0.9486231075123337,
      "grad_norm": 3.005122184753418,
      "learning_rate": 2.051917853321261e-05,
      "loss": 0.152,
      "step": 46100
    },
    {
      "epoch": 0.9506808582878484,
      "grad_norm": 4.093658924102783,
      "learning_rate": 2.049860070787719e-05,
      "loss": 0.2029,
      "step": 46200
    },
    {
      "epoch": 0.9527386090633633,
      "grad_norm": 1.8591582775115967,
      "learning_rate": 2.0478022882541774e-05,
      "loss": 0.1804,
      "step": 46300
    },
    {
      "epoch": 0.9547963598388781,
      "grad_norm": 2.6086339950561523,
      "learning_rate": 2.0457445057206354e-05,
      "loss": 0.1875,
      "step": 46400
    },
    {
      "epoch": 0.956854110614393,
      "grad_norm": 1.8631991147994995,
      "learning_rate": 2.0436867231870936e-05,
      "loss": 0.1796,
      "step": 46500
    },
    {
      "epoch": 0.9589118613899078,
      "grad_norm": 2.530219554901123,
      "learning_rate": 2.0416289406535516e-05,
      "loss": 0.1929,
      "step": 46600
    },
    {
      "epoch": 0.9609696121654225,
      "grad_norm": 4.178151607513428,
      "learning_rate": 2.03957115812001e-05,
      "loss": 0.1895,
      "step": 46700
    },
    {
      "epoch": 0.9630273629409374,
      "grad_norm": 1.9944968223571777,
      "learning_rate": 2.037513375586468e-05,
      "loss": 0.1906,
      "step": 46800
    },
    {
      "epoch": 0.9650851137164522,
      "grad_norm": 1.6906403303146362,
      "learning_rate": 2.0354761708782615e-05,
      "loss": 0.1853,
      "step": 46900
    },
    {
      "epoch": 0.9671428644919671,
      "grad_norm": 2.5012271404266357,
      "learning_rate": 2.0334183883447198e-05,
      "loss": 0.1767,
      "step": 47000
    },
    {
      "epoch": 0.9692006152674819,
      "grad_norm": 3.470604658126831,
      "learning_rate": 2.0313606058111777e-05,
      "loss": 0.1859,
      "step": 47100
    },
    {
      "epoch": 0.9712583660429968,
      "grad_norm": 3.762369155883789,
      "learning_rate": 2.029302823277636e-05,
      "loss": 0.1754,
      "step": 47200
    },
    {
      "epoch": 0.9733161168185115,
      "grad_norm": 1.6836191415786743,
      "learning_rate": 2.0272450407440943e-05,
      "loss": 0.2162,
      "step": 47300
    },
    {
      "epoch": 0.9753738675940263,
      "grad_norm": 1.370842695236206,
      "learning_rate": 2.0251872582105522e-05,
      "loss": 0.1779,
      "step": 47400
    },
    {
      "epoch": 0.9774316183695412,
      "grad_norm": 1.4005948305130005,
      "learning_rate": 2.0231294756770105e-05,
      "loss": 0.1837,
      "step": 47500
    },
    {
      "epoch": 0.979489369145056,
      "grad_norm": 1.359546422958374,
      "learning_rate": 2.0210716931434685e-05,
      "loss": 0.2033,
      "step": 47600
    },
    {
      "epoch": 0.9815471199205709,
      "grad_norm": 1.9664795398712158,
      "learning_rate": 2.0190139106099267e-05,
      "loss": 0.1619,
      "step": 47700
    },
    {
      "epoch": 0.9836048706960856,
      "grad_norm": 2.027801752090454,
      "learning_rate": 2.016956128076385e-05,
      "loss": 0.168,
      "step": 47800
    },
    {
      "epoch": 0.9856626214716004,
      "grad_norm": 3.2193140983581543,
      "learning_rate": 2.014898345542843e-05,
      "loss": 0.177,
      "step": 47900
    },
    {
      "epoch": 0.9877203722471153,
      "grad_norm": 1.9492968320846558,
      "learning_rate": 2.0128405630093012e-05,
      "loss": 0.1845,
      "step": 48000
    },
    {
      "epoch": 0.9897781230226301,
      "grad_norm": 0.22153137624263763,
      "learning_rate": 2.0107827804757592e-05,
      "loss": 0.1911,
      "step": 48100
    },
    {
      "epoch": 0.991835873798145,
      "grad_norm": 3.1331000328063965,
      "learning_rate": 2.0087249979422175e-05,
      "loss": 0.1787,
      "step": 48200
    },
    {
      "epoch": 0.9938936245736597,
      "grad_norm": 2.152242660522461,
      "learning_rate": 2.0066672154086757e-05,
      "loss": 0.187,
      "step": 48300
    },
    {
      "epoch": 0.9959513753491746,
      "grad_norm": 3.1611826419830322,
      "learning_rate": 2.0046094328751337e-05,
      "loss": 0.2037,
      "step": 48400
    },
    {
      "epoch": 0.9980091261246894,
      "grad_norm": 0.4129592776298523,
      "learning_rate": 2.002551650341592e-05,
      "loss": 0.1883,
      "step": 48500
    },
    {
      "epoch": 1.0000823100310205,
      "grad_norm": 0.7609781622886658,
      "learning_rate": 2.00049386780805e-05,
      "loss": 0.2006,
      "step": 48600
    },
    {
      "epoch": 1.0021400608065354,
      "grad_norm": 1.2998641729354858,
      "learning_rate": 1.9984360852745082e-05,
      "loss": 0.1699,
      "step": 48700
    },
    {
      "epoch": 1.0041978115820502,
      "grad_norm": 0.9601739048957825,
      "learning_rate": 1.996378302740966e-05,
      "loss": 0.1673,
      "step": 48800
    },
    {
      "epoch": 1.006255562357565,
      "grad_norm": 3.018451690673828,
      "learning_rate": 1.99434109803276e-05,
      "loss": 0.1664,
      "step": 48900
    },
    {
      "epoch": 1.00831331313308,
      "grad_norm": 2.5118160247802734,
      "learning_rate": 1.992283315499218e-05,
      "loss": 0.1924,
      "step": 49000
    },
    {
      "epoch": 1.0103710639085948,
      "grad_norm": 3.1495015621185303,
      "learning_rate": 1.990225532965676e-05,
      "loss": 0.1699,
      "step": 49100
    },
    {
      "epoch": 1.0124288146841096,
      "grad_norm": 2.0993194580078125,
      "learning_rate": 1.9881677504321343e-05,
      "loss": 0.195,
      "step": 49200
    },
    {
      "epoch": 1.0144865654596245,
      "grad_norm": 3.294973373413086,
      "learning_rate": 1.9861099678985926e-05,
      "loss": 0.1945,
      "step": 49300
    },
    {
      "epoch": 1.016544316235139,
      "grad_norm": 4.0878586769104,
      "learning_rate": 1.9840521853650506e-05,
      "loss": 0.1753,
      "step": 49400
    },
    {
      "epoch": 1.018602067010654,
      "grad_norm": 2.5797417163848877,
      "learning_rate": 1.981994402831509e-05,
      "loss": 0.1721,
      "step": 49500
    },
    {
      "epoch": 1.0206598177861688,
      "grad_norm": 9.595009803771973,
      "learning_rate": 1.9799366202979668e-05,
      "loss": 0.1668,
      "step": 49600
    },
    {
      "epoch": 1.0227175685616836,
      "grad_norm": 2.8922383785247803,
      "learning_rate": 1.977878837764425e-05,
      "loss": 0.1825,
      "step": 49700
    },
    {
      "epoch": 1.0247753193371985,
      "grad_norm": 1.6864434480667114,
      "learning_rate": 1.9758210552308833e-05,
      "loss": 0.1712,
      "step": 49800
    },
    {
      "epoch": 1.0268330701127133,
      "grad_norm": 5.90278434753418,
      "learning_rate": 1.9737632726973413e-05,
      "loss": 0.1631,
      "step": 49900
    },
    {
      "epoch": 1.0288908208882281,
      "grad_norm": 4.7954325675964355,
      "learning_rate": 1.9717054901637996e-05,
      "loss": 0.1714,
      "step": 50000
    },
    {
      "epoch": 1.0288908208882281,
      "eval_accuracy": 0.8279022403258656,
      "eval_f1_contradiction": 0.829992576095026,
      "eval_loss": 0.16582587361335754,
      "eval_runtime": 72.5539,
      "eval_samples_per_second": 54.139,
      "eval_steps_per_second": 6.767,
      "step": 50000
    },
    {
      "epoch": 1.030948571663743,
      "grad_norm": 3.0290780067443848,
      "learning_rate": 1.9696477076302575e-05,
      "loss": 0.208,
      "step": 50100
    },
    {
      "epoch": 1.0330063224392578,
      "grad_norm": 2.713083267211914,
      "learning_rate": 1.9675899250967158e-05,
      "loss": 0.1743,
      "step": 50200
    },
    {
      "epoch": 1.0350640732147727,
      "grad_norm": 1.7390763759613037,
      "learning_rate": 1.9655321425631737e-05,
      "loss": 0.2001,
      "step": 50300
    },
    {
      "epoch": 1.0371218239902875,
      "grad_norm": 1.9201927185058594,
      "learning_rate": 1.963474360029632e-05,
      "loss": 0.1714,
      "step": 50400
    },
    {
      "epoch": 1.0391795747658021,
      "grad_norm": 1.7777382135391235,
      "learning_rate": 1.9614165774960903e-05,
      "loss": 0.1883,
      "step": 50500
    },
    {
      "epoch": 1.041237325541317,
      "grad_norm": 2.860483169555664,
      "learning_rate": 1.9593587949625482e-05,
      "loss": 0.1912,
      "step": 50600
    },
    {
      "epoch": 1.0432950763168318,
      "grad_norm": 3.4373111724853516,
      "learning_rate": 1.9573010124290065e-05,
      "loss": 0.1812,
      "step": 50700
    },
    {
      "epoch": 1.0453528270923467,
      "grad_norm": 3.343775749206543,
      "learning_rate": 1.9552432298954645e-05,
      "loss": 0.2045,
      "step": 50800
    },
    {
      "epoch": 1.0474105778678615,
      "grad_norm": 2.9769399166107178,
      "learning_rate": 1.9531854473619227e-05,
      "loss": 0.1913,
      "step": 50900
    },
    {
      "epoch": 1.0494683286433764,
      "grad_norm": 3.7357378005981445,
      "learning_rate": 1.9511482426537164e-05,
      "loss": 0.2085,
      "step": 51000
    },
    {
      "epoch": 1.0515260794188912,
      "grad_norm": 3.512967348098755,
      "learning_rate": 1.9490904601201744e-05,
      "loss": 0.1844,
      "step": 51100
    },
    {
      "epoch": 1.053583830194406,
      "grad_norm": 4.2760329246521,
      "learning_rate": 1.9470326775866327e-05,
      "loss": 0.1671,
      "step": 51200
    },
    {
      "epoch": 1.055641580969921,
      "grad_norm": 1.4227640628814697,
      "learning_rate": 1.9449748950530906e-05,
      "loss": 0.1789,
      "step": 51300
    },
    {
      "epoch": 1.0576993317454357,
      "grad_norm": 3.195183038711548,
      "learning_rate": 1.942917112519549e-05,
      "loss": 0.174,
      "step": 51400
    },
    {
      "epoch": 1.0597570825209506,
      "grad_norm": 2.8941328525543213,
      "learning_rate": 1.940859329986007e-05,
      "loss": 0.1801,
      "step": 51500
    },
    {
      "epoch": 1.0618148332964652,
      "grad_norm": 2.569565773010254,
      "learning_rate": 1.938801547452465e-05,
      "loss": 0.1537,
      "step": 51600
    },
    {
      "epoch": 1.06387258407198,
      "grad_norm": 1.3375933170318604,
      "learning_rate": 1.9367437649189234e-05,
      "loss": 0.1729,
      "step": 51700
    },
    {
      "epoch": 1.0659303348474949,
      "grad_norm": 2.399844169616699,
      "learning_rate": 1.9346859823853813e-05,
      "loss": 0.1825,
      "step": 51800
    },
    {
      "epoch": 1.0679880856230097,
      "grad_norm": 2.6282896995544434,
      "learning_rate": 1.9326281998518396e-05,
      "loss": 0.1738,
      "step": 51900
    },
    {
      "epoch": 1.0700458363985246,
      "grad_norm": 1.3663629293441772,
      "learning_rate": 1.930570417318298e-05,
      "loss": 0.1816,
      "step": 52000
    },
    {
      "epoch": 1.0721035871740394,
      "grad_norm": 3.5727035999298096,
      "learning_rate": 1.9285126347847558e-05,
      "loss": 0.1724,
      "step": 52100
    },
    {
      "epoch": 1.0741613379495543,
      "grad_norm": 3.4098494052886963,
      "learning_rate": 1.926454852251214e-05,
      "loss": 0.1913,
      "step": 52200
    },
    {
      "epoch": 1.076219088725069,
      "grad_norm": 3.3205347061157227,
      "learning_rate": 1.924397069717672e-05,
      "loss": 0.1626,
      "step": 52300
    },
    {
      "epoch": 1.078276839500584,
      "grad_norm": 2.676621675491333,
      "learning_rate": 1.9223392871841303e-05,
      "loss": 0.1794,
      "step": 52400
    },
    {
      "epoch": 1.0803345902760988,
      "grad_norm": 2.96675181388855,
      "learning_rate": 1.9202815046505886e-05,
      "loss": 0.1764,
      "step": 52500
    },
    {
      "epoch": 1.0823923410516136,
      "grad_norm": 4.13690185546875,
      "learning_rate": 1.9182237221170466e-05,
      "loss": 0.1641,
      "step": 52600
    },
    {
      "epoch": 1.0844500918271283,
      "grad_norm": 2.7748665809631348,
      "learning_rate": 1.916165939583505e-05,
      "loss": 0.181,
      "step": 52700
    },
    {
      "epoch": 1.086507842602643,
      "grad_norm": 2.883452892303467,
      "learning_rate": 1.9141081570499628e-05,
      "loss": 0.1768,
      "step": 52800
    },
    {
      "epoch": 1.088565593378158,
      "grad_norm": 4.304203510284424,
      "learning_rate": 1.912050374516421e-05,
      "loss": 0.1754,
      "step": 52900
    },
    {
      "epoch": 1.0906233441536728,
      "grad_norm": 3.0312318801879883,
      "learning_rate": 1.9100131698082148e-05,
      "loss": 0.1585,
      "step": 53000
    },
    {
      "epoch": 1.0926810949291876,
      "grad_norm": 2.220998525619507,
      "learning_rate": 1.9079553872746727e-05,
      "loss": 0.1791,
      "step": 53100
    },
    {
      "epoch": 1.0947388457047025,
      "grad_norm": 5.075812339782715,
      "learning_rate": 1.905897604741131e-05,
      "loss": 0.1732,
      "step": 53200
    },
    {
      "epoch": 1.0967965964802173,
      "grad_norm": 3.8333842754364014,
      "learning_rate": 1.903839822207589e-05,
      "loss": 0.1679,
      "step": 53300
    },
    {
      "epoch": 1.0988543472557322,
      "grad_norm": 4.989726543426514,
      "learning_rate": 1.9017820396740472e-05,
      "loss": 0.1873,
      "step": 53400
    },
    {
      "epoch": 1.100912098031247,
      "grad_norm": 3.2562878131866455,
      "learning_rate": 1.8997242571405055e-05,
      "loss": 0.1713,
      "step": 53500
    },
    {
      "epoch": 1.1029698488067619,
      "grad_norm": 1.386557936668396,
      "learning_rate": 1.8976664746069634e-05,
      "loss": 0.1685,
      "step": 53600
    },
    {
      "epoch": 1.1050275995822765,
      "grad_norm": 1.8833873271942139,
      "learning_rate": 1.8956086920734217e-05,
      "loss": 0.188,
      "step": 53700
    },
    {
      "epoch": 1.1070853503577913,
      "grad_norm": 2.193737268447876,
      "learning_rate": 1.8935509095398797e-05,
      "loss": 0.1692,
      "step": 53800
    },
    {
      "epoch": 1.1091431011333062,
      "grad_norm": 4.5582051277160645,
      "learning_rate": 1.891493127006338e-05,
      "loss": 0.182,
      "step": 53900
    },
    {
      "epoch": 1.111200851908821,
      "grad_norm": 5.500086307525635,
      "learning_rate": 1.8894353444727962e-05,
      "loss": 0.1614,
      "step": 54000
    },
    {
      "epoch": 1.1132586026843359,
      "grad_norm": 3.124385118484497,
      "learning_rate": 1.887377561939254e-05,
      "loss": 0.1963,
      "step": 54100
    },
    {
      "epoch": 1.1153163534598507,
      "grad_norm": 2.109734296798706,
      "learning_rate": 1.8853197794057124e-05,
      "loss": 0.1802,
      "step": 54200
    },
    {
      "epoch": 1.1173741042353655,
      "grad_norm": 4.297554969787598,
      "learning_rate": 1.8832619968721704e-05,
      "loss": 0.1844,
      "step": 54300
    },
    {
      "epoch": 1.1194318550108804,
      "grad_norm": 1.2809573411941528,
      "learning_rate": 1.8812042143386287e-05,
      "loss": 0.1907,
      "step": 54400
    },
    {
      "epoch": 1.1214896057863952,
      "grad_norm": 3.0952606201171875,
      "learning_rate": 1.879146431805087e-05,
      "loss": 0.1732,
      "step": 54500
    },
    {
      "epoch": 1.12354735656191,
      "grad_norm": 2.7186174392700195,
      "learning_rate": 1.877088649271545e-05,
      "loss": 0.1726,
      "step": 54600
    },
    {
      "epoch": 1.125605107337425,
      "grad_norm": 3.0051634311676025,
      "learning_rate": 1.875030866738003e-05,
      "loss": 0.1746,
      "step": 54700
    },
    {
      "epoch": 1.1276628581129398,
      "grad_norm": 2.499004364013672,
      "learning_rate": 1.872973084204461e-05,
      "loss": 0.1902,
      "step": 54800
    },
    {
      "epoch": 1.1297206088884544,
      "grad_norm": 0.7816988229751587,
      "learning_rate": 1.8709153016709194e-05,
      "loss": 0.183,
      "step": 54900
    },
    {
      "epoch": 1.1317783596639692,
      "grad_norm": 2.170370101928711,
      "learning_rate": 1.8688575191373773e-05,
      "loss": 0.1606,
      "step": 55000
    },
    {
      "epoch": 1.133836110439484,
      "grad_norm": 2.3437325954437256,
      "learning_rate": 1.866820314429171e-05,
      "loss": 0.1978,
      "step": 55100
    },
    {
      "epoch": 1.135893861214999,
      "grad_norm": 1.29929780960083,
      "learning_rate": 1.8647625318956293e-05,
      "loss": 0.172,
      "step": 55200
    },
    {
      "epoch": 1.1379516119905138,
      "grad_norm": 3.2284841537475586,
      "learning_rate": 1.8627047493620873e-05,
      "loss": 0.1827,
      "step": 55300
    },
    {
      "epoch": 1.1400093627660286,
      "grad_norm": 2.2927887439727783,
      "learning_rate": 1.8606469668285455e-05,
      "loss": 0.1832,
      "step": 55400
    },
    {
      "epoch": 1.1420671135415434,
      "grad_norm": 1.4727160930633545,
      "learning_rate": 1.8585891842950038e-05,
      "loss": 0.2095,
      "step": 55500
    },
    {
      "epoch": 1.1441248643170583,
      "grad_norm": 2.5673344135284424,
      "learning_rate": 1.8565314017614618e-05,
      "loss": 0.1928,
      "step": 55600
    },
    {
      "epoch": 1.1461826150925731,
      "grad_norm": 1.9971256256103516,
      "learning_rate": 1.85447361922792e-05,
      "loss": 0.183,
      "step": 55700
    },
    {
      "epoch": 1.148240365868088,
      "grad_norm": 5.157988548278809,
      "learning_rate": 1.852415836694378e-05,
      "loss": 0.1897,
      "step": 55800
    },
    {
      "epoch": 1.1502981166436026,
      "grad_norm": 4.188204288482666,
      "learning_rate": 1.8503580541608363e-05,
      "loss": 0.1549,
      "step": 55900
    },
    {
      "epoch": 1.1523558674191174,
      "grad_norm": 4.394818305969238,
      "learning_rate": 1.8483002716272942e-05,
      "loss": 0.1866,
      "step": 56000
    },
    {
      "epoch": 1.1544136181946323,
      "grad_norm": 4.451461315155029,
      "learning_rate": 1.8462424890937525e-05,
      "loss": 0.1865,
      "step": 56100
    },
    {
      "epoch": 1.1564713689701471,
      "grad_norm": 3.9002974033355713,
      "learning_rate": 1.8441847065602108e-05,
      "loss": 0.1749,
      "step": 56200
    },
    {
      "epoch": 1.158529119745662,
      "grad_norm": 2.6267004013061523,
      "learning_rate": 1.8421269240266687e-05,
      "loss": 0.1974,
      "step": 56300
    },
    {
      "epoch": 1.1605868705211768,
      "grad_norm": 4.0449042320251465,
      "learning_rate": 1.840069141493127e-05,
      "loss": 0.1941,
      "step": 56400
    },
    {
      "epoch": 1.1626446212966917,
      "grad_norm": 3.83510422706604,
      "learning_rate": 1.838011358959585e-05,
      "loss": 0.1721,
      "step": 56500
    },
    {
      "epoch": 1.1647023720722065,
      "grad_norm": 3.009441375732422,
      "learning_rate": 1.8359535764260432e-05,
      "loss": 0.1863,
      "step": 56600
    },
    {
      "epoch": 1.1667601228477213,
      "grad_norm": 4.100818634033203,
      "learning_rate": 1.8338957938925015e-05,
      "loss": 0.1778,
      "step": 56700
    },
    {
      "epoch": 1.1688178736232362,
      "grad_norm": 1.920142412185669,
      "learning_rate": 1.8318380113589594e-05,
      "loss": 0.174,
      "step": 56800
    },
    {
      "epoch": 1.170875624398751,
      "grad_norm": 2.9058499336242676,
      "learning_rate": 1.8297802288254177e-05,
      "loss": 0.1868,
      "step": 56900
    },
    {
      "epoch": 1.1729333751742659,
      "grad_norm": 3.8486199378967285,
      "learning_rate": 1.8277224462918756e-05,
      "loss": 0.1766,
      "step": 57000
    },
    {
      "epoch": 1.1749911259497805,
      "grad_norm": 6.188560485839844,
      "learning_rate": 1.8256852415836694e-05,
      "loss": 0.1866,
      "step": 57100
    },
    {
      "epoch": 1.1770488767252953,
      "grad_norm": 2.5646586418151855,
      "learning_rate": 1.8236274590501276e-05,
      "loss": 0.1815,
      "step": 57200
    },
    {
      "epoch": 1.1791066275008102,
      "grad_norm": 1.920161485671997,
      "learning_rate": 1.8215696765165856e-05,
      "loss": 0.177,
      "step": 57300
    },
    {
      "epoch": 1.181164378276325,
      "grad_norm": 2.9532408714294434,
      "learning_rate": 1.819511893983044e-05,
      "loss": 0.1674,
      "step": 57400
    },
    {
      "epoch": 1.1832221290518399,
      "grad_norm": 2.8609273433685303,
      "learning_rate": 1.8174541114495018e-05,
      "loss": 0.1742,
      "step": 57500
    },
    {
      "epoch": 1.1852798798273547,
      "grad_norm": 1.003047227859497,
      "learning_rate": 1.81539632891596e-05,
      "loss": 0.169,
      "step": 57600
    },
    {
      "epoch": 1.1873376306028696,
      "grad_norm": 4.2520575523376465,
      "learning_rate": 1.8133385463824184e-05,
      "loss": 0.1733,
      "step": 57700
    },
    {
      "epoch": 1.1893953813783844,
      "grad_norm": 2.567997694015503,
      "learning_rate": 1.8112807638488763e-05,
      "loss": 0.1923,
      "step": 57800
    },
    {
      "epoch": 1.1914531321538993,
      "grad_norm": 4.732024192810059,
      "learning_rate": 1.8092229813153346e-05,
      "loss": 0.184,
      "step": 57900
    },
    {
      "epoch": 1.193510882929414,
      "grad_norm": 2.0867533683776855,
      "learning_rate": 1.8071651987817925e-05,
      "loss": 0.1862,
      "step": 58000
    },
    {
      "epoch": 1.1955686337049287,
      "grad_norm": 2.0674993991851807,
      "learning_rate": 1.8051074162482508e-05,
      "loss": 0.1837,
      "step": 58100
    },
    {
      "epoch": 1.1976263844804436,
      "grad_norm": 3.410367488861084,
      "learning_rate": 1.803049633714709e-05,
      "loss": 0.1835,
      "step": 58200
    },
    {
      "epoch": 1.1996841352559584,
      "grad_norm": 1.3297779560089111,
      "learning_rate": 1.800991851181167e-05,
      "loss": 0.1781,
      "step": 58300
    },
    {
      "epoch": 1.2017418860314732,
      "grad_norm": 1.6533513069152832,
      "learning_rate": 1.7989340686476253e-05,
      "loss": 0.1968,
      "step": 58400
    },
    {
      "epoch": 1.203799636806988,
      "grad_norm": 2.605537176132202,
      "learning_rate": 1.7968762861140832e-05,
      "loss": 0.1647,
      "step": 58500
    },
    {
      "epoch": 1.205857387582503,
      "grad_norm": 2.307032585144043,
      "learning_rate": 1.7948185035805415e-05,
      "loss": 0.1641,
      "step": 58600
    },
    {
      "epoch": 1.2079151383580178,
      "grad_norm": 2.327744245529175,
      "learning_rate": 1.7927607210469998e-05,
      "loss": 0.188,
      "step": 58700
    },
    {
      "epoch": 1.2099728891335326,
      "grad_norm": 2.081153392791748,
      "learning_rate": 1.7907029385134577e-05,
      "loss": 0.1935,
      "step": 58800
    },
    {
      "epoch": 1.2120306399090475,
      "grad_norm": 2.655611515045166,
      "learning_rate": 1.788645155979916e-05,
      "loss": 0.1879,
      "step": 58900
    },
    {
      "epoch": 1.2140883906845623,
      "grad_norm": 0.94102942943573,
      "learning_rate": 1.786587373446374e-05,
      "loss": 0.1849,
      "step": 59000
    },
    {
      "epoch": 1.2161461414600772,
      "grad_norm": 3.1353695392608643,
      "learning_rate": 1.7845501687381677e-05,
      "loss": 0.1745,
      "step": 59100
    },
    {
      "epoch": 1.218203892235592,
      "grad_norm": 4.475845813751221,
      "learning_rate": 1.782492386204626e-05,
      "loss": 0.1959,
      "step": 59200
    },
    {
      "epoch": 1.2202616430111066,
      "grad_norm": 1.9548135995864868,
      "learning_rate": 1.780434603671084e-05,
      "loss": 0.1632,
      "step": 59300
    },
    {
      "epoch": 1.2223193937866215,
      "grad_norm": 1.6510823965072632,
      "learning_rate": 1.7783768211375422e-05,
      "loss": 0.1506,
      "step": 59400
    },
    {
      "epoch": 1.2243771445621363,
      "grad_norm": 3.1697309017181396,
      "learning_rate": 1.776319038604e-05,
      "loss": 0.1884,
      "step": 59500
    },
    {
      "epoch": 1.2264348953376512,
      "grad_norm": 1.7418972253799438,
      "learning_rate": 1.7742612560704584e-05,
      "loss": 0.1613,
      "step": 59600
    },
    {
      "epoch": 1.228492646113166,
      "grad_norm": 3.068024158477783,
      "learning_rate": 1.7722034735369167e-05,
      "loss": 0.1909,
      "step": 59700
    },
    {
      "epoch": 1.2305503968886808,
      "grad_norm": 4.008087635040283,
      "learning_rate": 1.7701456910033746e-05,
      "loss": 0.1774,
      "step": 59800
    },
    {
      "epoch": 1.2326081476641957,
      "grad_norm": 4.209163188934326,
      "learning_rate": 1.768087908469833e-05,
      "loss": 0.1671,
      "step": 59900
    },
    {
      "epoch": 1.2346658984397105,
      "grad_norm": 1.8385227918624878,
      "learning_rate": 1.766030125936291e-05,
      "loss": 0.1722,
      "step": 60000
    },
    {
      "epoch": 1.2346658984397105,
      "eval_accuracy": 0.8322301425661914,
      "eval_f1_contradiction": 0.8385356454720616,
      "eval_loss": 0.15654391050338745,
      "eval_runtime": 76.2663,
      "eval_samples_per_second": 51.504,
      "eval_steps_per_second": 6.438,
      "step": 60000
    },
    {
      "epoch": 1.2367236492152254,
      "grad_norm": 6.084894180297852,
      "learning_rate": 1.763972343402749e-05,
      "loss": 0.1817,
      "step": 60100
    },
    {
      "epoch": 1.2387813999907402,
      "grad_norm": 1.2060890197753906,
      "learning_rate": 1.7619145608692074e-05,
      "loss": 0.1721,
      "step": 60200
    },
    {
      "epoch": 1.2408391507662548,
      "grad_norm": 1.2888658046722412,
      "learning_rate": 1.7598567783356653e-05,
      "loss": 0.1809,
      "step": 60300
    },
    {
      "epoch": 1.2428969015417697,
      "grad_norm": 2.4815196990966797,
      "learning_rate": 1.7577989958021236e-05,
      "loss": 0.1643,
      "step": 60400
    },
    {
      "epoch": 1.2449546523172845,
      "grad_norm": 1.1655449867248535,
      "learning_rate": 1.7557412132685816e-05,
      "loss": 0.1618,
      "step": 60500
    },
    {
      "epoch": 1.2470124030927994,
      "grad_norm": 2.7274718284606934,
      "learning_rate": 1.75368343073504e-05,
      "loss": 0.1845,
      "step": 60600
    },
    {
      "epoch": 1.2490701538683142,
      "grad_norm": 1.8182079792022705,
      "learning_rate": 1.7516256482014978e-05,
      "loss": 0.1823,
      "step": 60700
    },
    {
      "epoch": 1.251127904643829,
      "grad_norm": 1.5576728582382202,
      "learning_rate": 1.749567865667956e-05,
      "loss": 0.179,
      "step": 60800
    },
    {
      "epoch": 1.253185655419344,
      "grad_norm": 2.8995680809020996,
      "learning_rate": 1.7475100831344143e-05,
      "loss": 0.1792,
      "step": 60900
    },
    {
      "epoch": 1.2552434061948587,
      "grad_norm": 3.167677640914917,
      "learning_rate": 1.7454523006008726e-05,
      "loss": 0.1793,
      "step": 61000
    },
    {
      "epoch": 1.2573011569703736,
      "grad_norm": 5.6644062995910645,
      "learning_rate": 1.743415095892666e-05,
      "loss": 0.1782,
      "step": 61100
    },
    {
      "epoch": 1.2593589077458884,
      "grad_norm": 3.6644446849823,
      "learning_rate": 1.7413573133591243e-05,
      "loss": 0.19,
      "step": 61200
    },
    {
      "epoch": 1.2614166585214033,
      "grad_norm": 1.3430148363113403,
      "learning_rate": 1.7392995308255822e-05,
      "loss": 0.1633,
      "step": 61300
    },
    {
      "epoch": 1.2634744092969181,
      "grad_norm": 3.057260751724243,
      "learning_rate": 1.7372417482920405e-05,
      "loss": 0.1752,
      "step": 61400
    },
    {
      "epoch": 1.265532160072433,
      "grad_norm": 3.2104427814483643,
      "learning_rate": 1.7351839657584984e-05,
      "loss": 0.1611,
      "step": 61500
    },
    {
      "epoch": 1.2675899108479476,
      "grad_norm": 1.5718990564346313,
      "learning_rate": 1.7331261832249567e-05,
      "loss": 0.1976,
      "step": 61600
    },
    {
      "epoch": 1.2696476616234624,
      "grad_norm": 1.3723437786102295,
      "learning_rate": 1.7310684006914147e-05,
      "loss": 0.1713,
      "step": 61700
    },
    {
      "epoch": 1.2717054123989773,
      "grad_norm": 2.4298818111419678,
      "learning_rate": 1.729010618157873e-05,
      "loss": 0.1766,
      "step": 61800
    },
    {
      "epoch": 1.2737631631744921,
      "grad_norm": 5.31965446472168,
      "learning_rate": 1.7269528356243312e-05,
      "loss": 0.1827,
      "step": 61900
    },
    {
      "epoch": 1.275820913950007,
      "grad_norm": 4.306581974029541,
      "learning_rate": 1.724895053090789e-05,
      "loss": 0.1984,
      "step": 62000
    },
    {
      "epoch": 1.2778786647255218,
      "grad_norm": 2.3755481243133545,
      "learning_rate": 1.7228372705572474e-05,
      "loss": 0.1627,
      "step": 62100
    },
    {
      "epoch": 1.2799364155010367,
      "grad_norm": 3.341892719268799,
      "learning_rate": 1.7207794880237054e-05,
      "loss": 0.199,
      "step": 62200
    },
    {
      "epoch": 1.2819941662765515,
      "grad_norm": 3.9856908321380615,
      "learning_rate": 1.7187217054901637e-05,
      "loss": 0.1663,
      "step": 62300
    },
    {
      "epoch": 1.2840519170520661,
      "grad_norm": 1.5492255687713623,
      "learning_rate": 1.716663922956622e-05,
      "loss": 0.1738,
      "step": 62400
    },
    {
      "epoch": 1.286109667827581,
      "grad_norm": 4.7327423095703125,
      "learning_rate": 1.71460614042308e-05,
      "loss": 0.173,
      "step": 62500
    },
    {
      "epoch": 1.2881674186030958,
      "grad_norm": 3.1274945735931396,
      "learning_rate": 1.7125483578895385e-05,
      "loss": 0.1611,
      "step": 62600
    },
    {
      "epoch": 1.2902251693786106,
      "grad_norm": 4.260551929473877,
      "learning_rate": 1.7104905753559965e-05,
      "loss": 0.1878,
      "step": 62700
    },
    {
      "epoch": 1.2922829201541255,
      "grad_norm": 3.385758876800537,
      "learning_rate": 1.7084327928224547e-05,
      "loss": 0.1714,
      "step": 62800
    },
    {
      "epoch": 1.2943406709296403,
      "grad_norm": 3.675861120223999,
      "learning_rate": 1.706375010288913e-05,
      "loss": 0.1854,
      "step": 62900
    },
    {
      "epoch": 1.2963984217051552,
      "grad_norm": 2.155780792236328,
      "learning_rate": 1.704317227755371e-05,
      "loss": 0.1759,
      "step": 63000
    },
    {
      "epoch": 1.29845617248067,
      "grad_norm": 2.366588592529297,
      "learning_rate": 1.7022594452218292e-05,
      "loss": 0.1543,
      "step": 63100
    },
    {
      "epoch": 1.3005139232561849,
      "grad_norm": 1.8940253257751465,
      "learning_rate": 1.7002222405136223e-05,
      "loss": 0.1711,
      "step": 63200
    },
    {
      "epoch": 1.3025716740316997,
      "grad_norm": 1.0485504865646362,
      "learning_rate": 1.6981644579800805e-05,
      "loss": 0.1752,
      "step": 63300
    },
    {
      "epoch": 1.3046294248072146,
      "grad_norm": 1.7656160593032837,
      "learning_rate": 1.6961066754465388e-05,
      "loss": 0.182,
      "step": 63400
    },
    {
      "epoch": 1.3066871755827294,
      "grad_norm": 0.5106173157691956,
      "learning_rate": 1.6940488929129968e-05,
      "loss": 0.1713,
      "step": 63500
    },
    {
      "epoch": 1.3087449263582442,
      "grad_norm": 3.1962692737579346,
      "learning_rate": 1.691991110379455e-05,
      "loss": 0.1759,
      "step": 63600
    },
    {
      "epoch": 1.3108026771337589,
      "grad_norm": 5.429025650024414,
      "learning_rate": 1.689933327845913e-05,
      "loss": 0.1923,
      "step": 63700
    },
    {
      "epoch": 1.3128604279092737,
      "grad_norm": 1.5298702716827393,
      "learning_rate": 1.6878755453123713e-05,
      "loss": 0.181,
      "step": 63800
    },
    {
      "epoch": 1.3149181786847886,
      "grad_norm": 3.577383279800415,
      "learning_rate": 1.6858177627788296e-05,
      "loss": 0.1728,
      "step": 63900
    },
    {
      "epoch": 1.3169759294603034,
      "grad_norm": 2.0735864639282227,
      "learning_rate": 1.6837599802452875e-05,
      "loss": 0.173,
      "step": 64000
    },
    {
      "epoch": 1.3190336802358182,
      "grad_norm": 0.283562034368515,
      "learning_rate": 1.6817021977117458e-05,
      "loss": 0.1926,
      "step": 64100
    },
    {
      "epoch": 1.321091431011333,
      "grad_norm": 2.2735280990600586,
      "learning_rate": 1.679644415178204e-05,
      "loss": 0.1708,
      "step": 64200
    },
    {
      "epoch": 1.323149181786848,
      "grad_norm": 4.389495849609375,
      "learning_rate": 1.6775866326446623e-05,
      "loss": 0.1998,
      "step": 64300
    },
    {
      "epoch": 1.3252069325623628,
      "grad_norm": 1.390082597732544,
      "learning_rate": 1.6755288501111206e-05,
      "loss": 0.1663,
      "step": 64400
    },
    {
      "epoch": 1.3272646833378776,
      "grad_norm": 2.527143955230713,
      "learning_rate": 1.6734710675775786e-05,
      "loss": 0.1826,
      "step": 64500
    },
    {
      "epoch": 1.3293224341133922,
      "grad_norm": 2.2953732013702393,
      "learning_rate": 1.671413285044037e-05,
      "loss": 0.1827,
      "step": 64600
    },
    {
      "epoch": 1.331380184888907,
      "grad_norm": 2.1017258167266846,
      "learning_rate": 1.6693555025104948e-05,
      "loss": 0.1788,
      "step": 64700
    },
    {
      "epoch": 1.333437935664422,
      "grad_norm": 3.4805819988250732,
      "learning_rate": 1.667297719976953e-05,
      "loss": 0.1857,
      "step": 64800
    },
    {
      "epoch": 1.3354956864399368,
      "grad_norm": 2.1785192489624023,
      "learning_rate": 1.6652399374434113e-05,
      "loss": 0.1818,
      "step": 64900
    },
    {
      "epoch": 1.3375534372154516,
      "grad_norm": 3.366629123687744,
      "learning_rate": 1.6631821549098693e-05,
      "loss": 0.1956,
      "step": 65000
    },
    {
      "epoch": 1.3396111879909665,
      "grad_norm": 1.348803997039795,
      "learning_rate": 1.6611243723763276e-05,
      "loss": 0.1964,
      "step": 65100
    },
    {
      "epoch": 1.3416689387664813,
      "grad_norm": 2.5522336959838867,
      "learning_rate": 1.6590871676681206e-05,
      "loss": 0.1743,
      "step": 65200
    },
    {
      "epoch": 1.3437266895419961,
      "grad_norm": 2.2243432998657227,
      "learning_rate": 1.657029385134579e-05,
      "loss": 0.157,
      "step": 65300
    },
    {
      "epoch": 1.345784440317511,
      "grad_norm": 4.555011749267578,
      "learning_rate": 1.654971602601037e-05,
      "loss": 0.1667,
      "step": 65400
    },
    {
      "epoch": 1.3478421910930258,
      "grad_norm": 3.7619409561157227,
      "learning_rate": 1.652913820067495e-05,
      "loss": 0.1872,
      "step": 65500
    },
    {
      "epoch": 1.3498999418685407,
      "grad_norm": 1.584848165512085,
      "learning_rate": 1.6508560375339534e-05,
      "loss": 0.1735,
      "step": 65600
    },
    {
      "epoch": 1.3519576926440555,
      "grad_norm": 4.0105085372924805,
      "learning_rate": 1.6487982550004113e-05,
      "loss": 0.1859,
      "step": 65700
    },
    {
      "epoch": 1.3540154434195704,
      "grad_norm": 1.2995166778564453,
      "learning_rate": 1.6467404724668696e-05,
      "loss": 0.17,
      "step": 65800
    },
    {
      "epoch": 1.356073194195085,
      "grad_norm": 2.643157958984375,
      "learning_rate": 1.644682689933328e-05,
      "loss": 0.1809,
      "step": 65900
    },
    {
      "epoch": 1.3581309449705998,
      "grad_norm": 8.52954387664795,
      "learning_rate": 1.642624907399786e-05,
      "loss": 0.1779,
      "step": 66000
    },
    {
      "epoch": 1.3601886957461147,
      "grad_norm": 3.666907548904419,
      "learning_rate": 1.6405671248662444e-05,
      "loss": 0.1859,
      "step": 66100
    },
    {
      "epoch": 1.3622464465216295,
      "grad_norm": 1.1251742839813232,
      "learning_rate": 1.6385093423327024e-05,
      "loss": 0.1763,
      "step": 66200
    },
    {
      "epoch": 1.3643041972971444,
      "grad_norm": 1.706282138824463,
      "learning_rate": 1.6364515597991607e-05,
      "loss": 0.1748,
      "step": 66300
    },
    {
      "epoch": 1.3663619480726592,
      "grad_norm": 3.0823915004730225,
      "learning_rate": 1.6343937772656186e-05,
      "loss": 0.1741,
      "step": 66400
    },
    {
      "epoch": 1.368419698848174,
      "grad_norm": 2.113821029663086,
      "learning_rate": 1.632335994732077e-05,
      "loss": 0.1817,
      "step": 66500
    },
    {
      "epoch": 1.370477449623689,
      "grad_norm": 4.057358741760254,
      "learning_rate": 1.630278212198535e-05,
      "loss": 0.1637,
      "step": 66600
    },
    {
      "epoch": 1.3725352003992035,
      "grad_norm": 3.0949838161468506,
      "learning_rate": 1.628220429664993e-05,
      "loss": 0.1654,
      "step": 66700
    },
    {
      "epoch": 1.3745929511747184,
      "grad_norm": 2.6379594802856445,
      "learning_rate": 1.6261626471314514e-05,
      "loss": 0.1843,
      "step": 66800
    },
    {
      "epoch": 1.3766507019502332,
      "grad_norm": 3.1835501194000244,
      "learning_rate": 1.6241048645979093e-05,
      "loss": 0.1557,
      "step": 66900
    },
    {
      "epoch": 1.378708452725748,
      "grad_norm": 3.5806961059570312,
      "learning_rate": 1.6220470820643676e-05,
      "loss": 0.1793,
      "step": 67000
    },
    {
      "epoch": 1.380766203501263,
      "grad_norm": 6.651768684387207,
      "learning_rate": 1.619989299530826e-05,
      "loss": 0.1807,
      "step": 67100
    },
    {
      "epoch": 1.3828239542767777,
      "grad_norm": 3.3142611980438232,
      "learning_rate": 1.6179315169972838e-05,
      "loss": 0.1935,
      "step": 67200
    },
    {
      "epoch": 1.3848817050522926,
      "grad_norm": 1.802907109260559,
      "learning_rate": 1.6158943122890772e-05,
      "loss": 0.1886,
      "step": 67300
    },
    {
      "epoch": 1.3869394558278074,
      "grad_norm": 2.8078486919403076,
      "learning_rate": 1.6138365297555355e-05,
      "loss": 0.1742,
      "step": 67400
    },
    {
      "epoch": 1.3889972066033223,
      "grad_norm": 2.848313093185425,
      "learning_rate": 1.6117787472219938e-05,
      "loss": 0.1751,
      "step": 67500
    },
    {
      "epoch": 1.391054957378837,
      "grad_norm": 2.4644792079925537,
      "learning_rate": 1.609720964688452e-05,
      "loss": 0.1767,
      "step": 67600
    },
    {
      "epoch": 1.393112708154352,
      "grad_norm": 4.7010698318481445,
      "learning_rate": 1.60766318215491e-05,
      "loss": 0.1709,
      "step": 67700
    },
    {
      "epoch": 1.3951704589298668,
      "grad_norm": 1.966660976409912,
      "learning_rate": 1.6056053996213683e-05,
      "loss": 0.1765,
      "step": 67800
    },
    {
      "epoch": 1.3972282097053816,
      "grad_norm": 1.7774778604507446,
      "learning_rate": 1.6035476170878262e-05,
      "loss": 0.1637,
      "step": 67900
    },
    {
      "epoch": 1.3992859604808965,
      "grad_norm": 4.386480808258057,
      "learning_rate": 1.6014898345542845e-05,
      "loss": 0.1732,
      "step": 68000
    },
    {
      "epoch": 1.401343711256411,
      "grad_norm": 2.1781699657440186,
      "learning_rate": 1.5994320520207428e-05,
      "loss": 0.1903,
      "step": 68100
    },
    {
      "epoch": 1.403401462031926,
      "grad_norm": 2.438239812850952,
      "learning_rate": 1.5973742694872007e-05,
      "loss": 0.2041,
      "step": 68200
    },
    {
      "epoch": 1.4054592128074408,
      "grad_norm": 2.7399938106536865,
      "learning_rate": 1.595316486953659e-05,
      "loss": 0.2015,
      "step": 68300
    },
    {
      "epoch": 1.4075169635829556,
      "grad_norm": 3.9343647956848145,
      "learning_rate": 1.593258704420117e-05,
      "loss": 0.1793,
      "step": 68400
    },
    {
      "epoch": 1.4095747143584705,
      "grad_norm": 2.635326623916626,
      "learning_rate": 1.5912009218865752e-05,
      "loss": 0.1865,
      "step": 68500
    },
    {
      "epoch": 1.4116324651339853,
      "grad_norm": 1.4125295877456665,
      "learning_rate": 1.5891431393530335e-05,
      "loss": 0.202,
      "step": 68600
    },
    {
      "epoch": 1.4136902159095002,
      "grad_norm": 1.7178207635879517,
      "learning_rate": 1.5870853568194914e-05,
      "loss": 0.1453,
      "step": 68700
    },
    {
      "epoch": 1.415747966685015,
      "grad_norm": 1.0121740102767944,
      "learning_rate": 1.5850275742859497e-05,
      "loss": 0.1553,
      "step": 68800
    },
    {
      "epoch": 1.4178057174605296,
      "grad_norm": 2.593076467514038,
      "learning_rate": 1.5829697917524076e-05,
      "loss": 0.1953,
      "step": 68900
    },
    {
      "epoch": 1.4198634682360445,
      "grad_norm": 4.274007320404053,
      "learning_rate": 1.580912009218866e-05,
      "loss": 0.1682,
      "step": 69000
    },
    {
      "epoch": 1.4219212190115593,
      "grad_norm": 2.3112800121307373,
      "learning_rate": 1.5788542266853242e-05,
      "loss": 0.1743,
      "step": 69100
    },
    {
      "epoch": 1.4239789697870742,
      "grad_norm": 2.162597417831421,
      "learning_rate": 1.576796444151782e-05,
      "loss": 0.1872,
      "step": 69200
    },
    {
      "epoch": 1.426036720562589,
      "grad_norm": 0.7380082607269287,
      "learning_rate": 1.574759239443576e-05,
      "loss": 0.1681,
      "step": 69300
    },
    {
      "epoch": 1.4280944713381039,
      "grad_norm": 3.7291057109832764,
      "learning_rate": 1.5727014569100338e-05,
      "loss": 0.1696,
      "step": 69400
    },
    {
      "epoch": 1.4301522221136187,
      "grad_norm": 1.4439594745635986,
      "learning_rate": 1.570643674376492e-05,
      "loss": 0.1596,
      "step": 69500
    },
    {
      "epoch": 1.4322099728891335,
      "grad_norm": 2.1631457805633545,
      "learning_rate": 1.5685858918429504e-05,
      "loss": 0.1742,
      "step": 69600
    },
    {
      "epoch": 1.4342677236646484,
      "grad_norm": 4.083626747131348,
      "learning_rate": 1.5665281093094083e-05,
      "loss": 0.1692,
      "step": 69700
    },
    {
      "epoch": 1.4363254744401632,
      "grad_norm": 2.285554885864258,
      "learning_rate": 1.5644703267758666e-05,
      "loss": 0.167,
      "step": 69800
    },
    {
      "epoch": 1.438383225215678,
      "grad_norm": 4.0385589599609375,
      "learning_rate": 1.5624125442423245e-05,
      "loss": 0.1955,
      "step": 69900
    },
    {
      "epoch": 1.440440975991193,
      "grad_norm": 4.251014709472656,
      "learning_rate": 1.5603547617087828e-05,
      "loss": 0.1595,
      "step": 70000
    },
    {
      "epoch": 1.440440975991193,
      "eval_accuracy": 0.8342668024439919,
      "eval_f1_contradiction": 0.8369441277080958,
      "eval_loss": 0.15924079716205597,
      "eval_runtime": 76.5894,
      "eval_samples_per_second": 51.286,
      "eval_steps_per_second": 6.411,
      "step": 70000
    },
    {
      "epoch": 1.4424987267667078,
      "grad_norm": 2.4845261573791504,
      "learning_rate": 1.558296979175241e-05,
      "loss": 0.1685,
      "step": 70100
    },
    {
      "epoch": 1.4445564775422226,
      "grad_norm": 4.002135276794434,
      "learning_rate": 1.556239196641699e-05,
      "loss": 0.1847,
      "step": 70200
    },
    {
      "epoch": 1.4466142283177372,
      "grad_norm": 2.3644256591796875,
      "learning_rate": 1.5541814141081573e-05,
      "loss": 0.154,
      "step": 70300
    },
    {
      "epoch": 1.448671979093252,
      "grad_norm": 3.024811267852783,
      "learning_rate": 1.5521236315746152e-05,
      "loss": 0.1771,
      "step": 70400
    },
    {
      "epoch": 1.450729729868767,
      "grad_norm": 3.806406021118164,
      "learning_rate": 1.5500658490410735e-05,
      "loss": 0.1601,
      "step": 70500
    },
    {
      "epoch": 1.4527874806442818,
      "grad_norm": 2.506070852279663,
      "learning_rate": 1.5480080665075318e-05,
      "loss": 0.1792,
      "step": 70600
    },
    {
      "epoch": 1.4548452314197966,
      "grad_norm": 1.74257230758667,
      "learning_rate": 1.5459502839739897e-05,
      "loss": 0.1627,
      "step": 70700
    },
    {
      "epoch": 1.4569029821953114,
      "grad_norm": 4.851787567138672,
      "learning_rate": 1.543892501440448e-05,
      "loss": 0.1587,
      "step": 70800
    },
    {
      "epoch": 1.4589607329708263,
      "grad_norm": 1.401580572128296,
      "learning_rate": 1.541834718906906e-05,
      "loss": 0.1728,
      "step": 70900
    },
    {
      "epoch": 1.4610184837463411,
      "grad_norm": 4.125089645385742,
      "learning_rate": 1.5397769363733642e-05,
      "loss": 0.1777,
      "step": 71000
    },
    {
      "epoch": 1.4630762345218558,
      "grad_norm": 4.067082405090332,
      "learning_rate": 1.5377191538398222e-05,
      "loss": 0.1771,
      "step": 71100
    },
    {
      "epoch": 1.4651339852973706,
      "grad_norm": 6.573830604553223,
      "learning_rate": 1.5356613713062805e-05,
      "loss": 0.1733,
      "step": 71200
    },
    {
      "epoch": 1.4671917360728854,
      "grad_norm": 1.534125566482544,
      "learning_rate": 1.5336241665980742e-05,
      "loss": 0.1758,
      "step": 71300
    },
    {
      "epoch": 1.4692494868484003,
      "grad_norm": 7.00921630859375,
      "learning_rate": 1.531566384064532e-05,
      "loss": 0.177,
      "step": 71400
    },
    {
      "epoch": 1.4713072376239151,
      "grad_norm": 2.2436654567718506,
      "learning_rate": 1.5295086015309904e-05,
      "loss": 0.1829,
      "step": 71500
    },
    {
      "epoch": 1.47336498839943,
      "grad_norm": 3.689046859741211,
      "learning_rate": 1.5274508189974487e-05,
      "loss": 0.1635,
      "step": 71600
    },
    {
      "epoch": 1.4754227391749448,
      "grad_norm": 3.5442163944244385,
      "learning_rate": 1.5253930364639065e-05,
      "loss": 0.1833,
      "step": 71700
    },
    {
      "epoch": 1.4774804899504597,
      "grad_norm": 6.332870960235596,
      "learning_rate": 1.5233352539303647e-05,
      "loss": 0.1729,
      "step": 71800
    },
    {
      "epoch": 1.4795382407259745,
      "grad_norm": 0.7251411080360413,
      "learning_rate": 1.5212774713968227e-05,
      "loss": 0.1681,
      "step": 71900
    },
    {
      "epoch": 1.4815959915014894,
      "grad_norm": 2.608438730239868,
      "learning_rate": 1.519219688863281e-05,
      "loss": 0.1701,
      "step": 72000
    },
    {
      "epoch": 1.4836537422770042,
      "grad_norm": 3.188018321990967,
      "learning_rate": 1.5171619063297389e-05,
      "loss": 0.1551,
      "step": 72100
    },
    {
      "epoch": 1.485711493052519,
      "grad_norm": 4.038116455078125,
      "learning_rate": 1.5151041237961972e-05,
      "loss": 0.1682,
      "step": 72200
    },
    {
      "epoch": 1.4877692438280339,
      "grad_norm": 0.9388098120689392,
      "learning_rate": 1.5130463412626555e-05,
      "loss": 0.1726,
      "step": 72300
    },
    {
      "epoch": 1.4898269946035487,
      "grad_norm": 2.790950059890747,
      "learning_rate": 1.5109885587291134e-05,
      "loss": 0.1633,
      "step": 72400
    },
    {
      "epoch": 1.4918847453790633,
      "grad_norm": 1.9086647033691406,
      "learning_rate": 1.5089307761955717e-05,
      "loss": 0.1683,
      "step": 72500
    },
    {
      "epoch": 1.4939424961545782,
      "grad_norm": 5.2331390380859375,
      "learning_rate": 1.5068729936620296e-05,
      "loss": 0.1867,
      "step": 72600
    },
    {
      "epoch": 1.496000246930093,
      "grad_norm": 0.38318562507629395,
      "learning_rate": 1.5048152111284879e-05,
      "loss": 0.179,
      "step": 72700
    },
    {
      "epoch": 1.4980579977056079,
      "grad_norm": 3.0309221744537354,
      "learning_rate": 1.5027574285949462e-05,
      "loss": 0.1643,
      "step": 72800
    },
    {
      "epoch": 1.5001157484811227,
      "grad_norm": 4.250407695770264,
      "learning_rate": 1.5006996460614041e-05,
      "loss": 0.1915,
      "step": 72900
    },
    {
      "epoch": 1.5021734992566376,
      "grad_norm": 9.189359664916992,
      "learning_rate": 1.4986418635278624e-05,
      "loss": 0.1838,
      "step": 73000
    },
    {
      "epoch": 1.5042312500321522,
      "grad_norm": 2.4021198749542236,
      "learning_rate": 1.4965840809943205e-05,
      "loss": 0.1834,
      "step": 73100
    },
    {
      "epoch": 1.506289000807667,
      "grad_norm": 0.9695621728897095,
      "learning_rate": 1.4945262984607786e-05,
      "loss": 0.1699,
      "step": 73200
    },
    {
      "epoch": 1.5083467515831819,
      "grad_norm": 5.587017059326172,
      "learning_rate": 1.4924890937525722e-05,
      "loss": 0.186,
      "step": 73300
    },
    {
      "epoch": 1.5104045023586967,
      "grad_norm": 1.7323921918869019,
      "learning_rate": 1.4904313112190304e-05,
      "loss": 0.1812,
      "step": 73400
    },
    {
      "epoch": 1.5124622531342116,
      "grad_norm": 1.2407269477844238,
      "learning_rate": 1.4883735286854886e-05,
      "loss": 0.1591,
      "step": 73500
    },
    {
      "epoch": 1.5145200039097264,
      "grad_norm": 0.42540013790130615,
      "learning_rate": 1.4863157461519467e-05,
      "loss": 0.1845,
      "step": 73600
    },
    {
      "epoch": 1.5165777546852413,
      "grad_norm": 3.643066644668579,
      "learning_rate": 1.4842579636184048e-05,
      "loss": 0.157,
      "step": 73700
    },
    {
      "epoch": 1.518635505460756,
      "grad_norm": 1.8452229499816895,
      "learning_rate": 1.4822001810848629e-05,
      "loss": 0.179,
      "step": 73800
    },
    {
      "epoch": 1.520693256236271,
      "grad_norm": 1.502407431602478,
      "learning_rate": 1.480142398551321e-05,
      "loss": 0.1681,
      "step": 73900
    },
    {
      "epoch": 1.5227510070117858,
      "grad_norm": 2.3600780963897705,
      "learning_rate": 1.4780846160177793e-05,
      "loss": 0.1763,
      "step": 74000
    },
    {
      "epoch": 1.5248087577873006,
      "grad_norm": 6.126219272613525,
      "learning_rate": 1.4760268334842374e-05,
      "loss": 0.1896,
      "step": 74100
    },
    {
      "epoch": 1.5268665085628155,
      "grad_norm": 0.8845561742782593,
      "learning_rate": 1.4739690509506955e-05,
      "loss": 0.1781,
      "step": 74200
    },
    {
      "epoch": 1.5289242593383303,
      "grad_norm": 1.7715532779693604,
      "learning_rate": 1.4719112684171536e-05,
      "loss": 0.1873,
      "step": 74300
    },
    {
      "epoch": 1.5309820101138452,
      "grad_norm": 1.586052656173706,
      "learning_rate": 1.4698534858836117e-05,
      "loss": 0.1631,
      "step": 74400
    },
    {
      "epoch": 1.53303976088936,
      "grad_norm": 3.2894749641418457,
      "learning_rate": 1.46779570335007e-05,
      "loss": 0.1572,
      "step": 74500
    },
    {
      "epoch": 1.5350975116648748,
      "grad_norm": 5.966115474700928,
      "learning_rate": 1.4657379208165281e-05,
      "loss": 0.1685,
      "step": 74600
    },
    {
      "epoch": 1.5371552624403897,
      "grad_norm": 2.740065336227417,
      "learning_rate": 1.4636801382829862e-05,
      "loss": 0.1842,
      "step": 74700
    },
    {
      "epoch": 1.5392130132159043,
      "grad_norm": 2.4644863605499268,
      "learning_rate": 1.4616223557494443e-05,
      "loss": 0.1894,
      "step": 74800
    },
    {
      "epoch": 1.5412707639914192,
      "grad_norm": 1.3736063241958618,
      "learning_rate": 1.4595645732159026e-05,
      "loss": 0.1566,
      "step": 74900
    },
    {
      "epoch": 1.543328514766934,
      "grad_norm": 5.433162689208984,
      "learning_rate": 1.4575067906823607e-05,
      "loss": 0.17,
      "step": 75000
    },
    {
      "epoch": 1.5453862655424488,
      "grad_norm": 4.015876770019531,
      "learning_rate": 1.455449008148819e-05,
      "loss": 0.1683,
      "step": 75100
    },
    {
      "epoch": 1.5474440163179637,
      "grad_norm": 5.762784481048584,
      "learning_rate": 1.4533912256152771e-05,
      "loss": 0.1902,
      "step": 75200
    },
    {
      "epoch": 1.5495017670934783,
      "grad_norm": 1.0761334896087646,
      "learning_rate": 1.4513334430817352e-05,
      "loss": 0.1604,
      "step": 75300
    },
    {
      "epoch": 1.5515595178689932,
      "grad_norm": 1.122193694114685,
      "learning_rate": 1.4492756605481933e-05,
      "loss": 0.1718,
      "step": 75400
    },
    {
      "epoch": 1.553617268644508,
      "grad_norm": 3.690772294998169,
      "learning_rate": 1.4472384558399869e-05,
      "loss": 0.178,
      "step": 75500
    },
    {
      "epoch": 1.5556750194200228,
      "grad_norm": 3.974728584289551,
      "learning_rate": 1.445180673306445e-05,
      "loss": 0.1694,
      "step": 75600
    },
    {
      "epoch": 1.5577327701955377,
      "grad_norm": 5.167896270751953,
      "learning_rate": 1.4431228907729031e-05,
      "loss": 0.1815,
      "step": 75700
    },
    {
      "epoch": 1.5597905209710525,
      "grad_norm": 1.1794493198394775,
      "learning_rate": 1.4410651082393612e-05,
      "loss": 0.1786,
      "step": 75800
    },
    {
      "epoch": 1.5618482717465674,
      "grad_norm": 3.334402084350586,
      "learning_rate": 1.4390073257058193e-05,
      "loss": 0.1828,
      "step": 75900
    },
    {
      "epoch": 1.5639060225220822,
      "grad_norm": 3.2548279762268066,
      "learning_rate": 1.4369495431722776e-05,
      "loss": 0.1522,
      "step": 76000
    },
    {
      "epoch": 1.565963773297597,
      "grad_norm": 3.3457345962524414,
      "learning_rate": 1.4348917606387357e-05,
      "loss": 0.1897,
      "step": 76100
    },
    {
      "epoch": 1.568021524073112,
      "grad_norm": 4.353980541229248,
      "learning_rate": 1.4328339781051938e-05,
      "loss": 0.1903,
      "step": 76200
    },
    {
      "epoch": 1.5700792748486267,
      "grad_norm": 2.5709075927734375,
      "learning_rate": 1.430776195571652e-05,
      "loss": 0.1652,
      "step": 76300
    },
    {
      "epoch": 1.5721370256241416,
      "grad_norm": 3.041445255279541,
      "learning_rate": 1.42871841303811e-05,
      "loss": 0.1623,
      "step": 76400
    },
    {
      "epoch": 1.5741947763996564,
      "grad_norm": 5.445699214935303,
      "learning_rate": 1.4266606305045683e-05,
      "loss": 0.1795,
      "step": 76500
    },
    {
      "epoch": 1.5762525271751713,
      "grad_norm": 0.3979288339614868,
      "learning_rate": 1.4246028479710266e-05,
      "loss": 0.1631,
      "step": 76600
    },
    {
      "epoch": 1.5783102779506861,
      "grad_norm": 1.578138828277588,
      "learning_rate": 1.4225450654374847e-05,
      "loss": 0.1908,
      "step": 76700
    },
    {
      "epoch": 1.580368028726201,
      "grad_norm": 2.337371826171875,
      "learning_rate": 1.4204872829039428e-05,
      "loss": 0.1723,
      "step": 76800
    },
    {
      "epoch": 1.5824257795017158,
      "grad_norm": 1.5980087518692017,
      "learning_rate": 1.418429500370401e-05,
      "loss": 0.1749,
      "step": 76900
    },
    {
      "epoch": 1.5844835302772304,
      "grad_norm": 4.671072483062744,
      "learning_rate": 1.416371717836859e-05,
      "loss": 0.1719,
      "step": 77000
    },
    {
      "epoch": 1.5865412810527453,
      "grad_norm": 1.2531359195709229,
      "learning_rate": 1.4143139353033173e-05,
      "loss": 0.1657,
      "step": 77100
    },
    {
      "epoch": 1.5885990318282601,
      "grad_norm": 5.102917194366455,
      "learning_rate": 1.4122561527697754e-05,
      "loss": 0.1789,
      "step": 77200
    },
    {
      "epoch": 1.590656782603775,
      "grad_norm": 5.182437896728516,
      "learning_rate": 1.4101983702362335e-05,
      "loss": 0.1632,
      "step": 77300
    },
    {
      "epoch": 1.5927145333792898,
      "grad_norm": 2.27426815032959,
      "learning_rate": 1.4081405877026917e-05,
      "loss": 0.1771,
      "step": 77400
    },
    {
      "epoch": 1.5947722841548044,
      "grad_norm": 4.805375099182129,
      "learning_rate": 1.4060828051691498e-05,
      "loss": 0.2052,
      "step": 77500
    },
    {
      "epoch": 1.5968300349303193,
      "grad_norm": 4.021831512451172,
      "learning_rate": 1.4040456004609433e-05,
      "loss": 0.1935,
      "step": 77600
    },
    {
      "epoch": 1.5988877857058341,
      "grad_norm": 2.764939308166504,
      "learning_rate": 1.4019878179274014e-05,
      "loss": 0.1641,
      "step": 77700
    },
    {
      "epoch": 1.600945536481349,
      "grad_norm": 2.197425603866577,
      "learning_rate": 1.3999300353938595e-05,
      "loss": 0.178,
      "step": 77800
    },
    {
      "epoch": 1.6030032872568638,
      "grad_norm": 2.2652809619903564,
      "learning_rate": 1.3978722528603176e-05,
      "loss": 0.1688,
      "step": 77900
    },
    {
      "epoch": 1.6050610380323787,
      "grad_norm": 2.7077572345733643,
      "learning_rate": 1.3958144703267758e-05,
      "loss": 0.1801,
      "step": 78000
    },
    {
      "epoch": 1.6071187888078935,
      "grad_norm": 2.759434700012207,
      "learning_rate": 1.393756687793234e-05,
      "loss": 0.1552,
      "step": 78100
    },
    {
      "epoch": 1.6091765395834083,
      "grad_norm": 2.0106372833251953,
      "learning_rate": 1.3916989052596923e-05,
      "loss": 0.1868,
      "step": 78200
    },
    {
      "epoch": 1.6112342903589232,
      "grad_norm": 4.3746562004089355,
      "learning_rate": 1.3896411227261504e-05,
      "loss": 0.1624,
      "step": 78300
    },
    {
      "epoch": 1.613292041134438,
      "grad_norm": 3.0245323181152344,
      "learning_rate": 1.3875833401926085e-05,
      "loss": 0.1594,
      "step": 78400
    },
    {
      "epoch": 1.6153497919099529,
      "grad_norm": 3.8346002101898193,
      "learning_rate": 1.3855255576590666e-05,
      "loss": 0.1881,
      "step": 78500
    },
    {
      "epoch": 1.6174075426854677,
      "grad_norm": 1.6216304302215576,
      "learning_rate": 1.3834677751255248e-05,
      "loss": 0.1853,
      "step": 78600
    },
    {
      "epoch": 1.6194652934609826,
      "grad_norm": 4.810671329498291,
      "learning_rate": 1.381409992591983e-05,
      "loss": 0.1998,
      "step": 78700
    },
    {
      "epoch": 1.6215230442364974,
      "grad_norm": 4.119333744049072,
      "learning_rate": 1.3793522100584412e-05,
      "loss": 0.1896,
      "step": 78800
    },
    {
      "epoch": 1.6235807950120122,
      "grad_norm": 4.133127689361572,
      "learning_rate": 1.3772944275248993e-05,
      "loss": 0.1701,
      "step": 78900
    },
    {
      "epoch": 1.625638545787527,
      "grad_norm": 1.376145839691162,
      "learning_rate": 1.3752366449913574e-05,
      "loss": 0.181,
      "step": 79000
    },
    {
      "epoch": 1.627696296563042,
      "grad_norm": 1.827328085899353,
      "learning_rate": 1.3731788624578155e-05,
      "loss": 0.1652,
      "step": 79100
    },
    {
      "epoch": 1.6297540473385566,
      "grad_norm": 2.2105488777160645,
      "learning_rate": 1.3711210799242738e-05,
      "loss": 0.1635,
      "step": 79200
    },
    {
      "epoch": 1.6318117981140714,
      "grad_norm": 4.222012996673584,
      "learning_rate": 1.3690632973907319e-05,
      "loss": 0.1803,
      "step": 79300
    },
    {
      "epoch": 1.6338695488895862,
      "grad_norm": 2.1505308151245117,
      "learning_rate": 1.36700551485719e-05,
      "loss": 0.1767,
      "step": 79400
    },
    {
      "epoch": 1.635927299665101,
      "grad_norm": 2.724627733230591,
      "learning_rate": 1.3649477323236481e-05,
      "loss": 0.1832,
      "step": 79500
    },
    {
      "epoch": 1.637985050440616,
      "grad_norm": 2.497746706008911,
      "learning_rate": 1.3629105276154416e-05,
      "loss": 0.16,
      "step": 79600
    },
    {
      "epoch": 1.6400428012161306,
      "grad_norm": 3.7265024185180664,
      "learning_rate": 1.3608527450818997e-05,
      "loss": 0.1912,
      "step": 79700
    },
    {
      "epoch": 1.6421005519916454,
      "grad_norm": 6.481639862060547,
      "learning_rate": 1.3587949625483579e-05,
      "loss": 0.1643,
      "step": 79800
    },
    {
      "epoch": 1.6441583027671602,
      "grad_norm": 0.9636497497558594,
      "learning_rate": 1.3567371800148161e-05,
      "loss": 0.1615,
      "step": 79900
    },
    {
      "epoch": 1.646216053542675,
      "grad_norm": 8.51265811920166,
      "learning_rate": 1.3546793974812743e-05,
      "loss": 0.1887,
      "step": 80000
    },
    {
      "epoch": 1.646216053542675,
      "eval_accuracy": 0.834775967413442,
      "eval_f1_contradiction": 0.8438914027149321,
      "eval_loss": 0.1597379744052887,
      "eval_runtime": 73.1201,
      "eval_samples_per_second": 53.72,
      "eval_steps_per_second": 6.715,
      "step": 80000
    },
    {
      "epoch": 1.64827380431819,
      "grad_norm": 1.6306675672531128,
      "learning_rate": 1.3526216149477324e-05,
      "loss": 0.1663,
      "step": 80100
    },
    {
      "epoch": 1.6503315550937048,
      "grad_norm": 3.3805532455444336,
      "learning_rate": 1.3505638324141906e-05,
      "loss": 0.1539,
      "step": 80200
    },
    {
      "epoch": 1.6523893058692196,
      "grad_norm": 3.149472713470459,
      "learning_rate": 1.3485060498806488e-05,
      "loss": 0.1611,
      "step": 80300
    },
    {
      "epoch": 1.6544470566447345,
      "grad_norm": 0.9059389233589172,
      "learning_rate": 1.3464482673471069e-05,
      "loss": 0.1813,
      "step": 80400
    },
    {
      "epoch": 1.6565048074202493,
      "grad_norm": 5.406214714050293,
      "learning_rate": 1.344390484813565e-05,
      "loss": 0.1928,
      "step": 80500
    },
    {
      "epoch": 1.6585625581957641,
      "grad_norm": 2.6703314781188965,
      "learning_rate": 1.342332702280023e-05,
      "loss": 0.1745,
      "step": 80600
    },
    {
      "epoch": 1.660620308971279,
      "grad_norm": 4.487729549407959,
      "learning_rate": 1.3402749197464814e-05,
      "loss": 0.1766,
      "step": 80700
    },
    {
      "epoch": 1.6626780597467938,
      "grad_norm": 0.9832571148872375,
      "learning_rate": 1.3382171372129395e-05,
      "loss": 0.1761,
      "step": 80800
    },
    {
      "epoch": 1.6647358105223087,
      "grad_norm": 3.404552459716797,
      "learning_rate": 1.3361593546793976e-05,
      "loss": 0.1811,
      "step": 80900
    },
    {
      "epoch": 1.6667935612978235,
      "grad_norm": 6.726905822753906,
      "learning_rate": 1.3341015721458557e-05,
      "loss": 0.1603,
      "step": 81000
    },
    {
      "epoch": 1.6688513120733384,
      "grad_norm": 1.2289602756500244,
      "learning_rate": 1.3320437896123138e-05,
      "loss": 0.158,
      "step": 81100
    },
    {
      "epoch": 1.6709090628488532,
      "grad_norm": 1.6241580247879028,
      "learning_rate": 1.329986007078772e-05,
      "loss": 0.2116,
      "step": 81200
    },
    {
      "epoch": 1.6729668136243678,
      "grad_norm": 0.7052114009857178,
      "learning_rate": 1.3279282245452302e-05,
      "loss": 0.1859,
      "step": 81300
    },
    {
      "epoch": 1.6750245643998827,
      "grad_norm": 4.795991897583008,
      "learning_rate": 1.3258704420116883e-05,
      "loss": 0.1743,
      "step": 81400
    },
    {
      "epoch": 1.6770823151753975,
      "grad_norm": 3.28818416595459,
      "learning_rate": 1.3238126594781464e-05,
      "loss": 0.1754,
      "step": 81500
    },
    {
      "epoch": 1.6791400659509124,
      "grad_norm": 3.029689073562622,
      "learning_rate": 1.3217548769446045e-05,
      "loss": 0.1748,
      "step": 81600
    },
    {
      "epoch": 1.6811978167264272,
      "grad_norm": 3.641383409500122,
      "learning_rate": 1.3197176722363982e-05,
      "loss": 0.192,
      "step": 81700
    },
    {
      "epoch": 1.683255567501942,
      "grad_norm": 1.9239588975906372,
      "learning_rate": 1.3176598897028564e-05,
      "loss": 0.1483,
      "step": 81800
    },
    {
      "epoch": 1.6853133182774567,
      "grad_norm": 4.187154769897461,
      "learning_rate": 1.3156021071693145e-05,
      "loss": 0.1787,
      "step": 81900
    },
    {
      "epoch": 1.6873710690529715,
      "grad_norm": 6.021356582641602,
      "learning_rate": 1.3135443246357726e-05,
      "loss": 0.1723,
      "step": 82000
    },
    {
      "epoch": 1.6894288198284864,
      "grad_norm": 2.6771113872528076,
      "learning_rate": 1.3114865421022307e-05,
      "loss": 0.1842,
      "step": 82100
    },
    {
      "epoch": 1.6914865706040012,
      "grad_norm": 2.778153657913208,
      "learning_rate": 1.3094287595686888e-05,
      "loss": 0.1958,
      "step": 82200
    },
    {
      "epoch": 1.693544321379516,
      "grad_norm": 1.3372924327850342,
      "learning_rate": 1.307370977035147e-05,
      "loss": 0.1694,
      "step": 82300
    },
    {
      "epoch": 1.695602072155031,
      "grad_norm": 1.5275063514709473,
      "learning_rate": 1.3053131945016052e-05,
      "loss": 0.1801,
      "step": 82400
    },
    {
      "epoch": 1.6976598229305457,
      "grad_norm": 1.8538062572479248,
      "learning_rate": 1.3032554119680633e-05,
      "loss": 0.1762,
      "step": 82500
    },
    {
      "epoch": 1.6997175737060606,
      "grad_norm": 2.053974151611328,
      "learning_rate": 1.3011976294345214e-05,
      "loss": 0.1832,
      "step": 82600
    },
    {
      "epoch": 1.7017753244815754,
      "grad_norm": 2.1540520191192627,
      "learning_rate": 1.2991398469009795e-05,
      "loss": 0.1671,
      "step": 82700
    },
    {
      "epoch": 1.7038330752570903,
      "grad_norm": 7.7723822593688965,
      "learning_rate": 1.2970820643674378e-05,
      "loss": 0.1581,
      "step": 82800
    },
    {
      "epoch": 1.7058908260326051,
      "grad_norm": 3.671628713607788,
      "learning_rate": 1.2950242818338959e-05,
      "loss": 0.1831,
      "step": 82900
    },
    {
      "epoch": 1.70794857680812,
      "grad_norm": 1.8243733644485474,
      "learning_rate": 1.292966499300354e-05,
      "loss": 0.1825,
      "step": 83000
    },
    {
      "epoch": 1.7100063275836348,
      "grad_norm": 2.1563100814819336,
      "learning_rate": 1.2909087167668121e-05,
      "loss": 0.1881,
      "step": 83100
    },
    {
      "epoch": 1.7120640783591496,
      "grad_norm": 1.6999835968017578,
      "learning_rate": 1.2888509342332702e-05,
      "loss": 0.1597,
      "step": 83200
    },
    {
      "epoch": 1.7141218291346645,
      "grad_norm": 1.6321552991867065,
      "learning_rate": 1.2867931516997284e-05,
      "loss": 0.1721,
      "step": 83300
    },
    {
      "epoch": 1.7161795799101793,
      "grad_norm": 4.542159557342529,
      "learning_rate": 1.2847353691661866e-05,
      "loss": 0.1785,
      "step": 83400
    },
    {
      "epoch": 1.718237330685694,
      "grad_norm": 2.0117576122283936,
      "learning_rate": 1.2826775866326447e-05,
      "loss": 0.1775,
      "step": 83500
    },
    {
      "epoch": 1.7202950814612088,
      "grad_norm": 5.636791229248047,
      "learning_rate": 1.2806198040991029e-05,
      "loss": 0.1757,
      "step": 83600
    },
    {
      "epoch": 1.7223528322367236,
      "grad_norm": 2.73698353767395,
      "learning_rate": 1.2785825993908964e-05,
      "loss": 0.1836,
      "step": 83700
    },
    {
      "epoch": 1.7244105830122385,
      "grad_norm": 3.292477607727051,
      "learning_rate": 1.2765248168573547e-05,
      "loss": 0.1919,
      "step": 83800
    },
    {
      "epoch": 1.7264683337877533,
      "grad_norm": 4.595903396606445,
      "learning_rate": 1.2744670343238128e-05,
      "loss": 0.1611,
      "step": 83900
    },
    {
      "epoch": 1.7285260845632682,
      "grad_norm": 3.2714385986328125,
      "learning_rate": 1.2724092517902709e-05,
      "loss": 0.1821,
      "step": 84000
    },
    {
      "epoch": 1.7305838353387828,
      "grad_norm": 2.5536162853240967,
      "learning_rate": 1.270351469256729e-05,
      "loss": 0.1815,
      "step": 84100
    },
    {
      "epoch": 1.7326415861142976,
      "grad_norm": 2.8987648487091064,
      "learning_rate": 1.2682936867231871e-05,
      "loss": 0.1674,
      "step": 84200
    },
    {
      "epoch": 1.7346993368898125,
      "grad_norm": 2.398118257522583,
      "learning_rate": 1.2662359041896452e-05,
      "loss": 0.1975,
      "step": 84300
    },
    {
      "epoch": 1.7367570876653273,
      "grad_norm": 4.3456902503967285,
      "learning_rate": 1.2641781216561035e-05,
      "loss": 0.1829,
      "step": 84400
    },
    {
      "epoch": 1.7388148384408422,
      "grad_norm": 3.7109785079956055,
      "learning_rate": 1.2621203391225616e-05,
      "loss": 0.1521,
      "step": 84500
    },
    {
      "epoch": 1.740872589216357,
      "grad_norm": 2.300002098083496,
      "learning_rate": 1.2600625565890197e-05,
      "loss": 0.178,
      "step": 84600
    },
    {
      "epoch": 1.7429303399918719,
      "grad_norm": 4.694147109985352,
      "learning_rate": 1.2580047740554778e-05,
      "loss": 0.1732,
      "step": 84700
    },
    {
      "epoch": 1.7449880907673867,
      "grad_norm": 0.9541909694671631,
      "learning_rate": 1.255946991521936e-05,
      "loss": 0.1726,
      "step": 84800
    },
    {
      "epoch": 1.7470458415429015,
      "grad_norm": 3.007978677749634,
      "learning_rate": 1.2538892089883942e-05,
      "loss": 0.1759,
      "step": 84900
    },
    {
      "epoch": 1.7491035923184164,
      "grad_norm": 3.985089063644409,
      "learning_rate": 1.2518314264548523e-05,
      "loss": 0.1773,
      "step": 85000
    },
    {
      "epoch": 1.7511613430939312,
      "grad_norm": 3.7207183837890625,
      "learning_rate": 1.2497736439213105e-05,
      "loss": 0.1879,
      "step": 85100
    },
    {
      "epoch": 1.753219093869446,
      "grad_norm": 1.2055811882019043,
      "learning_rate": 1.2477158613877686e-05,
      "loss": 0.1728,
      "step": 85200
    },
    {
      "epoch": 1.755276844644961,
      "grad_norm": 5.535974979400635,
      "learning_rate": 1.2456580788542267e-05,
      "loss": 0.1756,
      "step": 85300
    },
    {
      "epoch": 1.7573345954204758,
      "grad_norm": 5.367703914642334,
      "learning_rate": 1.2436002963206848e-05,
      "loss": 0.1731,
      "step": 85400
    },
    {
      "epoch": 1.7593923461959906,
      "grad_norm": 3.1987714767456055,
      "learning_rate": 1.241542513787143e-05,
      "loss": 0.1894,
      "step": 85500
    },
    {
      "epoch": 1.7614500969715055,
      "grad_norm": 3.061984062194824,
      "learning_rate": 1.2394847312536012e-05,
      "loss": 0.1681,
      "step": 85600
    },
    {
      "epoch": 1.76350784774702,
      "grad_norm": 1.7580517530441284,
      "learning_rate": 1.2374269487200593e-05,
      "loss": 0.1736,
      "step": 85700
    },
    {
      "epoch": 1.765565598522535,
      "grad_norm": 9.145355224609375,
      "learning_rate": 1.2353897440118528e-05,
      "loss": 0.1699,
      "step": 85800
    },
    {
      "epoch": 1.7676233492980498,
      "grad_norm": 1.4296448230743408,
      "learning_rate": 1.2333319614783111e-05,
      "loss": 0.178,
      "step": 85900
    },
    {
      "epoch": 1.7696811000735646,
      "grad_norm": 0.42927226424217224,
      "learning_rate": 1.2312741789447692e-05,
      "loss": 0.1728,
      "step": 86000
    },
    {
      "epoch": 1.7717388508490794,
      "grad_norm": 4.50319766998291,
      "learning_rate": 1.2292163964112273e-05,
      "loss": 0.1584,
      "step": 86100
    },
    {
      "epoch": 1.773796601624594,
      "grad_norm": 3.2080514430999756,
      "learning_rate": 1.2271586138776854e-05,
      "loss": 0.1673,
      "step": 86200
    },
    {
      "epoch": 1.775854352400109,
      "grad_norm": 0.9786830544471741,
      "learning_rate": 1.2251008313441436e-05,
      "loss": 0.1815,
      "step": 86300
    },
    {
      "epoch": 1.7779121031756238,
      "grad_norm": 2.0416088104248047,
      "learning_rate": 1.2230430488106018e-05,
      "loss": 0.1802,
      "step": 86400
    },
    {
      "epoch": 1.7799698539511386,
      "grad_norm": 1.9795968532562256,
      "learning_rate": 1.22098526627706e-05,
      "loss": 0.2046,
      "step": 86500
    },
    {
      "epoch": 1.7820276047266534,
      "grad_norm": 0.9320564270019531,
      "learning_rate": 1.218927483743518e-05,
      "loss": 0.1739,
      "step": 86600
    },
    {
      "epoch": 1.7840853555021683,
      "grad_norm": 1.9448984861373901,
      "learning_rate": 1.2168697012099762e-05,
      "loss": 0.1922,
      "step": 86700
    },
    {
      "epoch": 1.7861431062776831,
      "grad_norm": 3.4789884090423584,
      "learning_rate": 1.2148119186764343e-05,
      "loss": 0.1906,
      "step": 86800
    },
    {
      "epoch": 1.788200857053198,
      "grad_norm": 2.492626667022705,
      "learning_rate": 1.2127541361428924e-05,
      "loss": 0.1917,
      "step": 86900
    },
    {
      "epoch": 1.7902586078287128,
      "grad_norm": 5.449689865112305,
      "learning_rate": 1.2106963536093507e-05,
      "loss": 0.1622,
      "step": 87000
    },
    {
      "epoch": 1.7923163586042277,
      "grad_norm": 0.551922082901001,
      "learning_rate": 1.2086385710758088e-05,
      "loss": 0.166,
      "step": 87100
    },
    {
      "epoch": 1.7943741093797425,
      "grad_norm": 2.6493895053863525,
      "learning_rate": 1.2065807885422669e-05,
      "loss": 0.1766,
      "step": 87200
    },
    {
      "epoch": 1.7964318601552574,
      "grad_norm": 1.7770657539367676,
      "learning_rate": 1.204523006008725e-05,
      "loss": 0.171,
      "step": 87300
    },
    {
      "epoch": 1.7984896109307722,
      "grad_norm": 4.861041069030762,
      "learning_rate": 1.2024652234751831e-05,
      "loss": 0.1747,
      "step": 87400
    },
    {
      "epoch": 1.800547361706287,
      "grad_norm": 1.1792466640472412,
      "learning_rate": 1.2004074409416414e-05,
      "loss": 0.2029,
      "step": 87500
    },
    {
      "epoch": 1.8026051124818019,
      "grad_norm": 0.9876183271408081,
      "learning_rate": 1.1983496584080995e-05,
      "loss": 0.1548,
      "step": 87600
    },
    {
      "epoch": 1.8046628632573167,
      "grad_norm": 4.908998489379883,
      "learning_rate": 1.1962918758745576e-05,
      "loss": 0.1649,
      "step": 87700
    },
    {
      "epoch": 1.8067206140328316,
      "grad_norm": 1.4644639492034912,
      "learning_rate": 1.1942340933410157e-05,
      "loss": 0.1861,
      "step": 87800
    },
    {
      "epoch": 1.8087783648083462,
      "grad_norm": 3.4788930416107178,
      "learning_rate": 1.1921968886328093e-05,
      "loss": 0.1871,
      "step": 87900
    },
    {
      "epoch": 1.810836115583861,
      "grad_norm": 9.686370849609375,
      "learning_rate": 1.1901391060992675e-05,
      "loss": 0.1668,
      "step": 88000
    },
    {
      "epoch": 1.8128938663593759,
      "grad_norm": 2.8655989170074463,
      "learning_rate": 1.1880813235657257e-05,
      "loss": 0.1785,
      "step": 88100
    },
    {
      "epoch": 1.8149516171348907,
      "grad_norm": 8.631932258605957,
      "learning_rate": 1.1860235410321838e-05,
      "loss": 0.155,
      "step": 88200
    },
    {
      "epoch": 1.8170093679104056,
      "grad_norm": 3.4562275409698486,
      "learning_rate": 1.1839657584986419e-05,
      "loss": 0.1702,
      "step": 88300
    },
    {
      "epoch": 1.8190671186859202,
      "grad_norm": 7.254769802093506,
      "learning_rate": 1.1819079759651e-05,
      "loss": 0.169,
      "step": 88400
    },
    {
      "epoch": 1.821124869461435,
      "grad_norm": 3.584866523742676,
      "learning_rate": 1.1798501934315583e-05,
      "loss": 0.1921,
      "step": 88500
    },
    {
      "epoch": 1.8231826202369499,
      "grad_norm": 3.3850865364074707,
      "learning_rate": 1.1777924108980164e-05,
      "loss": 0.1734,
      "step": 88600
    },
    {
      "epoch": 1.8252403710124647,
      "grad_norm": 4.827425956726074,
      "learning_rate": 1.1757346283644745e-05,
      "loss": 0.1889,
      "step": 88700
    },
    {
      "epoch": 1.8272981217879796,
      "grad_norm": 1.644006371498108,
      "learning_rate": 1.1736768458309326e-05,
      "loss": 0.1816,
      "step": 88800
    },
    {
      "epoch": 1.8293558725634944,
      "grad_norm": 0.9111657738685608,
      "learning_rate": 1.1716190632973907e-05,
      "loss": 0.1535,
      "step": 88900
    },
    {
      "epoch": 1.8314136233390093,
      "grad_norm": 2.5357744693756104,
      "learning_rate": 1.1695612807638488e-05,
      "loss": 0.1859,
      "step": 89000
    },
    {
      "epoch": 1.833471374114524,
      "grad_norm": 2.679115056991577,
      "learning_rate": 1.1675034982303071e-05,
      "loss": 0.1824,
      "step": 89100
    },
    {
      "epoch": 1.835529124890039,
      "grad_norm": 1.8364030122756958,
      "learning_rate": 1.1654457156967652e-05,
      "loss": 0.1889,
      "step": 89200
    },
    {
      "epoch": 1.8375868756655538,
      "grad_norm": 2.084099531173706,
      "learning_rate": 1.1633879331632233e-05,
      "loss": 0.1589,
      "step": 89300
    },
    {
      "epoch": 1.8396446264410686,
      "grad_norm": 3.9234838485717773,
      "learning_rate": 1.1613301506296814e-05,
      "loss": 0.1758,
      "step": 89400
    },
    {
      "epoch": 1.8417023772165835,
      "grad_norm": 2.7189204692840576,
      "learning_rate": 1.1592723680961395e-05,
      "loss": 0.2037,
      "step": 89500
    },
    {
      "epoch": 1.8437601279920983,
      "grad_norm": 1.2565882205963135,
      "learning_rate": 1.1572145855625978e-05,
      "loss": 0.169,
      "step": 89600
    },
    {
      "epoch": 1.8458178787676132,
      "grad_norm": 2.543661594390869,
      "learning_rate": 1.155156803029056e-05,
      "loss": 0.1515,
      "step": 89700
    },
    {
      "epoch": 1.847875629543128,
      "grad_norm": 1.8542978763580322,
      "learning_rate": 1.153099020495514e-05,
      "loss": 0.1668,
      "step": 89800
    },
    {
      "epoch": 1.8499333803186429,
      "grad_norm": 3.2552974224090576,
      "learning_rate": 1.1510412379619722e-05,
      "loss": 0.157,
      "step": 89900
    },
    {
      "epoch": 1.8519911310941577,
      "grad_norm": 5.041701316833496,
      "learning_rate": 1.1490040332537659e-05,
      "loss": 0.1676,
      "step": 90000
    },
    {
      "epoch": 1.8519911310941577,
      "eval_accuracy": 0.8368126272912424,
      "eval_f1_contradiction": 0.8414918414918415,
      "eval_loss": 0.1540929675102234,
      "eval_runtime": 79.5017,
      "eval_samples_per_second": 49.408,
      "eval_steps_per_second": 6.176,
      "step": 90000
    },
    {
      "epoch": 1.8540488818696723,
      "grad_norm": 1.0719181299209595,
      "learning_rate": 1.146946250720224e-05,
      "loss": 0.176,
      "step": 90100
    },
    {
      "epoch": 1.8561066326451872,
      "grad_norm": 1.0313506126403809,
      "learning_rate": 1.1448884681866821e-05,
      "loss": 0.1877,
      "step": 90200
    },
    {
      "epoch": 1.858164383420702,
      "grad_norm": 0.9711193442344666,
      "learning_rate": 1.1428306856531402e-05,
      "loss": 0.1737,
      "step": 90300
    },
    {
      "epoch": 1.8602221341962168,
      "grad_norm": 3.2748706340789795,
      "learning_rate": 1.1407729031195983e-05,
      "loss": 0.1682,
      "step": 90400
    },
    {
      "epoch": 1.8622798849717317,
      "grad_norm": 1.7212945222854614,
      "learning_rate": 1.1387151205860564e-05,
      "loss": 0.1792,
      "step": 90500
    },
    {
      "epoch": 1.8643376357472463,
      "grad_norm": 2.5972740650177,
      "learning_rate": 1.1366573380525147e-05,
      "loss": 0.1852,
      "step": 90600
    },
    {
      "epoch": 1.8663953865227612,
      "grad_norm": 3.0501155853271484,
      "learning_rate": 1.1345995555189728e-05,
      "loss": 0.1934,
      "step": 90700
    },
    {
      "epoch": 1.868453137298276,
      "grad_norm": 4.377586841583252,
      "learning_rate": 1.132541772985431e-05,
      "loss": 0.1705,
      "step": 90800
    },
    {
      "epoch": 1.8705108880737908,
      "grad_norm": 3.9680495262145996,
      "learning_rate": 1.130483990451889e-05,
      "loss": 0.1832,
      "step": 90900
    },
    {
      "epoch": 1.8725686388493057,
      "grad_norm": 0.8555777668952942,
      "learning_rate": 1.1284262079183471e-05,
      "loss": 0.1975,
      "step": 91000
    },
    {
      "epoch": 1.8746263896248205,
      "grad_norm": 4.712847709655762,
      "learning_rate": 1.1263684253848054e-05,
      "loss": 0.1696,
      "step": 91100
    },
    {
      "epoch": 1.8766841404003354,
      "grad_norm": 2.6212496757507324,
      "learning_rate": 1.1243106428512635e-05,
      "loss": 0.1849,
      "step": 91200
    },
    {
      "epoch": 1.8787418911758502,
      "grad_norm": 2.4811995029449463,
      "learning_rate": 1.1222528603177216e-05,
      "loss": 0.1897,
      "step": 91300
    },
    {
      "epoch": 1.880799641951365,
      "grad_norm": 0.9889414310455322,
      "learning_rate": 1.1201950777841798e-05,
      "loss": 0.1558,
      "step": 91400
    },
    {
      "epoch": 1.88285739272688,
      "grad_norm": 2.0474376678466797,
      "learning_rate": 1.1181372952506379e-05,
      "loss": 0.1665,
      "step": 91500
    },
    {
      "epoch": 1.8849151435023948,
      "grad_norm": 3.1070637702941895,
      "learning_rate": 1.116079512717096e-05,
      "loss": 0.1854,
      "step": 91600
    },
    {
      "epoch": 1.8869728942779096,
      "grad_norm": 3.2011144161224365,
      "learning_rate": 1.1140217301835543e-05,
      "loss": 0.1659,
      "step": 91700
    },
    {
      "epoch": 1.8890306450534244,
      "grad_norm": 1.5198873281478882,
      "learning_rate": 1.1119639476500124e-05,
      "loss": 0.1694,
      "step": 91800
    },
    {
      "epoch": 1.8910883958289393,
      "grad_norm": 2.7000811100006104,
      "learning_rate": 1.1099061651164705e-05,
      "loss": 0.1854,
      "step": 91900
    },
    {
      "epoch": 1.8931461466044541,
      "grad_norm": 1.0714455842971802,
      "learning_rate": 1.1078483825829286e-05,
      "loss": 0.1771,
      "step": 92000
    },
    {
      "epoch": 1.895203897379969,
      "grad_norm": 1.9156571626663208,
      "learning_rate": 1.1058111778747223e-05,
      "loss": 0.1791,
      "step": 92100
    },
    {
      "epoch": 1.8972616481554836,
      "grad_norm": 1.8444762229919434,
      "learning_rate": 1.1037533953411804e-05,
      "loss": 0.1562,
      "step": 92200
    },
    {
      "epoch": 1.8993193989309984,
      "grad_norm": 2.869678497314453,
      "learning_rate": 1.1016956128076385e-05,
      "loss": 0.1531,
      "step": 92300
    },
    {
      "epoch": 1.9013771497065133,
      "grad_norm": 6.9357829093933105,
      "learning_rate": 1.0996378302740966e-05,
      "loss": 0.1583,
      "step": 92400
    },
    {
      "epoch": 1.9034349004820281,
      "grad_norm": 6.283714771270752,
      "learning_rate": 1.0975800477405547e-05,
      "loss": 0.1983,
      "step": 92500
    },
    {
      "epoch": 1.905492651257543,
      "grad_norm": 1.9167660474777222,
      "learning_rate": 1.0955222652070129e-05,
      "loss": 0.1787,
      "step": 92600
    },
    {
      "epoch": 1.9075504020330578,
      "grad_norm": 1.9746007919311523,
      "learning_rate": 1.0934644826734711e-05,
      "loss": 0.1759,
      "step": 92700
    },
    {
      "epoch": 1.9096081528085724,
      "grad_norm": 4.18122673034668,
      "learning_rate": 1.0914067001399292e-05,
      "loss": 0.1608,
      "step": 92800
    },
    {
      "epoch": 1.9116659035840873,
      "grad_norm": 1.7174934148788452,
      "learning_rate": 1.0893489176063874e-05,
      "loss": 0.1839,
      "step": 92900
    },
    {
      "epoch": 1.9137236543596021,
      "grad_norm": 1.2631251811981201,
      "learning_rate": 1.0872911350728455e-05,
      "loss": 0.1783,
      "step": 93000
    },
    {
      "epoch": 1.915781405135117,
      "grad_norm": 1.3459302186965942,
      "learning_rate": 1.0852333525393036e-05,
      "loss": 0.1799,
      "step": 93100
    },
    {
      "epoch": 1.9178391559106318,
      "grad_norm": 2.7090463638305664,
      "learning_rate": 1.0831755700057619e-05,
      "loss": 0.1816,
      "step": 93200
    },
    {
      "epoch": 1.9198969066861467,
      "grad_norm": 1.9699763059616089,
      "learning_rate": 1.08111778747222e-05,
      "loss": 0.1526,
      "step": 93300
    },
    {
      "epoch": 1.9219546574616615,
      "grad_norm": 2.2183191776275635,
      "learning_rate": 1.079060004938678e-05,
      "loss": 0.1703,
      "step": 93400
    },
    {
      "epoch": 1.9240124082371763,
      "grad_norm": 2.590775489807129,
      "learning_rate": 1.0770022224051362e-05,
      "loss": 0.1642,
      "step": 93500
    },
    {
      "epoch": 1.9260701590126912,
      "grad_norm": 1.31861412525177,
      "learning_rate": 1.0749444398715943e-05,
      "loss": 0.1759,
      "step": 93600
    },
    {
      "epoch": 1.928127909788206,
      "grad_norm": 1.2986427545547485,
      "learning_rate": 1.0728866573380524e-05,
      "loss": 0.161,
      "step": 93700
    },
    {
      "epoch": 1.9301856605637209,
      "grad_norm": 0.17340347170829773,
      "learning_rate": 1.0708288748045107e-05,
      "loss": 0.1986,
      "step": 93800
    },
    {
      "epoch": 1.9322434113392357,
      "grad_norm": 1.9155845642089844,
      "learning_rate": 1.0687710922709688e-05,
      "loss": 0.1804,
      "step": 93900
    },
    {
      "epoch": 1.9343011621147506,
      "grad_norm": 4.496330738067627,
      "learning_rate": 1.0667133097374269e-05,
      "loss": 0.1743,
      "step": 94000
    },
    {
      "epoch": 1.9363589128902654,
      "grad_norm": 3.3867576122283936,
      "learning_rate": 1.0646761050292205e-05,
      "loss": 0.1668,
      "step": 94100
    },
    {
      "epoch": 1.9384166636657802,
      "grad_norm": 2.8285694122314453,
      "learning_rate": 1.0626183224956787e-05,
      "loss": 0.1677,
      "step": 94200
    },
    {
      "epoch": 1.940474414441295,
      "grad_norm": 8.223749160766602,
      "learning_rate": 1.0605605399621368e-05,
      "loss": 0.182,
      "step": 94300
    },
    {
      "epoch": 1.9425321652168097,
      "grad_norm": 0.7571973204612732,
      "learning_rate": 1.058502757428595e-05,
      "loss": 0.1562,
      "step": 94400
    },
    {
      "epoch": 1.9445899159923246,
      "grad_norm": 2.7787911891937256,
      "learning_rate": 1.056444974895053e-05,
      "loss": 0.1773,
      "step": 94500
    },
    {
      "epoch": 1.9466476667678394,
      "grad_norm": 3.0258781909942627,
      "learning_rate": 1.0543871923615112e-05,
      "loss": 0.1765,
      "step": 94600
    },
    {
      "epoch": 1.9487054175433542,
      "grad_norm": 2.9949333667755127,
      "learning_rate": 1.0523294098279693e-05,
      "loss": 0.176,
      "step": 94700
    },
    {
      "epoch": 1.950763168318869,
      "grad_norm": 3.0361270904541016,
      "learning_rate": 1.0502716272944276e-05,
      "loss": 0.1794,
      "step": 94800
    },
    {
      "epoch": 1.952820919094384,
      "grad_norm": 2.391089677810669,
      "learning_rate": 1.0482138447608857e-05,
      "loss": 0.1727,
      "step": 94900
    },
    {
      "epoch": 1.9548786698698986,
      "grad_norm": 4.112573623657227,
      "learning_rate": 1.0461560622273438e-05,
      "loss": 0.1868,
      "step": 95000
    },
    {
      "epoch": 1.9569364206454134,
      "grad_norm": 2.0025219917297363,
      "learning_rate": 1.0440982796938019e-05,
      "loss": 0.1671,
      "step": 95100
    },
    {
      "epoch": 1.9589941714209282,
      "grad_norm": 5.836048603057861,
      "learning_rate": 1.04204049716026e-05,
      "loss": 0.1765,
      "step": 95200
    },
    {
      "epoch": 1.961051922196443,
      "grad_norm": 0.512391984462738,
      "learning_rate": 1.0399827146267183e-05,
      "loss": 0.174,
      "step": 95300
    },
    {
      "epoch": 1.963109672971958,
      "grad_norm": 1.4751843214035034,
      "learning_rate": 1.0379249320931764e-05,
      "loss": 0.1689,
      "step": 95400
    },
    {
      "epoch": 1.9651674237474728,
      "grad_norm": 4.605969429016113,
      "learning_rate": 1.0358671495596345e-05,
      "loss": 0.1348,
      "step": 95500
    },
    {
      "epoch": 1.9672251745229876,
      "grad_norm": 2.8458430767059326,
      "learning_rate": 1.0338093670260926e-05,
      "loss": 0.1736,
      "step": 95600
    },
    {
      "epoch": 1.9692829252985025,
      "grad_norm": 3.399348735809326,
      "learning_rate": 1.0317515844925507e-05,
      "loss": 0.1803,
      "step": 95700
    },
    {
      "epoch": 1.9713406760740173,
      "grad_norm": 0.5279544591903687,
      "learning_rate": 1.0296938019590088e-05,
      "loss": 0.1909,
      "step": 95800
    },
    {
      "epoch": 1.9733984268495322,
      "grad_norm": 1.9945216178894043,
      "learning_rate": 1.0276360194254671e-05,
      "loss": 0.167,
      "step": 95900
    },
    {
      "epoch": 1.975456177625047,
      "grad_norm": 2.757519483566284,
      "learning_rate": 1.0255782368919252e-05,
      "loss": 0.1906,
      "step": 96000
    },
    {
      "epoch": 1.9775139284005618,
      "grad_norm": 2.3132057189941406,
      "learning_rate": 1.0235410321837188e-05,
      "loss": 0.1714,
      "step": 96100
    },
    {
      "epoch": 1.9795716791760767,
      "grad_norm": 1.221313238143921,
      "learning_rate": 1.0214832496501769e-05,
      "loss": 0.1976,
      "step": 96200
    },
    {
      "epoch": 1.9816294299515915,
      "grad_norm": 1.1654554605484009,
      "learning_rate": 1.0194254671166352e-05,
      "loss": 0.1552,
      "step": 96300
    },
    {
      "epoch": 1.9836871807271064,
      "grad_norm": 6.55230188369751,
      "learning_rate": 1.0173676845830933e-05,
      "loss": 0.1784,
      "step": 96400
    },
    {
      "epoch": 1.9857449315026212,
      "grad_norm": 4.446156978607178,
      "learning_rate": 1.0153099020495514e-05,
      "loss": 0.1745,
      "step": 96500
    },
    {
      "epoch": 1.9878026822781358,
      "grad_norm": 2.888605833053589,
      "learning_rate": 1.0132521195160095e-05,
      "loss": 0.1906,
      "step": 96600
    },
    {
      "epoch": 1.9898604330536507,
      "grad_norm": 4.1822285652160645,
      "learning_rate": 1.0111943369824676e-05,
      "loss": 0.1967,
      "step": 96700
    },
    {
      "epoch": 1.9919181838291655,
      "grad_norm": 3.797201156616211,
      "learning_rate": 1.0091365544489259e-05,
      "loss": 0.1687,
      "step": 96800
    },
    {
      "epoch": 1.9939759346046804,
      "grad_norm": 4.789938926696777,
      "learning_rate": 1.007078771915384e-05,
      "loss": 0.1821,
      "step": 96900
    },
    {
      "epoch": 1.9960336853801952,
      "grad_norm": 3.6397688388824463,
      "learning_rate": 1.0050209893818421e-05,
      "loss": 0.1921,
      "step": 97000
    },
    {
      "epoch": 1.99809143615571,
      "grad_norm": 5.182107925415039,
      "learning_rate": 1.0029632068483002e-05,
      "loss": 0.1674,
      "step": 97100
    },
    {
      "epoch": 2.000164620062041,
      "grad_norm": 0.8559210896492004,
      "learning_rate": 1.0009054243147583e-05,
      "loss": 0.1659,
      "step": 97200
    },
    {
      "epoch": 2.002222370837556,
      "grad_norm": 3.7620596885681152,
      "learning_rate": 9.988476417812164e-06,
      "loss": 0.1606,
      "step": 97300
    },
    {
      "epoch": 2.004280121613071,
      "grad_norm": 3.379542589187622,
      "learning_rate": 9.967898592476747e-06,
      "loss": 0.1554,
      "step": 97400
    },
    {
      "epoch": 2.0063378723885856,
      "grad_norm": 4.6604108810424805,
      "learning_rate": 9.947320767141328e-06,
      "loss": 0.1502,
      "step": 97500
    },
    {
      "epoch": 2.0083956231641005,
      "grad_norm": 5.030571937561035,
      "learning_rate": 9.92674294180591e-06,
      "loss": 0.1433,
      "step": 97600
    },
    {
      "epoch": 2.0104533739396153,
      "grad_norm": 1.5256208181381226,
      "learning_rate": 9.90616511647049e-06,
      "loss": 0.1774,
      "step": 97700
    },
    {
      "epoch": 2.01251112471513,
      "grad_norm": 2.362462043762207,
      "learning_rate": 9.885587291135072e-06,
      "loss": 0.1701,
      "step": 97800
    },
    {
      "epoch": 2.014568875490645,
      "grad_norm": 2.6160800457000732,
      "learning_rate": 9.865009465799656e-06,
      "loss": 0.1447,
      "step": 97900
    },
    {
      "epoch": 2.01662662626616,
      "grad_norm": 0.4242991805076599,
      "learning_rate": 9.844431640464237e-06,
      "loss": 0.1678,
      "step": 98000
    },
    {
      "epoch": 2.0186843770416747,
      "grad_norm": 3.741288661956787,
      "learning_rate": 9.823853815128818e-06,
      "loss": 0.1856,
      "step": 98100
    },
    {
      "epoch": 2.0207421278171895,
      "grad_norm": 4.050252914428711,
      "learning_rate": 9.803481768046752e-06,
      "loss": 0.1801,
      "step": 98200
    },
    {
      "epoch": 2.0227998785927044,
      "grad_norm": 3.219271659851074,
      "learning_rate": 9.782903942711333e-06,
      "loss": 0.1836,
      "step": 98300
    },
    {
      "epoch": 2.0248576293682192,
      "grad_norm": 1.5755467414855957,
      "learning_rate": 9.762326117375916e-06,
      "loss": 0.1677,
      "step": 98400
    },
    {
      "epoch": 2.026915380143734,
      "grad_norm": 1.6764816045761108,
      "learning_rate": 9.741748292040497e-06,
      "loss": 0.1703,
      "step": 98500
    },
    {
      "epoch": 2.028973130919249,
      "grad_norm": 1.6655622720718384,
      "learning_rate": 9.721170466705078e-06,
      "loss": 0.1692,
      "step": 98600
    },
    {
      "epoch": 2.0310308816947638,
      "grad_norm": 0.35371318459510803,
      "learning_rate": 9.70059264136966e-06,
      "loss": 0.1542,
      "step": 98700
    },
    {
      "epoch": 2.033088632470278,
      "grad_norm": 2.6832566261291504,
      "learning_rate": 9.68001481603424e-06,
      "loss": 0.1485,
      "step": 98800
    },
    {
      "epoch": 2.035146383245793,
      "grad_norm": 3.600400924682617,
      "learning_rate": 9.659436990698823e-06,
      "loss": 0.1693,
      "step": 98900
    },
    {
      "epoch": 2.037204134021308,
      "grad_norm": 2.3748650550842285,
      "learning_rate": 9.638859165363404e-06,
      "loss": 0.1635,
      "step": 99000
    },
    {
      "epoch": 2.0392618847968227,
      "grad_norm": 1.5592777729034424,
      "learning_rate": 9.618281340027986e-06,
      "loss": 0.1889,
      "step": 99100
    },
    {
      "epoch": 2.0413196355723375,
      "grad_norm": 2.927422523498535,
      "learning_rate": 9.597703514692567e-06,
      "loss": 0.1611,
      "step": 99200
    },
    {
      "epoch": 2.0433773863478524,
      "grad_norm": 1.4940733909606934,
      "learning_rate": 9.577125689357148e-06,
      "loss": 0.194,
      "step": 99300
    },
    {
      "epoch": 2.045435137123367,
      "grad_norm": 5.794574737548828,
      "learning_rate": 9.556547864021729e-06,
      "loss": 0.159,
      "step": 99400
    },
    {
      "epoch": 2.047492887898882,
      "grad_norm": 2.2510251998901367,
      "learning_rate": 9.535970038686312e-06,
      "loss": 0.1546,
      "step": 99500
    },
    {
      "epoch": 2.049550638674397,
      "grad_norm": 5.012346267700195,
      "learning_rate": 9.515392213350894e-06,
      "loss": 0.1903,
      "step": 99600
    },
    {
      "epoch": 2.0516083894499118,
      "grad_norm": 2.415297031402588,
      "learning_rate": 9.494814388015476e-06,
      "loss": 0.1637,
      "step": 99700
    },
    {
      "epoch": 2.0536661402254266,
      "grad_norm": 2.536255359649658,
      "learning_rate": 9.474236562680057e-06,
      "loss": 0.191,
      "step": 99800
    },
    {
      "epoch": 2.0557238910009414,
      "grad_norm": 3.720759868621826,
      "learning_rate": 9.453658737344638e-06,
      "loss": 0.1606,
      "step": 99900
    },
    {
      "epoch": 2.0577816417764563,
      "grad_norm": 1.7048205137252808,
      "learning_rate": 9.43308091200922e-06,
      "loss": 0.1683,
      "step": 100000
    },
    {
      "epoch": 2.0577816417764563,
      "eval_accuracy": 0.8370672097759674,
      "eval_f1_contradiction": 0.8447681103871215,
      "eval_loss": 0.15426670014858246,
      "eval_runtime": 79.2162,
      "eval_samples_per_second": 49.586,
      "eval_steps_per_second": 6.198,
      "step": 100000
    },
    {
      "epoch": 2.059839392551971,
      "grad_norm": 6.4018168449401855,
      "learning_rate": 9.412503086673802e-06,
      "loss": 0.1947,
      "step": 100100
    },
    {
      "epoch": 2.061897143327486,
      "grad_norm": 2.0310218334198,
      "learning_rate": 9.392131039591735e-06,
      "loss": 0.1703,
      "step": 100200
    },
    {
      "epoch": 2.063954894103001,
      "grad_norm": 3.830282211303711,
      "learning_rate": 9.371553214256317e-06,
      "loss": 0.1697,
      "step": 100300
    },
    {
      "epoch": 2.0660126448785157,
      "grad_norm": 2.951169729232788,
      "learning_rate": 9.3509753889209e-06,
      "loss": 0.1601,
      "step": 100400
    },
    {
      "epoch": 2.0680703956540305,
      "grad_norm": 1.0627766847610474,
      "learning_rate": 9.33039756358548e-06,
      "loss": 0.1781,
      "step": 100500
    },
    {
      "epoch": 2.0701281464295453,
      "grad_norm": 1.4708430767059326,
      "learning_rate": 9.309819738250062e-06,
      "loss": 0.1592,
      "step": 100600
    },
    {
      "epoch": 2.07218589720506,
      "grad_norm": 4.648277282714844,
      "learning_rate": 9.289241912914643e-06,
      "loss": 0.1652,
      "step": 100700
    },
    {
      "epoch": 2.074243647980575,
      "grad_norm": 1.8575152158737183,
      "learning_rate": 9.268664087579224e-06,
      "loss": 0.1821,
      "step": 100800
    },
    {
      "epoch": 2.0763013987560894,
      "grad_norm": 1.3369499444961548,
      "learning_rate": 9.248086262243805e-06,
      "loss": 0.1637,
      "step": 100900
    },
    {
      "epoch": 2.0783591495316043,
      "grad_norm": 6.761248588562012,
      "learning_rate": 9.227508436908388e-06,
      "loss": 0.1738,
      "step": 101000
    },
    {
      "epoch": 2.080416900307119,
      "grad_norm": 5.042257785797119,
      "learning_rate": 9.206930611572969e-06,
      "loss": 0.1886,
      "step": 101100
    },
    {
      "epoch": 2.082474651082634,
      "grad_norm": 3.3605000972747803,
      "learning_rate": 9.186352786237552e-06,
      "loss": 0.156,
      "step": 101200
    },
    {
      "epoch": 2.084532401858149,
      "grad_norm": 2.0075249671936035,
      "learning_rate": 9.165774960902133e-06,
      "loss": 0.1786,
      "step": 101300
    },
    {
      "epoch": 2.0865901526336637,
      "grad_norm": 3.7359421253204346,
      "learning_rate": 9.145197135566714e-06,
      "loss": 0.144,
      "step": 101400
    },
    {
      "epoch": 2.0886479034091785,
      "grad_norm": 3.4645771980285645,
      "learning_rate": 9.124619310231297e-06,
      "loss": 0.1684,
      "step": 101500
    },
    {
      "epoch": 2.0907056541846933,
      "grad_norm": 4.624330997467041,
      "learning_rate": 9.104041484895878e-06,
      "loss": 0.1634,
      "step": 101600
    },
    {
      "epoch": 2.092763404960208,
      "grad_norm": 3.707367181777954,
      "learning_rate": 9.083463659560459e-06,
      "loss": 0.1799,
      "step": 101700
    },
    {
      "epoch": 2.094821155735723,
      "grad_norm": 2.1873676776885986,
      "learning_rate": 9.06288583422504e-06,
      "loss": 0.1669,
      "step": 101800
    },
    {
      "epoch": 2.096878906511238,
      "grad_norm": 1.5344481468200684,
      "learning_rate": 9.042308008889621e-06,
      "loss": 0.148,
      "step": 101900
    },
    {
      "epoch": 2.0989366572867527,
      "grad_norm": 3.076354742050171,
      "learning_rate": 9.021730183554202e-06,
      "loss": 0.1623,
      "step": 102000
    },
    {
      "epoch": 2.1009944080622676,
      "grad_norm": 1.3518410921096802,
      "learning_rate": 9.001152358218785e-06,
      "loss": 0.1768,
      "step": 102100
    },
    {
      "epoch": 2.1030521588377824,
      "grad_norm": 1.1896564960479736,
      "learning_rate": 8.980780311136719e-06,
      "loss": 0.169,
      "step": 102200
    },
    {
      "epoch": 2.1051099096132972,
      "grad_norm": 3.309645891189575,
      "learning_rate": 8.9602024858013e-06,
      "loss": 0.1635,
      "step": 102300
    },
    {
      "epoch": 2.107167660388812,
      "grad_norm": 2.187779426574707,
      "learning_rate": 8.93962466046588e-06,
      "loss": 0.1661,
      "step": 102400
    },
    {
      "epoch": 2.109225411164327,
      "grad_norm": 3.9687631130218506,
      "learning_rate": 8.919046835130464e-06,
      "loss": 0.1714,
      "step": 102500
    },
    {
      "epoch": 2.111283161939842,
      "grad_norm": 3.3698179721832275,
      "learning_rate": 8.898469009795045e-06,
      "loss": 0.1828,
      "step": 102600
    },
    {
      "epoch": 2.1133409127153566,
      "grad_norm": 2.51910662651062,
      "learning_rate": 8.877891184459626e-06,
      "loss": 0.1688,
      "step": 102700
    },
    {
      "epoch": 2.1153986634908715,
      "grad_norm": 2.2106900215148926,
      "learning_rate": 8.857313359124209e-06,
      "loss": 0.1639,
      "step": 102800
    },
    {
      "epoch": 2.1174564142663863,
      "grad_norm": 5.1906962394714355,
      "learning_rate": 8.83673553378879e-06,
      "loss": 0.1468,
      "step": 102900
    },
    {
      "epoch": 2.119514165041901,
      "grad_norm": 3.5541608333587646,
      "learning_rate": 8.816157708453371e-06,
      "loss": 0.1839,
      "step": 103000
    },
    {
      "epoch": 2.121571915817416,
      "grad_norm": 2.507004737854004,
      "learning_rate": 8.795579883117954e-06,
      "loss": 0.1562,
      "step": 103100
    },
    {
      "epoch": 2.1236296665929304,
      "grad_norm": 4.551947116851807,
      "learning_rate": 8.775002057782535e-06,
      "loss": 0.1708,
      "step": 103200
    },
    {
      "epoch": 2.1256874173684452,
      "grad_norm": 4.553584575653076,
      "learning_rate": 8.754424232447116e-06,
      "loss": 0.1542,
      "step": 103300
    },
    {
      "epoch": 2.12774516814396,
      "grad_norm": 2.036776065826416,
      "learning_rate": 8.733846407111697e-06,
      "loss": 0.1789,
      "step": 103400
    },
    {
      "epoch": 2.129802918919475,
      "grad_norm": 1.12000572681427,
      "learning_rate": 8.713268581776278e-06,
      "loss": 0.191,
      "step": 103500
    },
    {
      "epoch": 2.1318606696949898,
      "grad_norm": 2.6558992862701416,
      "learning_rate": 8.692690756440861e-06,
      "loss": 0.1737,
      "step": 103600
    },
    {
      "epoch": 2.1339184204705046,
      "grad_norm": 2.97471284866333,
      "learning_rate": 8.672112931105442e-06,
      "loss": 0.1526,
      "step": 103700
    },
    {
      "epoch": 2.1359761712460195,
      "grad_norm": 1.98668372631073,
      "learning_rate": 8.651535105770023e-06,
      "loss": 0.1647,
      "step": 103800
    },
    {
      "epoch": 2.1380339220215343,
      "grad_norm": 3.486372232437134,
      "learning_rate": 8.630957280434604e-06,
      "loss": 0.1813,
      "step": 103900
    },
    {
      "epoch": 2.140091672797049,
      "grad_norm": 3.181793451309204,
      "learning_rate": 8.610379455099185e-06,
      "loss": 0.2054,
      "step": 104000
    },
    {
      "epoch": 2.142149423572564,
      "grad_norm": 6.466932773590088,
      "learning_rate": 8.589801629763766e-06,
      "loss": 0.1621,
      "step": 104100
    },
    {
      "epoch": 2.144207174348079,
      "grad_norm": 0.9070886969566345,
      "learning_rate": 8.56922380442835e-06,
      "loss": 0.1452,
      "step": 104200
    },
    {
      "epoch": 2.1462649251235937,
      "grad_norm": 2.0117907524108887,
      "learning_rate": 8.548851757346283e-06,
      "loss": 0.1739,
      "step": 104300
    },
    {
      "epoch": 2.1483226758991085,
      "grad_norm": 2.865987777709961,
      "learning_rate": 8.528273932010864e-06,
      "loss": 0.191,
      "step": 104400
    },
    {
      "epoch": 2.1503804266746234,
      "grad_norm": 3.1462464332580566,
      "learning_rate": 8.507696106675447e-06,
      "loss": 0.1578,
      "step": 104500
    },
    {
      "epoch": 2.152438177450138,
      "grad_norm": 3.56783127784729,
      "learning_rate": 8.48711828134003e-06,
      "loss": 0.174,
      "step": 104600
    },
    {
      "epoch": 2.154495928225653,
      "grad_norm": 5.067116737365723,
      "learning_rate": 8.46654045600461e-06,
      "loss": 0.1764,
      "step": 104700
    },
    {
      "epoch": 2.156553679001168,
      "grad_norm": 2.32694935798645,
      "learning_rate": 8.445962630669192e-06,
      "loss": 0.1822,
      "step": 104800
    },
    {
      "epoch": 2.1586114297766827,
      "grad_norm": 4.583948135375977,
      "learning_rate": 8.425384805333773e-06,
      "loss": 0.1504,
      "step": 104900
    },
    {
      "epoch": 2.1606691805521976,
      "grad_norm": 5.09554386138916,
      "learning_rate": 8.404806979998354e-06,
      "loss": 0.1779,
      "step": 105000
    },
    {
      "epoch": 2.1627269313277124,
      "grad_norm": 2.091315746307373,
      "learning_rate": 8.384229154662935e-06,
      "loss": 0.1802,
      "step": 105100
    },
    {
      "epoch": 2.1647846821032273,
      "grad_norm": 2.9501192569732666,
      "learning_rate": 8.363651329327518e-06,
      "loss": 0.1739,
      "step": 105200
    },
    {
      "epoch": 2.1668424328787417,
      "grad_norm": 3.426306962966919,
      "learning_rate": 8.343073503992099e-06,
      "loss": 0.1645,
      "step": 105300
    },
    {
      "epoch": 2.1689001836542565,
      "grad_norm": 0.5209833979606628,
      "learning_rate": 8.32249567865668e-06,
      "loss": 0.1846,
      "step": 105400
    },
    {
      "epoch": 2.1709579344297714,
      "grad_norm": 1.3720483779907227,
      "learning_rate": 8.301917853321261e-06,
      "loss": 0.1687,
      "step": 105500
    },
    {
      "epoch": 2.173015685205286,
      "grad_norm": 1.5743170976638794,
      "learning_rate": 8.281340027985842e-06,
      "loss": 0.155,
      "step": 105600
    },
    {
      "epoch": 2.175073435980801,
      "grad_norm": 6.095179557800293,
      "learning_rate": 8.260762202650425e-06,
      "loss": 0.1653,
      "step": 105700
    },
    {
      "epoch": 2.177131186756316,
      "grad_norm": 1.399053692817688,
      "learning_rate": 8.240184377315006e-06,
      "loss": 0.1649,
      "step": 105800
    },
    {
      "epoch": 2.1791889375318307,
      "grad_norm": 6.147397041320801,
      "learning_rate": 8.219606551979587e-06,
      "loss": 0.151,
      "step": 105900
    },
    {
      "epoch": 2.1812466883073456,
      "grad_norm": 2.6390111446380615,
      "learning_rate": 8.199028726644169e-06,
      "loss": 0.1667,
      "step": 106000
    },
    {
      "epoch": 2.1833044390828604,
      "grad_norm": 2.2884581089019775,
      "learning_rate": 8.17845090130875e-06,
      "loss": 0.1535,
      "step": 106100
    },
    {
      "epoch": 2.1853621898583753,
      "grad_norm": 3.9712741374969482,
      "learning_rate": 8.15787307597333e-06,
      "loss": 0.1679,
      "step": 106200
    },
    {
      "epoch": 2.18741994063389,
      "grad_norm": 6.4368791580200195,
      "learning_rate": 8.137295250637914e-06,
      "loss": 0.1592,
      "step": 106300
    },
    {
      "epoch": 2.189477691409405,
      "grad_norm": 3.151299238204956,
      "learning_rate": 8.116923203555849e-06,
      "loss": 0.1758,
      "step": 106400
    },
    {
      "epoch": 2.19153544218492,
      "grad_norm": 1.7791067361831665,
      "learning_rate": 8.09634537822043e-06,
      "loss": 0.1755,
      "step": 106500
    },
    {
      "epoch": 2.1935931929604346,
      "grad_norm": 0.8875295519828796,
      "learning_rate": 8.075767552885011e-06,
      "loss": 0.1684,
      "step": 106600
    },
    {
      "epoch": 2.1956509437359495,
      "grad_norm": 0.7745121121406555,
      "learning_rate": 8.055189727549594e-06,
      "loss": 0.1803,
      "step": 106700
    },
    {
      "epoch": 2.1977086945114643,
      "grad_norm": 0.34251081943511963,
      "learning_rate": 8.034611902214175e-06,
      "loss": 0.1643,
      "step": 106800
    },
    {
      "epoch": 2.199766445286979,
      "grad_norm": 2.6159770488739014,
      "learning_rate": 8.014034076878756e-06,
      "loss": 0.156,
      "step": 106900
    },
    {
      "epoch": 2.201824196062494,
      "grad_norm": 2.669562339782715,
      "learning_rate": 7.993456251543337e-06,
      "loss": 0.1826,
      "step": 107000
    },
    {
      "epoch": 2.203881946838009,
      "grad_norm": 3.5498082637786865,
      "learning_rate": 7.972878426207918e-06,
      "loss": 0.1591,
      "step": 107100
    },
    {
      "epoch": 2.2059396976135237,
      "grad_norm": 2.7765023708343506,
      "learning_rate": 7.952300600872501e-06,
      "loss": 0.1693,
      "step": 107200
    },
    {
      "epoch": 2.2079974483890386,
      "grad_norm": 1.978319525718689,
      "learning_rate": 7.931722775537082e-06,
      "loss": 0.1651,
      "step": 107300
    },
    {
      "epoch": 2.210055199164553,
      "grad_norm": 0.7244328856468201,
      "learning_rate": 7.911144950201663e-06,
      "loss": 0.1738,
      "step": 107400
    },
    {
      "epoch": 2.2121129499400682,
      "grad_norm": 1.025017499923706,
      "learning_rate": 7.890567124866245e-06,
      "loss": 0.1635,
      "step": 107500
    },
    {
      "epoch": 2.2141707007155826,
      "grad_norm": 4.122755527496338,
      "learning_rate": 7.869989299530826e-06,
      "loss": 0.1713,
      "step": 107600
    },
    {
      "epoch": 2.2162284514910975,
      "grad_norm": 5.230240821838379,
      "learning_rate": 7.849411474195407e-06,
      "loss": 0.1667,
      "step": 107700
    },
    {
      "epoch": 2.2182862022666123,
      "grad_norm": 6.9049906730651855,
      "learning_rate": 7.82883364885999e-06,
      "loss": 0.1678,
      "step": 107800
    },
    {
      "epoch": 2.220343953042127,
      "grad_norm": 2.3915603160858154,
      "learning_rate": 7.80825582352457e-06,
      "loss": 0.1682,
      "step": 107900
    },
    {
      "epoch": 2.222401703817642,
      "grad_norm": 1.7186522483825684,
      "learning_rate": 7.787677998189152e-06,
      "loss": 0.1614,
      "step": 108000
    },
    {
      "epoch": 2.224459454593157,
      "grad_norm": 5.621827602386475,
      "learning_rate": 7.767100172853733e-06,
      "loss": 0.1919,
      "step": 108100
    },
    {
      "epoch": 2.2265172053686717,
      "grad_norm": 4.756592273712158,
      "learning_rate": 7.746522347518314e-06,
      "loss": 0.15,
      "step": 108200
    },
    {
      "epoch": 2.2285749561441865,
      "grad_norm": 5.539632797241211,
      "learning_rate": 7.725944522182897e-06,
      "loss": 0.1559,
      "step": 108300
    },
    {
      "epoch": 2.2306327069197014,
      "grad_norm": 1.6488523483276367,
      "learning_rate": 7.705366696847478e-06,
      "loss": 0.1648,
      "step": 108400
    },
    {
      "epoch": 2.2326904576952162,
      "grad_norm": 4.332769393920898,
      "learning_rate": 7.684994649765413e-06,
      "loss": 0.1766,
      "step": 108500
    },
    {
      "epoch": 2.234748208470731,
      "grad_norm": 0.5430420637130737,
      "learning_rate": 7.664416824429994e-06,
      "loss": 0.1637,
      "step": 108600
    },
    {
      "epoch": 2.236805959246246,
      "grad_norm": 2.583909034729004,
      "learning_rate": 7.643838999094576e-06,
      "loss": 0.1577,
      "step": 108700
    },
    {
      "epoch": 2.2388637100217608,
      "grad_norm": 1.620810627937317,
      "learning_rate": 7.6232611737591575e-06,
      "loss": 0.183,
      "step": 108800
    },
    {
      "epoch": 2.2409214607972756,
      "grad_norm": 0.8990463018417358,
      "learning_rate": 7.602683348423739e-06,
      "loss": 0.1608,
      "step": 108900
    },
    {
      "epoch": 2.2429792115727905,
      "grad_norm": 5.1732988357543945,
      "learning_rate": 7.582105523088321e-06,
      "loss": 0.1495,
      "step": 109000
    },
    {
      "epoch": 2.2450369623483053,
      "grad_norm": 1.3971352577209473,
      "learning_rate": 7.561527697752902e-06,
      "loss": 0.1757,
      "step": 109100
    },
    {
      "epoch": 2.24709471312382,
      "grad_norm": 1.4064520597457886,
      "learning_rate": 7.540949872417483e-06,
      "loss": 0.1666,
      "step": 109200
    },
    {
      "epoch": 2.249152463899335,
      "grad_norm": 4.368133068084717,
      "learning_rate": 7.520372047082066e-06,
      "loss": 0.1586,
      "step": 109300
    },
    {
      "epoch": 2.25121021467485,
      "grad_norm": 2.313124179840088,
      "learning_rate": 7.499794221746647e-06,
      "loss": 0.1686,
      "step": 109400
    },
    {
      "epoch": 2.2532679654503642,
      "grad_norm": 2.698554515838623,
      "learning_rate": 7.479216396411228e-06,
      "loss": 0.162,
      "step": 109500
    },
    {
      "epoch": 2.2553257162258795,
      "grad_norm": 0.9136614799499512,
      "learning_rate": 7.458638571075809e-06,
      "loss": 0.1531,
      "step": 109600
    },
    {
      "epoch": 2.257383467001394,
      "grad_norm": 2.2514991760253906,
      "learning_rate": 7.438060745740391e-06,
      "loss": 0.1508,
      "step": 109700
    },
    {
      "epoch": 2.2594412177769088,
      "grad_norm": 2.0705432891845703,
      "learning_rate": 7.417482920404972e-06,
      "loss": 0.1739,
      "step": 109800
    },
    {
      "epoch": 2.2614989685524236,
      "grad_norm": 2.7571375370025635,
      "learning_rate": 7.396905095069553e-06,
      "loss": 0.1976,
      "step": 109900
    },
    {
      "epoch": 2.2635567193279384,
      "grad_norm": 4.39811897277832,
      "learning_rate": 7.376327269734135e-06,
      "loss": 0.164,
      "step": 110000
    },
    {
      "epoch": 2.2635567193279384,
      "eval_accuracy": 0.8391038696537678,
      "eval_f1_contradiction": 0.8439526898130485,
      "eval_loss": 0.15744823217391968,
      "eval_runtime": 66.1626,
      "eval_samples_per_second": 59.369,
      "eval_steps_per_second": 7.421,
      "step": 110000
    },
    {
      "epoch": 2.2656144701034533,
      "grad_norm": 1.8791050910949707,
      "learning_rate": 7.355749444398716e-06,
      "loss": 0.1749,
      "step": 110100
    },
    {
      "epoch": 2.267672220878968,
      "grad_norm": 1.0351011753082275,
      "learning_rate": 7.335171619063297e-06,
      "loss": 0.1704,
      "step": 110200
    },
    {
      "epoch": 2.269729971654483,
      "grad_norm": 5.488029956817627,
      "learning_rate": 7.314593793727879e-06,
      "loss": 0.1755,
      "step": 110300
    },
    {
      "epoch": 2.271787722429998,
      "grad_norm": 1.261389970779419,
      "learning_rate": 7.29401596839246e-06,
      "loss": 0.16,
      "step": 110400
    },
    {
      "epoch": 2.2738454732055127,
      "grad_norm": 2.4620301723480225,
      "learning_rate": 7.273643921310396e-06,
      "loss": 0.1679,
      "step": 110500
    },
    {
      "epoch": 2.2759032239810275,
      "grad_norm": 4.32930326461792,
      "learning_rate": 7.253066095974978e-06,
      "loss": 0.1595,
      "step": 110600
    },
    {
      "epoch": 2.2779609747565424,
      "grad_norm": 2.1501662731170654,
      "learning_rate": 7.23248827063956e-06,
      "loss": 0.1495,
      "step": 110700
    },
    {
      "epoch": 2.280018725532057,
      "grad_norm": 1.68975031375885,
      "learning_rate": 7.211910445304141e-06,
      "loss": 0.1728,
      "step": 110800
    },
    {
      "epoch": 2.282076476307572,
      "grad_norm": 1.5754854679107666,
      "learning_rate": 7.191332619968722e-06,
      "loss": 0.1609,
      "step": 110900
    },
    {
      "epoch": 2.284134227083087,
      "grad_norm": 3.3281092643737793,
      "learning_rate": 7.170754794633304e-06,
      "loss": 0.1621,
      "step": 111000
    },
    {
      "epoch": 2.2861919778586017,
      "grad_norm": 1.725659728050232,
      "learning_rate": 7.150176969297885e-06,
      "loss": 0.1824,
      "step": 111100
    },
    {
      "epoch": 2.2882497286341166,
      "grad_norm": 2.7717087268829346,
      "learning_rate": 7.129599143962466e-06,
      "loss": 0.1859,
      "step": 111200
    },
    {
      "epoch": 2.2903074794096314,
      "grad_norm": 1.7756328582763672,
      "learning_rate": 7.109021318627048e-06,
      "loss": 0.1632,
      "step": 111300
    },
    {
      "epoch": 2.2923652301851463,
      "grad_norm": 2.645587205886841,
      "learning_rate": 7.088443493291629e-06,
      "loss": 0.1738,
      "step": 111400
    },
    {
      "epoch": 2.294422980960661,
      "grad_norm": 2.068640947341919,
      "learning_rate": 7.067865667956211e-06,
      "loss": 0.1588,
      "step": 111500
    },
    {
      "epoch": 2.296480731736176,
      "grad_norm": 5.767068386077881,
      "learning_rate": 7.047287842620792e-06,
      "loss": 0.1603,
      "step": 111600
    },
    {
      "epoch": 2.298538482511691,
      "grad_norm": 2.1044023036956787,
      "learning_rate": 7.026710017285373e-06,
      "loss": 0.147,
      "step": 111700
    },
    {
      "epoch": 2.300596233287205,
      "grad_norm": 6.30472993850708,
      "learning_rate": 7.006132191949955e-06,
      "loss": 0.1678,
      "step": 111800
    },
    {
      "epoch": 2.3026539840627205,
      "grad_norm": 2.4580788612365723,
      "learning_rate": 6.985554366614536e-06,
      "loss": 0.1393,
      "step": 111900
    },
    {
      "epoch": 2.304711734838235,
      "grad_norm": 1.9313520193099976,
      "learning_rate": 6.964976541279117e-06,
      "loss": 0.1745,
      "step": 112000
    },
    {
      "epoch": 2.3067694856137497,
      "grad_norm": 4.9937944412231445,
      "learning_rate": 6.944398715943699e-06,
      "loss": 0.1804,
      "step": 112100
    },
    {
      "epoch": 2.3088272363892646,
      "grad_norm": 4.986326694488525,
      "learning_rate": 6.9238208906082805e-06,
      "loss": 0.1673,
      "step": 112200
    },
    {
      "epoch": 2.3108849871647794,
      "grad_norm": 1.2697350978851318,
      "learning_rate": 6.903243065272862e-06,
      "loss": 0.1778,
      "step": 112300
    },
    {
      "epoch": 2.3129427379402943,
      "grad_norm": 0.608889102935791,
      "learning_rate": 6.8826652399374435e-06,
      "loss": 0.1824,
      "step": 112400
    },
    {
      "epoch": 2.315000488715809,
      "grad_norm": 2.936816692352295,
      "learning_rate": 6.862087414602025e-06,
      "loss": 0.142,
      "step": 112500
    },
    {
      "epoch": 2.317058239491324,
      "grad_norm": 0.6314471364021301,
      "learning_rate": 6.841715367519961e-06,
      "loss": 0.1766,
      "step": 112600
    },
    {
      "epoch": 2.319115990266839,
      "grad_norm": 3.0527503490448,
      "learning_rate": 6.821137542184542e-06,
      "loss": 0.1726,
      "step": 112700
    },
    {
      "epoch": 2.3211737410423536,
      "grad_norm": 2.1125171184539795,
      "learning_rate": 6.800559716849124e-06,
      "loss": 0.1865,
      "step": 112800
    },
    {
      "epoch": 2.3232314918178685,
      "grad_norm": 5.028141975402832,
      "learning_rate": 6.779981891513705e-06,
      "loss": 0.1671,
      "step": 112900
    },
    {
      "epoch": 2.3252892425933833,
      "grad_norm": 5.1057233810424805,
      "learning_rate": 6.759404066178286e-06,
      "loss": 0.1523,
      "step": 113000
    },
    {
      "epoch": 2.327346993368898,
      "grad_norm": 5.4983134269714355,
      "learning_rate": 6.738826240842868e-06,
      "loss": 0.1813,
      "step": 113100
    },
    {
      "epoch": 2.329404744144413,
      "grad_norm": 0.8919934034347534,
      "learning_rate": 6.718248415507449e-06,
      "loss": 0.1526,
      "step": 113200
    },
    {
      "epoch": 2.331462494919928,
      "grad_norm": 4.204981327056885,
      "learning_rate": 6.697670590172031e-06,
      "loss": 0.1602,
      "step": 113300
    },
    {
      "epoch": 2.3335202456954427,
      "grad_norm": 2.618494749069214,
      "learning_rate": 6.677092764836612e-06,
      "loss": 0.1653,
      "step": 113400
    },
    {
      "epoch": 2.3355779964709575,
      "grad_norm": 3.682913303375244,
      "learning_rate": 6.6565149395011934e-06,
      "loss": 0.1644,
      "step": 113500
    },
    {
      "epoch": 2.3376357472464724,
      "grad_norm": 2.543701410293579,
      "learning_rate": 6.635937114165775e-06,
      "loss": 0.1873,
      "step": 113600
    },
    {
      "epoch": 2.3396934980219872,
      "grad_norm": 0.9755991101264954,
      "learning_rate": 6.6153592888303565e-06,
      "loss": 0.1457,
      "step": 113700
    },
    {
      "epoch": 2.341751248797502,
      "grad_norm": 2.718127489089966,
      "learning_rate": 6.594781463494938e-06,
      "loss": 0.1741,
      "step": 113800
    },
    {
      "epoch": 2.3438089995730165,
      "grad_norm": 1.858466386795044,
      "learning_rate": 6.5742036381595195e-06,
      "loss": 0.1714,
      "step": 113900
    },
    {
      "epoch": 2.3458667503485318,
      "grad_norm": 0.815391480922699,
      "learning_rate": 6.553625812824101e-06,
      "loss": 0.1708,
      "step": 114000
    },
    {
      "epoch": 2.347924501124046,
      "grad_norm": 0.8870444893836975,
      "learning_rate": 6.533047987488682e-06,
      "loss": 0.1692,
      "step": 114100
    },
    {
      "epoch": 2.349982251899561,
      "grad_norm": 3.4638633728027344,
      "learning_rate": 6.512470162153264e-06,
      "loss": 0.1703,
      "step": 114200
    },
    {
      "epoch": 2.352040002675076,
      "grad_norm": 5.026411056518555,
      "learning_rate": 6.491892336817845e-06,
      "loss": 0.1741,
      "step": 114300
    },
    {
      "epoch": 2.3540977534505907,
      "grad_norm": 0.44511064887046814,
      "learning_rate": 6.471314511482427e-06,
      "loss": 0.1817,
      "step": 114400
    },
    {
      "epoch": 2.3561555042261055,
      "grad_norm": 3.445869207382202,
      "learning_rate": 6.450736686147008e-06,
      "loss": 0.1545,
      "step": 114500
    },
    {
      "epoch": 2.3582132550016204,
      "grad_norm": 2.773752450942993,
      "learning_rate": 6.430158860811589e-06,
      "loss": 0.1722,
      "step": 114600
    },
    {
      "epoch": 2.3602710057771352,
      "grad_norm": 3.4507508277893066,
      "learning_rate": 6.409786813729525e-06,
      "loss": 0.1647,
      "step": 114700
    },
    {
      "epoch": 2.36232875655265,
      "grad_norm": 0.932746946811676,
      "learning_rate": 6.389208988394106e-06,
      "loss": 0.1759,
      "step": 114800
    },
    {
      "epoch": 2.364386507328165,
      "grad_norm": 2.951517343521118,
      "learning_rate": 6.368631163058688e-06,
      "loss": 0.171,
      "step": 114900
    },
    {
      "epoch": 2.3664442581036798,
      "grad_norm": 3.214142084121704,
      "learning_rate": 6.3480533377232694e-06,
      "loss": 0.1672,
      "step": 115000
    },
    {
      "epoch": 2.3685020088791946,
      "grad_norm": 2.731945037841797,
      "learning_rate": 6.327475512387851e-06,
      "loss": 0.1498,
      "step": 115100
    },
    {
      "epoch": 2.3705597596547094,
      "grad_norm": 7.650960445404053,
      "learning_rate": 6.3068976870524325e-06,
      "loss": 0.1752,
      "step": 115200
    },
    {
      "epoch": 2.3726175104302243,
      "grad_norm": 8.127032279968262,
      "learning_rate": 6.286319861717014e-06,
      "loss": 0.1463,
      "step": 115300
    },
    {
      "epoch": 2.374675261205739,
      "grad_norm": 2.2657129764556885,
      "learning_rate": 6.2657420363815956e-06,
      "loss": 0.1783,
      "step": 115400
    },
    {
      "epoch": 2.376733011981254,
      "grad_norm": 3.354976177215576,
      "learning_rate": 6.245164211046177e-06,
      "loss": 0.1803,
      "step": 115500
    },
    {
      "epoch": 2.378790762756769,
      "grad_norm": 6.972399711608887,
      "learning_rate": 6.224586385710758e-06,
      "loss": 0.1609,
      "step": 115600
    },
    {
      "epoch": 2.3808485135322837,
      "grad_norm": 2.689293146133423,
      "learning_rate": 6.20400856037534e-06,
      "loss": 0.1549,
      "step": 115700
    },
    {
      "epoch": 2.3829062643077985,
      "grad_norm": 1.243627667427063,
      "learning_rate": 6.183430735039921e-06,
      "loss": 0.1543,
      "step": 115800
    },
    {
      "epoch": 2.3849640150833133,
      "grad_norm": 1.3632371425628662,
      "learning_rate": 6.162852909704502e-06,
      "loss": 0.1489,
      "step": 115900
    },
    {
      "epoch": 2.387021765858828,
      "grad_norm": 4.190128326416016,
      "learning_rate": 6.142275084369084e-06,
      "loss": 0.1586,
      "step": 116000
    },
    {
      "epoch": 2.389079516634343,
      "grad_norm": 5.35525369644165,
      "learning_rate": 6.121697259033665e-06,
      "loss": 0.18,
      "step": 116100
    },
    {
      "epoch": 2.3911372674098574,
      "grad_norm": 1.6112626791000366,
      "learning_rate": 6.101119433698247e-06,
      "loss": 0.1685,
      "step": 116200
    },
    {
      "epoch": 2.3931950181853727,
      "grad_norm": 2.7936017513275146,
      "learning_rate": 6.080541608362828e-06,
      "loss": 0.1837,
      "step": 116300
    },
    {
      "epoch": 2.395252768960887,
      "grad_norm": 1.3723684549331665,
      "learning_rate": 6.05996378302741e-06,
      "loss": 0.1737,
      "step": 116400
    },
    {
      "epoch": 2.397310519736402,
      "grad_norm": 2.7391104698181152,
      "learning_rate": 6.039385957691992e-06,
      "loss": 0.1809,
      "step": 116500
    },
    {
      "epoch": 2.399368270511917,
      "grad_norm": 5.0753655433654785,
      "learning_rate": 6.018808132356573e-06,
      "loss": 0.1743,
      "step": 116600
    },
    {
      "epoch": 2.4014260212874317,
      "grad_norm": 0.8201907277107239,
      "learning_rate": 5.9984360852745085e-06,
      "loss": 0.1716,
      "step": 116700
    },
    {
      "epoch": 2.4034837720629465,
      "grad_norm": 3.991903305053711,
      "learning_rate": 5.97785825993909e-06,
      "loss": 0.1555,
      "step": 116800
    },
    {
      "epoch": 2.4055415228384613,
      "grad_norm": 3.5992774963378906,
      "learning_rate": 5.9572804346036716e-06,
      "loss": 0.1802,
      "step": 116900
    },
    {
      "epoch": 2.407599273613976,
      "grad_norm": 4.244687557220459,
      "learning_rate": 5.936702609268253e-06,
      "loss": 0.1487,
      "step": 117000
    },
    {
      "epoch": 2.409657024389491,
      "grad_norm": 3.3181822299957275,
      "learning_rate": 5.916124783932834e-06,
      "loss": 0.1522,
      "step": 117100
    },
    {
      "epoch": 2.411714775165006,
      "grad_norm": 2.333674192428589,
      "learning_rate": 5.895546958597416e-06,
      "loss": 0.1518,
      "step": 117200
    },
    {
      "epoch": 2.4137725259405207,
      "grad_norm": 4.625831127166748,
      "learning_rate": 5.874969133261997e-06,
      "loss": 0.1627,
      "step": 117300
    },
    {
      "epoch": 2.4158302767160356,
      "grad_norm": 1.198460340499878,
      "learning_rate": 5.854391307926578e-06,
      "loss": 0.169,
      "step": 117400
    },
    {
      "epoch": 2.4178880274915504,
      "grad_norm": 2.434295415878296,
      "learning_rate": 5.83381348259116e-06,
      "loss": 0.1806,
      "step": 117500
    },
    {
      "epoch": 2.4199457782670653,
      "grad_norm": 0.9600602984428406,
      "learning_rate": 5.813235657255741e-06,
      "loss": 0.1751,
      "step": 117600
    },
    {
      "epoch": 2.42200352904258,
      "grad_norm": 2.1865234375,
      "learning_rate": 5.792657831920322e-06,
      "loss": 0.1697,
      "step": 117700
    },
    {
      "epoch": 2.424061279818095,
      "grad_norm": 4.870008945465088,
      "learning_rate": 5.772080006584904e-06,
      "loss": 0.1689,
      "step": 117800
    },
    {
      "epoch": 2.42611903059361,
      "grad_norm": 1.0244114398956299,
      "learning_rate": 5.751502181249485e-06,
      "loss": 0.1632,
      "step": 117900
    },
    {
      "epoch": 2.4281767813691246,
      "grad_norm": 1.9051679372787476,
      "learning_rate": 5.730924355914067e-06,
      "loss": 0.153,
      "step": 118000
    },
    {
      "epoch": 2.4302345321446395,
      "grad_norm": 4.3816070556640625,
      "learning_rate": 5.710346530578649e-06,
      "loss": 0.1686,
      "step": 118100
    },
    {
      "epoch": 2.4322922829201543,
      "grad_norm": 3.081834077835083,
      "learning_rate": 5.68976870524323e-06,
      "loss": 0.1622,
      "step": 118200
    },
    {
      "epoch": 2.4343500336956687,
      "grad_norm": 3.562983989715576,
      "learning_rate": 5.669190879907812e-06,
      "loss": 0.1728,
      "step": 118300
    },
    {
      "epoch": 2.436407784471184,
      "grad_norm": 3.973179578781128,
      "learning_rate": 5.648613054572393e-06,
      "loss": 0.1582,
      "step": 118400
    },
    {
      "epoch": 2.4384655352466984,
      "grad_norm": 6.0391621589660645,
      "learning_rate": 5.628035229236974e-06,
      "loss": 0.1609,
      "step": 118500
    },
    {
      "epoch": 2.4405232860222132,
      "grad_norm": 3.481397867202759,
      "learning_rate": 5.607457403901556e-06,
      "loss": 0.1664,
      "step": 118600
    },
    {
      "epoch": 2.442581036797728,
      "grad_norm": 1.5353730916976929,
      "learning_rate": 5.587085356819492e-06,
      "loss": 0.1823,
      "step": 118700
    },
    {
      "epoch": 2.444638787573243,
      "grad_norm": 1.6838982105255127,
      "learning_rate": 5.566507531484073e-06,
      "loss": 0.1578,
      "step": 118800
    },
    {
      "epoch": 2.4466965383487578,
      "grad_norm": 2.047557830810547,
      "learning_rate": 5.545929706148654e-06,
      "loss": 0.1634,
      "step": 118900
    },
    {
      "epoch": 2.4487542891242726,
      "grad_norm": 2.143589973449707,
      "learning_rate": 5.525351880813236e-06,
      "loss": 0.1802,
      "step": 119000
    },
    {
      "epoch": 2.4508120398997875,
      "grad_norm": 3.2304701805114746,
      "learning_rate": 5.504774055477817e-06,
      "loss": 0.1786,
      "step": 119100
    },
    {
      "epoch": 2.4528697906753023,
      "grad_norm": 1.8990323543548584,
      "learning_rate": 5.484196230142398e-06,
      "loss": 0.1707,
      "step": 119200
    },
    {
      "epoch": 2.454927541450817,
      "grad_norm": 0.647040843963623,
      "learning_rate": 5.46361840480698e-06,
      "loss": 0.1667,
      "step": 119300
    },
    {
      "epoch": 2.456985292226332,
      "grad_norm": 11.893153190612793,
      "learning_rate": 5.443040579471561e-06,
      "loss": 0.1975,
      "step": 119400
    },
    {
      "epoch": 2.459043043001847,
      "grad_norm": 1.9745231866836548,
      "learning_rate": 5.422462754136142e-06,
      "loss": 0.173,
      "step": 119500
    },
    {
      "epoch": 2.4611007937773617,
      "grad_norm": 2.130467176437378,
      "learning_rate": 5.401884928800724e-06,
      "loss": 0.1655,
      "step": 119600
    },
    {
      "epoch": 2.4631585445528765,
      "grad_norm": 0.44346368312835693,
      "learning_rate": 5.381307103465306e-06,
      "loss": 0.1721,
      "step": 119700
    },
    {
      "epoch": 2.4652162953283914,
      "grad_norm": 2.113520860671997,
      "learning_rate": 5.360729278129888e-06,
      "loss": 0.1731,
      "step": 119800
    },
    {
      "epoch": 2.467274046103906,
      "grad_norm": 1.660825252532959,
      "learning_rate": 5.340151452794469e-06,
      "loss": 0.1525,
      "step": 119900
    },
    {
      "epoch": 2.469331796879421,
      "grad_norm": 4.656801223754883,
      "learning_rate": 5.31957362745905e-06,
      "loss": 0.1732,
      "step": 120000
    },
    {
      "epoch": 2.469331796879421,
      "eval_accuracy": 0.8375763747454175,
      "eval_f1_contradiction": 0.8431896222815719,
      "eval_loss": 0.15479959547519684,
      "eval_runtime": 78.2964,
      "eval_samples_per_second": 50.168,
      "eval_steps_per_second": 6.271,
      "step": 120000
    },
    {
      "epoch": 2.471389547654936,
      "grad_norm": 4.883155345916748,
      "learning_rate": 5.298995802123632e-06,
      "loss": 0.1518,
      "step": 120100
    },
    {
      "epoch": 2.4734472984304507,
      "grad_norm": 3.769827127456665,
      "learning_rate": 5.278417976788213e-06,
      "loss": 0.1677,
      "step": 120200
    },
    {
      "epoch": 2.4755050492059656,
      "grad_norm": 3.9381515979766846,
      "learning_rate": 5.2578401514527945e-06,
      "loss": 0.1654,
      "step": 120300
    },
    {
      "epoch": 2.4775627999814804,
      "grad_norm": 0.9807397127151489,
      "learning_rate": 5.2372623261173765e-06,
      "loss": 0.1448,
      "step": 120400
    },
    {
      "epoch": 2.4796205507569953,
      "grad_norm": 1.1171884536743164,
      "learning_rate": 5.216684500781958e-06,
      "loss": 0.1722,
      "step": 120500
    },
    {
      "epoch": 2.4816783015325097,
      "grad_norm": 4.451547145843506,
      "learning_rate": 5.196106675446539e-06,
      "loss": 0.1682,
      "step": 120600
    },
    {
      "epoch": 2.4837360523080245,
      "grad_norm": 5.595132827758789,
      "learning_rate": 5.175734628364474e-06,
      "loss": 0.1631,
      "step": 120700
    },
    {
      "epoch": 2.4857938030835394,
      "grad_norm": 3.147885322570801,
      "learning_rate": 5.155156803029056e-06,
      "loss": 0.1742,
      "step": 120800
    },
    {
      "epoch": 2.487851553859054,
      "grad_norm": 1.5978131294250488,
      "learning_rate": 5.134578977693637e-06,
      "loss": 0.1604,
      "step": 120900
    },
    {
      "epoch": 2.489909304634569,
      "grad_norm": 1.209723711013794,
      "learning_rate": 5.114001152358218e-06,
      "loss": 0.1671,
      "step": 121000
    },
    {
      "epoch": 2.491967055410084,
      "grad_norm": 4.646884918212891,
      "learning_rate": 5.0934233270228e-06,
      "loss": 0.1686,
      "step": 121100
    },
    {
      "epoch": 2.4940248061855987,
      "grad_norm": 5.086514472961426,
      "learning_rate": 5.072845501687381e-06,
      "loss": 0.1791,
      "step": 121200
    },
    {
      "epoch": 2.4960825569611136,
      "grad_norm": 3.357492208480835,
      "learning_rate": 5.052267676351963e-06,
      "loss": 0.1673,
      "step": 121300
    },
    {
      "epoch": 2.4981403077366284,
      "grad_norm": 1.073957920074463,
      "learning_rate": 5.031689851016545e-06,
      "loss": 0.1589,
      "step": 121400
    },
    {
      "epoch": 2.5001980585121433,
      "grad_norm": 3.345364570617676,
      "learning_rate": 5.011112025681126e-06,
      "loss": 0.1651,
      "step": 121500
    },
    {
      "epoch": 2.502255809287658,
      "grad_norm": 5.0549445152282715,
      "learning_rate": 4.9905342003457075e-06,
      "loss": 0.1857,
      "step": 121600
    },
    {
      "epoch": 2.504313560063173,
      "grad_norm": 3.1438398361206055,
      "learning_rate": 4.9699563750102894e-06,
      "loss": 0.1691,
      "step": 121700
    },
    {
      "epoch": 2.506371310838688,
      "grad_norm": 4.421518802642822,
      "learning_rate": 4.9493785496748705e-06,
      "loss": 0.1677,
      "step": 121800
    },
    {
      "epoch": 2.5084290616142026,
      "grad_norm": 4.147332668304443,
      "learning_rate": 4.9288007243394525e-06,
      "loss": 0.1818,
      "step": 121900
    },
    {
      "epoch": 2.5104868123897175,
      "grad_norm": 0.5560635924339294,
      "learning_rate": 4.908222899004034e-06,
      "loss": 0.1466,
      "step": 122000
    },
    {
      "epoch": 2.5125445631652323,
      "grad_norm": 2.404719114303589,
      "learning_rate": 4.887645073668615e-06,
      "loss": 0.1664,
      "step": 122100
    },
    {
      "epoch": 2.514602313940747,
      "grad_norm": 2.7595107555389404,
      "learning_rate": 4.867067248333197e-06,
      "loss": 0.1776,
      "step": 122200
    },
    {
      "epoch": 2.516660064716262,
      "grad_norm": 3.0548551082611084,
      "learning_rate": 4.846489422997778e-06,
      "loss": 0.1714,
      "step": 122300
    },
    {
      "epoch": 2.518717815491777,
      "grad_norm": 2.2037901878356934,
      "learning_rate": 4.825911597662359e-06,
      "loss": 0.1732,
      "step": 122400
    },
    {
      "epoch": 2.5207755662672913,
      "grad_norm": 3.844003677368164,
      "learning_rate": 4.805333772326941e-06,
      "loss": 0.1639,
      "step": 122500
    },
    {
      "epoch": 2.5228333170428066,
      "grad_norm": 3.2006661891937256,
      "learning_rate": 4.784755946991522e-06,
      "loss": 0.1721,
      "step": 122600
    },
    {
      "epoch": 2.524891067818321,
      "grad_norm": 2.771843910217285,
      "learning_rate": 4.764178121656103e-06,
      "loss": 0.1705,
      "step": 122700
    },
    {
      "epoch": 2.5269488185938362,
      "grad_norm": 3.5708067417144775,
      "learning_rate": 4.7438060745740385e-06,
      "loss": 0.1684,
      "step": 122800
    },
    {
      "epoch": 2.5290065693693506,
      "grad_norm": 1.2401916980743408,
      "learning_rate": 4.7232282492386204e-06,
      "loss": 0.1543,
      "step": 122900
    },
    {
      "epoch": 2.531064320144866,
      "grad_norm": 0.8677121996879578,
      "learning_rate": 4.702650423903202e-06,
      "loss": 0.1628,
      "step": 123000
    },
    {
      "epoch": 2.5331220709203803,
      "grad_norm": 2.7631404399871826,
      "learning_rate": 4.6820725985677835e-06,
      "loss": 0.1805,
      "step": 123100
    },
    {
      "epoch": 2.535179821695895,
      "grad_norm": 2.12876033782959,
      "learning_rate": 4.6614947732323654e-06,
      "loss": 0.1556,
      "step": 123200
    },
    {
      "epoch": 2.53723757247141,
      "grad_norm": 3.0719428062438965,
      "learning_rate": 4.6409169478969466e-06,
      "loss": 0.1892,
      "step": 123300
    },
    {
      "epoch": 2.539295323246925,
      "grad_norm": 0.418649286031723,
      "learning_rate": 4.620339122561528e-06,
      "loss": 0.1661,
      "step": 123400
    },
    {
      "epoch": 2.5413530740224397,
      "grad_norm": 2.0710065364837646,
      "learning_rate": 4.59976129722611e-06,
      "loss": 0.1649,
      "step": 123500
    },
    {
      "epoch": 2.5434108247979546,
      "grad_norm": 2.3961009979248047,
      "learning_rate": 4.579183471890691e-06,
      "loss": 0.1659,
      "step": 123600
    },
    {
      "epoch": 2.5454685755734694,
      "grad_norm": 6.381628513336182,
      "learning_rate": 4.558605646555273e-06,
      "loss": 0.1664,
      "step": 123700
    },
    {
      "epoch": 2.5475263263489842,
      "grad_norm": 4.300612926483154,
      "learning_rate": 4.538027821219854e-06,
      "loss": 0.16,
      "step": 123800
    },
    {
      "epoch": 2.549584077124499,
      "grad_norm": 4.048521995544434,
      "learning_rate": 4.517449995884435e-06,
      "loss": 0.182,
      "step": 123900
    },
    {
      "epoch": 2.551641827900014,
      "grad_norm": 0.6264606714248657,
      "learning_rate": 4.496872170549017e-06,
      "loss": 0.1656,
      "step": 124000
    },
    {
      "epoch": 2.5536995786755288,
      "grad_norm": 2.96769642829895,
      "learning_rate": 4.476294345213598e-06,
      "loss": 0.1573,
      "step": 124100
    },
    {
      "epoch": 2.5557573294510436,
      "grad_norm": 1.9191135168075562,
      "learning_rate": 4.455716519878179e-06,
      "loss": 0.1588,
      "step": 124200
    },
    {
      "epoch": 2.5578150802265585,
      "grad_norm": 0.7554588317871094,
      "learning_rate": 4.435138694542761e-06,
      "loss": 0.1638,
      "step": 124300
    },
    {
      "epoch": 2.5598728310020733,
      "grad_norm": 2.6686646938323975,
      "learning_rate": 4.414560869207342e-06,
      "loss": 0.1604,
      "step": 124400
    },
    {
      "epoch": 2.561930581777588,
      "grad_norm": 4.776908874511719,
      "learning_rate": 4.393983043871923e-06,
      "loss": 0.1788,
      "step": 124500
    },
    {
      "epoch": 2.563988332553103,
      "grad_norm": 0.8674485683441162,
      "learning_rate": 4.373405218536505e-06,
      "loss": 0.175,
      "step": 124600
    },
    {
      "epoch": 2.566046083328618,
      "grad_norm": 5.798128604888916,
      "learning_rate": 4.352827393201086e-06,
      "loss": 0.1885,
      "step": 124700
    },
    {
      "epoch": 2.5681038341041322,
      "grad_norm": 5.934340000152588,
      "learning_rate": 4.3324553461190226e-06,
      "loss": 0.1637,
      "step": 124800
    },
    {
      "epoch": 2.5701615848796475,
      "grad_norm": 1.632738709449768,
      "learning_rate": 4.311877520783604e-06,
      "loss": 0.1572,
      "step": 124900
    },
    {
      "epoch": 2.572219335655162,
      "grad_norm": 3.4573287963867188,
      "learning_rate": 4.291299695448186e-06,
      "loss": 0.1538,
      "step": 125000
    },
    {
      "epoch": 2.574277086430677,
      "grad_norm": 1.6129597425460815,
      "learning_rate": 4.270721870112767e-06,
      "loss": 0.1502,
      "step": 125100
    },
    {
      "epoch": 2.5763348372061916,
      "grad_norm": 2.6485595703125,
      "learning_rate": 4.250144044777348e-06,
      "loss": 0.1831,
      "step": 125200
    },
    {
      "epoch": 2.5783925879817065,
      "grad_norm": 3.0322787761688232,
      "learning_rate": 4.22956621944193e-06,
      "loss": 0.1784,
      "step": 125300
    },
    {
      "epoch": 2.5804503387572213,
      "grad_norm": 1.5358721017837524,
      "learning_rate": 4.208988394106511e-06,
      "loss": 0.1891,
      "step": 125400
    },
    {
      "epoch": 2.582508089532736,
      "grad_norm": 0.759533703327179,
      "learning_rate": 4.188410568771093e-06,
      "loss": 0.1727,
      "step": 125500
    },
    {
      "epoch": 2.584565840308251,
      "grad_norm": 2.1616175174713135,
      "learning_rate": 4.167832743435674e-06,
      "loss": 0.167,
      "step": 125600
    },
    {
      "epoch": 2.586623591083766,
      "grad_norm": 2.5254528522491455,
      "learning_rate": 4.147254918100255e-06,
      "loss": 0.1632,
      "step": 125700
    },
    {
      "epoch": 2.5886813418592807,
      "grad_norm": 1.0012311935424805,
      "learning_rate": 4.126677092764837e-06,
      "loss": 0.1472,
      "step": 125800
    },
    {
      "epoch": 2.5907390926347955,
      "grad_norm": 4.357839107513428,
      "learning_rate": 4.106099267429418e-06,
      "loss": 0.1682,
      "step": 125900
    },
    {
      "epoch": 2.5927968434103104,
      "grad_norm": 1.573156476020813,
      "learning_rate": 4.085521442093999e-06,
      "loss": 0.1859,
      "step": 126000
    },
    {
      "epoch": 2.594854594185825,
      "grad_norm": 2.8904600143432617,
      "learning_rate": 4.064943616758581e-06,
      "loss": 0.1738,
      "step": 126100
    },
    {
      "epoch": 2.59691234496134,
      "grad_norm": 2.4177796840667725,
      "learning_rate": 4.044365791423162e-06,
      "loss": 0.1701,
      "step": 126200
    },
    {
      "epoch": 2.598970095736855,
      "grad_norm": 7.399591445922852,
      "learning_rate": 4.023787966087743e-06,
      "loss": 0.2013,
      "step": 126300
    },
    {
      "epoch": 2.6010278465123697,
      "grad_norm": 1.816683292388916,
      "learning_rate": 4.003210140752325e-06,
      "loss": 0.1782,
      "step": 126400
    },
    {
      "epoch": 2.6030855972878846,
      "grad_norm": 3.193305492401123,
      "learning_rate": 3.9826323154169064e-06,
      "loss": 0.1641,
      "step": 126500
    },
    {
      "epoch": 2.6051433480633994,
      "grad_norm": 3.153404474258423,
      "learning_rate": 3.962054490081488e-06,
      "loss": 0.17,
      "step": 126600
    },
    {
      "epoch": 2.6072010988389143,
      "grad_norm": 7.259257793426514,
      "learning_rate": 3.9414766647460695e-06,
      "loss": 0.153,
      "step": 126700
    },
    {
      "epoch": 2.609258849614429,
      "grad_norm": NaN,
      "learning_rate": 3.920898839410651e-06,
      "loss": 0.1729,
      "step": 126800
    },
    {
      "epoch": 2.6113166003899435,
      "grad_norm": 2.5125768184661865,
      "learning_rate": 3.900526792328587e-06,
      "loss": 0.1977,
      "step": 126900
    },
    {
      "epoch": 2.613374351165459,
      "grad_norm": 2.149336338043213,
      "learning_rate": 3.879948966993168e-06,
      "loss": 0.1644,
      "step": 127000
    },
    {
      "epoch": 2.615432101940973,
      "grad_norm": 1.6174741983413696,
      "learning_rate": 3.85937114165775e-06,
      "loss": 0.1682,
      "step": 127100
    },
    {
      "epoch": 2.6174898527164885,
      "grad_norm": 4.442121505737305,
      "learning_rate": 3.838793316322331e-06,
      "loss": 0.1614,
      "step": 127200
    },
    {
      "epoch": 2.619547603492003,
      "grad_norm": 1.271479606628418,
      "learning_rate": 3.818215490986913e-06,
      "loss": 0.1594,
      "step": 127300
    },
    {
      "epoch": 2.6216053542675177,
      "grad_norm": 2.305386781692505,
      "learning_rate": 3.797637665651494e-06,
      "loss": 0.1858,
      "step": 127400
    },
    {
      "epoch": 2.6236631050430326,
      "grad_norm": 1.797957420349121,
      "learning_rate": 3.7770598403160752e-06,
      "loss": 0.1658,
      "step": 127500
    },
    {
      "epoch": 2.6257208558185474,
      "grad_norm": 1.8669565916061401,
      "learning_rate": 3.756482014980657e-06,
      "loss": 0.1497,
      "step": 127600
    },
    {
      "epoch": 2.6277786065940623,
      "grad_norm": 12.264488220214844,
      "learning_rate": 3.7359041896452383e-06,
      "loss": 0.1726,
      "step": 127700
    },
    {
      "epoch": 2.629836357369577,
      "grad_norm": 2.6710293292999268,
      "learning_rate": 3.71532636430982e-06,
      "loss": 0.1602,
      "step": 127800
    },
    {
      "epoch": 2.631894108145092,
      "grad_norm": 5.2080841064453125,
      "learning_rate": 3.694748538974401e-06,
      "loss": 0.1656,
      "step": 127900
    },
    {
      "epoch": 2.633951858920607,
      "grad_norm": 3.9248714447021484,
      "learning_rate": 3.6741707136389825e-06,
      "loss": 0.1678,
      "step": 128000
    },
    {
      "epoch": 2.6360096096961216,
      "grad_norm": 2.4925966262817383,
      "learning_rate": 3.6535928883035644e-06,
      "loss": 0.1693,
      "step": 128100
    },
    {
      "epoch": 2.6380673604716365,
      "grad_norm": 3.17154598236084,
      "learning_rate": 3.633015062968146e-06,
      "loss": 0.1791,
      "step": 128200
    },
    {
      "epoch": 2.6401251112471513,
      "grad_norm": 4.604854106903076,
      "learning_rate": 3.612437237632727e-06,
      "loss": 0.1643,
      "step": 128300
    },
    {
      "epoch": 2.642182862022666,
      "grad_norm": 2.9362447261810303,
      "learning_rate": 3.5918594122973086e-06,
      "loss": 0.1722,
      "step": 128400
    },
    {
      "epoch": 2.644240612798181,
      "grad_norm": 1.0631885528564453,
      "learning_rate": 3.57128158696189e-06,
      "loss": 0.1806,
      "step": 128500
    },
    {
      "epoch": 2.646298363573696,
      "grad_norm": 1.6389172077178955,
      "learning_rate": 3.5507037616264712e-06,
      "loss": 0.1568,
      "step": 128600
    },
    {
      "epoch": 2.6483561143492107,
      "grad_norm": 5.984403133392334,
      "learning_rate": 3.5301259362910527e-06,
      "loss": 0.1828,
      "step": 128700
    },
    {
      "epoch": 2.6504138651247255,
      "grad_norm": 2.813361883163452,
      "learning_rate": 3.5095481109556343e-06,
      "loss": 0.1659,
      "step": 128800
    },
    {
      "epoch": 2.6524716159002404,
      "grad_norm": 1.424174427986145,
      "learning_rate": 3.488970285620216e-06,
      "loss": 0.1286,
      "step": 128900
    },
    {
      "epoch": 2.6545293666757552,
      "grad_norm": 3.0279598236083984,
      "learning_rate": 3.4685982385381513e-06,
      "loss": 0.1577,
      "step": 129000
    },
    {
      "epoch": 2.65658711745127,
      "grad_norm": 3.506416082382202,
      "learning_rate": 3.4480204132027328e-06,
      "loss": 0.1672,
      "step": 129100
    },
    {
      "epoch": 2.6586448682267845,
      "grad_norm": 6.413703441619873,
      "learning_rate": 3.4274425878673143e-06,
      "loss": 0.1818,
      "step": 129200
    },
    {
      "epoch": 2.6607026190022998,
      "grad_norm": 0.5789111256599426,
      "learning_rate": 3.406864762531896e-06,
      "loss": 0.1696,
      "step": 129300
    },
    {
      "epoch": 2.662760369777814,
      "grad_norm": 2.110318660736084,
      "learning_rate": 3.386286937196477e-06,
      "loss": 0.1639,
      "step": 129400
    },
    {
      "epoch": 2.6648181205533295,
      "grad_norm": 2.7286994457244873,
      "learning_rate": 3.3657091118610585e-06,
      "loss": 0.1743,
      "step": 129500
    },
    {
      "epoch": 2.666875871328844,
      "grad_norm": 1.5172847509384155,
      "learning_rate": 3.34513128652564e-06,
      "loss": 0.1516,
      "step": 129600
    },
    {
      "epoch": 2.6689336221043587,
      "grad_norm": 6.0521697998046875,
      "learning_rate": 3.3245534611902215e-06,
      "loss": 0.1673,
      "step": 129700
    },
    {
      "epoch": 2.6709913728798735,
      "grad_norm": 2.7883243560791016,
      "learning_rate": 3.303975635854803e-06,
      "loss": 0.163,
      "step": 129800
    },
    {
      "epoch": 2.6730491236553884,
      "grad_norm": 4.475362777709961,
      "learning_rate": 3.2833978105193846e-06,
      "loss": 0.1674,
      "step": 129900
    },
    {
      "epoch": 2.6751068744309032,
      "grad_norm": 2.7354018688201904,
      "learning_rate": 3.262819985183966e-06,
      "loss": 0.1682,
      "step": 130000
    },
    {
      "epoch": 2.6751068744309032,
      "eval_accuracy": 0.8388492871690427,
      "eval_f1_contradiction": 0.8471313053523296,
      "eval_loss": 0.1539095789194107,
      "eval_runtime": 77.1352,
      "eval_samples_per_second": 50.924,
      "eval_steps_per_second": 6.365,
      "step": 130000
    },
    {
      "epoch": 2.677164625206418,
      "grad_norm": 3.716247797012329,
      "learning_rate": 3.2422421598485472e-06,
      "loss": 0.1688,
      "step": 130100
    },
    {
      "epoch": 2.679222375981933,
      "grad_norm": 3.544158935546875,
      "learning_rate": 3.2216643345131288e-06,
      "loss": 0.2055,
      "step": 130200
    },
    {
      "epoch": 2.6812801267574478,
      "grad_norm": 1.6136109828948975,
      "learning_rate": 3.2010865091777103e-06,
      "loss": 0.1617,
      "step": 130300
    },
    {
      "epoch": 2.6833378775329626,
      "grad_norm": 3.0197322368621826,
      "learning_rate": 3.1805086838422914e-06,
      "loss": 0.1654,
      "step": 130400
    },
    {
      "epoch": 2.6853956283084774,
      "grad_norm": 2.0643796920776367,
      "learning_rate": 3.159930858506873e-06,
      "loss": 0.1828,
      "step": 130500
    },
    {
      "epoch": 2.6874533790839923,
      "grad_norm": 5.389472007751465,
      "learning_rate": 3.1393530331714545e-06,
      "loss": 0.1651,
      "step": 130600
    },
    {
      "epoch": 2.689511129859507,
      "grad_norm": 1.5722650289535522,
      "learning_rate": 3.118775207836036e-06,
      "loss": 0.1717,
      "step": 130700
    },
    {
      "epoch": 2.691568880635022,
      "grad_norm": 3.2026569843292236,
      "learning_rate": 3.098197382500617e-06,
      "loss": 0.1675,
      "step": 130800
    },
    {
      "epoch": 2.693626631410537,
      "grad_norm": 3.691359043121338,
      "learning_rate": 3.0776195571651986e-06,
      "loss": 0.1806,
      "step": 130900
    },
    {
      "epoch": 2.6956843821860517,
      "grad_norm": 2.9607176780700684,
      "learning_rate": 3.0570417318297806e-06,
      "loss": 0.149,
      "step": 131000
    },
    {
      "epoch": 2.6977421329615665,
      "grad_norm": 2.960773468017578,
      "learning_rate": 3.036669684747716e-06,
      "loss": 0.1848,
      "step": 131100
    },
    {
      "epoch": 2.6997998837370814,
      "grad_norm": 3.356637477874756,
      "learning_rate": 3.016091859412297e-06,
      "loss": 0.1768,
      "step": 131200
    },
    {
      "epoch": 2.7018576345125958,
      "grad_norm": 4.351928234100342,
      "learning_rate": 2.9955140340768787e-06,
      "loss": 0.173,
      "step": 131300
    },
    {
      "epoch": 2.703915385288111,
      "grad_norm": 2.782405138015747,
      "learning_rate": 2.9749362087414606e-06,
      "loss": 0.1814,
      "step": 131400
    },
    {
      "epoch": 2.7059731360636254,
      "grad_norm": 2.045865058898926,
      "learning_rate": 2.9543583834060417e-06,
      "loss": 0.1667,
      "step": 131500
    },
    {
      "epoch": 2.7080308868391407,
      "grad_norm": 0.8209893703460693,
      "learning_rate": 2.9337805580706232e-06,
      "loss": 0.1741,
      "step": 131600
    },
    {
      "epoch": 2.710088637614655,
      "grad_norm": 1.6281356811523438,
      "learning_rate": 2.9132027327352048e-06,
      "loss": 0.1591,
      "step": 131700
    },
    {
      "epoch": 2.71214638839017,
      "grad_norm": 2.7668354511260986,
      "learning_rate": 2.8926249073997863e-06,
      "loss": 0.1515,
      "step": 131800
    },
    {
      "epoch": 2.714204139165685,
      "grad_norm": 3.054307460784912,
      "learning_rate": 2.8720470820643674e-06,
      "loss": 0.1594,
      "step": 131900
    },
    {
      "epoch": 2.7162618899411997,
      "grad_norm": 5.547600269317627,
      "learning_rate": 2.851469256728949e-06,
      "loss": 0.1734,
      "step": 132000
    },
    {
      "epoch": 2.7183196407167145,
      "grad_norm": 7.437699794769287,
      "learning_rate": 2.8308914313935305e-06,
      "loss": 0.1475,
      "step": 132100
    },
    {
      "epoch": 2.7203773914922293,
      "grad_norm": 2.8702378273010254,
      "learning_rate": 2.8103136060581116e-06,
      "loss": 0.1677,
      "step": 132200
    },
    {
      "epoch": 2.722435142267744,
      "grad_norm": 1.1750448942184448,
      "learning_rate": 2.789735780722693e-06,
      "loss": 0.1406,
      "step": 132300
    },
    {
      "epoch": 2.724492893043259,
      "grad_norm": 3.049614429473877,
      "learning_rate": 2.7691579553872746e-06,
      "loss": 0.1547,
      "step": 132400
    },
    {
      "epoch": 2.726550643818774,
      "grad_norm": 1.8811447620391846,
      "learning_rate": 2.748580130051856e-06,
      "loss": 0.1482,
      "step": 132500
    },
    {
      "epoch": 2.7286083945942887,
      "grad_norm": 2.014638662338257,
      "learning_rate": 2.7280023047164377e-06,
      "loss": 0.1512,
      "step": 132600
    },
    {
      "epoch": 2.7306661453698036,
      "grad_norm": 2.073387861251831,
      "learning_rate": 2.7074244793810192e-06,
      "loss": 0.1631,
      "step": 132700
    },
    {
      "epoch": 2.7327238961453184,
      "grad_norm": 4.041414737701416,
      "learning_rate": 2.6868466540456007e-06,
      "loss": 0.1518,
      "step": 132800
    },
    {
      "epoch": 2.7347816469208333,
      "grad_norm": 2.508553981781006,
      "learning_rate": 2.6662688287101823e-06,
      "loss": 0.1262,
      "step": 132900
    },
    {
      "epoch": 2.736839397696348,
      "grad_norm": 3.359694242477417,
      "learning_rate": 2.6456910033747634e-06,
      "loss": 0.1609,
      "step": 133000
    },
    {
      "epoch": 2.738897148471863,
      "grad_norm": 4.569678783416748,
      "learning_rate": 2.6253189562926993e-06,
      "loss": 0.1715,
      "step": 133100
    },
    {
      "epoch": 2.740954899247378,
      "grad_norm": 2.743732213973999,
      "learning_rate": 2.6047411309572808e-06,
      "loss": 0.1562,
      "step": 133200
    },
    {
      "epoch": 2.7430126500228926,
      "grad_norm": 5.464155673980713,
      "learning_rate": 2.584163305621862e-06,
      "loss": 0.1584,
      "step": 133300
    },
    {
      "epoch": 2.745070400798407,
      "grad_norm": 4.376391887664795,
      "learning_rate": 2.5635854802864434e-06,
      "loss": 0.1768,
      "step": 133400
    },
    {
      "epoch": 2.7471281515739223,
      "grad_norm": 4.023081302642822,
      "learning_rate": 2.543007654951025e-06,
      "loss": 0.1524,
      "step": 133500
    },
    {
      "epoch": 2.7491859023494367,
      "grad_norm": 2.017207384109497,
      "learning_rate": 2.5224298296156065e-06,
      "loss": 0.1795,
      "step": 133600
    },
    {
      "epoch": 2.751243653124952,
      "grad_norm": 5.392694473266602,
      "learning_rate": 2.5018520042801876e-06,
      "loss": 0.1747,
      "step": 133700
    },
    {
      "epoch": 2.7533014039004664,
      "grad_norm": 2.6607108116149902,
      "learning_rate": 2.481274178944769e-06,
      "loss": 0.1583,
      "step": 133800
    },
    {
      "epoch": 2.7553591546759817,
      "grad_norm": 5.352064609527588,
      "learning_rate": 2.4606963536093506e-06,
      "loss": 0.18,
      "step": 133900
    },
    {
      "epoch": 2.757416905451496,
      "grad_norm": 0.7467405200004578,
      "learning_rate": 2.4401185282739317e-06,
      "loss": 0.1574,
      "step": 134000
    },
    {
      "epoch": 2.759474656227011,
      "grad_norm": 4.512895107269287,
      "learning_rate": 2.4195407029385133e-06,
      "loss": 0.1716,
      "step": 134100
    },
    {
      "epoch": 2.761532407002526,
      "grad_norm": 2.390916347503662,
      "learning_rate": 2.398962877603095e-06,
      "loss": 0.1503,
      "step": 134200
    },
    {
      "epoch": 2.7635901577780406,
      "grad_norm": 3.5421669483184814,
      "learning_rate": 2.3783850522676768e-06,
      "loss": 0.159,
      "step": 134300
    },
    {
      "epoch": 2.7656479085535555,
      "grad_norm": 4.7321295738220215,
      "learning_rate": 2.357807226932258e-06,
      "loss": 0.1599,
      "step": 134400
    },
    {
      "epoch": 2.7677056593290703,
      "grad_norm": 3.358726739883423,
      "learning_rate": 2.3372294015968394e-06,
      "loss": 0.1793,
      "step": 134500
    },
    {
      "epoch": 2.769763410104585,
      "grad_norm": 4.658189296722412,
      "learning_rate": 2.316651576261421e-06,
      "loss": 0.1672,
      "step": 134600
    },
    {
      "epoch": 2.7718211608801,
      "grad_norm": 3.4587697982788086,
      "learning_rate": 2.296073750926002e-06,
      "loss": 0.1742,
      "step": 134700
    },
    {
      "epoch": 2.773878911655615,
      "grad_norm": 3.602673053741455,
      "learning_rate": 2.2754959255905836e-06,
      "loss": 0.1736,
      "step": 134800
    },
    {
      "epoch": 2.7759366624311297,
      "grad_norm": 3.992279052734375,
      "learning_rate": 2.254918100255165e-06,
      "loss": 0.1661,
      "step": 134900
    },
    {
      "epoch": 2.7779944132066445,
      "grad_norm": 1.3965774774551392,
      "learning_rate": 2.2343402749197466e-06,
      "loss": 0.1594,
      "step": 135000
    },
    {
      "epoch": 2.7800521639821594,
      "grad_norm": 2.80806565284729,
      "learning_rate": 2.213968227837682e-06,
      "loss": 0.1608,
      "step": 135100
    },
    {
      "epoch": 2.782109914757674,
      "grad_norm": 4.759430408477783,
      "learning_rate": 2.1933904025022636e-06,
      "loss": 0.1504,
      "step": 135200
    },
    {
      "epoch": 2.784167665533189,
      "grad_norm": 2.638047933578491,
      "learning_rate": 2.172812577166845e-06,
      "loss": 0.1806,
      "step": 135300
    },
    {
      "epoch": 2.786225416308704,
      "grad_norm": 2.844191074371338,
      "learning_rate": 2.1522347518314267e-06,
      "loss": 0.1715,
      "step": 135400
    },
    {
      "epoch": 2.7882831670842187,
      "grad_norm": 4.367191314697266,
      "learning_rate": 2.1316569264960078e-06,
      "loss": 0.1684,
      "step": 135500
    },
    {
      "epoch": 2.7903409178597336,
      "grad_norm": 3.0166356563568115,
      "learning_rate": 2.1110791011605893e-06,
      "loss": 0.1656,
      "step": 135600
    },
    {
      "epoch": 2.792398668635248,
      "grad_norm": 2.8720455169677734,
      "learning_rate": 2.090501275825171e-06,
      "loss": 0.153,
      "step": 135700
    },
    {
      "epoch": 2.7944564194107633,
      "grad_norm": 2.8301403522491455,
      "learning_rate": 2.069923450489752e-06,
      "loss": 0.1517,
      "step": 135800
    },
    {
      "epoch": 2.7965141701862777,
      "grad_norm": 2.6409482955932617,
      "learning_rate": 2.049345625154334e-06,
      "loss": 0.168,
      "step": 135900
    },
    {
      "epoch": 2.798571920961793,
      "grad_norm": 2.8598153591156006,
      "learning_rate": 2.0287677998189154e-06,
      "loss": 0.1738,
      "step": 136000
    },
    {
      "epoch": 2.8006296717373074,
      "grad_norm": 2.339085817337036,
      "learning_rate": 2.008189974483497e-06,
      "loss": 0.1687,
      "step": 136100
    },
    {
      "epoch": 2.802687422512822,
      "grad_norm": 5.988039970397949,
      "learning_rate": 1.987612149148078e-06,
      "loss": 0.1738,
      "step": 136200
    },
    {
      "epoch": 2.804745173288337,
      "grad_norm": 2.7636892795562744,
      "learning_rate": 1.9670343238126596e-06,
      "loss": 0.1495,
      "step": 136300
    },
    {
      "epoch": 2.806802924063852,
      "grad_norm": 4.041018486022949,
      "learning_rate": 1.946456498477241e-06,
      "loss": 0.1797,
      "step": 136400
    },
    {
      "epoch": 2.8088606748393667,
      "grad_norm": 2.4317166805267334,
      "learning_rate": 1.925878673141822e-06,
      "loss": 0.1519,
      "step": 136500
    },
    {
      "epoch": 2.8109184256148816,
      "grad_norm": 1.9161244630813599,
      "learning_rate": 1.9053008478064037e-06,
      "loss": 0.1684,
      "step": 136600
    },
    {
      "epoch": 2.8129761763903964,
      "grad_norm": 0.47919580340385437,
      "learning_rate": 1.8847230224709853e-06,
      "loss": 0.1762,
      "step": 136700
    },
    {
      "epoch": 2.8150339271659113,
      "grad_norm": 4.158141136169434,
      "learning_rate": 1.8641451971355668e-06,
      "loss": 0.1868,
      "step": 136800
    },
    {
      "epoch": 2.817091677941426,
      "grad_norm": 4.052377700805664,
      "learning_rate": 1.8435673718001483e-06,
      "loss": 0.1722,
      "step": 136900
    },
    {
      "epoch": 2.819149428716941,
      "grad_norm": 5.025249004364014,
      "learning_rate": 1.8229895464647296e-06,
      "loss": 0.1795,
      "step": 137000
    },
    {
      "epoch": 2.821207179492456,
      "grad_norm": 1.8160921335220337,
      "learning_rate": 1.8024117211293112e-06,
      "loss": 0.1561,
      "step": 137100
    },
    {
      "epoch": 2.8232649302679707,
      "grad_norm": 1.4022448062896729,
      "learning_rate": 1.7820396740472468e-06,
      "loss": 0.1726,
      "step": 137200
    },
    {
      "epoch": 2.8253226810434855,
      "grad_norm": 3.8811633586883545,
      "learning_rate": 1.7614618487118282e-06,
      "loss": 0.1696,
      "step": 137300
    },
    {
      "epoch": 2.8273804318190003,
      "grad_norm": 1.8784801959991455,
      "learning_rate": 1.7408840233764097e-06,
      "loss": 0.1545,
      "step": 137400
    },
    {
      "epoch": 2.829438182594515,
      "grad_norm": 1.538069486618042,
      "learning_rate": 1.720306198040991e-06,
      "loss": 0.1622,
      "step": 137500
    },
    {
      "epoch": 2.83149593337003,
      "grad_norm": 0.9570866823196411,
      "learning_rate": 1.6997283727055725e-06,
      "loss": 0.1537,
      "step": 137600
    },
    {
      "epoch": 2.833553684145545,
      "grad_norm": 3.7725870609283447,
      "learning_rate": 1.6791505473701538e-06,
      "loss": 0.1587,
      "step": 137700
    },
    {
      "epoch": 2.8356114349210593,
      "grad_norm": 2.1073150634765625,
      "learning_rate": 1.6585727220347354e-06,
      "loss": 0.1601,
      "step": 137800
    },
    {
      "epoch": 2.8376691856965746,
      "grad_norm": 2.019594430923462,
      "learning_rate": 1.637994896699317e-06,
      "loss": 0.1516,
      "step": 137900
    },
    {
      "epoch": 2.839726936472089,
      "grad_norm": 4.126962661743164,
      "learning_rate": 1.6174170713638984e-06,
      "loss": 0.1663,
      "step": 138000
    },
    {
      "epoch": 2.8417846872476042,
      "grad_norm": 3.3640804290771484,
      "learning_rate": 1.5968392460284798e-06,
      "loss": 0.175,
      "step": 138100
    },
    {
      "epoch": 2.8438424380231186,
      "grad_norm": 4.071017265319824,
      "learning_rate": 1.576261420693061e-06,
      "loss": 0.1589,
      "step": 138200
    },
    {
      "epoch": 2.8459001887986335,
      "grad_norm": 2.0276951789855957,
      "learning_rate": 1.5556835953576426e-06,
      "loss": 0.1551,
      "step": 138300
    },
    {
      "epoch": 2.8479579395741483,
      "grad_norm": 3.1375632286071777,
      "learning_rate": 1.535105770022224e-06,
      "loss": 0.1525,
      "step": 138400
    },
    {
      "epoch": 2.850015690349663,
      "grad_norm": 5.4509453773498535,
      "learning_rate": 1.5145279446868057e-06,
      "loss": 0.1759,
      "step": 138500
    },
    {
      "epoch": 2.852073441125178,
      "grad_norm": 1.2739266157150269,
      "learning_rate": 1.493950119351387e-06,
      "loss": 0.1532,
      "step": 138600
    },
    {
      "epoch": 2.854131191900693,
      "grad_norm": 2.7477192878723145,
      "learning_rate": 1.4733722940159685e-06,
      "loss": 0.1546,
      "step": 138700
    },
    {
      "epoch": 2.8561889426762077,
      "grad_norm": 0.7794429659843445,
      "learning_rate": 1.4527944686805498e-06,
      "loss": 0.1501,
      "step": 138800
    },
    {
      "epoch": 2.8582466934517226,
      "grad_norm": 2.8046841621398926,
      "learning_rate": 1.4322166433451314e-06,
      "loss": 0.1566,
      "step": 138900
    },
    {
      "epoch": 2.8603044442272374,
      "grad_norm": 2.2154183387756348,
      "learning_rate": 1.4116388180097127e-06,
      "loss": 0.154,
      "step": 139000
    },
    {
      "epoch": 2.8623621950027522,
      "grad_norm": 3.162393569946289,
      "learning_rate": 1.3910609926742942e-06,
      "loss": 0.1625,
      "step": 139100
    },
    {
      "epoch": 2.864419945778267,
      "grad_norm": 3.2641680240631104,
      "learning_rate": 1.3706889455922299e-06,
      "loss": 0.1676,
      "step": 139200
    },
    {
      "epoch": 2.866477696553782,
      "grad_norm": 3.823178291320801,
      "learning_rate": 1.3501111202568112e-06,
      "loss": 0.1659,
      "step": 139300
    },
    {
      "epoch": 2.8685354473292968,
      "grad_norm": 2.9856178760528564,
      "learning_rate": 1.3295332949213927e-06,
      "loss": 0.1429,
      "step": 139400
    },
    {
      "epoch": 2.8705931981048116,
      "grad_norm": 1.0811628103256226,
      "learning_rate": 1.3089554695859742e-06,
      "loss": 0.1568,
      "step": 139500
    },
    {
      "epoch": 2.8726509488803265,
      "grad_norm": 0.8775705099105835,
      "learning_rate": 1.2883776442505558e-06,
      "loss": 0.1735,
      "step": 139600
    },
    {
      "epoch": 2.8747086996558413,
      "grad_norm": 1.528242826461792,
      "learning_rate": 1.267799818915137e-06,
      "loss": 0.1782,
      "step": 139700
    },
    {
      "epoch": 2.876766450431356,
      "grad_norm": 6.2633585929870605,
      "learning_rate": 1.2472219935797186e-06,
      "loss": 0.169,
      "step": 139800
    },
    {
      "epoch": 2.878824201206871,
      "grad_norm": 4.103394031524658,
      "learning_rate": 1.2266441682443e-06,
      "loss": 0.1495,
      "step": 139900
    },
    {
      "epoch": 2.880881951982386,
      "grad_norm": 1.7542535066604614,
      "learning_rate": 1.2060663429088812e-06,
      "loss": 0.1758,
      "step": 140000
    },
    {
      "epoch": 2.880881951982386,
      "eval_accuracy": 0.8416496945010183,
      "eval_f1_contradiction": 0.8499807173158503,
      "eval_loss": 0.15449091792106628,
      "eval_runtime": 70.2208,
      "eval_samples_per_second": 55.938,
      "eval_steps_per_second": 6.992,
      "step": 140000
    },
    {
      "epoch": 2.8829397027579002,
      "grad_norm": 1.8424179553985596,
      "learning_rate": 1.185488517573463e-06,
      "loss": 0.1605,
      "step": 140100
    },
    {
      "epoch": 2.8849974535334155,
      "grad_norm": 2.5170860290527344,
      "learning_rate": 1.1649106922380443e-06,
      "loss": 0.1564,
      "step": 140200
    },
    {
      "epoch": 2.88705520430893,
      "grad_norm": 5.723362445831299,
      "learning_rate": 1.1443328669026258e-06,
      "loss": 0.1777,
      "step": 140300
    },
    {
      "epoch": 2.889112955084445,
      "grad_norm": 3.7968833446502686,
      "learning_rate": 1.1237550415672072e-06,
      "loss": 0.1682,
      "step": 140400
    },
    {
      "epoch": 2.8911707058599596,
      "grad_norm": 0.6509063243865967,
      "learning_rate": 1.1031772162317887e-06,
      "loss": 0.1623,
      "step": 140500
    },
    {
      "epoch": 2.8932284566354745,
      "grad_norm": 0.5834905505180359,
      "learning_rate": 1.08259939089637e-06,
      "loss": 0.1621,
      "step": 140600
    },
    {
      "epoch": 2.8952862074109893,
      "grad_norm": 4.429148197174072,
      "learning_rate": 1.0620215655609517e-06,
      "loss": 0.1632,
      "step": 140700
    },
    {
      "epoch": 2.897343958186504,
      "grad_norm": 0.6164339184761047,
      "learning_rate": 1.041443740225533e-06,
      "loss": 0.1571,
      "step": 140800
    },
    {
      "epoch": 2.899401708962019,
      "grad_norm": 1.1946343183517456,
      "learning_rate": 1.0208659148901144e-06,
      "loss": 0.1643,
      "step": 140900
    },
    {
      "epoch": 2.901459459737534,
      "grad_norm": 3.2478928565979004,
      "learning_rate": 1.000288089554696e-06,
      "loss": 0.1666,
      "step": 141000
    },
    {
      "epoch": 2.9035172105130487,
      "grad_norm": 2.283402442932129,
      "learning_rate": 9.797102642192772e-07,
      "loss": 0.1703,
      "step": 141100
    },
    {
      "epoch": 2.9055749612885635,
      "grad_norm": 4.522216796875,
      "learning_rate": 9.591324388838588e-07,
      "loss": 0.1778,
      "step": 141200
    },
    {
      "epoch": 2.9076327120640784,
      "grad_norm": 9.984742164611816,
      "learning_rate": 9.387603918017944e-07,
      "loss": 0.1656,
      "step": 141300
    },
    {
      "epoch": 2.909690462839593,
      "grad_norm": 1.1556081771850586,
      "learning_rate": 9.181825664663758e-07,
      "loss": 0.1731,
      "step": 141400
    },
    {
      "epoch": 2.911748213615108,
      "grad_norm": 5.56712007522583,
      "learning_rate": 8.976047411309573e-07,
      "loss": 0.1761,
      "step": 141500
    },
    {
      "epoch": 2.913805964390623,
      "grad_norm": 3.610502004623413,
      "learning_rate": 8.770269157955388e-07,
      "loss": 0.1729,
      "step": 141600
    },
    {
      "epoch": 2.9158637151661377,
      "grad_norm": 0.45596078038215637,
      "learning_rate": 8.564490904601202e-07,
      "loss": 0.1543,
      "step": 141700
    },
    {
      "epoch": 2.9179214659416526,
      "grad_norm": 4.596689701080322,
      "learning_rate": 8.358712651247016e-07,
      "loss": 0.1786,
      "step": 141800
    },
    {
      "epoch": 2.9199792167171674,
      "grad_norm": 4.201452732086182,
      "learning_rate": 8.152934397892832e-07,
      "loss": 0.1869,
      "step": 141900
    },
    {
      "epoch": 2.9220369674926823,
      "grad_norm": 3.0339603424072266,
      "learning_rate": 7.947156144538646e-07,
      "loss": 0.1595,
      "step": 142000
    },
    {
      "epoch": 2.924094718268197,
      "grad_norm": 2.3118226528167725,
      "learning_rate": 7.741377891184459e-07,
      "loss": 0.1665,
      "step": 142100
    },
    {
      "epoch": 2.9261524690437115,
      "grad_norm": 2.6731691360473633,
      "learning_rate": 7.535599637830274e-07,
      "loss": 0.155,
      "step": 142200
    },
    {
      "epoch": 2.928210219819227,
      "grad_norm": 4.761536121368408,
      "learning_rate": 7.329821384476089e-07,
      "loss": 0.1548,
      "step": 142300
    },
    {
      "epoch": 2.930267970594741,
      "grad_norm": 1.064620018005371,
      "learning_rate": 7.124043131121903e-07,
      "loss": 0.1683,
      "step": 142400
    },
    {
      "epoch": 2.9323257213702565,
      "grad_norm": 6.897587776184082,
      "learning_rate": 6.918264877767718e-07,
      "loss": 0.1806,
      "step": 142500
    },
    {
      "epoch": 2.934383472145771,
      "grad_norm": 3.5658223628997803,
      "learning_rate": 6.712486624413532e-07,
      "loss": 0.1676,
      "step": 142600
    },
    {
      "epoch": 2.9364412229212857,
      "grad_norm": 2.505833387374878,
      "learning_rate": 6.506708371059347e-07,
      "loss": 0.1867,
      "step": 142700
    },
    {
      "epoch": 2.9384989736968006,
      "grad_norm": 1.121394157409668,
      "learning_rate": 6.300930117705162e-07,
      "loss": 0.1747,
      "step": 142800
    },
    {
      "epoch": 2.9405567244723154,
      "grad_norm": 1.8212984800338745,
      "learning_rate": 6.095151864350976e-07,
      "loss": 0.1414,
      "step": 142900
    },
    {
      "epoch": 2.9426144752478303,
      "grad_norm": 1.6966956853866577,
      "learning_rate": 5.889373610996789e-07,
      "loss": 0.1653,
      "step": 143000
    },
    {
      "epoch": 2.944672226023345,
      "grad_norm": 2.2860052585601807,
      "learning_rate": 5.683595357642605e-07,
      "loss": 0.1822,
      "step": 143100
    },
    {
      "epoch": 2.94672997679886,
      "grad_norm": 3.257643938064575,
      "learning_rate": 5.477817104288419e-07,
      "loss": 0.1638,
      "step": 143200
    },
    {
      "epoch": 2.948787727574375,
      "grad_norm": 3.883902072906494,
      "learning_rate": 5.272038850934233e-07,
      "loss": 0.1507,
      "step": 143300
    },
    {
      "epoch": 2.9508454783498896,
      "grad_norm": 4.031667232513428,
      "learning_rate": 5.06831838011359e-07,
      "loss": 0.1762,
      "step": 143400
    },
    {
      "epoch": 2.9529032291254045,
      "grad_norm": 2.8208932876586914,
      "learning_rate": 4.862540126759404e-07,
      "loss": 0.1538,
      "step": 143500
    },
    {
      "epoch": 2.9549609799009193,
      "grad_norm": 3.9556596279144287,
      "learning_rate": 4.6567618734052187e-07,
      "loss": 0.1891,
      "step": 143600
    },
    {
      "epoch": 2.957018730676434,
      "grad_norm": 4.389959812164307,
      "learning_rate": 4.450983620051033e-07,
      "loss": 0.1781,
      "step": 143700
    },
    {
      "epoch": 2.959076481451949,
      "grad_norm": 2.778644561767578,
      "learning_rate": 4.2452053666968477e-07,
      "loss": 0.1801,
      "step": 143800
    },
    {
      "epoch": 2.961134232227464,
      "grad_norm": 1.0974681377410889,
      "learning_rate": 4.0394271133426624e-07,
      "loss": 0.18,
      "step": 143900
    },
    {
      "epoch": 2.9631919830029787,
      "grad_norm": 4.5860137939453125,
      "learning_rate": 3.833648859988476e-07,
      "loss": 0.1642,
      "step": 144000
    },
    {
      "epoch": 2.9652497337784935,
      "grad_norm": 3.4338579177856445,
      "learning_rate": 3.627870606634291e-07,
      "loss": 0.1988,
      "step": 144100
    },
    {
      "epoch": 2.9673074845540084,
      "grad_norm": 3.0552937984466553,
      "learning_rate": 3.4220923532801057e-07,
      "loss": 0.1718,
      "step": 144200
    },
    {
      "epoch": 2.969365235329523,
      "grad_norm": 2.124009847640991,
      "learning_rate": 3.21631409992592e-07,
      "loss": 0.1518,
      "step": 144300
    },
    {
      "epoch": 2.971422986105038,
      "grad_norm": 3.614293336868286,
      "learning_rate": 3.0105358465717347e-07,
      "loss": 0.1585,
      "step": 144400
    },
    {
      "epoch": 2.9734807368805525,
      "grad_norm": 1.8452162742614746,
      "learning_rate": 2.804757593217549e-07,
      "loss": 0.1646,
      "step": 144500
    },
    {
      "epoch": 2.9755384876560678,
      "grad_norm": 2.5276389122009277,
      "learning_rate": 2.598979339863363e-07,
      "loss": 0.1551,
      "step": 144600
    },
    {
      "epoch": 2.977596238431582,
      "grad_norm": 3.5822463035583496,
      "learning_rate": 2.393201086509178e-07,
      "loss": 0.1598,
      "step": 144700
    },
    {
      "epoch": 2.9796539892070975,
      "grad_norm": 2.49103045463562,
      "learning_rate": 2.1874228331549921e-07,
      "loss": 0.1695,
      "step": 144800
    },
    {
      "epoch": 2.981711739982612,
      "grad_norm": 5.013019561767578,
      "learning_rate": 1.9816445798008066e-07,
      "loss": 0.1742,
      "step": 144900
    },
    {
      "epoch": 2.9837694907581267,
      "grad_norm": 2.8933303356170654,
      "learning_rate": 1.7758663264466211e-07,
      "loss": 0.1626,
      "step": 145000
    },
    {
      "epoch": 2.9858272415336415,
      "grad_norm": 3.660342216491699,
      "learning_rate": 1.5700880730924356e-07,
      "loss": 0.1653,
      "step": 145100
    },
    {
      "epoch": 2.9878849923091564,
      "grad_norm": 3.447669744491577,
      "learning_rate": 1.36430981973825e-07,
      "loss": 0.1699,
      "step": 145200
    },
    {
      "epoch": 2.9899427430846712,
      "grad_norm": 5.28314208984375,
      "learning_rate": 1.1585315663840645e-07,
      "loss": 0.1706,
      "step": 145300
    },
    {
      "epoch": 2.992000493860186,
      "grad_norm": 2.569127321243286,
      "learning_rate": 9.548110955634208e-08,
      "loss": 0.1642,
      "step": 145400
    },
    {
      "epoch": 2.994058244635701,
      "grad_norm": 1.4691988229751587,
      "learning_rate": 7.490328422092353e-08,
      "loss": 0.1626,
      "step": 145500
    },
    {
      "epoch": 2.9961159954112158,
      "grad_norm": 4.018483638763428,
      "learning_rate": 5.432545888550498e-08,
      "loss": 0.1839,
      "step": 145600
    },
    {
      "epoch": 2.9981737461867306,
      "grad_norm": 2.5744006633758545,
      "learning_rate": 3.374763355008643e-08,
      "loss": 0.1741,
      "step": 145700
    },
    {
      "epoch": 3.000246930093062,
      "grad_norm": 0.30563944578170776,
      "learning_rate": 2.1003950942464403e-05,
      "loss": 0.1875,
      "step": 145800
    },
    {
      "epoch": 3.0023046808685767,
      "grad_norm": 3.1555166244506836,
      "learning_rate": 2.0997777594863776e-05,
      "loss": 0.1624,
      "step": 145900
    },
    {
      "epoch": 3.0043624316440916,
      "grad_norm": 3.5966403484344482,
      "learning_rate": 2.099160424726315e-05,
      "loss": 0.1843,
      "step": 146000
    },
    {
      "epoch": 3.0064201824196064,
      "grad_norm": 2.7267744541168213,
      "learning_rate": 2.0985430899662526e-05,
      "loss": 0.1754,
      "step": 146100
    },
    {
      "epoch": 3.0084779331951212,
      "grad_norm": 3.172657012939453,
      "learning_rate": 2.09792575520619e-05,
      "loss": 0.17,
      "step": 146200
    },
    {
      "epoch": 3.010535683970636,
      "grad_norm": 2.2597391605377197,
      "learning_rate": 2.0973084204461272e-05,
      "loss": 0.1669,
      "step": 146300
    },
    {
      "epoch": 3.012593434746151,
      "grad_norm": 1.945801854133606,
      "learning_rate": 2.0966910856860645e-05,
      "loss": 0.1584,
      "step": 146400
    },
    {
      "epoch": 3.0146511855216653,
      "grad_norm": 2.8985464572906494,
      "learning_rate": 2.096073750926002e-05,
      "loss": 0.1604,
      "step": 146500
    },
    {
      "epoch": 3.01670893629718,
      "grad_norm": 0.6168839335441589,
      "learning_rate": 2.0954564161659395e-05,
      "loss": 0.1649,
      "step": 146600
    },
    {
      "epoch": 3.018766687072695,
      "grad_norm": 3.7111077308654785,
      "learning_rate": 2.094839081405877e-05,
      "loss": 0.1685,
      "step": 146700
    },
    {
      "epoch": 3.02082443784821,
      "grad_norm": 2.9634146690368652,
      "learning_rate": 2.0942217466458148e-05,
      "loss": 0.1872,
      "step": 146800
    },
    {
      "epoch": 3.0228821886237247,
      "grad_norm": 4.577080726623535,
      "learning_rate": 2.093604411885752e-05,
      "loss": 0.1651,
      "step": 146900
    },
    {
      "epoch": 3.0249399393992396,
      "grad_norm": 2.8800137042999268,
      "learning_rate": 2.0929870771256894e-05,
      "loss": 0.1604,
      "step": 147000
    },
    {
      "epoch": 3.0269976901747544,
      "grad_norm": 2.34086537361145,
      "learning_rate": 2.0923697423656267e-05,
      "loss": 0.1846,
      "step": 147100
    },
    {
      "epoch": 3.0290554409502692,
      "grad_norm": 8.114653587341309,
      "learning_rate": 2.0917524076055644e-05,
      "loss": 0.1849,
      "step": 147200
    },
    {
      "epoch": 3.031113191725784,
      "grad_norm": 4.5837297439575195,
      "learning_rate": 2.0911350728455017e-05,
      "loss": 0.1621,
      "step": 147300
    },
    {
      "epoch": 3.033170942501299,
      "grad_norm": 2.7362570762634277,
      "learning_rate": 2.0905239114330397e-05,
      "loss": 0.1549,
      "step": 147400
    },
    {
      "epoch": 3.0352286932768138,
      "grad_norm": 2.1876485347747803,
      "learning_rate": 2.0899065766729774e-05,
      "loss": 0.1642,
      "step": 147500
    },
    {
      "epoch": 3.0372864440523286,
      "grad_norm": 1.435123085975647,
      "learning_rate": 2.0892892419129147e-05,
      "loss": 0.1684,
      "step": 147600
    },
    {
      "epoch": 3.0393441948278435,
      "grad_norm": 0.41466593742370605,
      "learning_rate": 2.0886719071528524e-05,
      "loss": 0.1518,
      "step": 147700
    },
    {
      "epoch": 3.0414019456033583,
      "grad_norm": 2.75951886177063,
      "learning_rate": 2.0880545723927897e-05,
      "loss": 0.1884,
      "step": 147800
    },
    {
      "epoch": 3.043459696378873,
      "grad_norm": 1.327933430671692,
      "learning_rate": 2.087437237632727e-05,
      "loss": 0.1552,
      "step": 147900
    },
    {
      "epoch": 3.045517447154388,
      "grad_norm": 6.172120094299316,
      "learning_rate": 2.0868199028726643e-05,
      "loss": 0.1638,
      "step": 148000
    },
    {
      "epoch": 3.047575197929903,
      "grad_norm": 1.361450433731079,
      "learning_rate": 2.086202568112602e-05,
      "loss": 0.1856,
      "step": 148100
    },
    {
      "epoch": 3.0496329487054177,
      "grad_norm": 2.7308096885681152,
      "learning_rate": 2.0855852333525393e-05,
      "loss": 0.1777,
      "step": 148200
    },
    {
      "epoch": 3.0516906994809325,
      "grad_norm": 1.6081305742263794,
      "learning_rate": 2.0849678985924766e-05,
      "loss": 0.1745,
      "step": 148300
    },
    {
      "epoch": 3.0537484502564474,
      "grad_norm": 3.311861991882324,
      "learning_rate": 2.0843505638324142e-05,
      "loss": 0.1739,
      "step": 148400
    },
    {
      "epoch": 3.055806201031962,
      "grad_norm": 3.062080144882202,
      "learning_rate": 2.083733229072352e-05,
      "loss": 0.1558,
      "step": 148500
    },
    {
      "epoch": 3.057863951807477,
      "grad_norm": 2.9477319717407227,
      "learning_rate": 2.0831158943122892e-05,
      "loss": 0.1748,
      "step": 148600
    },
    {
      "epoch": 3.0599217025829915,
      "grad_norm": 2.2063868045806885,
      "learning_rate": 2.0824985595522265e-05,
      "loss": 0.1699,
      "step": 148700
    },
    {
      "epoch": 3.0619794533585063,
      "grad_norm": 1.6952576637268066,
      "learning_rate": 2.0818812247921642e-05,
      "loss": 0.1689,
      "step": 148800
    },
    {
      "epoch": 3.064037204134021,
      "grad_norm": 3.397876262664795,
      "learning_rate": 2.0812638900321015e-05,
      "loss": 0.1796,
      "step": 148900
    },
    {
      "epoch": 3.066094954909536,
      "grad_norm": 0.7764749526977539,
      "learning_rate": 2.0806465552720388e-05,
      "loss": 0.1463,
      "step": 149000
    },
    {
      "epoch": 3.068152705685051,
      "grad_norm": 0.6113681793212891,
      "learning_rate": 2.080029220511976e-05,
      "loss": 0.1781,
      "step": 149100
    },
    {
      "epoch": 3.0702104564605657,
      "grad_norm": 0.9126091599464417,
      "learning_rate": 2.0794118857519138e-05,
      "loss": 0.1722,
      "step": 149200
    },
    {
      "epoch": 3.0722682072360805,
      "grad_norm": 1.671024203300476,
      "learning_rate": 2.078794550991851e-05,
      "loss": 0.1754,
      "step": 149300
    },
    {
      "epoch": 3.0743259580115954,
      "grad_norm": 1.0115598440170288,
      "learning_rate": 2.0781833895793895e-05,
      "loss": 0.1608,
      "step": 149400
    },
    {
      "epoch": 3.07638370878711,
      "grad_norm": 4.937492847442627,
      "learning_rate": 2.0775660548193268e-05,
      "loss": 0.1569,
      "step": 149500
    },
    {
      "epoch": 3.078441459562625,
      "grad_norm": 2.133450984954834,
      "learning_rate": 2.076948720059264e-05,
      "loss": 0.1419,
      "step": 149600
    },
    {
      "epoch": 3.08049921033814,
      "grad_norm": 5.1161932945251465,
      "learning_rate": 2.0763313852992018e-05,
      "loss": 0.1807,
      "step": 149700
    },
    {
      "epoch": 3.0825569611136547,
      "grad_norm": 1.5541328191757202,
      "learning_rate": 2.075714050539139e-05,
      "loss": 0.1825,
      "step": 149800
    },
    {
      "epoch": 3.0846147118891696,
      "grad_norm": 1.8402209281921387,
      "learning_rate": 2.0750967157790764e-05,
      "loss": 0.1781,
      "step": 149900
    },
    {
      "epoch": 3.0866724626646844,
      "grad_norm": 4.213313102722168,
      "learning_rate": 2.0744793810190137e-05,
      "loss": 0.1568,
      "step": 150000
    },
    {
      "epoch": 3.0866724626646844,
      "eval_accuracy": 0.8365580448065173,
      "eval_f1_contradiction": 0.8487199379363848,
      "eval_loss": 0.15416516363620758,
      "eval_runtime": 72.2899,
      "eval_samples_per_second": 54.337,
      "eval_steps_per_second": 6.792,
      "step": 150000
    },
    {
      "epoch": 3.0887302134401993,
      "grad_norm": 3.902207851409912,
      "learning_rate": 2.0738620462589514e-05,
      "loss": 0.1636,
      "step": 150100
    },
    {
      "epoch": 3.090787964215714,
      "grad_norm": 3.8204610347747803,
      "learning_rate": 2.0732447114988887e-05,
      "loss": 0.166,
      "step": 150200
    },
    {
      "epoch": 3.092845714991229,
      "grad_norm": 1.8185241222381592,
      "learning_rate": 2.0726273767388263e-05,
      "loss": 0.1617,
      "step": 150300
    },
    {
      "epoch": 3.094903465766744,
      "grad_norm": 2.784184694290161,
      "learning_rate": 2.072010041978764e-05,
      "loss": 0.17,
      "step": 150400
    },
    {
      "epoch": 3.0969612165422586,
      "grad_norm": 2.472830295562744,
      "learning_rate": 2.0713927072187013e-05,
      "loss": 0.1575,
      "step": 150500
    },
    {
      "epoch": 3.0990189673177735,
      "grad_norm": 2.5404860973358154,
      "learning_rate": 2.0707753724586386e-05,
      "loss": 0.163,
      "step": 150600
    },
    {
      "epoch": 3.1010767180932883,
      "grad_norm": 5.69659948348999,
      "learning_rate": 2.070158037698576e-05,
      "loss": 0.1683,
      "step": 150700
    },
    {
      "epoch": 3.103134468868803,
      "grad_norm": 1.891335368156433,
      "learning_rate": 2.0695407029385136e-05,
      "loss": 0.1569,
      "step": 150800
    },
    {
      "epoch": 3.1051922196443176,
      "grad_norm": 1.9461469650268555,
      "learning_rate": 2.068923368178451e-05,
      "loss": 0.194,
      "step": 150900
    },
    {
      "epoch": 3.1072499704198324,
      "grad_norm": 2.9202933311462402,
      "learning_rate": 2.0683060334183882e-05,
      "loss": 0.1781,
      "step": 151000
    },
    {
      "epoch": 3.1093077211953473,
      "grad_norm": 1.8347563743591309,
      "learning_rate": 2.067688698658326e-05,
      "loss": 0.1686,
      "step": 151100
    },
    {
      "epoch": 3.111365471970862,
      "grad_norm": 3.2287495136260986,
      "learning_rate": 2.0670713638982632e-05,
      "loss": 0.1601,
      "step": 151200
    },
    {
      "epoch": 3.113423222746377,
      "grad_norm": 2.5792934894561768,
      "learning_rate": 2.0664540291382008e-05,
      "loss": 0.1487,
      "step": 151300
    },
    {
      "epoch": 3.115480973521892,
      "grad_norm": 3.6407344341278076,
      "learning_rate": 2.065836694378138e-05,
      "loss": 0.1606,
      "step": 151400
    },
    {
      "epoch": 3.1175387242974066,
      "grad_norm": 4.3348541259765625,
      "learning_rate": 2.0652255329656762e-05,
      "loss": 0.1762,
      "step": 151500
    },
    {
      "epoch": 3.1195964750729215,
      "grad_norm": 2.4718611240386963,
      "learning_rate": 2.0646081982056135e-05,
      "loss": 0.1641,
      "step": 151600
    },
    {
      "epoch": 3.1216542258484363,
      "grad_norm": 1.1514025926589966,
      "learning_rate": 2.063990863445551e-05,
      "loss": 0.1663,
      "step": 151700
    },
    {
      "epoch": 3.123711976623951,
      "grad_norm": 1.432374119758606,
      "learning_rate": 2.0633735286854885e-05,
      "loss": 0.157,
      "step": 151800
    },
    {
      "epoch": 3.125769727399466,
      "grad_norm": 8.159262657165527,
      "learning_rate": 2.0627561939254258e-05,
      "loss": 0.1945,
      "step": 151900
    },
    {
      "epoch": 3.127827478174981,
      "grad_norm": 3.440699577331543,
      "learning_rate": 2.0621388591653634e-05,
      "loss": 0.1787,
      "step": 152000
    },
    {
      "epoch": 3.1298852289504957,
      "grad_norm": 2.409862995147705,
      "learning_rate": 2.061521524405301e-05,
      "loss": 0.1517,
      "step": 152100
    },
    {
      "epoch": 3.1319429797260105,
      "grad_norm": 5.906952381134033,
      "learning_rate": 2.0609041896452384e-05,
      "loss": 0.1665,
      "step": 152200
    },
    {
      "epoch": 3.1340007305015254,
      "grad_norm": 1.6761372089385986,
      "learning_rate": 2.0602868548851757e-05,
      "loss": 0.1469,
      "step": 152300
    },
    {
      "epoch": 3.1360584812770402,
      "grad_norm": 1.5891989469528198,
      "learning_rate": 2.0596695201251134e-05,
      "loss": 0.1803,
      "step": 152400
    },
    {
      "epoch": 3.138116232052555,
      "grad_norm": 0.42536798119544983,
      "learning_rate": 2.0590521853650507e-05,
      "loss": 0.1607,
      "step": 152500
    },
    {
      "epoch": 3.14017398282807,
      "grad_norm": 4.064503192901611,
      "learning_rate": 2.058434850604988e-05,
      "loss": 0.1793,
      "step": 152600
    },
    {
      "epoch": 3.1422317336035848,
      "grad_norm": 5.239378929138184,
      "learning_rate": 2.0578175158449257e-05,
      "loss": 0.198,
      "step": 152700
    },
    {
      "epoch": 3.1442894843790996,
      "grad_norm": 1.3485413789749146,
      "learning_rate": 2.057200181084863e-05,
      "loss": 0.1499,
      "step": 152800
    },
    {
      "epoch": 3.1463472351546145,
      "grad_norm": 9.276023864746094,
      "learning_rate": 2.0565828463248003e-05,
      "loss": 0.1653,
      "step": 152900
    },
    {
      "epoch": 3.148404985930129,
      "grad_norm": 3.228952169418335,
      "learning_rate": 2.055965511564738e-05,
      "loss": 0.1733,
      "step": 153000
    },
    {
      "epoch": 3.1504627367056437,
      "grad_norm": 4.537060737609863,
      "learning_rate": 2.0553481768046756e-05,
      "loss": 0.1516,
      "step": 153100
    },
    {
      "epoch": 3.1525204874811585,
      "grad_norm": 4.074699878692627,
      "learning_rate": 2.054730842044613e-05,
      "loss": 0.1619,
      "step": 153200
    },
    {
      "epoch": 3.1545782382566734,
      "grad_norm": 3.535257577896118,
      "learning_rate": 2.0541135072845502e-05,
      "loss": 0.1538,
      "step": 153300
    },
    {
      "epoch": 3.1566359890321882,
      "grad_norm": 3.2964675426483154,
      "learning_rate": 2.0534961725244875e-05,
      "loss": 0.1762,
      "step": 153400
    },
    {
      "epoch": 3.158693739807703,
      "grad_norm": 1.3869489431381226,
      "learning_rate": 2.0528850111120256e-05,
      "loss": 0.1675,
      "step": 153500
    },
    {
      "epoch": 3.160751490583218,
      "grad_norm": 1.2693102359771729,
      "learning_rate": 2.0522676763519632e-05,
      "loss": 0.1642,
      "step": 153600
    },
    {
      "epoch": 3.1628092413587328,
      "grad_norm": 5.311844348907471,
      "learning_rate": 2.0516503415919006e-05,
      "loss": 0.163,
      "step": 153700
    },
    {
      "epoch": 3.1648669921342476,
      "grad_norm": 3.359272003173828,
      "learning_rate": 2.051033006831838e-05,
      "loss": 0.1589,
      "step": 153800
    },
    {
      "epoch": 3.1669247429097624,
      "grad_norm": 1.782385230064392,
      "learning_rate": 2.0504156720717755e-05,
      "loss": 0.1895,
      "step": 153900
    },
    {
      "epoch": 3.1689824936852773,
      "grad_norm": 3.3674192428588867,
      "learning_rate": 2.0497983373117132e-05,
      "loss": 0.1657,
      "step": 154000
    },
    {
      "epoch": 3.171040244460792,
      "grad_norm": 3.1812045574188232,
      "learning_rate": 2.0491810025516505e-05,
      "loss": 0.1675,
      "step": 154100
    },
    {
      "epoch": 3.173097995236307,
      "grad_norm": 1.0256096124649048,
      "learning_rate": 2.0485636677915878e-05,
      "loss": 0.1632,
      "step": 154200
    },
    {
      "epoch": 3.175155746011822,
      "grad_norm": 2.887871742248535,
      "learning_rate": 2.047946333031525e-05,
      "loss": 0.1604,
      "step": 154300
    },
    {
      "epoch": 3.1772134967873367,
      "grad_norm": 2.8285388946533203,
      "learning_rate": 2.0473289982714628e-05,
      "loss": 0.1663,
      "step": 154400
    },
    {
      "epoch": 3.1792712475628515,
      "grad_norm": 3.9253039360046387,
      "learning_rate": 2.0467116635114e-05,
      "loss": 0.1611,
      "step": 154500
    },
    {
      "epoch": 3.1813289983383664,
      "grad_norm": 3.5254790782928467,
      "learning_rate": 2.0460943287513374e-05,
      "loss": 0.1825,
      "step": 154600
    },
    {
      "epoch": 3.183386749113881,
      "grad_norm": 3.948291540145874,
      "learning_rate": 2.045476993991275e-05,
      "loss": 0.1721,
      "step": 154700
    },
    {
      "epoch": 3.185444499889396,
      "grad_norm": 0.8120823502540588,
      "learning_rate": 2.0448596592312127e-05,
      "loss": 0.1449,
      "step": 154800
    },
    {
      "epoch": 3.187502250664911,
      "grad_norm": 1.8234626054763794,
      "learning_rate": 2.04424232447115e-05,
      "loss": 0.1623,
      "step": 154900
    },
    {
      "epoch": 3.1895600014404257,
      "grad_norm": 2.778653860092163,
      "learning_rate": 2.0436249897110873e-05,
      "loss": 0.1663,
      "step": 155000
    },
    {
      "epoch": 3.1916177522159406,
      "grad_norm": 4.091703414916992,
      "learning_rate": 2.043007654951025e-05,
      "loss": 0.172,
      "step": 155100
    },
    {
      "epoch": 3.1936755029914554,
      "grad_norm": 1.9946473836898804,
      "learning_rate": 2.0423903201909623e-05,
      "loss": 0.1753,
      "step": 155200
    },
    {
      "epoch": 3.19573325376697,
      "grad_norm": 2.089482069015503,
      "learning_rate": 2.0417729854308996e-05,
      "loss": 0.1635,
      "step": 155300
    },
    {
      "epoch": 3.1977910045424847,
      "grad_norm": 3.3368749618530273,
      "learning_rate": 2.0411556506708373e-05,
      "loss": 0.1689,
      "step": 155400
    },
    {
      "epoch": 3.1998487553179995,
      "grad_norm": 2.1489908695220947,
      "learning_rate": 2.040544489258375e-05,
      "loss": 0.1768,
      "step": 155500
    },
    {
      "epoch": 3.2019065060935143,
      "grad_norm": 2.046712636947632,
      "learning_rate": 2.0399271544983126e-05,
      "loss": 0.1802,
      "step": 155600
    },
    {
      "epoch": 3.203964256869029,
      "grad_norm": 5.004390239715576,
      "learning_rate": 2.0393098197382503e-05,
      "loss": 0.1572,
      "step": 155700
    },
    {
      "epoch": 3.206022007644544,
      "grad_norm": 5.164608955383301,
      "learning_rate": 2.0386924849781876e-05,
      "loss": 0.1794,
      "step": 155800
    },
    {
      "epoch": 3.208079758420059,
      "grad_norm": 3.698941230773926,
      "learning_rate": 2.038075150218125e-05,
      "loss": 0.17,
      "step": 155900
    },
    {
      "epoch": 3.2101375091955737,
      "grad_norm": 4.59806489944458,
      "learning_rate": 2.0374578154580626e-05,
      "loss": 0.1635,
      "step": 156000
    },
    {
      "epoch": 3.2121952599710886,
      "grad_norm": 0.5708600282669067,
      "learning_rate": 2.036840480698e-05,
      "loss": 0.1556,
      "step": 156100
    },
    {
      "epoch": 3.2142530107466034,
      "grad_norm": 4.344179630279541,
      "learning_rate": 2.0362231459379372e-05,
      "loss": 0.1687,
      "step": 156200
    },
    {
      "epoch": 3.2163107615221183,
      "grad_norm": 5.220786094665527,
      "learning_rate": 2.035605811177875e-05,
      "loss": 0.162,
      "step": 156300
    },
    {
      "epoch": 3.218368512297633,
      "grad_norm": 2.094627857208252,
      "learning_rate": 2.034988476417812e-05,
      "loss": 0.1869,
      "step": 156400
    },
    {
      "epoch": 3.220426263073148,
      "grad_norm": 1.8021408319473267,
      "learning_rate": 2.0343711416577495e-05,
      "loss": 0.1806,
      "step": 156500
    },
    {
      "epoch": 3.222484013848663,
      "grad_norm": 3.4865684509277344,
      "learning_rate": 2.033753806897687e-05,
      "loss": 0.1527,
      "step": 156600
    },
    {
      "epoch": 3.2245417646241776,
      "grad_norm": 3.4585416316986084,
      "learning_rate": 2.0331364721376248e-05,
      "loss": 0.1895,
      "step": 156700
    },
    {
      "epoch": 3.2265995153996925,
      "grad_norm": 3.2757859230041504,
      "learning_rate": 2.032519137377562e-05,
      "loss": 0.1644,
      "step": 156800
    },
    {
      "epoch": 3.2286572661752073,
      "grad_norm": 2.296051502227783,
      "learning_rate": 2.0319018026174994e-05,
      "loss": 0.162,
      "step": 156900
    },
    {
      "epoch": 3.230715016950722,
      "grad_norm": 2.336672067642212,
      "learning_rate": 2.0312844678574367e-05,
      "loss": 0.1602,
      "step": 157000
    },
    {
      "epoch": 3.232772767726237,
      "grad_norm": 4.407217502593994,
      "learning_rate": 2.0306671330973744e-05,
      "loss": 0.1651,
      "step": 157100
    },
    {
      "epoch": 3.234830518501752,
      "grad_norm": 0.8061791062355042,
      "learning_rate": 2.0300497983373117e-05,
      "loss": 0.1474,
      "step": 157200
    },
    {
      "epoch": 3.2368882692772667,
      "grad_norm": 2.6631579399108887,
      "learning_rate": 2.029432463577249e-05,
      "loss": 0.1538,
      "step": 157300
    },
    {
      "epoch": 3.238946020052781,
      "grad_norm": 2.5488734245300293,
      "learning_rate": 2.0288151288171867e-05,
      "loss": 0.1402,
      "step": 157400
    },
    {
      "epoch": 3.241003770828296,
      "grad_norm": 3.9768128395080566,
      "learning_rate": 2.028197794057124e-05,
      "loss": 0.1747,
      "step": 157500
    },
    {
      "epoch": 3.243061521603811,
      "grad_norm": 2.296656608581543,
      "learning_rate": 2.0275866326446624e-05,
      "loss": 0.1843,
      "step": 157600
    },
    {
      "epoch": 3.2451192723793256,
      "grad_norm": 2.6023709774017334,
      "learning_rate": 2.0269692978845997e-05,
      "loss": 0.1719,
      "step": 157700
    },
    {
      "epoch": 3.2471770231548405,
      "grad_norm": 1.877605676651001,
      "learning_rate": 2.026351963124537e-05,
      "loss": 0.1697,
      "step": 157800
    },
    {
      "epoch": 3.2492347739303553,
      "grad_norm": 2.8623006343841553,
      "learning_rate": 2.0257346283644747e-05,
      "loss": 0.1842,
      "step": 157900
    },
    {
      "epoch": 3.25129252470587,
      "grad_norm": 1.9125760793685913,
      "learning_rate": 2.025117293604412e-05,
      "loss": 0.1825,
      "step": 158000
    },
    {
      "epoch": 3.253350275481385,
      "grad_norm": 0.8304436802864075,
      "learning_rate": 2.0244999588443493e-05,
      "loss": 0.1759,
      "step": 158100
    },
    {
      "epoch": 3.2554080262569,
      "grad_norm": 1.6299312114715576,
      "learning_rate": 2.0238826240842866e-05,
      "loss": 0.1661,
      "step": 158200
    },
    {
      "epoch": 3.2574657770324147,
      "grad_norm": 0.68519526720047,
      "learning_rate": 2.0232652893242242e-05,
      "loss": 0.1675,
      "step": 158300
    },
    {
      "epoch": 3.2595235278079295,
      "grad_norm": 2.0508553981781006,
      "learning_rate": 2.022647954564162e-05,
      "loss": 0.1886,
      "step": 158400
    },
    {
      "epoch": 3.2615812785834444,
      "grad_norm": 2.578108310699463,
      "learning_rate": 2.0220306198040992e-05,
      "loss": 0.1622,
      "step": 158500
    },
    {
      "epoch": 3.263639029358959,
      "grad_norm": 5.248737335205078,
      "learning_rate": 2.0214132850440365e-05,
      "loss": 0.1793,
      "step": 158600
    },
    {
      "epoch": 3.265696780134474,
      "grad_norm": 2.18152117729187,
      "learning_rate": 2.0207959502839742e-05,
      "loss": 0.1822,
      "step": 158700
    },
    {
      "epoch": 3.267754530909989,
      "grad_norm": 2.9059669971466064,
      "learning_rate": 2.0201786155239115e-05,
      "loss": 0.1599,
      "step": 158800
    },
    {
      "epoch": 3.2698122816855038,
      "grad_norm": 2.378218650817871,
      "learning_rate": 2.0195612807638488e-05,
      "loss": 0.1543,
      "step": 158900
    },
    {
      "epoch": 3.2718700324610186,
      "grad_norm": 4.0237298011779785,
      "learning_rate": 2.0189439460037865e-05,
      "loss": 0.1632,
      "step": 159000
    },
    {
      "epoch": 3.2739277832365334,
      "grad_norm": 5.188135623931885,
      "learning_rate": 2.0183266112437238e-05,
      "loss": 0.1655,
      "step": 159100
    },
    {
      "epoch": 3.2759855340120483,
      "grad_norm": 2.8188934326171875,
      "learning_rate": 2.017709276483661e-05,
      "loss": 0.1781,
      "step": 159200
    },
    {
      "epoch": 3.278043284787563,
      "grad_norm": 4.832928657531738,
      "learning_rate": 2.0170919417235984e-05,
      "loss": 0.1808,
      "step": 159300
    },
    {
      "epoch": 3.280101035563078,
      "grad_norm": 2.807588577270508,
      "learning_rate": 2.0164746069635364e-05,
      "loss": 0.1512,
      "step": 159400
    },
    {
      "epoch": 3.2821587863385924,
      "grad_norm": 3.264935255050659,
      "learning_rate": 2.0158572722034737e-05,
      "loss": 0.1655,
      "step": 159500
    },
    {
      "epoch": 3.2842165371141077,
      "grad_norm": 0.697145402431488,
      "learning_rate": 2.0152461107910118e-05,
      "loss": 0.1543,
      "step": 159600
    },
    {
      "epoch": 3.286274287889622,
      "grad_norm": 2.717954158782959,
      "learning_rate": 2.014628776030949e-05,
      "loss": 0.1915,
      "step": 159700
    },
    {
      "epoch": 3.288332038665137,
      "grad_norm": 2.4629688262939453,
      "learning_rate": 2.0140114412708864e-05,
      "loss": 0.1646,
      "step": 159800
    },
    {
      "epoch": 3.2903897894406517,
      "grad_norm": 3.0744621753692627,
      "learning_rate": 2.013394106510824e-05,
      "loss": 0.1673,
      "step": 159900
    },
    {
      "epoch": 3.2924475402161666,
      "grad_norm": 2.3147358894348145,
      "learning_rate": 2.0127767717507614e-05,
      "loss": 0.1843,
      "step": 160000
    },
    {
      "epoch": 3.2924475402161666,
      "eval_accuracy": 0.8312118126272913,
      "eval_f1_contradiction": 0.8406572411157814,
      "eval_loss": 0.15912775695323944,
      "eval_runtime": 74.5348,
      "eval_samples_per_second": 52.7,
      "eval_steps_per_second": 6.588,
      "step": 160000
    },
    {
      "epoch": 3.2945052909916814,
      "grad_norm": 1.0054963827133179,
      "learning_rate": 2.0121594369906987e-05,
      "loss": 0.174,
      "step": 160100
    },
    {
      "epoch": 3.2965630417671963,
      "grad_norm": 3.458172082901001,
      "learning_rate": 2.0115421022306363e-05,
      "loss": 0.1665,
      "step": 160200
    },
    {
      "epoch": 3.298620792542711,
      "grad_norm": 5.686322212219238,
      "learning_rate": 2.010924767470574e-05,
      "loss": 0.1713,
      "step": 160300
    },
    {
      "epoch": 3.300678543318226,
      "grad_norm": 1.7933809757232666,
      "learning_rate": 2.0103074327105113e-05,
      "loss": 0.1801,
      "step": 160400
    },
    {
      "epoch": 3.302736294093741,
      "grad_norm": 0.7603342533111572,
      "learning_rate": 2.0096900979504486e-05,
      "loss": 0.1633,
      "step": 160500
    },
    {
      "epoch": 3.3047940448692557,
      "grad_norm": 5.359882831573486,
      "learning_rate": 2.0090727631903863e-05,
      "loss": 0.1655,
      "step": 160600
    },
    {
      "epoch": 3.3068517956447705,
      "grad_norm": 3.031111717224121,
      "learning_rate": 2.0084554284303236e-05,
      "loss": 0.1552,
      "step": 160700
    },
    {
      "epoch": 3.3089095464202853,
      "grad_norm": 1.2372722625732422,
      "learning_rate": 2.007838093670261e-05,
      "loss": 0.1598,
      "step": 160800
    },
    {
      "epoch": 3.3109672971958,
      "grad_norm": 2.8555331230163574,
      "learning_rate": 2.0072207589101982e-05,
      "loss": 0.1647,
      "step": 160900
    },
    {
      "epoch": 3.313025047971315,
      "grad_norm": 1.1421756744384766,
      "learning_rate": 2.006603424150136e-05,
      "loss": 0.1687,
      "step": 161000
    },
    {
      "epoch": 3.31508279874683,
      "grad_norm": 2.7482597827911377,
      "learning_rate": 2.0059860893900732e-05,
      "loss": 0.1553,
      "step": 161100
    },
    {
      "epoch": 3.3171405495223447,
      "grad_norm": 3.475353956222534,
      "learning_rate": 2.005368754630011e-05,
      "loss": 0.1916,
      "step": 161200
    },
    {
      "epoch": 3.3191983002978596,
      "grad_norm": 3.2279179096221924,
      "learning_rate": 2.004751419869948e-05,
      "loss": 0.1571,
      "step": 161300
    },
    {
      "epoch": 3.3212560510733744,
      "grad_norm": 1.5133979320526123,
      "learning_rate": 2.0041340851098858e-05,
      "loss": 0.1559,
      "step": 161400
    },
    {
      "epoch": 3.3233138018488892,
      "grad_norm": 2.6005327701568604,
      "learning_rate": 2.003516750349823e-05,
      "loss": 0.1595,
      "step": 161500
    },
    {
      "epoch": 3.3253715526244036,
      "grad_norm": 2.8183069229125977,
      "learning_rate": 2.0028994155897604e-05,
      "loss": 0.1642,
      "step": 161600
    },
    {
      "epoch": 3.327429303399919,
      "grad_norm": 0.65384441614151,
      "learning_rate": 2.0022882541772985e-05,
      "loss": 0.1548,
      "step": 161700
    },
    {
      "epoch": 3.3294870541754333,
      "grad_norm": 3.1434671878814697,
      "learning_rate": 2.0016709194172358e-05,
      "loss": 0.1723,
      "step": 161800
    },
    {
      "epoch": 3.331544804950948,
      "grad_norm": 2.067185878753662,
      "learning_rate": 2.0010535846571734e-05,
      "loss": 0.1614,
      "step": 161900
    },
    {
      "epoch": 3.333602555726463,
      "grad_norm": 1.109392762184143,
      "learning_rate": 2.000436249897111e-05,
      "loss": 0.1768,
      "step": 162000
    },
    {
      "epoch": 3.335660306501978,
      "grad_norm": 4.502112865447998,
      "learning_rate": 1.9998189151370484e-05,
      "loss": 0.1462,
      "step": 162100
    },
    {
      "epoch": 3.3377180572774927,
      "grad_norm": 7.610088348388672,
      "learning_rate": 1.999201580376986e-05,
      "loss": 0.1661,
      "step": 162200
    },
    {
      "epoch": 3.3397758080530076,
      "grad_norm": 1.8754682540893555,
      "learning_rate": 1.9985842456169234e-05,
      "loss": 0.1811,
      "step": 162300
    },
    {
      "epoch": 3.3418335588285224,
      "grad_norm": 1.9693328142166138,
      "learning_rate": 1.9979669108568607e-05,
      "loss": 0.1653,
      "step": 162400
    },
    {
      "epoch": 3.3438913096040372,
      "grad_norm": 1.6867780685424805,
      "learning_rate": 1.997349576096798e-05,
      "loss": 0.1676,
      "step": 162500
    },
    {
      "epoch": 3.345949060379552,
      "grad_norm": 3.757697582244873,
      "learning_rate": 1.9967322413367357e-05,
      "loss": 0.1857,
      "step": 162600
    },
    {
      "epoch": 3.348006811155067,
      "grad_norm": 4.331252574920654,
      "learning_rate": 1.996114906576673e-05,
      "loss": 0.1697,
      "step": 162700
    },
    {
      "epoch": 3.3500645619305818,
      "grad_norm": 1.871255874633789,
      "learning_rate": 1.9954975718166103e-05,
      "loss": 0.1581,
      "step": 162800
    },
    {
      "epoch": 3.3521223127060966,
      "grad_norm": 1.6338926553726196,
      "learning_rate": 1.9948802370565476e-05,
      "loss": 0.1627,
      "step": 162900
    },
    {
      "epoch": 3.3541800634816115,
      "grad_norm": 2.996440887451172,
      "learning_rate": 1.9942629022964856e-05,
      "loss": 0.1651,
      "step": 163000
    },
    {
      "epoch": 3.3562378142571263,
      "grad_norm": 1.5643020868301392,
      "learning_rate": 1.993645567536423e-05,
      "loss": 0.1746,
      "step": 163100
    },
    {
      "epoch": 3.358295565032641,
      "grad_norm": 1.8115167617797852,
      "learning_rate": 1.9930282327763602e-05,
      "loss": 0.1456,
      "step": 163200
    },
    {
      "epoch": 3.360353315808156,
      "grad_norm": 2.54994797706604,
      "learning_rate": 1.992410898016298e-05,
      "loss": 0.1657,
      "step": 163300
    },
    {
      "epoch": 3.362411066583671,
      "grad_norm": 1.714900016784668,
      "learning_rate": 1.9917935632562352e-05,
      "loss": 0.171,
      "step": 163400
    },
    {
      "epoch": 3.3644688173591857,
      "grad_norm": 6.41170072555542,
      "learning_rate": 1.9911762284961725e-05,
      "loss": 0.172,
      "step": 163500
    },
    {
      "epoch": 3.3665265681347005,
      "grad_norm": 4.866340637207031,
      "learning_rate": 1.9905588937361098e-05,
      "loss": 0.1758,
      "step": 163600
    },
    {
      "epoch": 3.3685843189102154,
      "grad_norm": 2.236112117767334,
      "learning_rate": 1.9899415589760475e-05,
      "loss": 0.1642,
      "step": 163700
    },
    {
      "epoch": 3.37064206968573,
      "grad_norm": 2.0903542041778564,
      "learning_rate": 1.9893303975635855e-05,
      "loss": 0.1763,
      "step": 163800
    },
    {
      "epoch": 3.3726998204612446,
      "grad_norm": 4.542496204376221,
      "learning_rate": 1.9887130628035232e-05,
      "loss": 0.1824,
      "step": 163900
    },
    {
      "epoch": 3.37475757123676,
      "grad_norm": 0.34153467416763306,
      "learning_rate": 1.9880957280434605e-05,
      "loss": 0.1818,
      "step": 164000
    },
    {
      "epoch": 3.3768153220122743,
      "grad_norm": 0.25640758872032166,
      "learning_rate": 1.9874783932833978e-05,
      "loss": 0.1601,
      "step": 164100
    },
    {
      "epoch": 3.378873072787789,
      "grad_norm": 4.093774795532227,
      "learning_rate": 1.9868610585233355e-05,
      "loss": 0.1544,
      "step": 164200
    },
    {
      "epoch": 3.380930823563304,
      "grad_norm": 2.7370221614837646,
      "learning_rate": 1.9862437237632728e-05,
      "loss": 0.1601,
      "step": 164300
    },
    {
      "epoch": 3.382988574338819,
      "grad_norm": 2.3477816581726074,
      "learning_rate": 1.98562638900321e-05,
      "loss": 0.1796,
      "step": 164400
    },
    {
      "epoch": 3.3850463251143337,
      "grad_norm": 1.1523444652557373,
      "learning_rate": 1.9850090542431474e-05,
      "loss": 0.1736,
      "step": 164500
    },
    {
      "epoch": 3.3871040758898485,
      "grad_norm": 2.1012117862701416,
      "learning_rate": 1.984391719483085e-05,
      "loss": 0.1721,
      "step": 164600
    },
    {
      "epoch": 3.3891618266653634,
      "grad_norm": 1.7671937942504883,
      "learning_rate": 1.9837743847230224e-05,
      "loss": 0.1658,
      "step": 164700
    },
    {
      "epoch": 3.391219577440878,
      "grad_norm": 1.6927562952041626,
      "learning_rate": 1.98315704996296e-05,
      "loss": 0.1817,
      "step": 164800
    },
    {
      "epoch": 3.393277328216393,
      "grad_norm": 2.7125017642974854,
      "learning_rate": 1.9825397152028977e-05,
      "loss": 0.1599,
      "step": 164900
    },
    {
      "epoch": 3.395335078991908,
      "grad_norm": 3.959123134613037,
      "learning_rate": 1.981922380442835e-05,
      "loss": 0.1637,
      "step": 165000
    },
    {
      "epoch": 3.3973928297674227,
      "grad_norm": 0.8994197249412537,
      "learning_rate": 1.9813050456827723e-05,
      "loss": 0.1769,
      "step": 165100
    },
    {
      "epoch": 3.3994505805429376,
      "grad_norm": 0.5240907669067383,
      "learning_rate": 1.9806877109227096e-05,
      "loss": 0.1527,
      "step": 165200
    },
    {
      "epoch": 3.4015083313184524,
      "grad_norm": 2.490236520767212,
      "learning_rate": 1.9800703761626473e-05,
      "loss": 0.1475,
      "step": 165300
    },
    {
      "epoch": 3.4035660820939673,
      "grad_norm": 3.841740608215332,
      "learning_rate": 1.9794530414025846e-05,
      "loss": 0.1715,
      "step": 165400
    },
    {
      "epoch": 3.405623832869482,
      "grad_norm": 0.6735965013504028,
      "learning_rate": 1.978835706642522e-05,
      "loss": 0.1838,
      "step": 165500
    },
    {
      "epoch": 3.407681583644997,
      "grad_norm": 2.0676350593566895,
      "learning_rate": 1.9782183718824592e-05,
      "loss": 0.179,
      "step": 165600
    },
    {
      "epoch": 3.409739334420512,
      "grad_norm": 2.1922268867492676,
      "learning_rate": 1.977601037122397e-05,
      "loss": 0.1661,
      "step": 165700
    },
    {
      "epoch": 3.4117970851960266,
      "grad_norm": 1.1723753213882446,
      "learning_rate": 1.9769837023623345e-05,
      "loss": 0.1527,
      "step": 165800
    },
    {
      "epoch": 3.4138548359715415,
      "grad_norm": 1.9544222354888916,
      "learning_rate": 1.9763725409498726e-05,
      "loss": 0.1768,
      "step": 165900
    },
    {
      "epoch": 3.415912586747056,
      "grad_norm": 6.008524417877197,
      "learning_rate": 1.97575520618981e-05,
      "loss": 0.166,
      "step": 166000
    },
    {
      "epoch": 3.417970337522571,
      "grad_norm": 2.454936981201172,
      "learning_rate": 1.9751378714297472e-05,
      "loss": 0.1636,
      "step": 166100
    },
    {
      "epoch": 3.4200280882980856,
      "grad_norm": 3.896928071975708,
      "learning_rate": 1.974520536669685e-05,
      "loss": 0.1477,
      "step": 166200
    },
    {
      "epoch": 3.4220858390736004,
      "grad_norm": 1.4617234468460083,
      "learning_rate": 1.9739032019096222e-05,
      "loss": 0.1781,
      "step": 166300
    },
    {
      "epoch": 3.4241435898491153,
      "grad_norm": 0.45399752259254456,
      "learning_rate": 1.9732858671495595e-05,
      "loss": 0.1606,
      "step": 166400
    },
    {
      "epoch": 3.42620134062463,
      "grad_norm": 2.8777530193328857,
      "learning_rate": 1.972668532389497e-05,
      "loss": 0.1597,
      "step": 166500
    },
    {
      "epoch": 3.428259091400145,
      "grad_norm": 1.7313475608825684,
      "learning_rate": 1.9720511976294348e-05,
      "loss": 0.1707,
      "step": 166600
    },
    {
      "epoch": 3.43031684217566,
      "grad_norm": 3.065110683441162,
      "learning_rate": 1.971433862869372e-05,
      "loss": 0.1811,
      "step": 166700
    },
    {
      "epoch": 3.4323745929511746,
      "grad_norm": 0.19663015007972717,
      "learning_rate": 1.9708165281093094e-05,
      "loss": 0.1715,
      "step": 166800
    },
    {
      "epoch": 3.4344323437266895,
      "grad_norm": 1.4981132745742798,
      "learning_rate": 1.970199193349247e-05,
      "loss": 0.1653,
      "step": 166900
    },
    {
      "epoch": 3.4364900945022043,
      "grad_norm": 4.208459854125977,
      "learning_rate": 1.9695818585891844e-05,
      "loss": 0.1625,
      "step": 167000
    },
    {
      "epoch": 3.438547845277719,
      "grad_norm": 4.003052234649658,
      "learning_rate": 1.9689645238291217e-05,
      "loss": 0.1812,
      "step": 167100
    },
    {
      "epoch": 3.440605596053234,
      "grad_norm": 2.56367564201355,
      "learning_rate": 1.968347189069059e-05,
      "loss": 0.1701,
      "step": 167200
    },
    {
      "epoch": 3.442663346828749,
      "grad_norm": 4.152351379394531,
      "learning_rate": 1.9677298543089967e-05,
      "loss": 0.1645,
      "step": 167300
    },
    {
      "epoch": 3.4447210976042637,
      "grad_norm": 3.183922052383423,
      "learning_rate": 1.967112519548934e-05,
      "loss": 0.1462,
      "step": 167400
    },
    {
      "epoch": 3.4467788483797785,
      "grad_norm": 2.1465115547180176,
      "learning_rate": 1.9664951847888716e-05,
      "loss": 0.1495,
      "step": 167500
    },
    {
      "epoch": 3.4488365991552934,
      "grad_norm": 7.8576483726501465,
      "learning_rate": 1.9658778500288093e-05,
      "loss": 0.1776,
      "step": 167600
    },
    {
      "epoch": 3.4508943499308082,
      "grad_norm": 3.052361249923706,
      "learning_rate": 1.9652605152687466e-05,
      "loss": 0.16,
      "step": 167700
    },
    {
      "epoch": 3.452952100706323,
      "grad_norm": 4.570282459259033,
      "learning_rate": 1.964643180508684e-05,
      "loss": 0.1572,
      "step": 167800
    },
    {
      "epoch": 3.455009851481838,
      "grad_norm": 6.333056926727295,
      "learning_rate": 1.964032019096222e-05,
      "loss": 0.1507,
      "step": 167900
    },
    {
      "epoch": 3.4570676022573528,
      "grad_norm": 1.9718294143676758,
      "learning_rate": 1.9634146843361593e-05,
      "loss": 0.1391,
      "step": 168000
    },
    {
      "epoch": 3.4591253530328676,
      "grad_norm": 0.4189302623271942,
      "learning_rate": 1.9627973495760966e-05,
      "loss": 0.1691,
      "step": 168100
    },
    {
      "epoch": 3.4611831038083825,
      "grad_norm": 0.9262032508850098,
      "learning_rate": 1.9621800148160343e-05,
      "loss": 0.1514,
      "step": 168200
    },
    {
      "epoch": 3.463240854583897,
      "grad_norm": 5.503417015075684,
      "learning_rate": 1.9615626800559716e-05,
      "loss": 0.1831,
      "step": 168300
    },
    {
      "epoch": 3.465298605359412,
      "grad_norm": 2.5564258098602295,
      "learning_rate": 1.9609453452959092e-05,
      "loss": 0.1647,
      "step": 168400
    },
    {
      "epoch": 3.4673563561349265,
      "grad_norm": 4.420770645141602,
      "learning_rate": 1.960328010535847e-05,
      "loss": 0.1783,
      "step": 168500
    },
    {
      "epoch": 3.4694141069104414,
      "grad_norm": 1.4400213956832886,
      "learning_rate": 1.9597106757757842e-05,
      "loss": 0.1485,
      "step": 168600
    },
    {
      "epoch": 3.4714718576859562,
      "grad_norm": 1.5504578351974487,
      "learning_rate": 1.9590933410157215e-05,
      "loss": 0.1713,
      "step": 168700
    },
    {
      "epoch": 3.473529608461471,
      "grad_norm": 3.7557809352874756,
      "learning_rate": 1.9584760062556588e-05,
      "loss": 0.1532,
      "step": 168800
    },
    {
      "epoch": 3.475587359236986,
      "grad_norm": 3.7499475479125977,
      "learning_rate": 1.9578586714955965e-05,
      "loss": 0.1846,
      "step": 168900
    },
    {
      "epoch": 3.4776451100125008,
      "grad_norm": 2.9931609630584717,
      "learning_rate": 1.9572413367355338e-05,
      "loss": 0.157,
      "step": 169000
    },
    {
      "epoch": 3.4797028607880156,
      "grad_norm": 1.6553574800491333,
      "learning_rate": 1.956624001975471e-05,
      "loss": 0.1668,
      "step": 169100
    },
    {
      "epoch": 3.4817606115635304,
      "grad_norm": 5.2074971199035645,
      "learning_rate": 1.9560066672154088e-05,
      "loss": 0.1725,
      "step": 169200
    },
    {
      "epoch": 3.4838183623390453,
      "grad_norm": 4.966374397277832,
      "learning_rate": 1.955389332455346e-05,
      "loss": 0.1848,
      "step": 169300
    },
    {
      "epoch": 3.48587611311456,
      "grad_norm": 3.13209867477417,
      "learning_rate": 1.9547719976952837e-05,
      "loss": 0.1865,
      "step": 169400
    },
    {
      "epoch": 3.487933863890075,
      "grad_norm": 2.00925612449646,
      "learning_rate": 1.954154662935221e-05,
      "loss": 0.1678,
      "step": 169500
    },
    {
      "epoch": 3.48999161466559,
      "grad_norm": 5.5276336669921875,
      "learning_rate": 1.9535373281751587e-05,
      "loss": 0.1852,
      "step": 169600
    },
    {
      "epoch": 3.4920493654411047,
      "grad_norm": 3.7355175018310547,
      "learning_rate": 1.952919993415096e-05,
      "loss": 0.1724,
      "step": 169700
    },
    {
      "epoch": 3.4941071162166195,
      "grad_norm": 0.5701804757118225,
      "learning_rate": 1.9523026586550333e-05,
      "loss": 0.1649,
      "step": 169800
    },
    {
      "epoch": 3.4961648669921344,
      "grad_norm": 2.015961170196533,
      "learning_rate": 1.9516914972425714e-05,
      "loss": 0.1695,
      "step": 169900
    },
    {
      "epoch": 3.498222617767649,
      "grad_norm": 3.414231538772583,
      "learning_rate": 1.9510741624825087e-05,
      "loss": 0.1598,
      "step": 170000
    },
    {
      "epoch": 3.498222617767649,
      "eval_accuracy": 0.8378309572301426,
      "eval_f1_contradiction": 0.8446866485013624,
      "eval_loss": 0.15275871753692627,
      "eval_runtime": 76.5222,
      "eval_samples_per_second": 51.332,
      "eval_steps_per_second": 6.416,
      "step": 170000
    },
    {
      "epoch": 3.500280368543164,
      "grad_norm": 4.777551174163818,
      "learning_rate": 1.9504568277224463e-05,
      "loss": 0.1836,
      "step": 170100
    },
    {
      "epoch": 3.5023381193186784,
      "grad_norm": 4.367696762084961,
      "learning_rate": 1.949839492962384e-05,
      "loss": 0.1641,
      "step": 170200
    },
    {
      "epoch": 3.5043958700941937,
      "grad_norm": 2.2860605716705322,
      "learning_rate": 1.9492221582023213e-05,
      "loss": 0.1639,
      "step": 170300
    },
    {
      "epoch": 3.506453620869708,
      "grad_norm": 3.1469271183013916,
      "learning_rate": 1.9486048234422586e-05,
      "loss": 0.1665,
      "step": 170400
    },
    {
      "epoch": 3.5085113716452234,
      "grad_norm": 2.8562204837799072,
      "learning_rate": 1.9479874886821963e-05,
      "loss": 0.1665,
      "step": 170500
    },
    {
      "epoch": 3.510569122420738,
      "grad_norm": 2.941406011581421,
      "learning_rate": 1.9473701539221336e-05,
      "loss": 0.1511,
      "step": 170600
    },
    {
      "epoch": 3.512626873196253,
      "grad_norm": 2.0562448501586914,
      "learning_rate": 1.946752819162071e-05,
      "loss": 0.1714,
      "step": 170700
    },
    {
      "epoch": 3.5146846239717675,
      "grad_norm": 3.7571709156036377,
      "learning_rate": 1.9461354844020082e-05,
      "loss": 0.1579,
      "step": 170800
    },
    {
      "epoch": 3.5167423747472824,
      "grad_norm": 2.5664138793945312,
      "learning_rate": 1.945518149641946e-05,
      "loss": 0.1629,
      "step": 170900
    },
    {
      "epoch": 3.518800125522797,
      "grad_norm": 6.023200511932373,
      "learning_rate": 1.9449008148818832e-05,
      "loss": 0.1708,
      "step": 171000
    },
    {
      "epoch": 3.520857876298312,
      "grad_norm": 1.4732937812805176,
      "learning_rate": 1.944283480121821e-05,
      "loss": 0.1565,
      "step": 171100
    },
    {
      "epoch": 3.522915627073827,
      "grad_norm": 8.628875732421875,
      "learning_rate": 1.9436661453617585e-05,
      "loss": 0.1566,
      "step": 171200
    },
    {
      "epoch": 3.5249733778493417,
      "grad_norm": 1.9574662446975708,
      "learning_rate": 1.9430488106016958e-05,
      "loss": 0.1618,
      "step": 171300
    },
    {
      "epoch": 3.5270311286248566,
      "grad_norm": 3.0561537742614746,
      "learning_rate": 1.942431475841633e-05,
      "loss": 0.1641,
      "step": 171400
    },
    {
      "epoch": 3.5290888794003714,
      "grad_norm": 6.814128398895264,
      "learning_rate": 1.9418141410815704e-05,
      "loss": 0.1568,
      "step": 171500
    },
    {
      "epoch": 3.5311466301758863,
      "grad_norm": 5.331801891326904,
      "learning_rate": 1.941196806321508e-05,
      "loss": 0.1643,
      "step": 171600
    },
    {
      "epoch": 3.533204380951401,
      "grad_norm": 1.062245488166809,
      "learning_rate": 1.9405794715614454e-05,
      "loss": 0.1707,
      "step": 171700
    },
    {
      "epoch": 3.535262131726916,
      "grad_norm": 1.3237495422363281,
      "learning_rate": 1.9399621368013827e-05,
      "loss": 0.1695,
      "step": 171800
    },
    {
      "epoch": 3.537319882502431,
      "grad_norm": 2.019333600997925,
      "learning_rate": 1.9393509753889208e-05,
      "loss": 0.1625,
      "step": 171900
    },
    {
      "epoch": 3.5393776332779456,
      "grad_norm": 1.6608868837356567,
      "learning_rate": 1.9387336406288584e-05,
      "loss": 0.1547,
      "step": 172000
    },
    {
      "epoch": 3.5414353840534605,
      "grad_norm": 5.211972236633301,
      "learning_rate": 1.938116305868796e-05,
      "loss": 0.1677,
      "step": 172100
    },
    {
      "epoch": 3.5434931348289753,
      "grad_norm": 4.975892543792725,
      "learning_rate": 1.9374989711087334e-05,
      "loss": 0.1602,
      "step": 172200
    },
    {
      "epoch": 3.54555088560449,
      "grad_norm": 3.4319541454315186,
      "learning_rate": 1.9368816363486707e-05,
      "loss": 0.1695,
      "step": 172300
    },
    {
      "epoch": 3.547608636380005,
      "grad_norm": 3.537148952484131,
      "learning_rate": 1.936264301588608e-05,
      "loss": 0.1749,
      "step": 172400
    },
    {
      "epoch": 3.5496663871555194,
      "grad_norm": 1.3666843175888062,
      "learning_rate": 1.9356469668285457e-05,
      "loss": 0.163,
      "step": 172500
    },
    {
      "epoch": 3.5517241379310347,
      "grad_norm": 2.4775209426879883,
      "learning_rate": 1.935029632068483e-05,
      "loss": 0.1681,
      "step": 172600
    },
    {
      "epoch": 3.553781888706549,
      "grad_norm": 3.7238504886627197,
      "learning_rate": 1.9344122973084203e-05,
      "loss": 0.177,
      "step": 172700
    },
    {
      "epoch": 3.5558396394820644,
      "grad_norm": 3.291477680206299,
      "learning_rate": 1.933794962548358e-05,
      "loss": 0.1805,
      "step": 172800
    },
    {
      "epoch": 3.557897390257579,
      "grad_norm": 4.388004779815674,
      "learning_rate": 1.9331776277882956e-05,
      "loss": 0.1758,
      "step": 172900
    },
    {
      "epoch": 3.5599551410330936,
      "grad_norm": 3.327609062194824,
      "learning_rate": 1.932560293028233e-05,
      "loss": 0.1781,
      "step": 173000
    },
    {
      "epoch": 3.5620128918086085,
      "grad_norm": 1.5880520343780518,
      "learning_rate": 1.9319429582681702e-05,
      "loss": 0.184,
      "step": 173100
    },
    {
      "epoch": 3.5640706425841233,
      "grad_norm": 1.9393965005874634,
      "learning_rate": 1.931325623508108e-05,
      "loss": 0.1713,
      "step": 173200
    },
    {
      "epoch": 3.566128393359638,
      "grad_norm": 3.0374724864959717,
      "learning_rate": 1.9307082887480452e-05,
      "loss": 0.1659,
      "step": 173300
    },
    {
      "epoch": 3.568186144135153,
      "grad_norm": 2.2011497020721436,
      "learning_rate": 1.9300909539879825e-05,
      "loss": 0.169,
      "step": 173400
    },
    {
      "epoch": 3.570243894910668,
      "grad_norm": 5.132964134216309,
      "learning_rate": 1.92947361922792e-05,
      "loss": 0.1734,
      "step": 173500
    },
    {
      "epoch": 3.5723016456861827,
      "grad_norm": 2.0639986991882324,
      "learning_rate": 1.9288562844678575e-05,
      "loss": 0.1777,
      "step": 173600
    },
    {
      "epoch": 3.5743593964616975,
      "grad_norm": 6.074296474456787,
      "learning_rate": 1.9282389497077948e-05,
      "loss": 0.1706,
      "step": 173700
    },
    {
      "epoch": 3.5764171472372124,
      "grad_norm": 0.5475917458534241,
      "learning_rate": 1.927621614947732e-05,
      "loss": 0.1696,
      "step": 173800
    },
    {
      "epoch": 3.5784748980127272,
      "grad_norm": 2.819406747817993,
      "learning_rate": 1.92700428018767e-05,
      "loss": 0.1612,
      "step": 173900
    },
    {
      "epoch": 3.580532648788242,
      "grad_norm": 4.917048931121826,
      "learning_rate": 1.9263931187752078e-05,
      "loss": 0.1844,
      "step": 174000
    },
    {
      "epoch": 3.582590399563757,
      "grad_norm": 3.8463640213012695,
      "learning_rate": 1.9257757840151455e-05,
      "loss": 0.1734,
      "step": 174100
    },
    {
      "epoch": 3.5846481503392718,
      "grad_norm": 3.8721117973327637,
      "learning_rate": 1.9251584492550828e-05,
      "loss": 0.1604,
      "step": 174200
    },
    {
      "epoch": 3.5867059011147866,
      "grad_norm": 4.0923662185668945,
      "learning_rate": 1.92454111449502e-05,
      "loss": 0.153,
      "step": 174300
    },
    {
      "epoch": 3.5887636518903014,
      "grad_norm": 0.8876078128814697,
      "learning_rate": 1.9239237797349577e-05,
      "loss": 0.1771,
      "step": 174400
    },
    {
      "epoch": 3.5908214026658163,
      "grad_norm": 4.558426380157471,
      "learning_rate": 1.923306444974895e-05,
      "loss": 0.1695,
      "step": 174500
    },
    {
      "epoch": 3.5928791534413307,
      "grad_norm": 4.322988033294678,
      "learning_rate": 1.9226891102148324e-05,
      "loss": 0.1705,
      "step": 174600
    },
    {
      "epoch": 3.594936904216846,
      "grad_norm": 1.526854395866394,
      "learning_rate": 1.92207177545477e-05,
      "loss": 0.1857,
      "step": 174700
    },
    {
      "epoch": 3.5969946549923604,
      "grad_norm": 1.728594183921814,
      "learning_rate": 1.9214544406947077e-05,
      "loss": 0.1747,
      "step": 174800
    },
    {
      "epoch": 3.5990524057678757,
      "grad_norm": 1.9038796424865723,
      "learning_rate": 1.920837105934645e-05,
      "loss": 0.1702,
      "step": 174900
    },
    {
      "epoch": 3.60111015654339,
      "grad_norm": 1.9794466495513916,
      "learning_rate": 1.9202197711745823e-05,
      "loss": 0.1762,
      "step": 175000
    },
    {
      "epoch": 3.603167907318905,
      "grad_norm": 2.862231731414795,
      "learning_rate": 1.9196024364145196e-05,
      "loss": 0.1474,
      "step": 175100
    },
    {
      "epoch": 3.6052256580944197,
      "grad_norm": 3.1317591667175293,
      "learning_rate": 1.9189851016544573e-05,
      "loss": 0.1721,
      "step": 175200
    },
    {
      "epoch": 3.6072834088699346,
      "grad_norm": 2.7495734691619873,
      "learning_rate": 1.9183677668943946e-05,
      "loss": 0.1512,
      "step": 175300
    },
    {
      "epoch": 3.6093411596454494,
      "grad_norm": 5.983201503753662,
      "learning_rate": 1.917750432134332e-05,
      "loss": 0.166,
      "step": 175400
    },
    {
      "epoch": 3.6113989104209643,
      "grad_norm": 2.0034384727478027,
      "learning_rate": 1.9171330973742696e-05,
      "loss": 0.1738,
      "step": 175500
    },
    {
      "epoch": 3.613456661196479,
      "grad_norm": 4.598941326141357,
      "learning_rate": 1.916515762614207e-05,
      "loss": 0.1635,
      "step": 175600
    },
    {
      "epoch": 3.615514411971994,
      "grad_norm": 0.58253413438797,
      "learning_rate": 1.9158984278541445e-05,
      "loss": 0.1636,
      "step": 175700
    },
    {
      "epoch": 3.617572162747509,
      "grad_norm": 1.8092997074127197,
      "learning_rate": 1.915281093094082e-05,
      "loss": 0.1652,
      "step": 175800
    },
    {
      "epoch": 3.6196299135230237,
      "grad_norm": 1.0861765146255493,
      "learning_rate": 1.9146637583340195e-05,
      "loss": 0.1602,
      "step": 175900
    },
    {
      "epoch": 3.6216876642985385,
      "grad_norm": 3.022780656814575,
      "learning_rate": 1.9140464235739568e-05,
      "loss": 0.1633,
      "step": 176000
    },
    {
      "epoch": 3.6237454150740533,
      "grad_norm": 5.48984432220459,
      "learning_rate": 1.913435262161495e-05,
      "loss": 0.1731,
      "step": 176100
    },
    {
      "epoch": 3.625803165849568,
      "grad_norm": 2.021878957748413,
      "learning_rate": 1.9128179274014322e-05,
      "loss": 0.1819,
      "step": 176200
    },
    {
      "epoch": 3.627860916625083,
      "grad_norm": 1.969173550605774,
      "learning_rate": 1.9122005926413695e-05,
      "loss": 0.164,
      "step": 176300
    },
    {
      "epoch": 3.629918667400598,
      "grad_norm": 4.118444919586182,
      "learning_rate": 1.911583257881307e-05,
      "loss": 0.1798,
      "step": 176400
    },
    {
      "epoch": 3.6319764181761127,
      "grad_norm": 2.670391321182251,
      "learning_rate": 1.9109659231212448e-05,
      "loss": 0.1726,
      "step": 176500
    },
    {
      "epoch": 3.6340341689516276,
      "grad_norm": 4.989063262939453,
      "learning_rate": 1.910348588361182e-05,
      "loss": 0.1679,
      "step": 176600
    },
    {
      "epoch": 3.6360919197271424,
      "grad_norm": 2.460786819458008,
      "learning_rate": 1.9097312536011194e-05,
      "loss": 0.1587,
      "step": 176700
    },
    {
      "epoch": 3.6381496705026573,
      "grad_norm": 1.8341271877288818,
      "learning_rate": 1.909113918841057e-05,
      "loss": 0.155,
      "step": 176800
    },
    {
      "epoch": 3.6402074212781717,
      "grad_norm": 2.840970277786255,
      "learning_rate": 1.9084965840809944e-05,
      "loss": 0.163,
      "step": 176900
    },
    {
      "epoch": 3.642265172053687,
      "grad_norm": 3.2334368228912354,
      "learning_rate": 1.9078792493209317e-05,
      "loss": 0.1647,
      "step": 177000
    },
    {
      "epoch": 3.6443229228292013,
      "grad_norm": 2.3388941287994385,
      "learning_rate": 1.9072619145608694e-05,
      "loss": 0.1851,
      "step": 177100
    },
    {
      "epoch": 3.6463806736047166,
      "grad_norm": 3.173485517501831,
      "learning_rate": 1.9066445798008067e-05,
      "loss": 0.1633,
      "step": 177200
    },
    {
      "epoch": 3.648438424380231,
      "grad_norm": 3.616626501083374,
      "learning_rate": 1.906027245040744e-05,
      "loss": 0.1736,
      "step": 177300
    },
    {
      "epoch": 3.650496175155746,
      "grad_norm": 2.37211537361145,
      "learning_rate": 1.9054099102806813e-05,
      "loss": 0.1761,
      "step": 177400
    },
    {
      "epoch": 3.6525539259312607,
      "grad_norm": 6.812224864959717,
      "learning_rate": 1.9047925755206193e-05,
      "loss": 0.1627,
      "step": 177500
    },
    {
      "epoch": 3.6546116767067756,
      "grad_norm": 4.322886943817139,
      "learning_rate": 1.9041752407605566e-05,
      "loss": 0.1791,
      "step": 177600
    },
    {
      "epoch": 3.6566694274822904,
      "grad_norm": 2.6267998218536377,
      "learning_rate": 1.903557906000494e-05,
      "loss": 0.1763,
      "step": 177700
    },
    {
      "epoch": 3.6587271782578052,
      "grad_norm": 2.130113363265991,
      "learning_rate": 1.9029405712404316e-05,
      "loss": 0.1717,
      "step": 177800
    },
    {
      "epoch": 3.66078492903332,
      "grad_norm": 4.381498336791992,
      "learning_rate": 1.902323236480369e-05,
      "loss": 0.1723,
      "step": 177900
    },
    {
      "epoch": 3.662842679808835,
      "grad_norm": 1.6336259841918945,
      "learning_rate": 1.9017059017203062e-05,
      "loss": 0.1689,
      "step": 178000
    },
    {
      "epoch": 3.6649004305843498,
      "grad_norm": 2.7744646072387695,
      "learning_rate": 1.9010885669602435e-05,
      "loss": 0.1656,
      "step": 178100
    },
    {
      "epoch": 3.6669581813598646,
      "grad_norm": 1.986761450767517,
      "learning_rate": 1.9004712322001812e-05,
      "loss": 0.1799,
      "step": 178200
    },
    {
      "epoch": 3.6690159321353795,
      "grad_norm": 1.644465684890747,
      "learning_rate": 1.8998600707877192e-05,
      "loss": 0.1486,
      "step": 178300
    },
    {
      "epoch": 3.6710736829108943,
      "grad_norm": 6.280462741851807,
      "learning_rate": 1.899242736027657e-05,
      "loss": 0.165,
      "step": 178400
    },
    {
      "epoch": 3.673131433686409,
      "grad_norm": 3.8129494190216064,
      "learning_rate": 1.8986254012675942e-05,
      "loss": 0.1729,
      "step": 178500
    },
    {
      "epoch": 3.675189184461924,
      "grad_norm": 1.4444959163665771,
      "learning_rate": 1.8980080665075315e-05,
      "loss": 0.1639,
      "step": 178600
    },
    {
      "epoch": 3.677246935237439,
      "grad_norm": 1.897009253501892,
      "learning_rate": 1.897390731747469e-05,
      "loss": 0.1542,
      "step": 178700
    },
    {
      "epoch": 3.6793046860129537,
      "grad_norm": 1.543661117553711,
      "learning_rate": 1.8967733969874065e-05,
      "loss": 0.1817,
      "step": 178800
    },
    {
      "epoch": 3.6813624367884685,
      "grad_norm": 3.858292818069458,
      "learning_rate": 1.8961560622273438e-05,
      "loss": 0.1673,
      "step": 178900
    },
    {
      "epoch": 3.683420187563983,
      "grad_norm": 3.4076929092407227,
      "learning_rate": 1.895538727467281e-05,
      "loss": 0.1717,
      "step": 179000
    },
    {
      "epoch": 3.685477938339498,
      "grad_norm": 5.437809467315674,
      "learning_rate": 1.8949213927072188e-05,
      "loss": 0.1684,
      "step": 179100
    },
    {
      "epoch": 3.6875356891150126,
      "grad_norm": 2.9400956630706787,
      "learning_rate": 1.894304057947156e-05,
      "loss": 0.1688,
      "step": 179200
    },
    {
      "epoch": 3.689593439890528,
      "grad_norm": 3.748326539993286,
      "learning_rate": 1.8936867231870937e-05,
      "loss": 0.1718,
      "step": 179300
    },
    {
      "epoch": 3.6916511906660423,
      "grad_norm": 4.106453895568848,
      "learning_rate": 1.893069388427031e-05,
      "loss": 0.1805,
      "step": 179400
    },
    {
      "epoch": 3.693708941441557,
      "grad_norm": 2.512482166290283,
      "learning_rate": 1.8924520536669687e-05,
      "loss": 0.1775,
      "step": 179500
    },
    {
      "epoch": 3.695766692217072,
      "grad_norm": 2.187946081161499,
      "learning_rate": 1.891834718906906e-05,
      "loss": 0.1731,
      "step": 179600
    },
    {
      "epoch": 3.697824442992587,
      "grad_norm": 2.829714059829712,
      "learning_rate": 1.8912173841468433e-05,
      "loss": 0.1636,
      "step": 179700
    },
    {
      "epoch": 3.6998821937681017,
      "grad_norm": 2.1676063537597656,
      "learning_rate": 1.890600049386781e-05,
      "loss": 0.1705,
      "step": 179800
    },
    {
      "epoch": 3.7019399445436165,
      "grad_norm": 1.765998363494873,
      "learning_rate": 1.8899827146267183e-05,
      "loss": 0.1525,
      "step": 179900
    },
    {
      "epoch": 3.7039976953191314,
      "grad_norm": 1.146570086479187,
      "learning_rate": 1.8893653798666556e-05,
      "loss": 0.1686,
      "step": 180000
    },
    {
      "epoch": 3.7039976953191314,
      "eval_accuracy": 0.8357942973523421,
      "eval_f1_contradiction": 0.84246316584813,
      "eval_loss": 0.16281089186668396,
      "eval_runtime": 74.679,
      "eval_samples_per_second": 52.598,
      "eval_steps_per_second": 6.575,
      "step": 180000
    },
    {
      "epoch": 3.706055446094646,
      "grad_norm": 8.82954216003418,
      "learning_rate": 1.888748045106593e-05,
      "loss": 0.1695,
      "step": 180100
    },
    {
      "epoch": 3.708113196870161,
      "grad_norm": 2.954598903656006,
      "learning_rate": 1.8881307103465306e-05,
      "loss": 0.1775,
      "step": 180200
    },
    {
      "epoch": 3.710170947645676,
      "grad_norm": 4.415834426879883,
      "learning_rate": 1.887519548934069e-05,
      "loss": 0.1585,
      "step": 180300
    },
    {
      "epoch": 3.7122286984211907,
      "grad_norm": 1.845905065536499,
      "learning_rate": 1.8869022141740063e-05,
      "loss": 0.1701,
      "step": 180400
    },
    {
      "epoch": 3.7142864491967056,
      "grad_norm": 0.9783936738967896,
      "learning_rate": 1.8862848794139436e-05,
      "loss": 0.1691,
      "step": 180500
    },
    {
      "epoch": 3.7163441999722204,
      "grad_norm": 0.7646698951721191,
      "learning_rate": 1.885667544653881e-05,
      "loss": 0.1718,
      "step": 180600
    },
    {
      "epoch": 3.7184019507477353,
      "grad_norm": 3.522526741027832,
      "learning_rate": 1.8850502098938186e-05,
      "loss": 0.1861,
      "step": 180700
    },
    {
      "epoch": 3.72045970152325,
      "grad_norm": 1.2880522012710571,
      "learning_rate": 1.884432875133756e-05,
      "loss": 0.1579,
      "step": 180800
    },
    {
      "epoch": 3.722517452298765,
      "grad_norm": 4.099974632263184,
      "learning_rate": 1.8838155403736932e-05,
      "loss": 0.1633,
      "step": 180900
    },
    {
      "epoch": 3.72457520307428,
      "grad_norm": 1.409828543663025,
      "learning_rate": 1.8831982056136305e-05,
      "loss": 0.1554,
      "step": 181000
    },
    {
      "epoch": 3.726632953849794,
      "grad_norm": 3.8190629482269287,
      "learning_rate": 1.8825808708535685e-05,
      "loss": 0.2004,
      "step": 181100
    },
    {
      "epoch": 3.7286907046253095,
      "grad_norm": 3.3043198585510254,
      "learning_rate": 1.8819635360935058e-05,
      "loss": 0.1474,
      "step": 181200
    },
    {
      "epoch": 3.730748455400824,
      "grad_norm": 3.1787428855895996,
      "learning_rate": 1.881346201333443e-05,
      "loss": 0.1701,
      "step": 181300
    },
    {
      "epoch": 3.732806206176339,
      "grad_norm": 3.0305216312408447,
      "learning_rate": 1.8807288665733808e-05,
      "loss": 0.1468,
      "step": 181400
    },
    {
      "epoch": 3.7348639569518536,
      "grad_norm": 4.788018226623535,
      "learning_rate": 1.880111531813318e-05,
      "loss": 0.1591,
      "step": 181500
    },
    {
      "epoch": 3.736921707727369,
      "grad_norm": 1.3751713037490845,
      "learning_rate": 1.8794941970532554e-05,
      "loss": 0.1709,
      "step": 181600
    },
    {
      "epoch": 3.7389794585028833,
      "grad_norm": 2.0862584114074707,
      "learning_rate": 1.8788768622931927e-05,
      "loss": 0.1619,
      "step": 181700
    },
    {
      "epoch": 3.741037209278398,
      "grad_norm": 3.364429473876953,
      "learning_rate": 1.8782595275331304e-05,
      "loss": 0.1553,
      "step": 181800
    },
    {
      "epoch": 3.743094960053913,
      "grad_norm": 6.173477649688721,
      "learning_rate": 1.8776421927730677e-05,
      "loss": 0.1801,
      "step": 181900
    },
    {
      "epoch": 3.745152710829428,
      "grad_norm": 1.5518194437026978,
      "learning_rate": 1.877024858013005e-05,
      "loss": 0.1767,
      "step": 182000
    },
    {
      "epoch": 3.7472104616049426,
      "grad_norm": 4.122287273406982,
      "learning_rate": 1.8764075232529427e-05,
      "loss": 0.193,
      "step": 182100
    },
    {
      "epoch": 3.7492682123804575,
      "grad_norm": 3.3240280151367188,
      "learning_rate": 1.8757901884928803e-05,
      "loss": 0.1803,
      "step": 182200
    },
    {
      "epoch": 3.7513259631559723,
      "grad_norm": 3.7588698863983154,
      "learning_rate": 1.8751790270804183e-05,
      "loss": 0.1598,
      "step": 182300
    },
    {
      "epoch": 3.753383713931487,
      "grad_norm": 1.7859725952148438,
      "learning_rate": 1.8745616923203557e-05,
      "loss": 0.1371,
      "step": 182400
    },
    {
      "epoch": 3.755441464707002,
      "grad_norm": 1.018584132194519,
      "learning_rate": 1.873944357560293e-05,
      "loss": 0.1768,
      "step": 182500
    },
    {
      "epoch": 3.757499215482517,
      "grad_norm": 4.0299272537231445,
      "learning_rate": 1.8733270228002303e-05,
      "loss": 0.1698,
      "step": 182600
    },
    {
      "epoch": 3.7595569662580317,
      "grad_norm": 0.46543893218040466,
      "learning_rate": 1.872709688040168e-05,
      "loss": 0.1679,
      "step": 182700
    },
    {
      "epoch": 3.7616147170335466,
      "grad_norm": 2.411430835723877,
      "learning_rate": 1.8720923532801053e-05,
      "loss": 0.181,
      "step": 182800
    },
    {
      "epoch": 3.7636724678090614,
      "grad_norm": 1.5695428848266602,
      "learning_rate": 1.871475018520043e-05,
      "loss": 0.1747,
      "step": 182900
    },
    {
      "epoch": 3.7657302185845762,
      "grad_norm": 1.9781594276428223,
      "learning_rate": 1.8708576837599806e-05,
      "loss": 0.1659,
      "step": 183000
    },
    {
      "epoch": 3.767787969360091,
      "grad_norm": 5.037245273590088,
      "learning_rate": 1.870240348999918e-05,
      "loss": 0.1872,
      "step": 183100
    },
    {
      "epoch": 3.769845720135606,
      "grad_norm": 0.9385711550712585,
      "learning_rate": 1.8696230142398552e-05,
      "loss": 0.168,
      "step": 183200
    },
    {
      "epoch": 3.7719034709111208,
      "grad_norm": 3.6329054832458496,
      "learning_rate": 1.8690056794797925e-05,
      "loss": 0.1565,
      "step": 183300
    },
    {
      "epoch": 3.773961221686635,
      "grad_norm": 2.449178457260132,
      "learning_rate": 1.86838834471973e-05,
      "loss": 0.1689,
      "step": 183400
    },
    {
      "epoch": 3.7760189724621505,
      "grad_norm": 5.287802696228027,
      "learning_rate": 1.8677710099596675e-05,
      "loss": 0.2072,
      "step": 183500
    },
    {
      "epoch": 3.778076723237665,
      "grad_norm": 2.5389018058776855,
      "learning_rate": 1.8671536751996048e-05,
      "loss": 0.1616,
      "step": 183600
    },
    {
      "epoch": 3.78013447401318,
      "grad_norm": 1.0058069229125977,
      "learning_rate": 1.866536340439542e-05,
      "loss": 0.1558,
      "step": 183700
    },
    {
      "epoch": 3.7821922247886945,
      "grad_norm": 2.1194450855255127,
      "learning_rate": 1.8659190056794798e-05,
      "loss": 0.1802,
      "step": 183800
    },
    {
      "epoch": 3.7842499755642094,
      "grad_norm": 3.343808650970459,
      "learning_rate": 1.8653016709194174e-05,
      "loss": 0.1538,
      "step": 183900
    },
    {
      "epoch": 3.7863077263397242,
      "grad_norm": 2.8464438915252686,
      "learning_rate": 1.8646843361593547e-05,
      "loss": 0.1813,
      "step": 184000
    },
    {
      "epoch": 3.788365477115239,
      "grad_norm": 3.74560284614563,
      "learning_rate": 1.8640670013992924e-05,
      "loss": 0.151,
      "step": 184100
    },
    {
      "epoch": 3.790423227890754,
      "grad_norm": 2.31659197807312,
      "learning_rate": 1.8634496666392297e-05,
      "loss": 0.1601,
      "step": 184200
    },
    {
      "epoch": 3.7924809786662688,
      "grad_norm": 3.0350282192230225,
      "learning_rate": 1.862832331879167e-05,
      "loss": 0.1837,
      "step": 184300
    },
    {
      "epoch": 3.7945387294417836,
      "grad_norm": 0.8726878762245178,
      "learning_rate": 1.862221170466705e-05,
      "loss": 0.1539,
      "step": 184400
    },
    {
      "epoch": 3.7965964802172985,
      "grad_norm": 1.3634421825408936,
      "learning_rate": 1.8616038357066424e-05,
      "loss": 0.1972,
      "step": 184500
    },
    {
      "epoch": 3.7986542309928133,
      "grad_norm": 1.8463339805603027,
      "learning_rate": 1.8609865009465797e-05,
      "loss": 0.1501,
      "step": 184600
    },
    {
      "epoch": 3.800711981768328,
      "grad_norm": 1.108392357826233,
      "learning_rate": 1.8603691661865177e-05,
      "loss": 0.1575,
      "step": 184700
    },
    {
      "epoch": 3.802769732543843,
      "grad_norm": 2.8652379512786865,
      "learning_rate": 1.859751831426455e-05,
      "loss": 0.1643,
      "step": 184800
    },
    {
      "epoch": 3.804827483319358,
      "grad_norm": 0.5034043192863464,
      "learning_rate": 1.8591344966663923e-05,
      "loss": 0.1713,
      "step": 184900
    },
    {
      "epoch": 3.8068852340948727,
      "grad_norm": 4.752838611602783,
      "learning_rate": 1.85851716190633e-05,
      "loss": 0.182,
      "step": 185000
    },
    {
      "epoch": 3.8089429848703875,
      "grad_norm": 1.9725905656814575,
      "learning_rate": 1.8578998271462673e-05,
      "loss": 0.1754,
      "step": 185100
    },
    {
      "epoch": 3.8110007356459024,
      "grad_norm": 0.5742479562759399,
      "learning_rate": 1.8572824923862046e-05,
      "loss": 0.1712,
      "step": 185200
    },
    {
      "epoch": 3.813058486421417,
      "grad_norm": 4.0643110275268555,
      "learning_rate": 1.856665157626142e-05,
      "loss": 0.1825,
      "step": 185300
    },
    {
      "epoch": 3.815116237196932,
      "grad_norm": 4.98847770690918,
      "learning_rate": 1.8560478228660796e-05,
      "loss": 0.1597,
      "step": 185400
    },
    {
      "epoch": 3.8171739879724464,
      "grad_norm": 1.518343448638916,
      "learning_rate": 1.855430488106017e-05,
      "loss": 0.1678,
      "step": 185500
    },
    {
      "epoch": 3.8192317387479617,
      "grad_norm": 1.345301628112793,
      "learning_rate": 1.8548131533459545e-05,
      "loss": 0.152,
      "step": 185600
    },
    {
      "epoch": 3.821289489523476,
      "grad_norm": 5.415390491485596,
      "learning_rate": 1.8541958185858922e-05,
      "loss": 0.1645,
      "step": 185700
    },
    {
      "epoch": 3.8233472402989914,
      "grad_norm": 1.7135897874832153,
      "learning_rate": 1.8535784838258295e-05,
      "loss": 0.1762,
      "step": 185800
    },
    {
      "epoch": 3.825404991074506,
      "grad_norm": 3.2571194171905518,
      "learning_rate": 1.8529611490657668e-05,
      "loss": 0.1733,
      "step": 185900
    },
    {
      "epoch": 3.827462741850021,
      "grad_norm": 3.8725619316101074,
      "learning_rate": 1.852343814305704e-05,
      "loss": 0.1847,
      "step": 186000
    },
    {
      "epoch": 3.8295204926255355,
      "grad_norm": 2.7932684421539307,
      "learning_rate": 1.8517264795456418e-05,
      "loss": 0.1678,
      "step": 186100
    },
    {
      "epoch": 3.8315782434010504,
      "grad_norm": 1.0579187870025635,
      "learning_rate": 1.851109144785579e-05,
      "loss": 0.1738,
      "step": 186200
    },
    {
      "epoch": 3.833635994176565,
      "grad_norm": 3.279684066772461,
      "learning_rate": 1.8504918100255164e-05,
      "loss": 0.1627,
      "step": 186300
    },
    {
      "epoch": 3.83569374495208,
      "grad_norm": 2.3887007236480713,
      "learning_rate": 1.8498806486130545e-05,
      "loss": 0.1749,
      "step": 186400
    },
    {
      "epoch": 3.837751495727595,
      "grad_norm": 2.7788009643554688,
      "learning_rate": 1.849263313852992e-05,
      "loss": 0.1623,
      "step": 186500
    },
    {
      "epoch": 3.8398092465031097,
      "grad_norm": 3.5917670726776123,
      "learning_rate": 1.8486459790929298e-05,
      "loss": 0.1496,
      "step": 186600
    },
    {
      "epoch": 3.8418669972786246,
      "grad_norm": 3.75207257270813,
      "learning_rate": 1.848028644332867e-05,
      "loss": 0.169,
      "step": 186700
    },
    {
      "epoch": 3.8439247480541394,
      "grad_norm": 2.0274980068206787,
      "learning_rate": 1.8474113095728044e-05,
      "loss": 0.1811,
      "step": 186800
    },
    {
      "epoch": 3.8459824988296543,
      "grad_norm": 3.1930103302001953,
      "learning_rate": 1.8467939748127417e-05,
      "loss": 0.1638,
      "step": 186900
    },
    {
      "epoch": 3.848040249605169,
      "grad_norm": 2.1253232955932617,
      "learning_rate": 1.8461766400526794e-05,
      "loss": 0.1717,
      "step": 187000
    },
    {
      "epoch": 3.850098000380684,
      "grad_norm": 0.18736083805561066,
      "learning_rate": 1.8455593052926167e-05,
      "loss": 0.1653,
      "step": 187100
    },
    {
      "epoch": 3.852155751156199,
      "grad_norm": 3.972806930541992,
      "learning_rate": 1.844941970532554e-05,
      "loss": 0.176,
      "step": 187200
    },
    {
      "epoch": 3.8542135019317136,
      "grad_norm": 4.340750694274902,
      "learning_rate": 1.8443246357724916e-05,
      "loss": 0.156,
      "step": 187300
    },
    {
      "epoch": 3.8562712527072285,
      "grad_norm": 3.638742446899414,
      "learning_rate": 1.843707301012429e-05,
      "loss": 0.1618,
      "step": 187400
    },
    {
      "epoch": 3.8583290034827433,
      "grad_norm": 2.033879518508911,
      "learning_rate": 1.8430899662523666e-05,
      "loss": 0.1682,
      "step": 187500
    },
    {
      "epoch": 3.860386754258258,
      "grad_norm": 0.5934545993804932,
      "learning_rate": 1.842472631492304e-05,
      "loss": 0.1724,
      "step": 187600
    },
    {
      "epoch": 3.862444505033773,
      "grad_norm": 5.051367282867432,
      "learning_rate": 1.8418552967322416e-05,
      "loss": 0.154,
      "step": 187700
    },
    {
      "epoch": 3.8645022558092874,
      "grad_norm": 0.40771484375,
      "learning_rate": 1.841237961972179e-05,
      "loss": 0.1621,
      "step": 187800
    },
    {
      "epoch": 3.8665600065848027,
      "grad_norm": 2.1526753902435303,
      "learning_rate": 1.8406206272121162e-05,
      "loss": 0.1582,
      "step": 187900
    },
    {
      "epoch": 3.868617757360317,
      "grad_norm": 0.9880255460739136,
      "learning_rate": 1.8400032924520535e-05,
      "loss": 0.2069,
      "step": 188000
    },
    {
      "epoch": 3.8706755081358324,
      "grad_norm": 2.5153396129608154,
      "learning_rate": 1.8393859576919912e-05,
      "loss": 0.1549,
      "step": 188100
    },
    {
      "epoch": 3.872733258911347,
      "grad_norm": 3.4432547092437744,
      "learning_rate": 1.8387686229319285e-05,
      "loss": 0.1751,
      "step": 188200
    },
    {
      "epoch": 3.8747910096868616,
      "grad_norm": 1.9074347019195557,
      "learning_rate": 1.8381512881718658e-05,
      "loss": 0.1754,
      "step": 188300
    },
    {
      "epoch": 3.8768487604623765,
      "grad_norm": 2.3661904335021973,
      "learning_rate": 1.8375339534118038e-05,
      "loss": 0.174,
      "step": 188400
    },
    {
      "epoch": 3.8789065112378913,
      "grad_norm": 2.10971736907959,
      "learning_rate": 1.8369227919993415e-05,
      "loss": 0.1673,
      "step": 188500
    },
    {
      "epoch": 3.880964262013406,
      "grad_norm": 2.72723650932312,
      "learning_rate": 1.836305457239279e-05,
      "loss": 0.1736,
      "step": 188600
    },
    {
      "epoch": 3.883022012788921,
      "grad_norm": 3.2782061100006104,
      "learning_rate": 1.8356881224792165e-05,
      "loss": 0.1683,
      "step": 188700
    },
    {
      "epoch": 3.885079763564436,
      "grad_norm": 1.646308422088623,
      "learning_rate": 1.8350707877191538e-05,
      "loss": 0.1464,
      "step": 188800
    },
    {
      "epoch": 3.8871375143399507,
      "grad_norm": 1.1452739238739014,
      "learning_rate": 1.834453452959091e-05,
      "loss": 0.1491,
      "step": 188900
    },
    {
      "epoch": 3.8891952651154655,
      "grad_norm": 6.158506870269775,
      "learning_rate": 1.8338361181990288e-05,
      "loss": 0.1751,
      "step": 189000
    },
    {
      "epoch": 3.8912530158909804,
      "grad_norm": 2.114152431488037,
      "learning_rate": 1.833218783438966e-05,
      "loss": 0.1568,
      "step": 189100
    },
    {
      "epoch": 3.8933107666664952,
      "grad_norm": 2.111159086227417,
      "learning_rate": 1.8326014486789037e-05,
      "loss": 0.1751,
      "step": 189200
    },
    {
      "epoch": 3.89536851744201,
      "grad_norm": 1.8053969144821167,
      "learning_rate": 1.8319841139188414e-05,
      "loss": 0.1842,
      "step": 189300
    },
    {
      "epoch": 3.897426268217525,
      "grad_norm": 4.424723148345947,
      "learning_rate": 1.8313667791587787e-05,
      "loss": 0.1771,
      "step": 189400
    },
    {
      "epoch": 3.8994840189930398,
      "grad_norm": 5.4829583168029785,
      "learning_rate": 1.830749444398716e-05,
      "loss": 0.165,
      "step": 189500
    },
    {
      "epoch": 3.9015417697685546,
      "grad_norm": 3.8385097980499268,
      "learning_rate": 1.8301321096386533e-05,
      "loss": 0.1583,
      "step": 189600
    },
    {
      "epoch": 3.9035995205440694,
      "grad_norm": 4.5386457443237305,
      "learning_rate": 1.829514774878591e-05,
      "loss": 0.1785,
      "step": 189700
    },
    {
      "epoch": 3.9056572713195843,
      "grad_norm": 3.7065348625183105,
      "learning_rate": 1.8288974401185283e-05,
      "loss": 0.1642,
      "step": 189800
    },
    {
      "epoch": 3.9077150220950987,
      "grad_norm": 2.7148265838623047,
      "learning_rate": 1.8282801053584656e-05,
      "loss": 0.1742,
      "step": 189900
    },
    {
      "epoch": 3.909772772870614,
      "grad_norm": 0.7893210053443909,
      "learning_rate": 1.8276627705984033e-05,
      "loss": 0.1519,
      "step": 190000
    },
    {
      "epoch": 3.909772772870614,
      "eval_accuracy": 0.8370672097759674,
      "eval_f1_contradiction": 0.8430769230769231,
      "eval_loss": 0.1544497162103653,
      "eval_runtime": 67.7412,
      "eval_samples_per_second": 57.985,
      "eval_steps_per_second": 7.248,
      "step": 190000
    },
    {
      "epoch": 3.9118305236461284,
      "grad_norm": 7.726395606994629,
      "learning_rate": 1.8270454358383406e-05,
      "loss": 0.1718,
      "step": 190100
    },
    {
      "epoch": 3.9138882744216437,
      "grad_norm": 1.7654491662979126,
      "learning_rate": 1.8264281010782782e-05,
      "loss": 0.1595,
      "step": 190200
    },
    {
      "epoch": 3.915946025197158,
      "grad_norm": 4.290985107421875,
      "learning_rate": 1.8258107663182155e-05,
      "loss": 0.1672,
      "step": 190300
    },
    {
      "epoch": 3.918003775972673,
      "grad_norm": 0.35672250390052795,
      "learning_rate": 1.8251934315581532e-05,
      "loss": 0.1594,
      "step": 190400
    },
    {
      "epoch": 3.9200615267481878,
      "grad_norm": 0.3259274661540985,
      "learning_rate": 1.824582270145691e-05,
      "loss": 0.1611,
      "step": 190500
    },
    {
      "epoch": 3.9221192775237026,
      "grad_norm": 2.503366231918335,
      "learning_rate": 1.8239649353856286e-05,
      "loss": 0.1629,
      "step": 190600
    },
    {
      "epoch": 3.9241770282992174,
      "grad_norm": 1.7877365350723267,
      "learning_rate": 1.823347600625566e-05,
      "loss": 0.1704,
      "step": 190700
    },
    {
      "epoch": 3.9262347790747323,
      "grad_norm": 2.8721542358398438,
      "learning_rate": 1.8227302658655032e-05,
      "loss": 0.1733,
      "step": 190800
    },
    {
      "epoch": 3.928292529850247,
      "grad_norm": 2.482426881790161,
      "learning_rate": 1.822112931105441e-05,
      "loss": 0.1466,
      "step": 190900
    },
    {
      "epoch": 3.930350280625762,
      "grad_norm": 2.2900826930999756,
      "learning_rate": 1.8214955963453785e-05,
      "loss": 0.1814,
      "step": 191000
    },
    {
      "epoch": 3.932408031401277,
      "grad_norm": 1.6951851844787598,
      "learning_rate": 1.8208782615853158e-05,
      "loss": 0.1581,
      "step": 191100
    },
    {
      "epoch": 3.9344657821767917,
      "grad_norm": 3.3834969997406006,
      "learning_rate": 1.820260926825253e-05,
      "loss": 0.1695,
      "step": 191200
    },
    {
      "epoch": 3.9365235329523065,
      "grad_norm": 3.9629271030426025,
      "learning_rate": 1.8196435920651908e-05,
      "loss": 0.1684,
      "step": 191300
    },
    {
      "epoch": 3.9385812837278213,
      "grad_norm": 1.9629703760147095,
      "learning_rate": 1.819026257305128e-05,
      "loss": 0.1922,
      "step": 191400
    },
    {
      "epoch": 3.940639034503336,
      "grad_norm": 1.589903712272644,
      "learning_rate": 1.8184089225450654e-05,
      "loss": 0.16,
      "step": 191500
    },
    {
      "epoch": 3.942696785278851,
      "grad_norm": 3.9534802436828613,
      "learning_rate": 1.8177915877850027e-05,
      "loss": 0.1646,
      "step": 191600
    },
    {
      "epoch": 3.944754536054366,
      "grad_norm": 0.8657364845275879,
      "learning_rate": 1.8171742530249404e-05,
      "loss": 0.1707,
      "step": 191700
    },
    {
      "epoch": 3.9468122868298807,
      "grad_norm": 2.8274378776550293,
      "learning_rate": 1.8165569182648777e-05,
      "loss": 0.1584,
      "step": 191800
    },
    {
      "epoch": 3.9488700376053956,
      "grad_norm": 7.227002143859863,
      "learning_rate": 1.815939583504815e-05,
      "loss": 0.1764,
      "step": 191900
    },
    {
      "epoch": 3.9509277883809104,
      "grad_norm": 1.099170207977295,
      "learning_rate": 1.815322248744753e-05,
      "loss": 0.1868,
      "step": 192000
    },
    {
      "epoch": 3.9529855391564253,
      "grad_norm": 1.4120473861694336,
      "learning_rate": 1.8147049139846903e-05,
      "loss": 0.1691,
      "step": 192100
    },
    {
      "epoch": 3.9550432899319397,
      "grad_norm": 2.074032783508301,
      "learning_rate": 1.8140875792246276e-05,
      "loss": 0.1652,
      "step": 192200
    },
    {
      "epoch": 3.957101040707455,
      "grad_norm": 2.3718631267547607,
      "learning_rate": 1.813470244464565e-05,
      "loss": 0.1538,
      "step": 192300
    },
    {
      "epoch": 3.9591587914829693,
      "grad_norm": 0.9483223557472229,
      "learning_rate": 1.8128529097045026e-05,
      "loss": 0.163,
      "step": 192400
    },
    {
      "epoch": 3.9612165422584846,
      "grad_norm": 4.163228511810303,
      "learning_rate": 1.8122417482920406e-05,
      "loss": 0.1549,
      "step": 192500
    },
    {
      "epoch": 3.963274293033999,
      "grad_norm": 4.565577507019043,
      "learning_rate": 1.811624413531978e-05,
      "loss": 0.14,
      "step": 192600
    },
    {
      "epoch": 3.965332043809514,
      "grad_norm": 6.339554309844971,
      "learning_rate": 1.8110070787719153e-05,
      "loss": 0.1539,
      "step": 192700
    },
    {
      "epoch": 3.9673897945850287,
      "grad_norm": 2.530489444732666,
      "learning_rate": 1.810389744011853e-05,
      "loss": 0.1797,
      "step": 192800
    },
    {
      "epoch": 3.9694475453605436,
      "grad_norm": 1.9774022102355957,
      "learning_rate": 1.8097724092517906e-05,
      "loss": 0.1645,
      "step": 192900
    },
    {
      "epoch": 3.9715052961360584,
      "grad_norm": 3.7749505043029785,
      "learning_rate": 1.809155074491728e-05,
      "loss": 0.1709,
      "step": 193000
    },
    {
      "epoch": 3.9735630469115732,
      "grad_norm": 1.983304500579834,
      "learning_rate": 1.8085377397316652e-05,
      "loss": 0.1713,
      "step": 193100
    },
    {
      "epoch": 3.975620797687088,
      "grad_norm": 6.6477532386779785,
      "learning_rate": 1.8079204049716025e-05,
      "loss": 0.1625,
      "step": 193200
    },
    {
      "epoch": 3.977678548462603,
      "grad_norm": 0.9150437116622925,
      "learning_rate": 1.80730307021154e-05,
      "loss": 0.1625,
      "step": 193300
    },
    {
      "epoch": 3.979736299238118,
      "grad_norm": 1.5843642950057983,
      "learning_rate": 1.8066857354514775e-05,
      "loss": 0.1456,
      "step": 193400
    },
    {
      "epoch": 3.9817940500136326,
      "grad_norm": 0.9388474225997925,
      "learning_rate": 1.8060684006914148e-05,
      "loss": 0.1668,
      "step": 193500
    },
    {
      "epoch": 3.9838518007891475,
      "grad_norm": 2.714369058609009,
      "learning_rate": 1.8054510659313524e-05,
      "loss": 0.1644,
      "step": 193600
    },
    {
      "epoch": 3.9859095515646623,
      "grad_norm": 3.665041446685791,
      "learning_rate": 1.8048337311712898e-05,
      "loss": 0.1834,
      "step": 193700
    },
    {
      "epoch": 3.987967302340177,
      "grad_norm": 1.983105182647705,
      "learning_rate": 1.8042163964112274e-05,
      "loss": 0.169,
      "step": 193800
    },
    {
      "epoch": 3.990025053115692,
      "grad_norm": 0.4814910590648651,
      "learning_rate": 1.8035990616511647e-05,
      "loss": 0.1705,
      "step": 193900
    },
    {
      "epoch": 3.992082803891207,
      "grad_norm": 0.18282939493656158,
      "learning_rate": 1.8029817268911024e-05,
      "loss": 0.1654,
      "step": 194000
    },
    {
      "epoch": 3.9941405546667217,
      "grad_norm": 3.0141313076019287,
      "learning_rate": 1.8023643921310397e-05,
      "loss": 0.1717,
      "step": 194100
    },
    {
      "epoch": 3.9961983054422365,
      "grad_norm": 1.899416208267212,
      "learning_rate": 1.801747057370977e-05,
      "loss": 0.1495,
      "step": 194200
    },
    {
      "epoch": 3.998256056217751,
      "grad_norm": 1.2434769868850708,
      "learning_rate": 1.8011297226109147e-05,
      "loss": 0.1907,
      "step": 194300
    },
    {
      "epoch": 4.000329240124082,
      "grad_norm": 1.5089279413223267,
      "learning_rate": 1.800512387850852e-05,
      "loss": 0.1848,
      "step": 194400
    },
    {
      "epoch": 4.0023869908995975,
      "grad_norm": 3.8422117233276367,
      "learning_rate": 1.79990122643839e-05,
      "loss": 0.1503,
      "step": 194500
    },
    {
      "epoch": 4.004444741675112,
      "grad_norm": 3.4370040893554688,
      "learning_rate": 1.7992838916783277e-05,
      "loss": 0.1661,
      "step": 194600
    },
    {
      "epoch": 4.006502492450627,
      "grad_norm": 3.9911043643951416,
      "learning_rate": 1.798666556918265e-05,
      "loss": 0.1575,
      "step": 194700
    },
    {
      "epoch": 4.008560243226142,
      "grad_norm": 0.47091957926750183,
      "learning_rate": 1.7980492221582023e-05,
      "loss": 0.1512,
      "step": 194800
    },
    {
      "epoch": 4.010617994001657,
      "grad_norm": 3.767404317855835,
      "learning_rate": 1.79743188739814e-05,
      "loss": 0.1615,
      "step": 194900
    },
    {
      "epoch": 4.012675744777171,
      "grad_norm": 2.915660858154297,
      "learning_rate": 1.7968145526380773e-05,
      "loss": 0.151,
      "step": 195000
    },
    {
      "epoch": 4.0147334955526865,
      "grad_norm": 1.924545407295227,
      "learning_rate": 1.7961972178780146e-05,
      "loss": 0.1491,
      "step": 195100
    },
    {
      "epoch": 4.016791246328201,
      "grad_norm": 2.9379467964172363,
      "learning_rate": 1.7955798831179522e-05,
      "loss": 0.1714,
      "step": 195200
    },
    {
      "epoch": 4.018848997103715,
      "grad_norm": 3.080618143081665,
      "learning_rate": 1.7949625483578896e-05,
      "loss": 0.168,
      "step": 195300
    },
    {
      "epoch": 4.020906747879231,
      "grad_norm": 3.6178581714630127,
      "learning_rate": 1.794345213597827e-05,
      "loss": 0.1572,
      "step": 195400
    },
    {
      "epoch": 4.022964498654745,
      "grad_norm": 2.8425564765930176,
      "learning_rate": 1.7937278788377642e-05,
      "loss": 0.1658,
      "step": 195500
    },
    {
      "epoch": 4.02502224943026,
      "grad_norm": 1.448212742805481,
      "learning_rate": 1.7931105440777022e-05,
      "loss": 0.1624,
      "step": 195600
    },
    {
      "epoch": 4.027080000205775,
      "grad_norm": 6.028225421905518,
      "learning_rate": 1.7924932093176395e-05,
      "loss": 0.153,
      "step": 195700
    },
    {
      "epoch": 4.02913775098129,
      "grad_norm": 2.544255018234253,
      "learning_rate": 1.7918758745575768e-05,
      "loss": 0.1546,
      "step": 195800
    },
    {
      "epoch": 4.031195501756804,
      "grad_norm": 2.75437331199646,
      "learning_rate": 1.791258539797514e-05,
      "loss": 0.1583,
      "step": 195900
    },
    {
      "epoch": 4.03325325253232,
      "grad_norm": 1.3490681648254395,
      "learning_rate": 1.7906412050374518e-05,
      "loss": 0.1504,
      "step": 196000
    },
    {
      "epoch": 4.035311003307834,
      "grad_norm": 2.9543519020080566,
      "learning_rate": 1.790023870277389e-05,
      "loss": 0.1423,
      "step": 196100
    },
    {
      "epoch": 4.037368754083349,
      "grad_norm": 4.150830268859863,
      "learning_rate": 1.7894065355173264e-05,
      "loss": 0.1677,
      "step": 196200
    },
    {
      "epoch": 4.039426504858864,
      "grad_norm": 3.3577208518981934,
      "learning_rate": 1.788789200757264e-05,
      "loss": 0.1647,
      "step": 196300
    },
    {
      "epoch": 4.041484255634379,
      "grad_norm": 2.534466505050659,
      "learning_rate": 1.7881718659972014e-05,
      "loss": 0.1633,
      "step": 196400
    },
    {
      "epoch": 4.0435420064098935,
      "grad_norm": 6.330008029937744,
      "learning_rate": 1.7875545312371387e-05,
      "loss": 0.1494,
      "step": 196500
    },
    {
      "epoch": 4.045599757185409,
      "grad_norm": 3.6140642166137695,
      "learning_rate": 1.7869371964770763e-05,
      "loss": 0.1581,
      "step": 196600
    },
    {
      "epoch": 4.047657507960923,
      "grad_norm": 0.2747795879840851,
      "learning_rate": 1.7863260350646144e-05,
      "loss": 0.1785,
      "step": 196700
    },
    {
      "epoch": 4.0497152587364385,
      "grad_norm": 2.528110980987549,
      "learning_rate": 1.785708700304552e-05,
      "loss": 0.1642,
      "step": 196800
    },
    {
      "epoch": 4.051773009511953,
      "grad_norm": 1.841178059577942,
      "learning_rate": 1.7850913655444894e-05,
      "loss": 0.1557,
      "step": 196900
    },
    {
      "epoch": 4.053830760287468,
      "grad_norm": 2.2592506408691406,
      "learning_rate": 1.7844740307844267e-05,
      "loss": 0.1567,
      "step": 197000
    },
    {
      "epoch": 4.0558885110629825,
      "grad_norm": 0.39790084958076477,
      "learning_rate": 1.783856696024364e-05,
      "loss": 0.1664,
      "step": 197100
    },
    {
      "epoch": 4.057946261838498,
      "grad_norm": 4.44966459274292,
      "learning_rate": 1.7832393612643016e-05,
      "loss": 0.1423,
      "step": 197200
    },
    {
      "epoch": 4.060004012614012,
      "grad_norm": 3.8201804161071777,
      "learning_rate": 1.782622026504239e-05,
      "loss": 0.1614,
      "step": 197300
    },
    {
      "epoch": 4.0620617633895275,
      "grad_norm": 3.7407944202423096,
      "learning_rate": 1.7820046917441766e-05,
      "loss": 0.1484,
      "step": 197400
    },
    {
      "epoch": 4.064119514165042,
      "grad_norm": 2.399301767349243,
      "learning_rate": 1.781387356984114e-05,
      "loss": 0.1653,
      "step": 197500
    },
    {
      "epoch": 4.066177264940556,
      "grad_norm": 3.027012348175049,
      "learning_rate": 1.7807700222240516e-05,
      "loss": 0.1632,
      "step": 197600
    },
    {
      "epoch": 4.068235015716072,
      "grad_norm": 3.564180374145508,
      "learning_rate": 1.780152687463989e-05,
      "loss": 0.1416,
      "step": 197700
    },
    {
      "epoch": 4.070292766491586,
      "grad_norm": 1.9500199556350708,
      "learning_rate": 1.7795353527039262e-05,
      "loss": 0.1506,
      "step": 197800
    },
    {
      "epoch": 4.072350517267101,
      "grad_norm": 2.5697546005249023,
      "learning_rate": 1.778918017943864e-05,
      "loss": 0.147,
      "step": 197900
    },
    {
      "epoch": 4.074408268042616,
      "grad_norm": 1.9503884315490723,
      "learning_rate": 1.7783006831838012e-05,
      "loss": 0.1929,
      "step": 198000
    },
    {
      "epoch": 4.076466018818131,
      "grad_norm": 3.69735050201416,
      "learning_rate": 1.7776833484237385e-05,
      "loss": 0.1736,
      "step": 198100
    },
    {
      "epoch": 4.078523769593645,
      "grad_norm": 5.583792686462402,
      "learning_rate": 1.7770660136636758e-05,
      "loss": 0.144,
      "step": 198200
    },
    {
      "epoch": 4.080581520369161,
      "grad_norm": 2.1443543434143066,
      "learning_rate": 1.7764486789036135e-05,
      "loss": 0.1415,
      "step": 198300
    },
    {
      "epoch": 4.082639271144675,
      "grad_norm": 2.004443407058716,
      "learning_rate": 1.775831344143551e-05,
      "loss": 0.1781,
      "step": 198400
    },
    {
      "epoch": 4.08469702192019,
      "grad_norm": 1.6848255395889282,
      "learning_rate": 1.7752140093834884e-05,
      "loss": 0.1698,
      "step": 198500
    },
    {
      "epoch": 4.086754772695705,
      "grad_norm": 2.8336312770843506,
      "learning_rate": 1.774596674623426e-05,
      "loss": 0.1714,
      "step": 198600
    },
    {
      "epoch": 4.08881252347122,
      "grad_norm": 1.8465858697891235,
      "learning_rate": 1.7739855132109638e-05,
      "loss": 0.1564,
      "step": 198700
    },
    {
      "epoch": 4.090870274246734,
      "grad_norm": 1.5693187713623047,
      "learning_rate": 1.7733681784509014e-05,
      "loss": 0.1673,
      "step": 198800
    },
    {
      "epoch": 4.09292802502225,
      "grad_norm": 2.6155283451080322,
      "learning_rate": 1.7727508436908388e-05,
      "loss": 0.173,
      "step": 198900
    },
    {
      "epoch": 4.094985775797764,
      "grad_norm": 4.395873069763184,
      "learning_rate": 1.772133508930776e-05,
      "loss": 0.1513,
      "step": 199000
    },
    {
      "epoch": 4.097043526573279,
      "grad_norm": 4.157442092895508,
      "learning_rate": 1.7715161741707134e-05,
      "loss": 0.1724,
      "step": 199100
    },
    {
      "epoch": 4.099101277348794,
      "grad_norm": 2.6671972274780273,
      "learning_rate": 1.7708988394106514e-05,
      "loss": 0.1778,
      "step": 199200
    },
    {
      "epoch": 4.101159028124309,
      "grad_norm": 1.216214895248413,
      "learning_rate": 1.7702815046505887e-05,
      "loss": 0.1523,
      "step": 199300
    },
    {
      "epoch": 4.1032167788998235,
      "grad_norm": 4.690430641174316,
      "learning_rate": 1.769664169890526e-05,
      "loss": 0.1589,
      "step": 199400
    },
    {
      "epoch": 4.105274529675339,
      "grad_norm": 1.817145824432373,
      "learning_rate": 1.7690468351304637e-05,
      "loss": 0.1606,
      "step": 199500
    },
    {
      "epoch": 4.107332280450853,
      "grad_norm": 3.464834213256836,
      "learning_rate": 1.768429500370401e-05,
      "loss": 0.1787,
      "step": 199600
    },
    {
      "epoch": 4.109390031226368,
      "grad_norm": 4.815982341766357,
      "learning_rate": 1.7678121656103383e-05,
      "loss": 0.1522,
      "step": 199700
    },
    {
      "epoch": 4.111447782001883,
      "grad_norm": 0.8616669178009033,
      "learning_rate": 1.7671948308502756e-05,
      "loss": 0.1564,
      "step": 199800
    },
    {
      "epoch": 4.113505532777397,
      "grad_norm": 0.7479374408721924,
      "learning_rate": 1.7665774960902133e-05,
      "loss": 0.1841,
      "step": 199900
    },
    {
      "epoch": 4.115563283552913,
      "grad_norm": 3.636986017227173,
      "learning_rate": 1.7659601613301506e-05,
      "loss": 0.1465,
      "step": 200000
    },
    {
      "epoch": 4.115563283552913,
      "eval_accuracy": 0.839867617107943,
      "eval_f1_contradiction": 0.8474314407106991,
      "eval_loss": 0.15447109937667847,
      "eval_runtime": 75.2926,
      "eval_samples_per_second": 52.17,
      "eval_steps_per_second": 6.521,
      "step": 200000
    },
    {
      "epoch": 4.117621034328427,
      "grad_norm": 2.230220317840576,
      "learning_rate": 1.765342826570088e-05,
      "loss": 0.1714,
      "step": 200100
    },
    {
      "epoch": 4.119678785103942,
      "grad_norm": 3.9732415676116943,
      "learning_rate": 1.7647254918100255e-05,
      "loss": 0.168,
      "step": 200200
    },
    {
      "epoch": 4.121736535879457,
      "grad_norm": 1.651879906654358,
      "learning_rate": 1.7641081570499632e-05,
      "loss": 0.1637,
      "step": 200300
    },
    {
      "epoch": 4.123794286654972,
      "grad_norm": 3.45085072517395,
      "learning_rate": 1.7634908222899005e-05,
      "loss": 0.1772,
      "step": 200400
    },
    {
      "epoch": 4.125852037430486,
      "grad_norm": 4.683771133422852,
      "learning_rate": 1.7628734875298378e-05,
      "loss": 0.1581,
      "step": 200500
    },
    {
      "epoch": 4.127909788206002,
      "grad_norm": 0.6168407797813416,
      "learning_rate": 1.7622561527697755e-05,
      "loss": 0.1468,
      "step": 200600
    },
    {
      "epoch": 4.129967538981516,
      "grad_norm": 1.4965740442276,
      "learning_rate": 1.7616449913573132e-05,
      "loss": 0.1747,
      "step": 200700
    },
    {
      "epoch": 4.132025289757031,
      "grad_norm": 6.005526065826416,
      "learning_rate": 1.761027656597251e-05,
      "loss": 0.1577,
      "step": 200800
    },
    {
      "epoch": 4.134083040532546,
      "grad_norm": 3.869934320449829,
      "learning_rate": 1.760410321837188e-05,
      "loss": 0.1698,
      "step": 200900
    },
    {
      "epoch": 4.136140791308061,
      "grad_norm": 3.3719542026519775,
      "learning_rate": 1.7597929870771258e-05,
      "loss": 0.1594,
      "step": 201000
    },
    {
      "epoch": 4.138198542083575,
      "grad_norm": 1.571045160293579,
      "learning_rate": 1.7591756523170635e-05,
      "loss": 0.1688,
      "step": 201100
    },
    {
      "epoch": 4.140256292859091,
      "grad_norm": 0.4646068215370178,
      "learning_rate": 1.7585583175570008e-05,
      "loss": 0.155,
      "step": 201200
    },
    {
      "epoch": 4.142314043634605,
      "grad_norm": 5.8161444664001465,
      "learning_rate": 1.757940982796938e-05,
      "loss": 0.155,
      "step": 201300
    },
    {
      "epoch": 4.14437179441012,
      "grad_norm": 12.521068572998047,
      "learning_rate": 1.7573236480368754e-05,
      "loss": 0.1632,
      "step": 201400
    },
    {
      "epoch": 4.146429545185635,
      "grad_norm": 6.206974506378174,
      "learning_rate": 1.756706313276813e-05,
      "loss": 0.1591,
      "step": 201500
    },
    {
      "epoch": 4.14848729596115,
      "grad_norm": 1.4564051628112793,
      "learning_rate": 1.7560889785167504e-05,
      "loss": 0.1531,
      "step": 201600
    },
    {
      "epoch": 4.1505450467366645,
      "grad_norm": 1.6695476770401,
      "learning_rate": 1.7554716437566877e-05,
      "loss": 0.1797,
      "step": 201700
    },
    {
      "epoch": 4.152602797512179,
      "grad_norm": 4.348841667175293,
      "learning_rate": 1.754854308996625e-05,
      "loss": 0.1545,
      "step": 201800
    },
    {
      "epoch": 4.154660548287694,
      "grad_norm": 1.7006635665893555,
      "learning_rate": 1.7542369742365627e-05,
      "loss": 0.1657,
      "step": 201900
    },
    {
      "epoch": 4.1567182990632086,
      "grad_norm": 2.9776623249053955,
      "learning_rate": 1.7536196394765003e-05,
      "loss": 0.1698,
      "step": 202000
    },
    {
      "epoch": 4.158776049838724,
      "grad_norm": 0.9138694405555725,
      "learning_rate": 1.7530023047164376e-05,
      "loss": 0.1626,
      "step": 202100
    },
    {
      "epoch": 4.160833800614238,
      "grad_norm": 1.6491886377334595,
      "learning_rate": 1.7523849699563753e-05,
      "loss": 0.1745,
      "step": 202200
    },
    {
      "epoch": 4.1628915513897535,
      "grad_norm": 2.2101492881774902,
      "learning_rate": 1.7517676351963126e-05,
      "loss": 0.1695,
      "step": 202300
    },
    {
      "epoch": 4.164949302165268,
      "grad_norm": 2.4384665489196777,
      "learning_rate": 1.75115030043625e-05,
      "loss": 0.1683,
      "step": 202400
    },
    {
      "epoch": 4.167007052940783,
      "grad_norm": 1.3995330333709717,
      "learning_rate": 1.7505329656761872e-05,
      "loss": 0.1561,
      "step": 202500
    },
    {
      "epoch": 4.169064803716298,
      "grad_norm": 3.587285041809082,
      "learning_rate": 1.749915630916125e-05,
      "loss": 0.1698,
      "step": 202600
    },
    {
      "epoch": 4.171122554491813,
      "grad_norm": 1.2972596883773804,
      "learning_rate": 1.7493044695036626e-05,
      "loss": 0.165,
      "step": 202700
    },
    {
      "epoch": 4.173180305267327,
      "grad_norm": 1.508414387702942,
      "learning_rate": 1.7486871347436006e-05,
      "loss": 0.1489,
      "step": 202800
    },
    {
      "epoch": 4.175238056042843,
      "grad_norm": 3.686941623687744,
      "learning_rate": 1.748069799983538e-05,
      "loss": 0.1551,
      "step": 202900
    },
    {
      "epoch": 4.177295806818357,
      "grad_norm": 5.047100067138672,
      "learning_rate": 1.7474524652234752e-05,
      "loss": 0.1609,
      "step": 203000
    },
    {
      "epoch": 4.179353557593872,
      "grad_norm": 2.6870546340942383,
      "learning_rate": 1.746835130463413e-05,
      "loss": 0.1788,
      "step": 203100
    },
    {
      "epoch": 4.181411308369387,
      "grad_norm": 3.7575087547302246,
      "learning_rate": 1.74621779570335e-05,
      "loss": 0.1541,
      "step": 203200
    },
    {
      "epoch": 4.183469059144902,
      "grad_norm": 2.3066091537475586,
      "learning_rate": 1.7456004609432875e-05,
      "loss": 0.1706,
      "step": 203300
    },
    {
      "epoch": 4.185526809920416,
      "grad_norm": 0.9583984017372131,
      "learning_rate": 1.7449831261832248e-05,
      "loss": 0.1654,
      "step": 203400
    },
    {
      "epoch": 4.187584560695932,
      "grad_norm": 1.527022361755371,
      "learning_rate": 1.7443657914231625e-05,
      "loss": 0.1585,
      "step": 203500
    },
    {
      "epoch": 4.189642311471446,
      "grad_norm": 1.2753256559371948,
      "learning_rate": 1.7437484566630998e-05,
      "loss": 0.1525,
      "step": 203600
    },
    {
      "epoch": 4.191700062246961,
      "grad_norm": 4.159229755401611,
      "learning_rate": 1.7431311219030374e-05,
      "loss": 0.149,
      "step": 203700
    },
    {
      "epoch": 4.193757813022476,
      "grad_norm": 11.55263614654541,
      "learning_rate": 1.742513787142975e-05,
      "loss": 0.1429,
      "step": 203800
    },
    {
      "epoch": 4.195815563797991,
      "grad_norm": 1.7434536218643188,
      "learning_rate": 1.7418964523829124e-05,
      "loss": 0.1638,
      "step": 203900
    },
    {
      "epoch": 4.197873314573505,
      "grad_norm": 7.3670334815979,
      "learning_rate": 1.7412791176228497e-05,
      "loss": 0.139,
      "step": 204000
    },
    {
      "epoch": 4.19993106534902,
      "grad_norm": 4.846238613128662,
      "learning_rate": 1.740661782862787e-05,
      "loss": 0.1591,
      "step": 204100
    },
    {
      "epoch": 4.201988816124535,
      "grad_norm": 3.334048271179199,
      "learning_rate": 1.7400444481027247e-05,
      "loss": 0.1524,
      "step": 204200
    },
    {
      "epoch": 4.2040465669000495,
      "grad_norm": 2.7132482528686523,
      "learning_rate": 1.739427113342662e-05,
      "loss": 0.1651,
      "step": 204300
    },
    {
      "epoch": 4.206104317675565,
      "grad_norm": 3.5491530895233154,
      "learning_rate": 1.7388097785825993e-05,
      "loss": 0.176,
      "step": 204400
    },
    {
      "epoch": 4.208162068451079,
      "grad_norm": 2.623056173324585,
      "learning_rate": 1.7381924438225366e-05,
      "loss": 0.1398,
      "step": 204500
    },
    {
      "epoch": 4.2102198192265945,
      "grad_norm": 3.3935701847076416,
      "learning_rate": 1.7375751090624743e-05,
      "loss": 0.1751,
      "step": 204600
    },
    {
      "epoch": 4.212277570002109,
      "grad_norm": 1.5620163679122925,
      "learning_rate": 1.736957774302412e-05,
      "loss": 0.157,
      "step": 204700
    },
    {
      "epoch": 4.214335320777624,
      "grad_norm": 2.628966808319092,
      "learning_rate": 1.73634661288995e-05,
      "loss": 0.1784,
      "step": 204800
    },
    {
      "epoch": 4.216393071553139,
      "grad_norm": 0.5051974058151245,
      "learning_rate": 1.7357292781298873e-05,
      "loss": 0.1646,
      "step": 204900
    },
    {
      "epoch": 4.218450822328654,
      "grad_norm": 3.7262353897094727,
      "learning_rate": 1.7351119433698246e-05,
      "loss": 0.1437,
      "step": 205000
    },
    {
      "epoch": 4.220508573104168,
      "grad_norm": 2.384561777114868,
      "learning_rate": 1.7344946086097622e-05,
      "loss": 0.1764,
      "step": 205100
    },
    {
      "epoch": 4.222566323879684,
      "grad_norm": 5.1494293212890625,
      "learning_rate": 1.7338772738496996e-05,
      "loss": 0.1685,
      "step": 205200
    },
    {
      "epoch": 4.224624074655198,
      "grad_norm": 3.2820749282836914,
      "learning_rate": 1.733259939089637e-05,
      "loss": 0.1487,
      "step": 205300
    },
    {
      "epoch": 4.226681825430713,
      "grad_norm": 2.0612130165100098,
      "learning_rate": 1.7326426043295742e-05,
      "loss": 0.1573,
      "step": 205400
    },
    {
      "epoch": 4.228739576206228,
      "grad_norm": 1.934484839439392,
      "learning_rate": 1.732025269569512e-05,
      "loss": 0.1546,
      "step": 205500
    },
    {
      "epoch": 4.230797326981743,
      "grad_norm": 0.5730684995651245,
      "learning_rate": 1.7314079348094495e-05,
      "loss": 0.1613,
      "step": 205600
    },
    {
      "epoch": 4.232855077757257,
      "grad_norm": 0.3887934982776642,
      "learning_rate": 1.7307906000493868e-05,
      "loss": 0.1666,
      "step": 205700
    },
    {
      "epoch": 4.234912828532773,
      "grad_norm": 1.365385890007019,
      "learning_rate": 1.7301732652893245e-05,
      "loss": 0.1666,
      "step": 205800
    },
    {
      "epoch": 4.236970579308287,
      "grad_norm": 1.4643497467041016,
      "learning_rate": 1.7295559305292618e-05,
      "loss": 0.1495,
      "step": 205900
    },
    {
      "epoch": 4.239028330083802,
      "grad_norm": 2.5599544048309326,
      "learning_rate": 1.728938595769199e-05,
      "loss": 0.1613,
      "step": 206000
    },
    {
      "epoch": 4.241086080859317,
      "grad_norm": 3.4205307960510254,
      "learning_rate": 1.7283212610091364e-05,
      "loss": 0.168,
      "step": 206100
    },
    {
      "epoch": 4.243143831634832,
      "grad_norm": 4.952600955963135,
      "learning_rate": 1.727703926249074e-05,
      "loss": 0.1657,
      "step": 206200
    },
    {
      "epoch": 4.245201582410346,
      "grad_norm": 4.145991325378418,
      "learning_rate": 1.7270865914890114e-05,
      "loss": 0.1727,
      "step": 206300
    },
    {
      "epoch": 4.247259333185861,
      "grad_norm": 1.0400149822235107,
      "learning_rate": 1.7264692567289487e-05,
      "loss": 0.1641,
      "step": 206400
    },
    {
      "epoch": 4.249317083961376,
      "grad_norm": 3.491438627243042,
      "learning_rate": 1.7258519219688867e-05,
      "loss": 0.1648,
      "step": 206500
    },
    {
      "epoch": 4.2513748347368905,
      "grad_norm": 1.245504379272461,
      "learning_rate": 1.725234587208824e-05,
      "loss": 0.1542,
      "step": 206600
    },
    {
      "epoch": 4.253432585512406,
      "grad_norm": 4.959839820861816,
      "learning_rate": 1.7246172524487613e-05,
      "loss": 0.1514,
      "step": 206700
    },
    {
      "epoch": 4.25549033628792,
      "grad_norm": 1.6580383777618408,
      "learning_rate": 1.7240060910362994e-05,
      "loss": 0.1542,
      "step": 206800
    },
    {
      "epoch": 4.2575480870634355,
      "grad_norm": 3.6942317485809326,
      "learning_rate": 1.7233887562762367e-05,
      "loss": 0.1616,
      "step": 206900
    },
    {
      "epoch": 4.25960583783895,
      "grad_norm": 4.95591402053833,
      "learning_rate": 1.722771421516174e-05,
      "loss": 0.1829,
      "step": 207000
    },
    {
      "epoch": 4.261663588614465,
      "grad_norm": 1.5789915323257446,
      "learning_rate": 1.7221540867561116e-05,
      "loss": 0.1802,
      "step": 207100
    },
    {
      "epoch": 4.2637213393899795,
      "grad_norm": 2.0588696002960205,
      "learning_rate": 1.721536751996049e-05,
      "loss": 0.1581,
      "step": 207200
    },
    {
      "epoch": 4.265779090165495,
      "grad_norm": 3.064364194869995,
      "learning_rate": 1.7209194172359866e-05,
      "loss": 0.1418,
      "step": 207300
    },
    {
      "epoch": 4.267836840941009,
      "grad_norm": 13.50959587097168,
      "learning_rate": 1.7203020824759243e-05,
      "loss": 0.1508,
      "step": 207400
    },
    {
      "epoch": 4.2698945917165245,
      "grad_norm": 14.476386070251465,
      "learning_rate": 1.7196847477158616e-05,
      "loss": 0.174,
      "step": 207500
    },
    {
      "epoch": 4.271952342492039,
      "grad_norm": 4.061112880706787,
      "learning_rate": 1.719067412955799e-05,
      "loss": 0.1502,
      "step": 207600
    },
    {
      "epoch": 4.274010093267554,
      "grad_norm": 3.5343048572540283,
      "learning_rate": 1.7184500781957362e-05,
      "loss": 0.1732,
      "step": 207700
    },
    {
      "epoch": 4.276067844043069,
      "grad_norm": 1.1468048095703125,
      "learning_rate": 1.717832743435674e-05,
      "loss": 0.1546,
      "step": 207800
    },
    {
      "epoch": 4.278125594818584,
      "grad_norm": 1.5576887130737305,
      "learning_rate": 1.7172154086756112e-05,
      "loss": 0.1808,
      "step": 207900
    },
    {
      "epoch": 4.280183345594098,
      "grad_norm": 7.082417011260986,
      "learning_rate": 1.7165980739155485e-05,
      "loss": 0.1631,
      "step": 208000
    },
    {
      "epoch": 4.282241096369614,
      "grad_norm": 0.9637296795845032,
      "learning_rate": 1.715980739155486e-05,
      "loss": 0.1671,
      "step": 208100
    },
    {
      "epoch": 4.284298847145128,
      "grad_norm": 1.2440438270568848,
      "learning_rate": 1.7153634043954235e-05,
      "loss": 0.1522,
      "step": 208200
    },
    {
      "epoch": 4.286356597920642,
      "grad_norm": 1.42735755443573,
      "learning_rate": 1.714746069635361e-05,
      "loss": 0.1487,
      "step": 208300
    },
    {
      "epoch": 4.288414348696158,
      "grad_norm": 4.848312854766846,
      "learning_rate": 1.7141287348752984e-05,
      "loss": 0.1579,
      "step": 208400
    },
    {
      "epoch": 4.290472099471672,
      "grad_norm": 5.596212863922119,
      "learning_rate": 1.713511400115236e-05,
      "loss": 0.1856,
      "step": 208500
    },
    {
      "epoch": 4.292529850247187,
      "grad_norm": 4.002908706665039,
      "learning_rate": 1.7128940653551734e-05,
      "loss": 0.1641,
      "step": 208600
    },
    {
      "epoch": 4.294587601022702,
      "grad_norm": 0.7355480790138245,
      "learning_rate": 1.7122767305951107e-05,
      "loss": 0.1652,
      "step": 208700
    },
    {
      "epoch": 4.296645351798217,
      "grad_norm": 2.11553692817688,
      "learning_rate": 1.7116655691826488e-05,
      "loss": 0.1611,
      "step": 208800
    },
    {
      "epoch": 4.2987031025737314,
      "grad_norm": 0.14040540158748627,
      "learning_rate": 1.711048234422586e-05,
      "loss": 0.152,
      "step": 208900
    },
    {
      "epoch": 4.300760853349247,
      "grad_norm": 7.186023712158203,
      "learning_rate": 1.7104308996625237e-05,
      "loss": 0.1626,
      "step": 209000
    },
    {
      "epoch": 4.302818604124761,
      "grad_norm": 3.089080572128296,
      "learning_rate": 1.7098135649024614e-05,
      "loss": 0.1564,
      "step": 209100
    },
    {
      "epoch": 4.304876354900276,
      "grad_norm": 4.909149169921875,
      "learning_rate": 1.7091962301423987e-05,
      "loss": 0.171,
      "step": 209200
    },
    {
      "epoch": 4.306934105675791,
      "grad_norm": 1.406649112701416,
      "learning_rate": 1.708578895382336e-05,
      "loss": 0.1551,
      "step": 209300
    },
    {
      "epoch": 4.308991856451306,
      "grad_norm": 1.7471202611923218,
      "learning_rate": 1.7079615606222737e-05,
      "loss": 0.1827,
      "step": 209400
    },
    {
      "epoch": 4.3110496072268205,
      "grad_norm": 3.7828993797302246,
      "learning_rate": 1.707344225862211e-05,
      "loss": 0.1538,
      "step": 209500
    },
    {
      "epoch": 4.313107358002336,
      "grad_norm": 4.268435478210449,
      "learning_rate": 1.7067268911021483e-05,
      "loss": 0.1605,
      "step": 209600
    },
    {
      "epoch": 4.31516510877785,
      "grad_norm": 6.199422836303711,
      "learning_rate": 1.7061095563420856e-05,
      "loss": 0.1582,
      "step": 209700
    },
    {
      "epoch": 4.3172228595533655,
      "grad_norm": 2.944214344024658,
      "learning_rate": 1.7054922215820233e-05,
      "loss": 0.1433,
      "step": 209800
    },
    {
      "epoch": 4.31928061032888,
      "grad_norm": 0.7742490768432617,
      "learning_rate": 1.7048748868219606e-05,
      "loss": 0.1607,
      "step": 209900
    },
    {
      "epoch": 4.321338361104395,
      "grad_norm": 2.501401901245117,
      "learning_rate": 1.704257552061898e-05,
      "loss": 0.1757,
      "step": 210000
    },
    {
      "epoch": 4.321338361104395,
      "eval_accuracy": 0.8368126272912424,
      "eval_f1_contradiction": 0.8418640183346066,
      "eval_loss": 0.15437182784080505,
      "eval_runtime": 69.7586,
      "eval_samples_per_second": 56.308,
      "eval_steps_per_second": 7.039,
      "step": 210000
    },
    {
      "epoch": 4.32339611187991,
      "grad_norm": 5.989663600921631,
      "learning_rate": 1.703640217301836e-05,
      "loss": 0.1798,
      "step": 210100
    },
    {
      "epoch": 4.325453862655425,
      "grad_norm": 1.5125564336776733,
      "learning_rate": 1.7030228825417732e-05,
      "loss": 0.1599,
      "step": 210200
    },
    {
      "epoch": 4.327511613430939,
      "grad_norm": 3.647303342819214,
      "learning_rate": 1.7024055477817105e-05,
      "loss": 0.1612,
      "step": 210300
    },
    {
      "epoch": 4.3295693642064546,
      "grad_norm": 5.017117977142334,
      "learning_rate": 1.7017882130216478e-05,
      "loss": 0.1492,
      "step": 210400
    },
    {
      "epoch": 4.331627114981969,
      "grad_norm": 2.303508758544922,
      "learning_rate": 1.7011708782615855e-05,
      "loss": 0.1612,
      "step": 210500
    },
    {
      "epoch": 4.333684865757483,
      "grad_norm": 1.7875486612319946,
      "learning_rate": 1.7005535435015228e-05,
      "loss": 0.1688,
      "step": 210600
    },
    {
      "epoch": 4.335742616532999,
      "grad_norm": 4.354035377502441,
      "learning_rate": 1.69993620874146e-05,
      "loss": 0.164,
      "step": 210700
    },
    {
      "epoch": 4.337800367308513,
      "grad_norm": 2.703376054763794,
      "learning_rate": 1.699325047328998e-05,
      "loss": 0.1771,
      "step": 210800
    },
    {
      "epoch": 4.339858118084028,
      "grad_norm": 2.083251953125,
      "learning_rate": 1.6987077125689358e-05,
      "loss": 0.1658,
      "step": 210900
    },
    {
      "epoch": 4.341915868859543,
      "grad_norm": 1.4247506856918335,
      "learning_rate": 1.6980903778088735e-05,
      "loss": 0.1715,
      "step": 211000
    },
    {
      "epoch": 4.343973619635058,
      "grad_norm": 3.7015483379364014,
      "learning_rate": 1.6974730430488108e-05,
      "loss": 0.1804,
      "step": 211100
    },
    {
      "epoch": 4.346031370410572,
      "grad_norm": 2.932699203491211,
      "learning_rate": 1.696855708288748e-05,
      "loss": 0.1504,
      "step": 211200
    },
    {
      "epoch": 4.348089121186088,
      "grad_norm": 1.6106970310211182,
      "learning_rate": 1.6962383735286854e-05,
      "loss": 0.1598,
      "step": 211300
    },
    {
      "epoch": 4.350146871961602,
      "grad_norm": 2.858684539794922,
      "learning_rate": 1.695621038768623e-05,
      "loss": 0.1548,
      "step": 211400
    },
    {
      "epoch": 4.352204622737117,
      "grad_norm": 4.194264888763428,
      "learning_rate": 1.6950037040085604e-05,
      "loss": 0.161,
      "step": 211500
    },
    {
      "epoch": 4.354262373512632,
      "grad_norm": 2.729496479034424,
      "learning_rate": 1.6943863692484977e-05,
      "loss": 0.1663,
      "step": 211600
    },
    {
      "epoch": 4.356320124288147,
      "grad_norm": 3.7067713737487793,
      "learning_rate": 1.6937690344884353e-05,
      "loss": 0.1558,
      "step": 211700
    },
    {
      "epoch": 4.3583778750636615,
      "grad_norm": 1.639130711555481,
      "learning_rate": 1.6931516997283727e-05,
      "loss": 0.1535,
      "step": 211800
    },
    {
      "epoch": 4.360435625839177,
      "grad_norm": 2.8707728385925293,
      "learning_rate": 1.6925343649683103e-05,
      "loss": 0.1714,
      "step": 211900
    },
    {
      "epoch": 4.362493376614691,
      "grad_norm": 3.518787145614624,
      "learning_rate": 1.6919170302082476e-05,
      "loss": 0.1532,
      "step": 212000
    },
    {
      "epoch": 4.3645511273902065,
      "grad_norm": 0.5795359015464783,
      "learning_rate": 1.6912996954481853e-05,
      "loss": 0.1717,
      "step": 212100
    },
    {
      "epoch": 4.366608878165721,
      "grad_norm": 2.4844303131103516,
      "learning_rate": 1.6906823606881226e-05,
      "loss": 0.169,
      "step": 212200
    },
    {
      "epoch": 4.368666628941236,
      "grad_norm": 3.923293113708496,
      "learning_rate": 1.69006502592806e-05,
      "loss": 0.1466,
      "step": 212300
    },
    {
      "epoch": 4.3707243797167505,
      "grad_norm": 2.3162872791290283,
      "learning_rate": 1.6894476911679972e-05,
      "loss": 0.1876,
      "step": 212400
    },
    {
      "epoch": 4.372782130492266,
      "grad_norm": 5.9961161613464355,
      "learning_rate": 1.688830356407935e-05,
      "loss": 0.1624,
      "step": 212500
    },
    {
      "epoch": 4.37483988126778,
      "grad_norm": 2.3881454467773438,
      "learning_rate": 1.6882130216478722e-05,
      "loss": 0.1595,
      "step": 212600
    },
    {
      "epoch": 4.3768976320432955,
      "grad_norm": 3.2176871299743652,
      "learning_rate": 1.6875956868878095e-05,
      "loss": 0.1642,
      "step": 212700
    },
    {
      "epoch": 4.37895538281881,
      "grad_norm": 1.7966405153274536,
      "learning_rate": 1.686984525475348e-05,
      "loss": 0.1609,
      "step": 212800
    },
    {
      "epoch": 4.381013133594324,
      "grad_norm": 1.8334393501281738,
      "learning_rate": 1.6863671907152852e-05,
      "loss": 0.1677,
      "step": 212900
    },
    {
      "epoch": 4.38307088436984,
      "grad_norm": 3.2390382289886475,
      "learning_rate": 1.685749855955223e-05,
      "loss": 0.1559,
      "step": 213000
    },
    {
      "epoch": 4.385128635145354,
      "grad_norm": 1.5871001482009888,
      "learning_rate": 1.6851325211951602e-05,
      "loss": 0.1611,
      "step": 213100
    },
    {
      "epoch": 4.387186385920869,
      "grad_norm": 5.054305553436279,
      "learning_rate": 1.6845151864350975e-05,
      "loss": 0.1353,
      "step": 213200
    },
    {
      "epoch": 4.389244136696384,
      "grad_norm": 3.4830121994018555,
      "learning_rate": 1.683897851675035e-05,
      "loss": 0.1686,
      "step": 213300
    },
    {
      "epoch": 4.391301887471899,
      "grad_norm": 1.4161956310272217,
      "learning_rate": 1.6832805169149725e-05,
      "loss": 0.1605,
      "step": 213400
    },
    {
      "epoch": 4.393359638247413,
      "grad_norm": 3.2084014415740967,
      "learning_rate": 1.6826631821549098e-05,
      "loss": 0.1851,
      "step": 213500
    },
    {
      "epoch": 4.395417389022929,
      "grad_norm": 3.4451229572296143,
      "learning_rate": 1.682045847394847e-05,
      "loss": 0.1572,
      "step": 213600
    },
    {
      "epoch": 4.397475139798443,
      "grad_norm": 5.48343563079834,
      "learning_rate": 1.681428512634785e-05,
      "loss": 0.1535,
      "step": 213700
    },
    {
      "epoch": 4.399532890573958,
      "grad_norm": 3.5827441215515137,
      "learning_rate": 1.6808111778747224e-05,
      "loss": 0.1579,
      "step": 213800
    },
    {
      "epoch": 4.401590641349473,
      "grad_norm": 2.8590760231018066,
      "learning_rate": 1.6801938431146597e-05,
      "loss": 0.1517,
      "step": 213900
    },
    {
      "epoch": 4.403648392124988,
      "grad_norm": 2.8355648517608643,
      "learning_rate": 1.679576508354597e-05,
      "loss": 0.1403,
      "step": 214000
    },
    {
      "epoch": 4.405706142900502,
      "grad_norm": 3.529984712600708,
      "learning_rate": 1.6789591735945347e-05,
      "loss": 0.1647,
      "step": 214100
    },
    {
      "epoch": 4.407763893676018,
      "grad_norm": 3.3578474521636963,
      "learning_rate": 1.678341838834472e-05,
      "loss": 0.1417,
      "step": 214200
    },
    {
      "epoch": 4.409821644451532,
      "grad_norm": 2.8115434646606445,
      "learning_rate": 1.6777245040744093e-05,
      "loss": 0.1311,
      "step": 214300
    },
    {
      "epoch": 4.411879395227047,
      "grad_norm": 3.711742401123047,
      "learning_rate": 1.677107169314347e-05,
      "loss": 0.1578,
      "step": 214400
    },
    {
      "epoch": 4.413937146002562,
      "grad_norm": 6.199990272521973,
      "learning_rate": 1.6764898345542843e-05,
      "loss": 0.1541,
      "step": 214500
    },
    {
      "epoch": 4.415994896778077,
      "grad_norm": 3.3331100940704346,
      "learning_rate": 1.6758724997942216e-05,
      "loss": 0.1409,
      "step": 214600
    },
    {
      "epoch": 4.4180526475535915,
      "grad_norm": 4.974605083465576,
      "learning_rate": 1.6752551650341592e-05,
      "loss": 0.1622,
      "step": 214700
    },
    {
      "epoch": 4.420110398329106,
      "grad_norm": 3.0347414016723633,
      "learning_rate": 1.674637830274097e-05,
      "loss": 0.1554,
      "step": 214800
    },
    {
      "epoch": 4.422168149104621,
      "grad_norm": 4.0793776512146,
      "learning_rate": 1.6740266688616346e-05,
      "loss": 0.1485,
      "step": 214900
    },
    {
      "epoch": 4.4242258998801365,
      "grad_norm": 4.928658485412598,
      "learning_rate": 1.6734093341015723e-05,
      "loss": 0.1679,
      "step": 215000
    },
    {
      "epoch": 4.426283650655651,
      "grad_norm": 3.5439653396606445,
      "learning_rate": 1.6727919993415096e-05,
      "loss": 0.1556,
      "step": 215100
    },
    {
      "epoch": 4.428341401431165,
      "grad_norm": 2.4445879459381104,
      "learning_rate": 1.672174664581447e-05,
      "loss": 0.1659,
      "step": 215200
    },
    {
      "epoch": 4.430399152206681,
      "grad_norm": 0.9298418760299683,
      "learning_rate": 1.6715573298213845e-05,
      "loss": 0.1767,
      "step": 215300
    },
    {
      "epoch": 4.432456902982195,
      "grad_norm": 2.5594890117645264,
      "learning_rate": 1.670939995061322e-05,
      "loss": 0.1514,
      "step": 215400
    },
    {
      "epoch": 4.43451465375771,
      "grad_norm": 3.5843589305877686,
      "learning_rate": 1.6703226603012595e-05,
      "loss": 0.1615,
      "step": 215500
    },
    {
      "epoch": 4.436572404533225,
      "grad_norm": 0.6041052341461182,
      "learning_rate": 1.6697053255411968e-05,
      "loss": 0.1668,
      "step": 215600
    },
    {
      "epoch": 4.43863015530874,
      "grad_norm": 0.5502153038978577,
      "learning_rate": 1.6690879907811345e-05,
      "loss": 0.1765,
      "step": 215700
    },
    {
      "epoch": 4.440687906084254,
      "grad_norm": 2.2714781761169434,
      "learning_rate": 1.6684706560210718e-05,
      "loss": 0.1525,
      "step": 215800
    },
    {
      "epoch": 4.44274565685977,
      "grad_norm": 1.342572808265686,
      "learning_rate": 1.667853321261009e-05,
      "loss": 0.1786,
      "step": 215900
    },
    {
      "epoch": 4.444803407635284,
      "grad_norm": 4.163675308227539,
      "learning_rate": 1.6672359865009468e-05,
      "loss": 0.1569,
      "step": 216000
    },
    {
      "epoch": 4.446861158410799,
      "grad_norm": 5.8405561447143555,
      "learning_rate": 1.666618651740884e-05,
      "loss": 0.1565,
      "step": 216100
    },
    {
      "epoch": 4.448918909186314,
      "grad_norm": 2.0390632152557373,
      "learning_rate": 1.6660013169808214e-05,
      "loss": 0.1759,
      "step": 216200
    },
    {
      "epoch": 4.450976659961829,
      "grad_norm": 1.7667351961135864,
      "learning_rate": 1.6653839822207587e-05,
      "loss": 0.1631,
      "step": 216300
    },
    {
      "epoch": 4.453034410737343,
      "grad_norm": 1.275038242340088,
      "learning_rate": 1.6647666474606963e-05,
      "loss": 0.1645,
      "step": 216400
    },
    {
      "epoch": 4.455092161512859,
      "grad_norm": 2.4252474308013916,
      "learning_rate": 1.664149312700634e-05,
      "loss": 0.1559,
      "step": 216500
    },
    {
      "epoch": 4.457149912288373,
      "grad_norm": 3.680346965789795,
      "learning_rate": 1.6635319779405713e-05,
      "loss": 0.1515,
      "step": 216600
    },
    {
      "epoch": 4.459207663063888,
      "grad_norm": 2.136992931365967,
      "learning_rate": 1.6629146431805086e-05,
      "loss": 0.1491,
      "step": 216700
    },
    {
      "epoch": 4.461265413839403,
      "grad_norm": 3.184551954269409,
      "learning_rate": 1.6622973084204463e-05,
      "loss": 0.1591,
      "step": 216800
    },
    {
      "epoch": 4.463323164614918,
      "grad_norm": 3.0266804695129395,
      "learning_rate": 1.6616861470079843e-05,
      "loss": 0.1556,
      "step": 216900
    },
    {
      "epoch": 4.4653809153904325,
      "grad_norm": 7.531976222991943,
      "learning_rate": 1.6610688122479216e-05,
      "loss": 0.1698,
      "step": 217000
    },
    {
      "epoch": 4.467438666165947,
      "grad_norm": 2.6020543575286865,
      "learning_rate": 1.660451477487859e-05,
      "loss": 0.1714,
      "step": 217100
    },
    {
      "epoch": 4.469496416941462,
      "grad_norm": 0.8713513612747192,
      "learning_rate": 1.6598341427277963e-05,
      "loss": 0.1556,
      "step": 217200
    },
    {
      "epoch": 4.471554167716977,
      "grad_norm": 3.4291021823883057,
      "learning_rate": 1.6592168079677343e-05,
      "loss": 0.1547,
      "step": 217300
    },
    {
      "epoch": 4.473611918492492,
      "grad_norm": 2.614154100418091,
      "learning_rate": 1.6585994732076716e-05,
      "loss": 0.1614,
      "step": 217400
    },
    {
      "epoch": 4.475669669268006,
      "grad_norm": 5.324831962585449,
      "learning_rate": 1.657982138447609e-05,
      "loss": 0.1607,
      "step": 217500
    },
    {
      "epoch": 4.4777274200435215,
      "grad_norm": 2.8320348262786865,
      "learning_rate": 1.6573648036875466e-05,
      "loss": 0.1683,
      "step": 217600
    },
    {
      "epoch": 4.479785170819036,
      "grad_norm": 2.2511024475097656,
      "learning_rate": 1.656747468927484e-05,
      "loss": 0.1414,
      "step": 217700
    },
    {
      "epoch": 4.481842921594551,
      "grad_norm": 1.8303090333938599,
      "learning_rate": 1.6561301341674212e-05,
      "loss": 0.1729,
      "step": 217800
    },
    {
      "epoch": 4.483900672370066,
      "grad_norm": 2.752315044403076,
      "learning_rate": 1.6555127994073585e-05,
      "loss": 0.15,
      "step": 217900
    },
    {
      "epoch": 4.485958423145581,
      "grad_norm": 3.693756103515625,
      "learning_rate": 1.654895464647296e-05,
      "loss": 0.144,
      "step": 218000
    },
    {
      "epoch": 4.488016173921095,
      "grad_norm": 1.1915578842163086,
      "learning_rate": 1.6542781298872335e-05,
      "loss": 0.1579,
      "step": 218100
    },
    {
      "epoch": 4.490073924696611,
      "grad_norm": 3.0841543674468994,
      "learning_rate": 1.6536607951271708e-05,
      "loss": 0.1702,
      "step": 218200
    },
    {
      "epoch": 4.492131675472125,
      "grad_norm": 0.6894586086273193,
      "learning_rate": 1.6530434603671084e-05,
      "loss": 0.1564,
      "step": 218300
    },
    {
      "epoch": 4.49418942624764,
      "grad_norm": 1.4525549411773682,
      "learning_rate": 1.652426125607046e-05,
      "loss": 0.146,
      "step": 218400
    },
    {
      "epoch": 4.496247177023155,
      "grad_norm": 1.9616504907608032,
      "learning_rate": 1.6518087908469834e-05,
      "loss": 0.175,
      "step": 218500
    },
    {
      "epoch": 4.49830492779867,
      "grad_norm": 3.994530439376831,
      "learning_rate": 1.6511914560869207e-05,
      "loss": 0.1835,
      "step": 218600
    },
    {
      "epoch": 4.500362678574184,
      "grad_norm": 2.2338051795959473,
      "learning_rate": 1.6505741213268584e-05,
      "loss": 0.1499,
      "step": 218700
    },
    {
      "epoch": 4.5024204293497,
      "grad_norm": 3.444952964782715,
      "learning_rate": 1.6499567865667957e-05,
      "loss": 0.1767,
      "step": 218800
    },
    {
      "epoch": 4.504478180125214,
      "grad_norm": 3.2513391971588135,
      "learning_rate": 1.649339451806733e-05,
      "loss": 0.1684,
      "step": 218900
    },
    {
      "epoch": 4.5065359309007285,
      "grad_norm": 2.4503517150878906,
      "learning_rate": 1.6487221170466703e-05,
      "loss": 0.1427,
      "step": 219000
    },
    {
      "epoch": 4.508593681676244,
      "grad_norm": 1.895686149597168,
      "learning_rate": 1.6481109556342087e-05,
      "loss": 0.1645,
      "step": 219100
    },
    {
      "epoch": 4.510651432451759,
      "grad_norm": 0.9967121481895447,
      "learning_rate": 1.647493620874146e-05,
      "loss": 0.1641,
      "step": 219200
    },
    {
      "epoch": 4.512709183227273,
      "grad_norm": 1.3307386636734009,
      "learning_rate": 1.6468762861140837e-05,
      "loss": 0.1604,
      "step": 219300
    },
    {
      "epoch": 4.514766934002788,
      "grad_norm": 2.501382827758789,
      "learning_rate": 1.646258951354021e-05,
      "loss": 0.1653,
      "step": 219400
    },
    {
      "epoch": 4.516824684778303,
      "grad_norm": 3.4566328525543213,
      "learning_rate": 1.6456416165939583e-05,
      "loss": 0.1857,
      "step": 219500
    },
    {
      "epoch": 4.5188824355538175,
      "grad_norm": 3.158472776412964,
      "learning_rate": 1.645024281833896e-05,
      "loss": 0.1713,
      "step": 219600
    },
    {
      "epoch": 4.520940186329333,
      "grad_norm": 2.860483169555664,
      "learning_rate": 1.6444069470738333e-05,
      "loss": 0.1548,
      "step": 219700
    },
    {
      "epoch": 4.522997937104847,
      "grad_norm": 2.107673168182373,
      "learning_rate": 1.6437896123137706e-05,
      "loss": 0.1437,
      "step": 219800
    },
    {
      "epoch": 4.5250556878803625,
      "grad_norm": 0.969523549079895,
      "learning_rate": 1.643172277553708e-05,
      "loss": 0.1554,
      "step": 219900
    },
    {
      "epoch": 4.527113438655877,
      "grad_norm": 1.4690114259719849,
      "learning_rate": 1.6425549427936455e-05,
      "loss": 0.1557,
      "step": 220000
    },
    {
      "epoch": 4.527113438655877,
      "eval_accuracy": 0.8383401221995926,
      "eval_f1_contradiction": 0.8468677494199536,
      "eval_loss": 0.15912416577339172,
      "eval_runtime": 69.9291,
      "eval_samples_per_second": 56.171,
      "eval_steps_per_second": 7.021,
      "step": 220000
    },
    {
      "epoch": 4.529171189431392,
      "grad_norm": 0.3283129334449768,
      "learning_rate": 1.6419376080335832e-05,
      "loss": 0.1291,
      "step": 220100
    },
    {
      "epoch": 4.531228940206907,
      "grad_norm": 4.3158416748046875,
      "learning_rate": 1.6413202732735205e-05,
      "loss": 0.1586,
      "step": 220200
    },
    {
      "epoch": 4.533286690982422,
      "grad_norm": 0.3667912781238556,
      "learning_rate": 1.640702938513458e-05,
      "loss": 0.1635,
      "step": 220300
    },
    {
      "epoch": 4.535344441757936,
      "grad_norm": 5.418963432312012,
      "learning_rate": 1.6400856037533955e-05,
      "loss": 0.1435,
      "step": 220400
    },
    {
      "epoch": 4.537402192533452,
      "grad_norm": 1.5659172534942627,
      "learning_rate": 1.6394682689933328e-05,
      "loss": 0.1529,
      "step": 220500
    },
    {
      "epoch": 4.539459943308966,
      "grad_norm": 3.9545514583587646,
      "learning_rate": 1.63885093423327e-05,
      "loss": 0.1649,
      "step": 220600
    },
    {
      "epoch": 4.541517694084481,
      "grad_norm": 2.902097463607788,
      "learning_rate": 1.6382335994732078e-05,
      "loss": 0.1537,
      "step": 220700
    },
    {
      "epoch": 4.543575444859996,
      "grad_norm": 0.19613546133041382,
      "learning_rate": 1.637616264713145e-05,
      "loss": 0.161,
      "step": 220800
    },
    {
      "epoch": 4.545633195635511,
      "grad_norm": 0.21841645240783691,
      "learning_rate": 1.6369989299530824e-05,
      "loss": 0.1666,
      "step": 220900
    },
    {
      "epoch": 4.547690946411025,
      "grad_norm": 3.1646347045898438,
      "learning_rate": 1.63638159519302e-05,
      "loss": 0.1755,
      "step": 221000
    },
    {
      "epoch": 4.549748697186541,
      "grad_norm": 3.3131635189056396,
      "learning_rate": 1.6357642604329577e-05,
      "loss": 0.1492,
      "step": 221100
    },
    {
      "epoch": 4.551806447962055,
      "grad_norm": 2.0516183376312256,
      "learning_rate": 1.6351530990204957e-05,
      "loss": 0.1586,
      "step": 221200
    },
    {
      "epoch": 4.553864198737569,
      "grad_norm": 7.342978477478027,
      "learning_rate": 1.634535764260433e-05,
      "loss": 0.1639,
      "step": 221300
    },
    {
      "epoch": 4.555921949513085,
      "grad_norm": 4.625969886779785,
      "learning_rate": 1.6339184295003704e-05,
      "loss": 0.1624,
      "step": 221400
    },
    {
      "epoch": 4.5579797002886,
      "grad_norm": 5.729063034057617,
      "learning_rate": 1.6333010947403077e-05,
      "loss": 0.1478,
      "step": 221500
    },
    {
      "epoch": 4.560037451064114,
      "grad_norm": 2.8930983543395996,
      "learning_rate": 1.6326837599802453e-05,
      "loss": 0.1599,
      "step": 221600
    },
    {
      "epoch": 4.562095201839629,
      "grad_norm": 1.5265299081802368,
      "learning_rate": 1.6320664252201827e-05,
      "loss": 0.1759,
      "step": 221700
    },
    {
      "epoch": 4.564152952615144,
      "grad_norm": 2.8987274169921875,
      "learning_rate": 1.6314490904601203e-05,
      "loss": 0.1575,
      "step": 221800
    },
    {
      "epoch": 4.5662107033906585,
      "grad_norm": 2.6812634468078613,
      "learning_rate": 1.630831755700058e-05,
      "loss": 0.1656,
      "step": 221900
    },
    {
      "epoch": 4.568268454166174,
      "grad_norm": 2.947251796722412,
      "learning_rate": 1.6302144209399953e-05,
      "loss": 0.1554,
      "step": 222000
    },
    {
      "epoch": 4.570326204941688,
      "grad_norm": 2.9904990196228027,
      "learning_rate": 1.6295970861799326e-05,
      "loss": 0.1818,
      "step": 222100
    },
    {
      "epoch": 4.5723839557172035,
      "grad_norm": 2.6367948055267334,
      "learning_rate": 1.62897975141987e-05,
      "loss": 0.1576,
      "step": 222200
    },
    {
      "epoch": 4.574441706492718,
      "grad_norm": 0.7017467617988586,
      "learning_rate": 1.6283624166598076e-05,
      "loss": 0.1519,
      "step": 222300
    },
    {
      "epoch": 4.576499457268233,
      "grad_norm": 3.9516963958740234,
      "learning_rate": 1.627745081899745e-05,
      "loss": 0.154,
      "step": 222400
    },
    {
      "epoch": 4.5785572080437476,
      "grad_norm": 3.235578775405884,
      "learning_rate": 1.6271277471396822e-05,
      "loss": 0.16,
      "step": 222500
    },
    {
      "epoch": 4.580614958819263,
      "grad_norm": 1.3838577270507812,
      "learning_rate": 1.6265104123796195e-05,
      "loss": 0.1751,
      "step": 222600
    },
    {
      "epoch": 4.582672709594777,
      "grad_norm": 1.5434083938598633,
      "learning_rate": 1.625893077619557e-05,
      "loss": 0.141,
      "step": 222700
    },
    {
      "epoch": 4.5847304603702925,
      "grad_norm": 3.365288257598877,
      "learning_rate": 1.6252757428594948e-05,
      "loss": 0.1465,
      "step": 222800
    },
    {
      "epoch": 4.586788211145807,
      "grad_norm": 2.080005407333374,
      "learning_rate": 1.624658408099432e-05,
      "loss": 0.1536,
      "step": 222900
    },
    {
      "epoch": 4.588845961921322,
      "grad_norm": 4.125865936279297,
      "learning_rate": 1.6240410733393698e-05,
      "loss": 0.1718,
      "step": 223000
    },
    {
      "epoch": 4.590903712696837,
      "grad_norm": 4.1465744972229,
      "learning_rate": 1.623423738579307e-05,
      "loss": 0.1614,
      "step": 223100
    },
    {
      "epoch": 4.592961463472352,
      "grad_norm": 3.1565134525299072,
      "learning_rate": 1.622812577166845e-05,
      "loss": 0.1668,
      "step": 223200
    },
    {
      "epoch": 4.595019214247866,
      "grad_norm": 1.5848803520202637,
      "learning_rate": 1.6221952424067825e-05,
      "loss": 0.1563,
      "step": 223300
    },
    {
      "epoch": 4.597076965023382,
      "grad_norm": 3.8896431922912598,
      "learning_rate": 1.6215779076467198e-05,
      "loss": 0.1489,
      "step": 223400
    },
    {
      "epoch": 4.599134715798896,
      "grad_norm": 2.318753719329834,
      "learning_rate": 1.620960572886657e-05,
      "loss": 0.1448,
      "step": 223500
    },
    {
      "epoch": 4.60119246657441,
      "grad_norm": 0.20824001729488373,
      "learning_rate": 1.6203432381265947e-05,
      "loss": 0.1554,
      "step": 223600
    },
    {
      "epoch": 4.603250217349926,
      "grad_norm": 3.369175672531128,
      "learning_rate": 1.6197259033665324e-05,
      "loss": 0.1656,
      "step": 223700
    },
    {
      "epoch": 4.605307968125441,
      "grad_norm": 1.3009319305419922,
      "learning_rate": 1.6191085686064697e-05,
      "loss": 0.153,
      "step": 223800
    },
    {
      "epoch": 4.607365718900955,
      "grad_norm": 3.050938367843628,
      "learning_rate": 1.6184912338464074e-05,
      "loss": 0.1639,
      "step": 223900
    },
    {
      "epoch": 4.60942346967647,
      "grad_norm": 1.4680341482162476,
      "learning_rate": 1.6178738990863447e-05,
      "loss": 0.1563,
      "step": 224000
    },
    {
      "epoch": 4.611481220451985,
      "grad_norm": 2.6067726612091064,
      "learning_rate": 1.617256564326282e-05,
      "loss": 0.1443,
      "step": 224100
    },
    {
      "epoch": 4.6135389712274995,
      "grad_norm": 0.5897017121315002,
      "learning_rate": 1.6166392295662193e-05,
      "loss": 0.1494,
      "step": 224200
    },
    {
      "epoch": 4.615596722003015,
      "grad_norm": 2.01296067237854,
      "learning_rate": 1.616021894806157e-05,
      "loss": 0.15,
      "step": 224300
    },
    {
      "epoch": 4.617654472778529,
      "grad_norm": 0.9882594347000122,
      "learning_rate": 1.6154045600460943e-05,
      "loss": 0.1457,
      "step": 224400
    },
    {
      "epoch": 4.619712223554044,
      "grad_norm": 1.8480855226516724,
      "learning_rate": 1.6147872252860316e-05,
      "loss": 0.1608,
      "step": 224500
    },
    {
      "epoch": 4.621769974329559,
      "grad_norm": 1.7162235975265503,
      "learning_rate": 1.6141698905259696e-05,
      "loss": 0.1741,
      "step": 224600
    },
    {
      "epoch": 4.623827725105074,
      "grad_norm": 3.91972279548645,
      "learning_rate": 1.613552555765907e-05,
      "loss": 0.1586,
      "step": 224700
    },
    {
      "epoch": 4.6258854758805885,
      "grad_norm": 3.650245428085327,
      "learning_rate": 1.6129352210058442e-05,
      "loss": 0.1684,
      "step": 224800
    },
    {
      "epoch": 4.627943226656104,
      "grad_norm": 3.826046943664551,
      "learning_rate": 1.6123178862457815e-05,
      "loss": 0.159,
      "step": 224900
    },
    {
      "epoch": 4.630000977431618,
      "grad_norm": 2.6455395221710205,
      "learning_rate": 1.6117005514857192e-05,
      "loss": 0.1595,
      "step": 225000
    },
    {
      "epoch": 4.6320587282071335,
      "grad_norm": 5.507946014404297,
      "learning_rate": 1.6110832167256565e-05,
      "loss": 0.1561,
      "step": 225100
    },
    {
      "epoch": 4.634116478982648,
      "grad_norm": 2.8958075046539307,
      "learning_rate": 1.6104720553131945e-05,
      "loss": 0.1625,
      "step": 225200
    },
    {
      "epoch": 4.636174229758163,
      "grad_norm": 1.0829230546951294,
      "learning_rate": 1.609854720553132e-05,
      "loss": 0.181,
      "step": 225300
    },
    {
      "epoch": 4.638231980533678,
      "grad_norm": 2.1302666664123535,
      "learning_rate": 1.6092373857930695e-05,
      "loss": 0.1872,
      "step": 225400
    },
    {
      "epoch": 4.640289731309193,
      "grad_norm": 0.5810479521751404,
      "learning_rate": 1.608620051033007e-05,
      "loss": 0.1384,
      "step": 225500
    },
    {
      "epoch": 4.642347482084707,
      "grad_norm": 3.2703070640563965,
      "learning_rate": 1.6080027162729445e-05,
      "loss": 0.1742,
      "step": 225600
    },
    {
      "epoch": 4.6444052328602226,
      "grad_norm": 4.72988748550415,
      "learning_rate": 1.6073853815128818e-05,
      "loss": 0.1769,
      "step": 225700
    },
    {
      "epoch": 4.646462983635737,
      "grad_norm": 1.4625163078308105,
      "learning_rate": 1.606768046752819e-05,
      "loss": 0.168,
      "step": 225800
    },
    {
      "epoch": 4.648520734411251,
      "grad_norm": 1.852950096130371,
      "learning_rate": 1.6061507119927568e-05,
      "loss": 0.145,
      "step": 225900
    },
    {
      "epoch": 4.650578485186767,
      "grad_norm": 7.1211419105529785,
      "learning_rate": 1.605533377232694e-05,
      "loss": 0.148,
      "step": 226000
    },
    {
      "epoch": 4.652636235962281,
      "grad_norm": 6.105647563934326,
      "learning_rate": 1.6049160424726314e-05,
      "loss": 0.1703,
      "step": 226100
    },
    {
      "epoch": 4.654693986737796,
      "grad_norm": 2.9068474769592285,
      "learning_rate": 1.6042987077125687e-05,
      "loss": 0.1689,
      "step": 226200
    },
    {
      "epoch": 4.656751737513311,
      "grad_norm": 1.3419742584228516,
      "learning_rate": 1.6036813729525064e-05,
      "loss": 0.1569,
      "step": 226300
    },
    {
      "epoch": 4.658809488288826,
      "grad_norm": 3.0345075130462646,
      "learning_rate": 1.603064038192444e-05,
      "loss": 0.1625,
      "step": 226400
    },
    {
      "epoch": 4.66086723906434,
      "grad_norm": 1.693929672241211,
      "learning_rate": 1.6024467034323813e-05,
      "loss": 0.1669,
      "step": 226500
    },
    {
      "epoch": 4.662924989839856,
      "grad_norm": 4.3205060958862305,
      "learning_rate": 1.601829368672319e-05,
      "loss": 0.1653,
      "step": 226600
    },
    {
      "epoch": 4.66498274061537,
      "grad_norm": 1.3599553108215332,
      "learning_rate": 1.6012120339122563e-05,
      "loss": 0.1624,
      "step": 226700
    },
    {
      "epoch": 4.667040491390885,
      "grad_norm": 3.8830881118774414,
      "learning_rate": 1.6005946991521936e-05,
      "loss": 0.1676,
      "step": 226800
    },
    {
      "epoch": 4.6690982421664,
      "grad_norm": 2.5571200847625732,
      "learning_rate": 1.599977364392131e-05,
      "loss": 0.1569,
      "step": 226900
    },
    {
      "epoch": 4.671155992941915,
      "grad_norm": 5.546660900115967,
      "learning_rate": 1.5993600296320686e-05,
      "loss": 0.155,
      "step": 227000
    },
    {
      "epoch": 4.6732137437174295,
      "grad_norm": 3.195136547088623,
      "learning_rate": 1.598742694872006e-05,
      "loss": 0.155,
      "step": 227100
    },
    {
      "epoch": 4.675271494492945,
      "grad_norm": 2.8372750282287598,
      "learning_rate": 1.5981315334595443e-05,
      "loss": 0.1675,
      "step": 227200
    },
    {
      "epoch": 4.677329245268459,
      "grad_norm": 3.2813711166381836,
      "learning_rate": 1.5975141986994816e-05,
      "loss": 0.1697,
      "step": 227300
    },
    {
      "epoch": 4.6793869960439745,
      "grad_norm": 3.1720292568206787,
      "learning_rate": 1.596896863939419e-05,
      "loss": 0.1739,
      "step": 227400
    },
    {
      "epoch": 4.681444746819489,
      "grad_norm": 2.6287336349487305,
      "learning_rate": 1.5962795291793566e-05,
      "loss": 0.1647,
      "step": 227500
    },
    {
      "epoch": 4.683502497595004,
      "grad_norm": 3.1212308406829834,
      "learning_rate": 1.595662194419294e-05,
      "loss": 0.1404,
      "step": 227600
    },
    {
      "epoch": 4.6855602483705185,
      "grad_norm": 2.109168291091919,
      "learning_rate": 1.5950448596592312e-05,
      "loss": 0.1618,
      "step": 227700
    },
    {
      "epoch": 4.687617999146033,
      "grad_norm": 2.3951549530029297,
      "learning_rate": 1.5944275248991685e-05,
      "loss": 0.1589,
      "step": 227800
    },
    {
      "epoch": 4.689675749921548,
      "grad_norm": 2.0611112117767334,
      "learning_rate": 1.593810190139106e-05,
      "loss": 0.1661,
      "step": 227900
    },
    {
      "epoch": 4.6917335006970635,
      "grad_norm": 5.397365093231201,
      "learning_rate": 1.5931928553790435e-05,
      "loss": 0.1793,
      "step": 228000
    },
    {
      "epoch": 4.693791251472578,
      "grad_norm": 2.210501194000244,
      "learning_rate": 1.5925755206189808e-05,
      "loss": 0.1646,
      "step": 228100
    },
    {
      "epoch": 4.695849002248092,
      "grad_norm": 3.7068400382995605,
      "learning_rate": 1.5919581858589188e-05,
      "loss": 0.1532,
      "step": 228200
    },
    {
      "epoch": 4.697906753023608,
      "grad_norm": 2.460974931716919,
      "learning_rate": 1.591340851098856e-05,
      "loss": 0.1295,
      "step": 228300
    },
    {
      "epoch": 4.699964503799122,
      "grad_norm": 5.532732963562012,
      "learning_rate": 1.5907235163387934e-05,
      "loss": 0.153,
      "step": 228400
    },
    {
      "epoch": 4.702022254574637,
      "grad_norm": 3.522089719772339,
      "learning_rate": 1.5901061815787307e-05,
      "loss": 0.1509,
      "step": 228500
    },
    {
      "epoch": 4.704080005350152,
      "grad_norm": 5.1017632484436035,
      "learning_rate": 1.5894888468186684e-05,
      "loss": 0.1476,
      "step": 228600
    },
    {
      "epoch": 4.706137756125667,
      "grad_norm": 2.090766191482544,
      "learning_rate": 1.5888715120586057e-05,
      "loss": 0.159,
      "step": 228700
    },
    {
      "epoch": 4.708195506901181,
      "grad_norm": 2.125314474105835,
      "learning_rate": 1.588254177298543e-05,
      "loss": 0.1804,
      "step": 228800
    },
    {
      "epoch": 4.710253257676697,
      "grad_norm": 3.256894111633301,
      "learning_rate": 1.5876368425384807e-05,
      "loss": 0.1527,
      "step": 228900
    },
    {
      "epoch": 4.712311008452211,
      "grad_norm": 2.5431036949157715,
      "learning_rate": 1.587019507778418e-05,
      "loss": 0.1558,
      "step": 229000
    },
    {
      "epoch": 4.714368759227726,
      "grad_norm": 2.9938106536865234,
      "learning_rate": 1.5864021730183553e-05,
      "loss": 0.16,
      "step": 229100
    },
    {
      "epoch": 4.716426510003241,
      "grad_norm": 2.939371109008789,
      "learning_rate": 1.585784838258293e-05,
      "loss": 0.1519,
      "step": 229200
    },
    {
      "epoch": 4.718484260778756,
      "grad_norm": 4.283596992492676,
      "learning_rate": 1.585173676845831e-05,
      "loss": 0.1753,
      "step": 229300
    },
    {
      "epoch": 4.7205420115542704,
      "grad_norm": 1.769505262374878,
      "learning_rate": 1.5845563420857683e-05,
      "loss": 0.1491,
      "step": 229400
    },
    {
      "epoch": 4.722599762329786,
      "grad_norm": 10.049619674682617,
      "learning_rate": 1.583939007325706e-05,
      "loss": 0.1633,
      "step": 229500
    },
    {
      "epoch": 4.7246575131053,
      "grad_norm": 5.229977607727051,
      "learning_rate": 1.5833216725656433e-05,
      "loss": 0.1688,
      "step": 229600
    },
    {
      "epoch": 4.726715263880815,
      "grad_norm": 0.9831101298332214,
      "learning_rate": 1.5827043378055806e-05,
      "loss": 0.1467,
      "step": 229700
    },
    {
      "epoch": 4.72877301465633,
      "grad_norm": 3.6560702323913574,
      "learning_rate": 1.5820870030455182e-05,
      "loss": 0.1612,
      "step": 229800
    },
    {
      "epoch": 4.730830765431845,
      "grad_norm": 0.9488540887832642,
      "learning_rate": 1.5814696682854555e-05,
      "loss": 0.1509,
      "step": 229900
    },
    {
      "epoch": 4.7328885162073595,
      "grad_norm": 2.3053386211395264,
      "learning_rate": 1.5808523335253932e-05,
      "loss": 0.1437,
      "step": 230000
    },
    {
      "epoch": 4.7328885162073595,
      "eval_accuracy": 0.8355397148676171,
      "eval_f1_contradiction": 0.84375,
      "eval_loss": 0.16184324026107788,
      "eval_runtime": 69.4107,
      "eval_samples_per_second": 56.591,
      "eval_steps_per_second": 7.074,
      "step": 230000
    },
    {
      "epoch": 4.734946266982874,
      "grad_norm": 2.67698335647583,
      "learning_rate": 1.5802349987653305e-05,
      "loss": 0.1671,
      "step": 230100
    },
    {
      "epoch": 4.737004017758389,
      "grad_norm": 3.4081413745880127,
      "learning_rate": 1.579617664005268e-05,
      "loss": 0.1604,
      "step": 230200
    },
    {
      "epoch": 4.7390617685339045,
      "grad_norm": 3.61434268951416,
      "learning_rate": 1.5790003292452055e-05,
      "loss": 0.1642,
      "step": 230300
    },
    {
      "epoch": 4.741119519309419,
      "grad_norm": 1.2119027376174927,
      "learning_rate": 1.5783829944851428e-05,
      "loss": 0.1666,
      "step": 230400
    },
    {
      "epoch": 4.743177270084933,
      "grad_norm": 3.4614744186401367,
      "learning_rate": 1.57776565972508e-05,
      "loss": 0.1785,
      "step": 230500
    },
    {
      "epoch": 4.745235020860449,
      "grad_norm": 3.1988799571990967,
      "learning_rate": 1.5771483249650178e-05,
      "loss": 0.1692,
      "step": 230600
    },
    {
      "epoch": 4.747292771635963,
      "grad_norm": 5.136847496032715,
      "learning_rate": 1.576530990204955e-05,
      "loss": 0.1629,
      "step": 230700
    },
    {
      "epoch": 4.749350522411478,
      "grad_norm": 4.124204158782959,
      "learning_rate": 1.5759136554448924e-05,
      "loss": 0.1601,
      "step": 230800
    },
    {
      "epoch": 4.751408273186993,
      "grad_norm": 1.8158961534500122,
      "learning_rate": 1.57529632068483e-05,
      "loss": 0.1555,
      "step": 230900
    },
    {
      "epoch": 4.753466023962508,
      "grad_norm": 4.45113468170166,
      "learning_rate": 1.5746789859247677e-05,
      "loss": 0.17,
      "step": 231000
    },
    {
      "epoch": 4.755523774738022,
      "grad_norm": 2.9240574836730957,
      "learning_rate": 1.574061651164705e-05,
      "loss": 0.1636,
      "step": 231100
    },
    {
      "epoch": 4.757581525513538,
      "grad_norm": 5.211057186126709,
      "learning_rate": 1.5734443164046423e-05,
      "loss": 0.1713,
      "step": 231200
    },
    {
      "epoch": 4.759639276289052,
      "grad_norm": 3.8711469173431396,
      "learning_rate": 1.5728331549921804e-05,
      "loss": 0.1427,
      "step": 231300
    },
    {
      "epoch": 4.761697027064567,
      "grad_norm": 1.713956594467163,
      "learning_rate": 1.572215820232118e-05,
      "loss": 0.1824,
      "step": 231400
    },
    {
      "epoch": 4.763754777840082,
      "grad_norm": 0.5128964781761169,
      "learning_rate": 1.5715984854720553e-05,
      "loss": 0.1472,
      "step": 231500
    },
    {
      "epoch": 4.765812528615597,
      "grad_norm": 0.7211188673973083,
      "learning_rate": 1.5709811507119927e-05,
      "loss": 0.1658,
      "step": 231600
    },
    {
      "epoch": 4.767870279391111,
      "grad_norm": 0.7621785998344421,
      "learning_rate": 1.57036381595193e-05,
      "loss": 0.1516,
      "step": 231700
    },
    {
      "epoch": 4.769928030166627,
      "grad_norm": 2.3052501678466797,
      "learning_rate": 1.569746481191868e-05,
      "loss": 0.1814,
      "step": 231800
    },
    {
      "epoch": 4.771985780942141,
      "grad_norm": 6.950222015380859,
      "learning_rate": 1.5691291464318053e-05,
      "loss": 0.1639,
      "step": 231900
    },
    {
      "epoch": 4.774043531717656,
      "grad_norm": 1.3386180400848389,
      "learning_rate": 1.5685118116717426e-05,
      "loss": 0.1796,
      "step": 232000
    },
    {
      "epoch": 4.776101282493171,
      "grad_norm": 4.4138875007629395,
      "learning_rate": 1.56789447691168e-05,
      "loss": 0.1621,
      "step": 232100
    },
    {
      "epoch": 4.778159033268686,
      "grad_norm": 2.556277275085449,
      "learning_rate": 1.5672771421516176e-05,
      "loss": 0.147,
      "step": 232200
    },
    {
      "epoch": 4.7802167840442005,
      "grad_norm": 0.2395734339952469,
      "learning_rate": 1.566659807391555e-05,
      "loss": 0.1648,
      "step": 232300
    },
    {
      "epoch": 4.782274534819715,
      "grad_norm": 1.519643783569336,
      "learning_rate": 1.5660424726314922e-05,
      "loss": 0.1605,
      "step": 232400
    },
    {
      "epoch": 4.78433228559523,
      "grad_norm": 4.571925640106201,
      "learning_rate": 1.56542513787143e-05,
      "loss": 0.1467,
      "step": 232500
    },
    {
      "epoch": 4.7863900363707454,
      "grad_norm": 3.545933723449707,
      "learning_rate": 1.564807803111367e-05,
      "loss": 0.1536,
      "step": 232600
    },
    {
      "epoch": 4.78844778714626,
      "grad_norm": 2.351282835006714,
      "learning_rate": 1.5641904683513045e-05,
      "loss": 0.1722,
      "step": 232700
    },
    {
      "epoch": 4.790505537921774,
      "grad_norm": 3.5572593212127686,
      "learning_rate": 1.563573133591242e-05,
      "loss": 0.1551,
      "step": 232800
    },
    {
      "epoch": 4.7925632886972895,
      "grad_norm": 7.648490905761719,
      "learning_rate": 1.5629557988311798e-05,
      "loss": 0.1546,
      "step": 232900
    },
    {
      "epoch": 4.794621039472804,
      "grad_norm": 3.369828939437866,
      "learning_rate": 1.562338464071117e-05,
      "loss": 0.1788,
      "step": 233000
    },
    {
      "epoch": 4.796678790248319,
      "grad_norm": 3.643683671951294,
      "learning_rate": 1.5617211293110544e-05,
      "loss": 0.1494,
      "step": 233100
    },
    {
      "epoch": 4.798736541023834,
      "grad_norm": 2.8695473670959473,
      "learning_rate": 1.5611037945509917e-05,
      "loss": 0.1484,
      "step": 233200
    },
    {
      "epoch": 4.800794291799349,
      "grad_norm": 2.5562031269073486,
      "learning_rate": 1.5604926331385298e-05,
      "loss": 0.1846,
      "step": 233300
    },
    {
      "epoch": 4.802852042574863,
      "grad_norm": 3.1607494354248047,
      "learning_rate": 1.5598752983784674e-05,
      "loss": 0.1616,
      "step": 233400
    },
    {
      "epoch": 4.804909793350379,
      "grad_norm": 1.3197795152664185,
      "learning_rate": 1.5592579636184047e-05,
      "loss": 0.1564,
      "step": 233500
    },
    {
      "epoch": 4.806967544125893,
      "grad_norm": 2.505521774291992,
      "learning_rate": 1.5586406288583424e-05,
      "loss": 0.1512,
      "step": 233600
    },
    {
      "epoch": 4.809025294901408,
      "grad_norm": 3.219446897506714,
      "learning_rate": 1.5580232940982797e-05,
      "loss": 0.1596,
      "step": 233700
    },
    {
      "epoch": 4.811083045676923,
      "grad_norm": 3.7932851314544678,
      "learning_rate": 1.5574059593382174e-05,
      "loss": 0.1568,
      "step": 233800
    },
    {
      "epoch": 4.813140796452438,
      "grad_norm": 3.460306406021118,
      "learning_rate": 1.5567886245781547e-05,
      "loss": 0.1636,
      "step": 233900
    },
    {
      "epoch": 4.815198547227952,
      "grad_norm": 1.7352418899536133,
      "learning_rate": 1.556171289818092e-05,
      "loss": 0.1716,
      "step": 234000
    },
    {
      "epoch": 4.817256298003468,
      "grad_norm": 2.2832891941070557,
      "learning_rate": 1.5555539550580296e-05,
      "loss": 0.1433,
      "step": 234100
    },
    {
      "epoch": 4.819314048778982,
      "grad_norm": 2.483027935028076,
      "learning_rate": 1.554936620297967e-05,
      "loss": 0.1664,
      "step": 234200
    },
    {
      "epoch": 4.8213717995544965,
      "grad_norm": 6.921822547912598,
      "learning_rate": 1.5543192855379043e-05,
      "loss": 0.1535,
      "step": 234300
    },
    {
      "epoch": 4.823429550330012,
      "grad_norm": 6.0557403564453125,
      "learning_rate": 1.5537019507778416e-05,
      "loss": 0.1751,
      "step": 234400
    },
    {
      "epoch": 4.825487301105527,
      "grad_norm": 3.0708463191986084,
      "learning_rate": 1.5530846160177792e-05,
      "loss": 0.1512,
      "step": 234500
    },
    {
      "epoch": 4.827545051881041,
      "grad_norm": 1.041448950767517,
      "learning_rate": 1.552467281257717e-05,
      "loss": 0.1627,
      "step": 234600
    },
    {
      "epoch": 4.829602802656556,
      "grad_norm": 4.071575164794922,
      "learning_rate": 1.5518499464976542e-05,
      "loss": 0.1616,
      "step": 234700
    },
    {
      "epoch": 4.831660553432071,
      "grad_norm": 3.9323837757110596,
      "learning_rate": 1.5512326117375915e-05,
      "loss": 0.1558,
      "step": 234800
    },
    {
      "epoch": 4.8337183042075855,
      "grad_norm": 3.005239963531494,
      "learning_rate": 1.5506152769775292e-05,
      "loss": 0.1719,
      "step": 234900
    },
    {
      "epoch": 4.835776054983101,
      "grad_norm": 4.920050621032715,
      "learning_rate": 1.5499979422174665e-05,
      "loss": 0.1513,
      "step": 235000
    },
    {
      "epoch": 4.837833805758615,
      "grad_norm": 4.593583106994629,
      "learning_rate": 1.5493806074574038e-05,
      "loss": 0.1435,
      "step": 235100
    },
    {
      "epoch": 4.8398915565341305,
      "grad_norm": 0.787757933139801,
      "learning_rate": 1.5487632726973415e-05,
      "loss": 0.1505,
      "step": 235200
    },
    {
      "epoch": 4.841949307309645,
      "grad_norm": 0.4879056513309479,
      "learning_rate": 1.5481459379372788e-05,
      "loss": 0.1699,
      "step": 235300
    },
    {
      "epoch": 4.84400705808516,
      "grad_norm": 5.174548625946045,
      "learning_rate": 1.547534776524817e-05,
      "loss": 0.1673,
      "step": 235400
    },
    {
      "epoch": 4.846064808860675,
      "grad_norm": 2.7443671226501465,
      "learning_rate": 1.5469174417647545e-05,
      "loss": 0.1656,
      "step": 235500
    },
    {
      "epoch": 4.84812255963619,
      "grad_norm": 0.6126723885536194,
      "learning_rate": 1.5463001070046918e-05,
      "loss": 0.1418,
      "step": 235600
    },
    {
      "epoch": 4.850180310411704,
      "grad_norm": 3.3705217838287354,
      "learning_rate": 1.545682772244629e-05,
      "loss": 0.1707,
      "step": 235700
    },
    {
      "epoch": 4.85223806118722,
      "grad_norm": 3.2490856647491455,
      "learning_rate": 1.5450654374845668e-05,
      "loss": 0.1797,
      "step": 235800
    },
    {
      "epoch": 4.854295811962734,
      "grad_norm": 0.6705502867698669,
      "learning_rate": 1.544448102724504e-05,
      "loss": 0.1496,
      "step": 235900
    },
    {
      "epoch": 4.856353562738249,
      "grad_norm": 4.8408355712890625,
      "learning_rate": 1.5438307679644414e-05,
      "loss": 0.1521,
      "step": 236000
    },
    {
      "epoch": 4.858411313513764,
      "grad_norm": 2.566718578338623,
      "learning_rate": 1.543213433204379e-05,
      "loss": 0.1533,
      "step": 236100
    },
    {
      "epoch": 4.860469064289279,
      "grad_norm": 0.3923313021659851,
      "learning_rate": 1.5425960984443164e-05,
      "loss": 0.1559,
      "step": 236200
    },
    {
      "epoch": 4.862526815064793,
      "grad_norm": 1.6704024076461792,
      "learning_rate": 1.5419787636842537e-05,
      "loss": 0.149,
      "step": 236300
    },
    {
      "epoch": 4.864584565840309,
      "grad_norm": 1.8673179149627686,
      "learning_rate": 1.5413614289241913e-05,
      "loss": 0.1442,
      "step": 236400
    },
    {
      "epoch": 4.866642316615823,
      "grad_norm": 0.7213481664657593,
      "learning_rate": 1.540744094164129e-05,
      "loss": 0.1441,
      "step": 236500
    },
    {
      "epoch": 4.868700067391337,
      "grad_norm": 2.893873691558838,
      "learning_rate": 1.5401267594040663e-05,
      "loss": 0.1658,
      "step": 236600
    },
    {
      "epoch": 4.870757818166853,
      "grad_norm": 4.186720371246338,
      "learning_rate": 1.5395094246440036e-05,
      "loss": 0.1568,
      "step": 236700
    },
    {
      "epoch": 4.872815568942368,
      "grad_norm": 1.4197865724563599,
      "learning_rate": 1.5388920898839413e-05,
      "loss": 0.156,
      "step": 236800
    },
    {
      "epoch": 4.874873319717882,
      "grad_norm": 7.870905876159668,
      "learning_rate": 1.5382747551238786e-05,
      "loss": 0.1574,
      "step": 236900
    },
    {
      "epoch": 4.876931070493397,
      "grad_norm": 4.363961219787598,
      "learning_rate": 1.537657420363816e-05,
      "loss": 0.1613,
      "step": 237000
    },
    {
      "epoch": 4.878988821268912,
      "grad_norm": 3.2152414321899414,
      "learning_rate": 1.5370400856037532e-05,
      "loss": 0.1468,
      "step": 237100
    },
    {
      "epoch": 4.8810465720444265,
      "grad_norm": 1.8843541145324707,
      "learning_rate": 1.536422750843691e-05,
      "loss": 0.154,
      "step": 237200
    },
    {
      "epoch": 4.883104322819942,
      "grad_norm": 4.165694236755371,
      "learning_rate": 1.5358054160836285e-05,
      "loss": 0.1621,
      "step": 237300
    },
    {
      "epoch": 4.885162073595456,
      "grad_norm": 1.6534054279327393,
      "learning_rate": 1.5351942546711666e-05,
      "loss": 0.1649,
      "step": 237400
    },
    {
      "epoch": 4.8872198243709715,
      "grad_norm": 3.800227165222168,
      "learning_rate": 1.534576919911104e-05,
      "loss": 0.168,
      "step": 237500
    },
    {
      "epoch": 4.889277575146486,
      "grad_norm": 2.0483453273773193,
      "learning_rate": 1.5339595851510412e-05,
      "loss": 0.1451,
      "step": 237600
    },
    {
      "epoch": 4.891335325922001,
      "grad_norm": 1.2560323476791382,
      "learning_rate": 1.533342250390979e-05,
      "loss": 0.1505,
      "step": 237700
    },
    {
      "epoch": 4.8933930766975156,
      "grad_norm": 5.1592254638671875,
      "learning_rate": 1.532724915630916e-05,
      "loss": 0.1715,
      "step": 237800
    },
    {
      "epoch": 4.895450827473031,
      "grad_norm": 0.3458094894886017,
      "learning_rate": 1.5321075808708535e-05,
      "loss": 0.1454,
      "step": 237900
    },
    {
      "epoch": 4.897508578248545,
      "grad_norm": 2.6572868824005127,
      "learning_rate": 1.5314902461107908e-05,
      "loss": 0.179,
      "step": 238000
    },
    {
      "epoch": 4.8995663290240605,
      "grad_norm": 5.317713737487793,
      "learning_rate": 1.5308729113507284e-05,
      "loss": 0.1711,
      "step": 238100
    },
    {
      "epoch": 4.901624079799575,
      "grad_norm": 2.8696751594543457,
      "learning_rate": 1.530255576590666e-05,
      "loss": 0.1744,
      "step": 238200
    },
    {
      "epoch": 4.90368183057509,
      "grad_norm": 1.598419427871704,
      "learning_rate": 1.5296382418306034e-05,
      "loss": 0.1525,
      "step": 238300
    },
    {
      "epoch": 4.905739581350605,
      "grad_norm": 2.0575294494628906,
      "learning_rate": 1.529020907070541e-05,
      "loss": 0.174,
      "step": 238400
    },
    {
      "epoch": 4.90779733212612,
      "grad_norm": 4.233075141906738,
      "learning_rate": 1.5284035723104784e-05,
      "loss": 0.1738,
      "step": 238500
    },
    {
      "epoch": 4.909855082901634,
      "grad_norm": 3.6067895889282227,
      "learning_rate": 1.5277862375504157e-05,
      "loss": 0.1568,
      "step": 238600
    },
    {
      "epoch": 4.91191283367715,
      "grad_norm": 2.0226497650146484,
      "learning_rate": 1.527168902790353e-05,
      "loss": 0.1354,
      "step": 238700
    },
    {
      "epoch": 4.913970584452664,
      "grad_norm": 5.791934013366699,
      "learning_rate": 1.5265515680302907e-05,
      "loss": 0.1796,
      "step": 238800
    },
    {
      "epoch": 4.916028335228178,
      "grad_norm": 3.3447365760803223,
      "learning_rate": 1.525934233270228e-05,
      "loss": 0.1766,
      "step": 238900
    },
    {
      "epoch": 4.918086086003694,
      "grad_norm": 8.52668285369873,
      "learning_rate": 1.5253168985101655e-05,
      "loss": 0.1754,
      "step": 239000
    },
    {
      "epoch": 4.920143836779209,
      "grad_norm": 4.386167049407959,
      "learning_rate": 1.5246995637501028e-05,
      "loss": 0.1521,
      "step": 239100
    },
    {
      "epoch": 4.922201587554723,
      "grad_norm": 0.5425662994384766,
      "learning_rate": 1.5240822289900404e-05,
      "loss": 0.1509,
      "step": 239200
    },
    {
      "epoch": 4.924259338330238,
      "grad_norm": 5.068217754364014,
      "learning_rate": 1.5234648942299777e-05,
      "loss": 0.165,
      "step": 239300
    },
    {
      "epoch": 4.926317089105753,
      "grad_norm": 1.5277822017669678,
      "learning_rate": 1.522853732817516e-05,
      "loss": 0.1604,
      "step": 239400
    },
    {
      "epoch": 4.9283748398812675,
      "grad_norm": 2.5423219203948975,
      "learning_rate": 1.5222363980574533e-05,
      "loss": 0.1515,
      "step": 239500
    },
    {
      "epoch": 4.930432590656783,
      "grad_norm": 1.561698079109192,
      "learning_rate": 1.5216190632973906e-05,
      "loss": 0.1476,
      "step": 239600
    },
    {
      "epoch": 4.932490341432297,
      "grad_norm": 2.9065358638763428,
      "learning_rate": 1.5210017285373284e-05,
      "loss": 0.1537,
      "step": 239700
    },
    {
      "epoch": 4.934548092207812,
      "grad_norm": 4.137548446655273,
      "learning_rate": 1.5203843937772657e-05,
      "loss": 0.1689,
      "step": 239800
    },
    {
      "epoch": 4.936605842983327,
      "grad_norm": 4.623397350311279,
      "learning_rate": 1.519767059017203e-05,
      "loss": 0.1805,
      "step": 239900
    },
    {
      "epoch": 4.938663593758842,
      "grad_norm": 5.9665093421936035,
      "learning_rate": 1.5191497242571403e-05,
      "loss": 0.1574,
      "step": 240000
    },
    {
      "epoch": 4.938663593758842,
      "eval_accuracy": 0.8378309572301426,
      "eval_f1_contradiction": 0.8459770114942529,
      "eval_loss": 0.1581602543592453,
      "eval_runtime": 70.1501,
      "eval_samples_per_second": 55.994,
      "eval_steps_per_second": 6.999,
      "step": 240000
    },
    {
      "epoch": 4.9407213445343565,
      "grad_norm": 5.496894359588623,
      "learning_rate": 1.518532389497078e-05,
      "loss": 0.1531,
      "step": 240100
    },
    {
      "epoch": 4.942779095309872,
      "grad_norm": 0.35649117827415466,
      "learning_rate": 1.5179150547370155e-05,
      "loss": 0.163,
      "step": 240200
    },
    {
      "epoch": 4.944836846085386,
      "grad_norm": 4.194265842437744,
      "learning_rate": 1.5172977199769528e-05,
      "loss": 0.1741,
      "step": 240300
    },
    {
      "epoch": 4.9468945968609015,
      "grad_norm": 3.670860528945923,
      "learning_rate": 1.5166803852168905e-05,
      "loss": 0.1623,
      "step": 240400
    },
    {
      "epoch": 4.948952347636416,
      "grad_norm": 3.5196263790130615,
      "learning_rate": 1.5160630504568278e-05,
      "loss": 0.1724,
      "step": 240500
    },
    {
      "epoch": 4.951010098411931,
      "grad_norm": 0.6757171750068665,
      "learning_rate": 1.515445715696765e-05,
      "loss": 0.169,
      "step": 240600
    },
    {
      "epoch": 4.953067849187446,
      "grad_norm": 1.5392568111419678,
      "learning_rate": 1.5148283809367026e-05,
      "loss": 0.1511,
      "step": 240700
    },
    {
      "epoch": 4.955125599962961,
      "grad_norm": 3.5867838859558105,
      "learning_rate": 1.5142110461766402e-05,
      "loss": 0.1565,
      "step": 240800
    },
    {
      "epoch": 4.957183350738475,
      "grad_norm": 5.962772369384766,
      "learning_rate": 1.5135937114165775e-05,
      "loss": 0.1543,
      "step": 240900
    },
    {
      "epoch": 4.959241101513991,
      "grad_norm": 5.780513286590576,
      "learning_rate": 1.5129763766565148e-05,
      "loss": 0.178,
      "step": 241000
    },
    {
      "epoch": 4.961298852289505,
      "grad_norm": 2.6117804050445557,
      "learning_rate": 1.5123590418964525e-05,
      "loss": 0.1606,
      "step": 241100
    },
    {
      "epoch": 4.963356603065019,
      "grad_norm": 6.6920647621154785,
      "learning_rate": 1.51174170713639e-05,
      "loss": 0.164,
      "step": 241200
    },
    {
      "epoch": 4.965414353840535,
      "grad_norm": 1.645462155342102,
      "learning_rate": 1.5111243723763273e-05,
      "loss": 0.1615,
      "step": 241300
    },
    {
      "epoch": 4.967472104616049,
      "grad_norm": 1.4550307989120483,
      "learning_rate": 1.5105070376162646e-05,
      "loss": 0.1596,
      "step": 241400
    },
    {
      "epoch": 4.969529855391564,
      "grad_norm": 3.1982710361480713,
      "learning_rate": 1.5098958762038028e-05,
      "loss": 0.15,
      "step": 241500
    },
    {
      "epoch": 4.971587606167079,
      "grad_norm": 3.922826051712036,
      "learning_rate": 1.5092785414437401e-05,
      "loss": 0.1645,
      "step": 241600
    },
    {
      "epoch": 4.973645356942594,
      "grad_norm": 3.41636323928833,
      "learning_rate": 1.5086612066836778e-05,
      "loss": 0.1434,
      "step": 241700
    },
    {
      "epoch": 4.975703107718108,
      "grad_norm": 4.430042743682861,
      "learning_rate": 1.5080438719236151e-05,
      "loss": 0.1712,
      "step": 241800
    },
    {
      "epoch": 4.977760858493624,
      "grad_norm": 2.082089424133301,
      "learning_rate": 1.5074265371635524e-05,
      "loss": 0.1632,
      "step": 241900
    },
    {
      "epoch": 4.979818609269138,
      "grad_norm": 4.149839401245117,
      "learning_rate": 1.5068092024034902e-05,
      "loss": 0.1519,
      "step": 242000
    },
    {
      "epoch": 4.981876360044653,
      "grad_norm": 2.5043132305145264,
      "learning_rate": 1.5061918676434276e-05,
      "loss": 0.1559,
      "step": 242100
    },
    {
      "epoch": 4.983934110820168,
      "grad_norm": 3.008662223815918,
      "learning_rate": 1.5055745328833649e-05,
      "loss": 0.1607,
      "step": 242200
    },
    {
      "epoch": 4.985991861595683,
      "grad_norm": 5.073230266571045,
      "learning_rate": 1.5049571981233022e-05,
      "loss": 0.1644,
      "step": 242300
    },
    {
      "epoch": 4.9880496123711975,
      "grad_norm": 2.3921916484832764,
      "learning_rate": 1.5043398633632398e-05,
      "loss": 0.1676,
      "step": 242400
    },
    {
      "epoch": 4.990107363146713,
      "grad_norm": 0.44136783480644226,
      "learning_rate": 1.5037225286031773e-05,
      "loss": 0.1416,
      "step": 242500
    },
    {
      "epoch": 4.992165113922227,
      "grad_norm": 4.7793169021606445,
      "learning_rate": 1.5031051938431146e-05,
      "loss": 0.1858,
      "step": 242600
    },
    {
      "epoch": 4.9942228646977425,
      "grad_norm": 5.804821014404297,
      "learning_rate": 1.5024878590830523e-05,
      "loss": 0.154,
      "step": 242700
    },
    {
      "epoch": 4.996280615473257,
      "grad_norm": 1.9589145183563232,
      "learning_rate": 1.5018705243229896e-05,
      "loss": 0.152,
      "step": 242800
    },
    {
      "epoch": 4.998338366248772,
      "grad_norm": 2.178692579269409,
      "learning_rate": 1.501253189562927e-05,
      "loss": 0.1833,
      "step": 242900
    },
    {
      "epoch": 5.0004115501551025,
      "grad_norm": 2.7817814350128174,
      "learning_rate": 1.5006358548028644e-05,
      "loss": 0.1607,
      "step": 243000
    },
    {
      "epoch": 5.002469300930618,
      "grad_norm": 9.383370399475098,
      "learning_rate": 1.500018520042802e-05,
      "loss": 0.1487,
      "step": 243100
    },
    {
      "epoch": 5.004527051706132,
      "grad_norm": 4.036697864532471,
      "learning_rate": 1.4994011852827394e-05,
      "loss": 0.1618,
      "step": 243200
    },
    {
      "epoch": 5.0065848024816475,
      "grad_norm": 3.4212164878845215,
      "learning_rate": 1.4987838505226767e-05,
      "loss": 0.164,
      "step": 243300
    },
    {
      "epoch": 5.008642553257162,
      "grad_norm": 4.445551872253418,
      "learning_rate": 1.4981665157626143e-05,
      "loss": 0.1481,
      "step": 243400
    },
    {
      "epoch": 5.010700304032677,
      "grad_norm": 1.2403085231781006,
      "learning_rate": 1.4975553543501524e-05,
      "loss": 0.181,
      "step": 243500
    },
    {
      "epoch": 5.012758054808192,
      "grad_norm": 2.660292863845825,
      "learning_rate": 1.4969380195900897e-05,
      "loss": 0.1572,
      "step": 243600
    },
    {
      "epoch": 5.014815805583707,
      "grad_norm": 1.8885315656661987,
      "learning_rate": 1.4963206848300272e-05,
      "loss": 0.1672,
      "step": 243700
    },
    {
      "epoch": 5.016873556359221,
      "grad_norm": 3.9953701496124268,
      "learning_rate": 1.4957033500699647e-05,
      "loss": 0.159,
      "step": 243800
    },
    {
      "epoch": 5.018931307134737,
      "grad_norm": 2.7068281173706055,
      "learning_rate": 1.4950860153099022e-05,
      "loss": 0.1638,
      "step": 243900
    },
    {
      "epoch": 5.020989057910251,
      "grad_norm": 0.6530325412750244,
      "learning_rate": 1.4944686805498395e-05,
      "loss": 0.1589,
      "step": 244000
    },
    {
      "epoch": 5.023046808685766,
      "grad_norm": 3.300182342529297,
      "learning_rate": 1.493851345789777e-05,
      "loss": 0.1426,
      "step": 244100
    },
    {
      "epoch": 5.025104559461281,
      "grad_norm": 9.221161842346191,
      "learning_rate": 1.4932340110297143e-05,
      "loss": 0.1376,
      "step": 244200
    },
    {
      "epoch": 5.027162310236796,
      "grad_norm": 1.3601034879684448,
      "learning_rate": 1.492616676269652e-05,
      "loss": 0.142,
      "step": 244300
    },
    {
      "epoch": 5.02922006101231,
      "grad_norm": 3.6811726093292236,
      "learning_rate": 1.4919993415095894e-05,
      "loss": 0.1558,
      "step": 244400
    },
    {
      "epoch": 5.031277811787826,
      "grad_norm": 3.2739157676696777,
      "learning_rate": 1.4913820067495267e-05,
      "loss": 0.1518,
      "step": 244500
    },
    {
      "epoch": 5.03333556256334,
      "grad_norm": 7.267519474029541,
      "learning_rate": 1.4907646719894642e-05,
      "loss": 0.1465,
      "step": 244600
    },
    {
      "epoch": 5.035393313338855,
      "grad_norm": 1.012107253074646,
      "learning_rate": 1.4901473372294015e-05,
      "loss": 0.1516,
      "step": 244700
    },
    {
      "epoch": 5.03745106411437,
      "grad_norm": 3.7241387367248535,
      "learning_rate": 1.4895300024693392e-05,
      "loss": 0.1348,
      "step": 244800
    },
    {
      "epoch": 5.039508814889885,
      "grad_norm": 3.9437758922576904,
      "learning_rate": 1.4889126677092765e-05,
      "loss": 0.1739,
      "step": 244900
    },
    {
      "epoch": 5.041566565665399,
      "grad_norm": 2.890174388885498,
      "learning_rate": 1.488295332949214e-05,
      "loss": 0.1573,
      "step": 245000
    },
    {
      "epoch": 5.043624316440915,
      "grad_norm": 4.683450698852539,
      "learning_rate": 1.4876779981891513e-05,
      "loss": 0.1543,
      "step": 245100
    },
    {
      "epoch": 5.045682067216429,
      "grad_norm": 5.410669326782227,
      "learning_rate": 1.487060663429089e-05,
      "loss": 0.1467,
      "step": 245200
    },
    {
      "epoch": 5.0477398179919435,
      "grad_norm": 2.076792001724243,
      "learning_rate": 1.4864433286690263e-05,
      "loss": 0.1397,
      "step": 245300
    },
    {
      "epoch": 5.049797568767459,
      "grad_norm": 2.79984450340271,
      "learning_rate": 1.4858259939089637e-05,
      "loss": 0.1655,
      "step": 245400
    },
    {
      "epoch": 5.051855319542973,
      "grad_norm": 3.8998305797576904,
      "learning_rate": 1.4852086591489012e-05,
      "loss": 0.1486,
      "step": 245500
    },
    {
      "epoch": 5.0539130703184885,
      "grad_norm": 0.6675061583518982,
      "learning_rate": 1.4845974977364393e-05,
      "loss": 0.1431,
      "step": 245600
    },
    {
      "epoch": 5.055970821094003,
      "grad_norm": 5.590930461883545,
      "learning_rate": 1.4839801629763768e-05,
      "loss": 0.1519,
      "step": 245700
    },
    {
      "epoch": 5.058028571869518,
      "grad_norm": 1.3790489435195923,
      "learning_rate": 1.483362828216314e-05,
      "loss": 0.1776,
      "step": 245800
    },
    {
      "epoch": 5.0600863226450326,
      "grad_norm": 1.6285961866378784,
      "learning_rate": 1.4827454934562516e-05,
      "loss": 0.1744,
      "step": 245900
    },
    {
      "epoch": 5.062144073420548,
      "grad_norm": 2.605295181274414,
      "learning_rate": 1.4821281586961889e-05,
      "loss": 0.139,
      "step": 246000
    },
    {
      "epoch": 5.064201824196062,
      "grad_norm": 2.53623366355896,
      "learning_rate": 1.4815108239361265e-05,
      "loss": 0.1269,
      "step": 246100
    },
    {
      "epoch": 5.0662595749715775,
      "grad_norm": 3.6353707313537598,
      "learning_rate": 1.480893489176064e-05,
      "loss": 0.1369,
      "step": 246200
    },
    {
      "epoch": 5.068317325747092,
      "grad_norm": 3.861454486846924,
      "learning_rate": 1.4802761544160013e-05,
      "loss": 0.1338,
      "step": 246300
    },
    {
      "epoch": 5.070375076522607,
      "grad_norm": 5.256803512573242,
      "learning_rate": 1.4796588196559388e-05,
      "loss": 0.1722,
      "step": 246400
    },
    {
      "epoch": 5.072432827298122,
      "grad_norm": 4.354219436645508,
      "learning_rate": 1.4790414848958763e-05,
      "loss": 0.1657,
      "step": 246500
    },
    {
      "epoch": 5.074490578073637,
      "grad_norm": 2.892364025115967,
      "learning_rate": 1.4784241501358138e-05,
      "loss": 0.1313,
      "step": 246600
    },
    {
      "epoch": 5.076548328849151,
      "grad_norm": 2.571157455444336,
      "learning_rate": 1.4778068153757511e-05,
      "loss": 0.1542,
      "step": 246700
    },
    {
      "epoch": 5.078606079624667,
      "grad_norm": 1.511016607284546,
      "learning_rate": 1.4771894806156886e-05,
      "loss": 0.1689,
      "step": 246800
    },
    {
      "epoch": 5.080663830400181,
      "grad_norm": 6.433999061584473,
      "learning_rate": 1.4765721458556259e-05,
      "loss": 0.1463,
      "step": 246900
    },
    {
      "epoch": 5.082721581175696,
      "grad_norm": 6.226926326751709,
      "learning_rate": 1.4759548110955635e-05,
      "loss": 0.1399,
      "step": 247000
    },
    {
      "epoch": 5.084779331951211,
      "grad_norm": 3.508341073989868,
      "learning_rate": 1.475337476335501e-05,
      "loss": 0.1148,
      "step": 247100
    },
    {
      "epoch": 5.086837082726726,
      "grad_norm": 4.422985553741455,
      "learning_rate": 1.4747201415754383e-05,
      "loss": 0.1673,
      "step": 247200
    },
    {
      "epoch": 5.08889483350224,
      "grad_norm": 8.4369535446167,
      "learning_rate": 1.4741028068153758e-05,
      "loss": 0.1385,
      "step": 247300
    },
    {
      "epoch": 5.090952584277755,
      "grad_norm": 2.0434606075286865,
      "learning_rate": 1.4734854720553131e-05,
      "loss": 0.1543,
      "step": 247400
    },
    {
      "epoch": 5.09301033505327,
      "grad_norm": 2.9782257080078125,
      "learning_rate": 1.4728681372952508e-05,
      "loss": 0.1571,
      "step": 247500
    },
    {
      "epoch": 5.0950680858287845,
      "grad_norm": 5.183617115020752,
      "learning_rate": 1.4722569758827887e-05,
      "loss": 0.1553,
      "step": 247600
    },
    {
      "epoch": 5.0971258366043,
      "grad_norm": 2.2070679664611816,
      "learning_rate": 1.4716396411227262e-05,
      "loss": 0.1621,
      "step": 247700
    },
    {
      "epoch": 5.099183587379814,
      "grad_norm": 0.32893499732017517,
      "learning_rate": 1.4710223063626635e-05,
      "loss": 0.1396,
      "step": 247800
    },
    {
      "epoch": 5.101241338155329,
      "grad_norm": 2.024322986602783,
      "learning_rate": 1.4704049716026011e-05,
      "loss": 0.1615,
      "step": 247900
    },
    {
      "epoch": 5.103299088930844,
      "grad_norm": 7.368779182434082,
      "learning_rate": 1.4697876368425386e-05,
      "loss": 0.1565,
      "step": 248000
    },
    {
      "epoch": 5.105356839706359,
      "grad_norm": 3.658688545227051,
      "learning_rate": 1.469170302082476e-05,
      "loss": 0.1771,
      "step": 248100
    },
    {
      "epoch": 5.1074145904818735,
      "grad_norm": 3.2602503299713135,
      "learning_rate": 1.4685529673224134e-05,
      "loss": 0.1426,
      "step": 248200
    },
    {
      "epoch": 5.109472341257389,
      "grad_norm": 0.8660656213760376,
      "learning_rate": 1.4679356325623509e-05,
      "loss": 0.1415,
      "step": 248300
    },
    {
      "epoch": 5.111530092032903,
      "grad_norm": 3.757689952850342,
      "learning_rate": 1.4673182978022884e-05,
      "loss": 0.1579,
      "step": 248400
    },
    {
      "epoch": 5.1135878428084185,
      "grad_norm": 1.8851146697998047,
      "learning_rate": 1.4667009630422257e-05,
      "loss": 0.138,
      "step": 248500
    },
    {
      "epoch": 5.115645593583933,
      "grad_norm": 1.9406331777572632,
      "learning_rate": 1.4660836282821632e-05,
      "loss": 0.1435,
      "step": 248600
    },
    {
      "epoch": 5.117703344359448,
      "grad_norm": 2.5897057056427,
      "learning_rate": 1.4654662935221005e-05,
      "loss": 0.1472,
      "step": 248700
    },
    {
      "epoch": 5.119761095134963,
      "grad_norm": 2.772484540939331,
      "learning_rate": 1.4648489587620381e-05,
      "loss": 0.1575,
      "step": 248800
    },
    {
      "epoch": 5.121818845910478,
      "grad_norm": 4.90939998626709,
      "learning_rate": 1.4642316240019756e-05,
      "loss": 0.1298,
      "step": 248900
    },
    {
      "epoch": 5.123876596685992,
      "grad_norm": 0.5810935497283936,
      "learning_rate": 1.463614289241913e-05,
      "loss": 0.1616,
      "step": 249000
    },
    {
      "epoch": 5.125934347461508,
      "grad_norm": 3.2003138065338135,
      "learning_rate": 1.4629969544818504e-05,
      "loss": 0.1477,
      "step": 249100
    },
    {
      "epoch": 5.127992098237022,
      "grad_norm": 1.5571529865264893,
      "learning_rate": 1.4623796197217877e-05,
      "loss": 0.1485,
      "step": 249200
    },
    {
      "epoch": 5.130049849012537,
      "grad_norm": 0.4827997386455536,
      "learning_rate": 1.4617622849617254e-05,
      "loss": 0.1507,
      "step": 249300
    },
    {
      "epoch": 5.132107599788052,
      "grad_norm": 1.842935562133789,
      "learning_rate": 1.4611449502016627e-05,
      "loss": 0.1613,
      "step": 249400
    },
    {
      "epoch": 5.134165350563567,
      "grad_norm": 0.14549289643764496,
      "learning_rate": 1.4605276154416002e-05,
      "loss": 0.1752,
      "step": 249500
    },
    {
      "epoch": 5.136223101339081,
      "grad_norm": 2.737365484237671,
      "learning_rate": 1.4599164540291382e-05,
      "loss": 0.1618,
      "step": 249600
    },
    {
      "epoch": 5.138280852114596,
      "grad_norm": 3.1263856887817383,
      "learning_rate": 1.4592991192690757e-05,
      "loss": 0.1435,
      "step": 249700
    },
    {
      "epoch": 5.140338602890111,
      "grad_norm": 1.1747924089431763,
      "learning_rate": 1.4586817845090132e-05,
      "loss": 0.1527,
      "step": 249800
    },
    {
      "epoch": 5.142396353665625,
      "grad_norm": 4.592738628387451,
      "learning_rate": 1.4580644497489505e-05,
      "loss": 0.1642,
      "step": 249900
    },
    {
      "epoch": 5.144454104441141,
      "grad_norm": 1.3986613750457764,
      "learning_rate": 1.457447114988888e-05,
      "loss": 0.1411,
      "step": 250000
    },
    {
      "epoch": 5.144454104441141,
      "eval_accuracy": 0.8383401221995926,
      "eval_f1_contradiction": 0.8494749124854143,
      "eval_loss": 0.15742723643779755,
      "eval_runtime": 70.9187,
      "eval_samples_per_second": 55.387,
      "eval_steps_per_second": 6.923,
      "step": 250000
    }
  ],
  "logging_steps": 100,
  "max_steps": 485960,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 10000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3534315489001472e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
